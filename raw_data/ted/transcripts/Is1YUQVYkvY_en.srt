1
0:00:13.52,000 --> 0:00:16,000
I got invited to an exclusive resort

2
0:00:17.44,000 --> 0:00:19,000
to deliver a talk about the digital future

3
0:00:19.92,000 --> 0:00:22,000
to what I assumed would be a couple of hundred tech executives.

4
0:00:23.52,000 --> 0:00:25,000
And I was there in the green room, waiting to go on,

5
0:00:26.24,000 --> 0:00:31,000
and instead of bringing me to the stage, they brought five men into the green room

6
0:00:31.44,000 --> 0:00:33,000
who sat around this little table with me.

7
0:00:33.52,000 --> 0:00:35,000
They were tech billionaires.

8
0:00:35.64,000 --> 0:00:39,000
And they started peppering me with these really binary questions,

9
0:00:40.2,000 --> 0:00:42,000
like: Bitcoin or Etherium?

10
0:00:43.12,000 --> 0:00:45,000
Virtual reality or augmented reality?

11
0:00:45.8,000 --> 0:00:47,000
I don't know if they were taking bets or what.

12
0:00:48.32,000 --> 0:00:5,000
And as they got more comfortable with me,

13
0:00:51.16,000 --> 0:00:54,000
they edged towards their real question of concern.

14
0:00:54.4,000 --> 0:00:56,000
Alaska or New Zealand?

15
0:00:57.76,000 --> 0:00:58,000
That's right.

16
0:00:59,000 --> 0:01:01,000
These tech billionaires were asking a media theorist for advice

17
0:01:02,000 --> 0:01:03,000
on where to put their doomsday bunkers.

18
0:01:04.6,000 --> 0:01:07,000
We spent the rest of the hour on the single question:

19
0:01:07.76,000 --> 0:01:1,000
"How do I maintain control of my security staff

20
0:01:11.4,000 --> 0:01:12,000
after the event?"

21
0:01:13.92,000 --> 0:01:15,000
By "the event" they mean the thermonuclear war

22
0:01:16.68,000 --> 0:01:2,000
or climate catastrophe or social unrest that ends the world as we know it,

23
0:01:21.36,000 --> 0:01:24,000
and more importantly, makes their money obsolete.

24
0:01:26.2,000 --> 0:01:28,000
And I couldn't help but think:

25
0:01:28.44,000 --> 0:01:32,000
these are the wealthiest, most powerful men in the world,

26
0:01:33.2,000 --> 0:01:37,000
yet they see themselves as utterly powerless to influence the future.

27
0:01:37.88,000 --> 0:01:41,000
The best they can do is hang on for the inevitable catastrophe

28
0:01:42.36,000 --> 0:01:45,000
and then use their technology and money to get away from the rest of us.

29
0:01:47.52,000 --> 0:01:49,000
And these are the winners of the digital economy.

30
0:01:50.08,000 --> 0:01:53,000
(Laughter)

31
0:01:53.52,000 --> 0:01:55,000
The digital renaissance

32
0:01:56.32,000 --> 0:02:,000
was about the unbridled potential

33
0:02:00.6,000 --> 0:02:02,000
of the collective human imagination.

34
0:02:03.04,000 --> 0:02:08,000
It spanned everything from chaos math and quantum physics

35
0:02:08.2,000 --> 0:02:12,000
to fantasy role-playing and the Gaia hypothesis, right?

36
0:02:12.4,000 --> 0:02:18,000
We believed that human beings connected could create any future we could imagine.

37
0:02:20.84,000 --> 0:02:22,000
And then came the dot com boom.

38
0:02:24.6,000 --> 0:02:27,000
And the digital future became stock futures.

39
0:02:28.24,000 --> 0:02:31,000
And we used all that energy of the digital age

40
0:02:31.28,000 --> 0:02:35,000
to pump steroids into the already dying NASDAQ stock exchange.

41
0:02:35.56,000 --> 0:02:38,000
The tech magazines told us a tsunami was coming.

42
0:02:39.2,000 --> 0:02:43,000
And only the investors who hired the best scenario-planners and futurists

43
0:02:43.68,000 --> 0:02:45,000
would be able to survive the wave.

44
0:02:47.16,000 --> 0:02:52,000
And so the future changed from this thing we create together in the present

45
0:02:53.08,000 --> 0:02:54,000
to something we bet on

46
0:02:54.6,000 --> 0:02:57,000
in some kind of a zero-sum winner-takes-all competition.

47
0:03:00.12,000 --> 0:03:03,000
And when things get that competitive about the future,

48
0:03:03.28,000 --> 0:03:06,000
humans are no longer valued for our creativity.

49
0:03:06.6,000 --> 0:03:09,000
No, now we're just valued for our data.

50
0:03:09.76,000 --> 0:03:11,000
Because they can use the data to make predictions.

51
0:03:12.16,000 --> 0:03:14,000
Creativity, if anything, that creates noise.

52
0:03:14.76,000 --> 0:03:16,000
That makes it harder to predict.

53
0:03:17,000 --> 0:03:19,000
So we ended up with a digital landscape

54
0:03:19.44,000 --> 0:03:22,000
that really repressed creativity, repressed novelty,

55
0:03:22.72,000 --> 0:03:24,000
it repressed what makes us most human.

56
0:03:26.76,000 --> 0:03:27,000
We ended up with social media.

57
0:03:28.24,000 --> 0:03:31,000
Does social media really connect people in new, interesting ways?

58
0:03:31.72,000 --> 0:03:36,000
No, social media is about using our data to predict our future behavior.

59
0:03:36.76,000 --> 0:03:38,000
Or when necessary, to influence our future behavior

60
0:03:39.68,000 --> 0:03:43,000
so that we act more in accordance with our statistical profiles.

61
0:03:45.2,000 --> 0:03:47,000
The digital economy -- does it like people?

62
0:03:47.44,000 --> 0:03:49,000
No, if you have a business plan, what are you supposed to do?

63
0:03:50.36,000 --> 0:03:51,000
Get rid of all the people.

64
0:03:51.64,000 --> 0:03:54,000
Human beings, they want health care, they want money, they want meaning.

65
0:03:56.36,000 --> 0:03:57,000
You can't scale with people.

66
0:03:59.36,000 --> 0:04:,000
(Laughter)

67
0:04:00.84,000 --> 0:04:01,000
Even our digital apps --

68
0:04:02.08,000 --> 0:04:05,000
they don't help us form any rapport or solidarity.

69
0:04:05.32,000 --> 0:04:07,000
I mean, where's the button on the ride hailing app

70
0:04:07.76,000 --> 0:04:1,000
for the drivers to talk to one another about their working conditions

71
0:04:11.28,000 --> 0:04:12,000
or to unionize?

72
0:04:13.6,000 --> 0:04:15,000
Even our videoconferencing tools,

73
0:04:15.64,000 --> 0:04:17,000
they don't allow us to establish real rapport.

74
0:04:18.04,000 --> 0:04:21,000
However good the resolution of the video,

75
0:04:21.4,000 --> 0:04:25,000
you still can't see if somebody's irises are opening to really take you in.

76
0:04:25.44,000 --> 0:04:27,000
All of the things that we've done to establish rapport

77
0:04:28.04,000 --> 0:04:31,000
that we've developed over hundreds of thousands of years of evolution,

78
0:04:31.399,000 --> 0:04:32,000
they don't work,

79
0:04:32.64,000 --> 0:04:35,000
you can't see if someone's breath is syncing up with yours.

80
0:04:35.68,000 --> 0:04:38,000
So the mirror neurons never fire, the oxytocin never goes through your body,

81
0:04:39.36,000 --> 0:04:42,000
you never have that experience of bonding with the other human being.

82
0:04:43.36,000 --> 0:04:44,000
And instead, you're left like,

83
0:04:44.84,000 --> 0:04:46,000
"Well, they agreed with me, but did they really,

84
0:04:47.12,000 --> 0:04:48,000
did they really get me?"

85
0:04:48.84,000 --> 0:04:51,000
And we don't blame the technology for that lack of fidelity.

86
0:04:52.24,000 --> 0:04:53,000
We blame the other person.

87
0:04:55.32,000 --> 0:04:59,000
You know, even the technologies and the digital initiatives that we have

88
0:04:59.4,000 --> 0:05:01,000
to promote humans,

89
0:05:01.6,000 --> 0:05:03,000
are intensely anti-human at the core.

90
0:05:05.6,000 --> 0:05:07,000
Think about the blockchain.

91
0:05:08.52,000 --> 0:05:11,000
The blockchain is here to help us have a great humanized economy? No.

92
0:05:12.16,000 --> 0:05:14,000
The blockchain does not engender trust between users,

93
0:05:14.88,000 --> 0:05:17,000
the blockchain simply substitutes for trust in a new,

94
0:05:18.44,000 --> 0:05:2,000
even less transparent way.

95
0:05:21.6,000 --> 0:05:22,000
Or the code movement.

96
0:05:23.44,000 --> 0:05:25,000
I mean, education is great, we love education,

97
0:05:25.64,000 --> 0:05:26,000
and it's a wonderful idea

98
0:05:27.12,000 --> 0:05:3,000
that we want kids to be able to get jobs in the digital future,

99
0:05:30.28,000 --> 0:05:31,000
so we'll teach them code now.

100
0:05:32.64,000 --> 0:05:34,000
But since when is education about getting jobs?

101
0:05:35.92,000 --> 0:05:36,000
Education wasn't about getting jobs.

102
0:05:37.68,000 --> 0:05:4,000
Education was compensation for a job well done.

103
0:05:41.68,000 --> 0:05:42,000
The idea of public education

104
0:05:43.28,000 --> 0:05:46,000
was for coal miners, who would work in the coal mines all day,

105
0:05:46.68,000 --> 0:05:48,000
then they'd come home and they should have the dignity

106
0:05:49.28,000 --> 0:05:51,000
to be able to read a novel and understand it.

107
0:05:51.44,000 --> 0:05:53,000
Or the intelligence to be able to participate in democracy.

108
0:05:55.2,000 --> 0:05:58,000
When we make it an extension of the job, what are we really doing?

109
0:05:58.44,000 --> 0:06:,000
We're just letting corporations really

110
0:06:01,000 --> 0:06:04,000
externalize the cost of training their workers.

111
0:06:05.52,000 --> 0:06:09,000
And the worst of all really is the humane technology movement.

112
0:06:09.64,000 --> 0:06:11,000
I mean, I love these guys, the former guys who used to take

113
0:06:12.48,000 --> 0:06:14,000
the algorithms from Las Vegas slot machines

114
0:06:15.44,000 --> 0:06:17,000
and put them in our social media feed so that we get addicted.

115
0:06:18.4,000 --> 0:06:19,000
Now they've seen the error of their ways

116
0:06:20.36,000 --> 0:06:22,000
and they want to make technology more humane.

117
0:06:22.84,000 --> 0:06:24,000
But when I hear the expression "humane technology,"

118
0:06:25.28,000 --> 0:06:27,000
I think about cage-free chickens or something.

119
0:06:28.16,000 --> 0:06:3,000
We're going to be as humane as possible to them,

120
0:06:30.44,000 --> 0:06:31,000
until we take them to the slaughter.

121
0:06:33.2,000 --> 0:06:36,000
So now they're going to let these technologies be as humane as possible,

122
0:06:36.64,000 --> 0:06:39,000
as long as they extract enough data and extract enough money from us

123
0:06:39.88,000 --> 0:06:4,000
to please their shareholders.

124
0:06:42.52,000 --> 0:06:45,000
Meanwhile, the shareholders, for their part, they're just thinking,

125
0:06:45.72,000 --> 0:06:47,000
"I need to earn enough money now, so I can insulate myself

126
0:06:48.72,000 --> 0:06:51,000
from the world I'm creating by earning money in this way."

127
0:06:51.8,000 --> 0:06:53,000
(Laughter)

128
0:06:54.2,000 --> 0:06:58,000
No matter how many VR goggles they slap on their faces

129
0:06:58.28,000 --> 0:07:,000
and whatever fantasy world they go into,

130
0:07:00.56,000 --> 0:07:03,000
they can't externalize the slavery and pollution that was caused

131
0:07:04.12,000 --> 0:07:06,000
through the manufacture of the very device.

132
0:07:07.12,000 --> 0:07:1,000
It reminds me of Thomas Jefferson's dumbwaiter.

133
0:07:10.32,000 --> 0:07:12,000
Now, we like to think that he made the dumbwaiter

134
0:07:12.68,000 --> 0:07:15,000
in order to spare his slaves all that labor of carrying the food

135
0:07:16.36,000 --> 0:07:18,000
up to the dining room for the people to eat.

136
0:07:19.16,000 --> 0:07:21,000
That's not what it was for, it wasn't for the slaves,

137
0:07:21.68,000 --> 0:07:23,000
it was for Thomas Jefferson and his dinner guests,

138
0:07:24.04,000 --> 0:07:27,000
so they didn't have to see the slave bringing the food up.

139
0:07:27.16,000 --> 0:07:28,000
The food just arrived magically,

140
0:07:28.76,000 --> 0:07:31,000
like it was coming out of a "Start Trek" replicator.

141
0:07:32.72,000 --> 0:07:34,000
It's part of an ethos that says,

142
0:07:34.84,000 --> 0:07:38,000
human beings are the problem and technology is the solution.

143
0:07:40.68,000 --> 0:07:42,000
We can't think that way anymore.

144
0:07:42.76,000 --> 0:07:47,000
We have to stop using technology to optimize human beings for the market

145
0:07:48.08,000 --> 0:07:53,000
and start optimizing technology for the human future.

146
0:07:55.08,000 --> 0:07:57,000
But that's a really hard argument to make these days,

147
0:07:57.76,000 --> 0:08:01,000
because humans are not popular beings.

148
0:08:01.84,000 --> 0:08:04,000
I talked about this in front of an environmentalist just the other day,

149
0:08:05.24,000 --> 0:08:07,000
and she said, "Why are you defending humans?

150
0:08:07.36,000 --> 0:08:09,000
Humans destroyed the planet. They deserve to go extinct."

151
0:08:10.08,000 --> 0:08:13,000
(Laughter)

152
0:08:13.56,000 --> 0:08:15,000
Even our popular media hates humans.

153
0:08:16.16,000 --> 0:08:17,000
Watch television,

154
0:08:17.44,000 --> 0:08:2,000
all the sci-fi shows are about how robots are better and nicer than people.

155
0:08:21.2,000 --> 0:08:23,000
Even zombie shows -- what is every zombie show about?

156
0:08:24.2,000 --> 0:08:27,000
Some person, looking at the horizon at some zombie going by,

157
0:08:27.48,000 --> 0:08:29,000
and they zoom in on the person and you see the person's face,

158
0:08:30.4,000 --> 0:08:31,000
and you know what they're thinking:

159
0:08:32.16,000 --> 0:08:34,000
"What's really the difference between that zombie and me?

160
0:08:34.92,000 --> 0:08:35,000
He walks, I walk.

161
0:08:36.48,000 --> 0:08:38,000
He eats, I eat.

162
0:08:38.52,000 --> 0:08:4,000
He kills, I kill."

163
0:08:42.36,000 --> 0:08:43,000
But he's a zombie.

164
0:08:43.92,000 --> 0:08:44,000
At least you're aware of it.

165
0:08:45.36,000 --> 0:08:48,000
If we are actually having trouble distinguishing ourselves from zombies,

166
0:08:49.08,000 --> 0:08:51,000
we have a pretty big problem going on.

167
0:08:51.28,000 --> 0:08:52,000
(Laughter)

168
0:08:52.52,000 --> 0:08:54,000
And don't even get me started on the transhumanists.

169
0:08:55.48,000 --> 0:08:58,000
I was on a panel with a transhumanist, and he's going on about the singularity.

170
0:08:59.32,000 --> 0:09:02,000
"Oh, the day is going to come really soon when computers are smarter than people.

171
0:09:03.2,000 --> 0:09:05,000
And the only option for people at that point

172
0:09:05.36,000 --> 0:09:08,000
is to pass the evolutionary torch to our successor

173
0:09:08.72,000 --> 0:09:09,000
and fade into the background.

174
0:09:10.36,000 --> 0:09:13,000
Maybe at best, upload your consciousness to a silicon chip.

175
0:09:13.84,000 --> 0:09:14,000
And accept your extinction."

176
0:09:16.64,000 --> 0:09:17,000
(Laughter)

177
0:09:18.12,000 --> 0:09:21,000
And I said, "No, human beings are special.

178
0:09:21.52,000 --> 0:09:24,000
We can embrace ambiguity, we understand paradox,

179
0:09:25.08,000 --> 0:09:27,000
we're conscious, we're weird, we're quirky.

180
0:09:27.72,000 --> 0:09:3,000
There should be a place for humans in the digital future."

181
0:09:31.08,000 --> 0:09:32,000
And he said, "Oh, Rushkoff,

182
0:09:32.64,000 --> 0:09:34,000
you're just saying that because you're a human."

183
0:09:34.96,000 --> 0:09:35,000
(Laughter)

184
0:09:36.76,000 --> 0:09:37,000
As if it's hubris.

185
0:09:39.28,000 --> 0:09:41,000
OK, I'm on "Team Human."

186
0:09:43.2,000 --> 0:09:46,000
That was the original insight of the digital age.

187
0:09:47.08,000 --> 0:09:49,000
That being human is a team sport,

188
0:09:49.32,000 --> 0:09:51,000
evolution's a collaborative act.

189
0:09:52.08,000 --> 0:09:53,000
Even the trees in the forest,

190
0:09:53.52,000 --> 0:09:55,000
they're not all in competition with each other,

191
0:09:55.76,000 --> 0:09:58,000
they're connected with the vast network of roots and mushrooms

192
0:09:59,000 --> 0:10:03,000
that let them communicate with one another and pass nutrients back and forth.

193
0:10:03.56,000 --> 0:10:05,000
If human beings are the most evolved species,

194
0:10:05.72,000 --> 0:10:09,000
it's because we have the most evolved ways of collaborating and communicating.

195
0:10:09.88,000 --> 0:10:1,000
We have language.

196
0:10:11.4,000 --> 0:10:12,000
We have technology.

197
0:10:14.12,000 --> 0:10:18,000
It's funny, I used to be the guy who talked about the digital future

198
0:10:18.72,000 --> 0:10:2,000
for people who hadn't yet experienced anything digital.

199
0:10:22.2,000 --> 0:10:23,000
And now I feel like I'm the last guy

200
0:10:24.04,000 --> 0:10:26,000
who remembers what life was like before digital technology.

201
0:10:28.68,000 --> 0:10:32,000
It's not a matter of rejecting the digital or rejecting the technological.

202
0:10:32.92,000 --> 0:10:36,000
It's a matter of retrieving the values that we're in danger of leaving behind

203
0:10:37.04,000 --> 0:10:4,000
and then embedding them in the digital infrastructure for the future.

204
0:10:41.88,000 --> 0:10:43,000
And that's not rocket science.

205
0:10:44.2,000 --> 0:10:46,000
It's as simple as making a social network

206
0:10:46.32,000 --> 0:10:49,000
that instead of teaching us to see people as adversaries,

207
0:10:49.88,000 --> 0:10:52,000
it teaches us to see our adversaries as people.

208
0:10:54.24,000 --> 0:10:58,000
It means creating an economy that doesn't favor a platform monopoly

209
0:10:58.56,000 --> 0:11:01,000
that wants to extract all the value out of people and places,

210
0:11:01.92,000 --> 0:11:04,000
but one that promotes the circulation of value through a community

211
0:11:05.88,000 --> 0:11:07,000
and allows us to establish platform cooperatives

212
0:11:08.32,000 --> 0:11:11,000
that distribute ownership as wide as possible.

213
0:11:12.16,000 --> 0:11:13,000
It means building platforms

214
0:11:13.84,000 --> 0:11:17,000
that don't repress our creativity and novelty in the name of prediction

215
0:11:18.52,000 --> 0:11:2,000
but actually promote creativity and novelty,

216
0:11:21.12,000 --> 0:11:23,000
so that we can come up with some of the solutions

217
0:11:23.48,000 --> 0:11:25,000
to actually get ourselves out of the mess that we're in.

218
0:11:27.44,000 --> 0:11:3,000
No, instead of trying to earn enough money to insulate ourselves

219
0:11:30.52,000 --> 0:11:31,000
from the world we're creating,

220
0:11:32.04,000 --> 0:11:35,000
why don't we spend that time and energy making the world a place

221
0:11:35.12,000 --> 0:11:37,000
that we don't feel the need to escape from.

222
0:11:38,000 --> 0:11:41,000
There is no escape, there is only one thing going on here.

223
0:11:42.68,000 --> 0:11:44,000
Please, don't leave.

224
0:11:45.64,000 --> 0:11:46,000
Join us.

225
0:11:47.8,000 --> 0:11:48,000
We may not be perfect,

226
0:11:49.12,000 --> 0:11:51,000
but whatever happens, at least you won't be alone.

227
0:11:52.64,000 --> 0:11:53,000
Join "Team Human."

228
0:11:55.16,000 --> 0:11:57,000
Find the others.

229
0:11:57.28,000 --> 0:11:59,000
Together, let's make the future that we always wanted.

230
0:12:01.56,000 --> 0:12:03,000
Oh, and those tech billionaires who wanted to know

231
0:12:04.08,000 --> 0:12:07,000
how to maintain control of their security force after the apocalypse,

232
0:12:07.36,000 --> 0:12:08,000
you know what I told them?

233
0:12:09.28,000 --> 0:12:13,000
"Start treating those people with love and respect right now.

234
0:12:13.52,000 --> 0:12:15,000
Maybe you won't have an apocalypse to worry about."

235
0:12:16.84,000 --> 0:12:17,000
Thank you.

236
0:12:18.08,000 --> 0:12:22,000
(Applause)

