1
0:00:,000 --> 0:00:07,000
Translator: Joseph Geni Reviewer: Morton Bast

2
0:00:12.328,000 --> 0:00:14,000
The writer George Eliot cautioned us that,

3
0:00:15.277,000 --> 0:00:17,000
among all forms of mistake,

4
0:00:17.344,000 --> 0:00:19,000
prophesy is the most gratuitous.

5
0:00:19.707,000 --> 0:00:2,000
The person that we would all acknowledge

6
0:00:21.555,000 --> 0:00:25,000
as her 20th-century counterpart, Yogi Berra, agreed.

7
0:00:25.857,000 --> 0:00:26,000
He said, "It's tough to make predictions,

8
0:00:27.722,000 --> 0:00:29,000
especially about the future."

9
0:00:30.458,000 --> 0:00:31,000
I'm going to ignore their cautions

10
0:00:32.269,000 --> 0:00:33,000
and make one very specific forecast.

11
0:00:34.242,000 --> 0:00:36,000
In the world that we are creating very quickly,

12
0:00:36.882,000 --> 0:00:37,000
we're going to see more and more things

13
0:00:38.595,000 --> 0:00:39,000
that look like science fiction,

14
0:00:40.32,000 --> 0:00:43,000
and fewer and fewer things that look like jobs.

15
0:00:43.436,000 --> 0:00:45,000
Our cars are very quickly going to start driving themselves,

16
0:00:46.188,000 --> 0:00:48,000
which means we're going to need fewer truck drivers.

17
0:00:48.884,000 --> 0:00:5,000
We're going to hook Siri up to Watson

18
0:00:51.005,000 --> 0:00:53,000
and use that to automate a lot of the work

19
0:00:53.602,000 --> 0:00:55,000
that's currently done by customer service reps

20
0:00:55.828,000 --> 0:00:57,000
and troubleshooters and diagnosers,

21
0:00:58.732,000 --> 0:01:,000
and we're already taking R2D2,

22
0:01:00.988,000 --> 0:01:03,000
painting him orange, and putting him to work

23
0:01:04.228,000 --> 0:01:06,000
carrying shelves around warehouses,

24
0:01:06.777,000 --> 0:01:08,000
which means we need a lot fewer people

25
0:01:08.852,000 --> 0:01:09,000
to be walking up and down those aisles.

26
0:01:10.818,000 --> 0:01:13,000
Now, for about 200 years,

27
0:01:14.62,000 --> 0:01:16,000
people have been saying exactly what I'm telling you --

28
0:01:16.803,000 --> 0:01:18,000
the age of technological unemployment is at hand —

29
0:01:19.62,000 --> 0:01:21,000
starting with the Luddites smashing looms in Britain

30
0:01:22.035,000 --> 0:01:23,000
just about two centuries ago,

31
0:01:23.931,000 --> 0:01:25,000
and they have been wrong.

32
0:01:25.963,000 --> 0:01:27,000
Our economies in the developed world have coasted along

33
0:01:28.78,000 --> 0:01:29,000
on something pretty close to full employment.

34
0:01:30.714,000 --> 0:01:32,000
Which brings up a critical question:

35
0:01:32.813,000 --> 0:01:34,000
Why is this time different, if it really is?

36
0:01:35.739,000 --> 0:01:37,000
The reason it's different is that, just in the past few years,

37
0:01:38.735,000 --> 0:01:39,000
our machines have started demonstrating skills

38
0:01:40.63,000 --> 0:01:42,000
they have never, ever had before:

39
0:01:43.255,000 --> 0:01:46,000
understanding, speaking, hearing, seeing,

40
0:01:46.515,000 --> 0:01:5,000
answering, writing, and they're still acquiring new skills.

41
0:01:50.728,000 --> 0:01:52,000
For example, mobile humanoid robots

42
0:01:53.298,000 --> 0:01:54,000
are still incredibly primitive,

43
0:01:55.245,000 --> 0:01:56,000
but the research arm of the Defense Department

44
0:01:57.083,000 --> 0:01:58,000
just launched a competition

45
0:01:58.598,000 --> 0:02:,000
to have them do things like this,

46
0:02:00.912,000 --> 0:02:01,000
and if the track record is any guide,

47
0:02:02.645,000 --> 0:02:04,000
this competition is going to be successful.

48
0:02:05.044,000 --> 0:02:08,000
So when I look around, I think the day is not too far off at all

49
0:02:08.68,000 --> 0:02:1,000
when we're going to have androids

50
0:02:10.856,000 --> 0:02:12,000
doing a lot of the work that we are doing right now.

51
0:02:13.737,000 --> 0:02:16,000
And we're creating a world where there is going to be

52
0:02:17.495,000 --> 0:02:2,000
more and more technology and fewer and fewer jobs.

53
0:02:21.18,000 --> 0:02:23,000
It's a world that Erik Brynjolfsson and I are calling

54
0:02:23.429,000 --> 0:02:24,000
"the new machine age."

55
0:02:24.92,000 --> 0:02:26,000
The thing to keep in mind is that

56
0:02:27.053,000 --> 0:02:29,000
this is absolutely great news.

57
0:02:29.602,000 --> 0:02:32,000
This is the best economic news on the planet these days.

58
0:02:32.919,000 --> 0:02:35,000
Not that there's a lot of competition, right?

59
0:02:36.448,000 --> 0:02:37,000
This is the best economic news we have these days

60
0:02:38.347,000 --> 0:02:39,000
for two main reasons.

61
0:02:39.963,000 --> 0:02:41,000
The first is, technological progress is what allows us

62
0:02:42.948,000 --> 0:02:45,000
to continue this amazing recent run that we're on

63
0:02:46.685,000 --> 0:02:48,000
where output goes up over time,

64
0:02:49.206,000 --> 0:02:52,000
while at the same time, prices go down,

65
0:02:52.532,000 --> 0:02:56,000
and volume and quality just continue to explode.

66
0:02:56.736,000 --> 0:02:58,000
Now, some people look at this and talk about

67
0:02:58.737,000 --> 0:02:59,000
shallow materialism,

68
0:03:00.143,000 --> 0:03:02,000
but that's absolutely the wrong way to look at it.

69
0:03:02.561,000 --> 0:03:04,000
This is abundance, which is exactly

70
0:03:05.056,000 --> 0:03:08,000
what we want our economic system to provide.

71
0:03:08.478,000 --> 0:03:11,000
The second reason that the new machine age

72
0:03:11.694,000 --> 0:03:13,000
is such great news is that, once the androids

73
0:03:14,000 --> 0:03:17,000
start doing jobs, we don't have to do them anymore,

74
0:03:17.252,000 --> 0:03:2,000
and we get freed up from drudgery and toil.

75
0:03:21.008,000 --> 0:03:23,000
Now, when I talk about this with my friends

76
0:03:23.032,000 --> 0:03:25,000
in Cambridge and Silicon Valley, they say,

77
0:03:25.584,000 --> 0:03:27,000
"Fantastic. No more drudgery, no more toil.

78
0:03:27.857,000 --> 0:03:29,000
This gives us the chance to imagine

79
0:03:29.908,000 --> 0:03:31,000
an entirely different kind of society,

80
0:03:32.201,000 --> 0:03:34,000
a society where the creators and the discoverers

81
0:03:35.113,000 --> 0:03:36,000
and the performers and the innovators

82
0:03:36.942,000 --> 0:03:39,000
come together with their patrons and their financiers

83
0:03:40.451,000 --> 0:03:42,000
to talk about issues, entertain, enlighten,

84
0:03:43.13,000 --> 0:03:45,000
provoke each other."

85
0:03:45.208,000 --> 0:03:49,000
It's a society really, that looks a lot like the TED Conference.

86
0:03:49.783,000 --> 0:03:51,000
And there's actually a huge amount of truth here.

87
0:03:52.266,000 --> 0:03:55,000
We are seeing an amazing flourishing taking place.

88
0:03:55.289,000 --> 0:03:57,000
In a world where it is just about as easy

89
0:03:57.291,000 --> 0:04:,000
to generate an object as it is to print a document,

90
0:04:00.698,000 --> 0:04:02,000
we have amazing new possibilities.

91
0:04:02.787,000 --> 0:04:05,000
The people who used to be craftsmen and hobbyists

92
0:04:06.464,000 --> 0:04:07,000
are now makers, and they're responsible

93
0:04:08.331,000 --> 0:04:1,000
for massive amounts of innovation.

94
0:04:10.721,000 --> 0:04:12,000
And artists who were formerly constrained

95
0:04:13.003,000 --> 0:04:16,000
can now do things that were never, ever possible

96
0:04:16.171,000 --> 0:04:17,000
for them before.

97
0:04:18.067,000 --> 0:04:2,000
So this is a time of great flourishing,

98
0:04:20.184,000 --> 0:04:22,000
and the more I look around, the more convinced I become

99
0:04:23.116,000 --> 0:04:26,000
that this quote, from the physicist Freeman Dyson,

100
0:04:26.19,000 --> 0:04:28,000
is not hyperbole at all.

101
0:04:28.223,000 --> 0:04:3,000
This is just a plain statement of the facts.

102
0:04:31.013,000 --> 0:04:32,000
We are in the middle of an astonishing period.

103
0:04:32.858,000 --> 0:04:32,000
["Technology is a gift of God. After the gift of life it is perhaps the greatest of God's gifts. It is the mother of civilizations, of arts and of sciences." — Freeman Dyson]

104
0:04:33.742,000 --> 0:04:35,000
Which brings up another great question:

105
0:04:36.533,000 --> 0:04:38,000
What could possibly go wrong in this new machine age?

106
0:04:39.509,000 --> 0:04:42,000
Right? Great, hang up, flourish, go home.

107
0:04:42.871,000 --> 0:04:44,000
We're going to face two really thorny sets of challenges

108
0:04:45.537,000 --> 0:04:47,000
as we head deeper into the future that we're creating.

109
0:04:48.33,000 --> 0:04:51,000
The first are economic, and they're really nicely summarized

110
0:04:51.58,000 --> 0:04:54,000
in an apocryphal story about a back-and-forth

111
0:04:54.67,000 --> 0:04:57,000
between Henry Ford II and Walter Reuther,

112
0:04:57.712,000 --> 0:04:59,000
who was the head of the auto workers union.

113
0:05:00.457,000 --> 0:05:02,000
They were touring one of the new modern factories,

114
0:05:02.64,000 --> 0:05:04,000
and Ford playfully turns to Reuther and says,

115
0:05:05.39,000 --> 0:05:07,000
"Hey Walter, how are you going to get these robots

116
0:05:07.552,000 --> 0:05:08,000
to pay union dues?"

117
0:05:09.366,000 --> 0:05:1,000
And Reuther shoots back, "Hey Henry,

118
0:05:11.311,000 --> 0:05:15,000
how are you going to get them to buy cars?"

119
0:05:15.853,000 --> 0:05:18,000
Reuther's problem in that anecdote

120
0:05:18.864,000 --> 0:05:22,000
is that it is tough to offer your labor to an economy

121
0:05:22.973,000 --> 0:05:23,000
that's full of machines,

122
0:05:24.608,000 --> 0:05:26,000
and we see this very clearly in the statistics.

123
0:05:26.832,000 --> 0:05:28,000
If you look over the past couple decades

124
0:05:29.224,000 --> 0:05:32,000
at the returns to capital -- in other words, corporate profits --

125
0:05:32.888,000 --> 0:05:33,000
we see them going up,

126
0:05:34.572,000 --> 0:05:36,000
and we see that they're now at an all-time high.

127
0:05:36.659,000 --> 0:05:38,000
If we look at the returns to labor, in other words

128
0:05:39.36,000 --> 0:05:4,000
total wages paid out in the economy,

129
0:05:41.244,000 --> 0:05:43,000
we see them at an all-time low

130
0:05:43.791,000 --> 0:05:46,000
and heading very quickly in the opposite direction.

131
0:05:46.856,000 --> 0:05:47,000
So this is clearly bad news for Reuther.

132
0:05:48.626,000 --> 0:05:51,000
It looks like it might be great news for Ford,

133
0:05:52.024,000 --> 0:05:54,000
but it's actually not. If you want to sell

134
0:05:54.328,000 --> 0:05:57,000
huge volumes of somewhat expensive goods to people,

135
0:05:57.672,000 --> 0:06:,000
you really want a large, stable, prosperous middle class.

136
0:06:01.46,000 --> 0:06:03,000
We have had one of those in America

137
0:06:03.684,000 --> 0:06:05,000
for just about the entire postwar period.

138
0:06:06.317,000 --> 0:06:1,000
But the middle class is clearly under huge threat right now.

139
0:06:10.669,000 --> 0:06:11,000
We all know a lot of the statistics,

140
0:06:12.08,000 --> 0:06:14,000
but just to repeat one of them,

141
0:06:14.439,000 --> 0:06:16,000
median income in America has actually gone down

142
0:06:17.206,000 --> 0:06:18,000
over the past 15 years,

143
0:06:18.897,000 --> 0:06:19,000
and we're in danger of getting trapped

144
0:06:20.612,000 --> 0:06:23,000
in some vicious cycle where inequality and polarization

145
0:06:24.537,000 --> 0:06:27,000
continue to go up over time.

146
0:06:27.717,000 --> 0:06:29,000
The societal challenges that come along

147
0:06:30.116,000 --> 0:06:32,000
with that kind of inequality deserve some attention.

148
0:06:32.692,000 --> 0:06:33,000
There are a set of societal challenges

149
0:06:34.36,000 --> 0:06:35,000
that I'm actually not that worried about,

150
0:06:36.304,000 --> 0:06:38,000
and they're captured by images like this.

151
0:06:38.655,000 --> 0:06:39,000
This is not the kind of societal problem

152
0:06:40.477,000 --> 0:06:42,000
that I am concerned about.

153
0:06:42.941,000 --> 0:06:44,000
There is no shortage of dystopian visions

154
0:06:45.084,000 --> 0:06:48,000
about what happens when our machines become self-aware,

155
0:06:48.567,000 --> 0:06:51,000
and they decide to rise up and coordinate attacks against us.

156
0:06:51.743,000 --> 0:06:52,000
I'm going to start worrying about those

157
0:06:53.49,000 --> 0:06:56,000
the day my computer becomes aware of my printer.

158
0:06:56.719,000 --> 0:06:59,000
(Laughter) (Applause)

159
0:07:00.348,000 --> 0:07:02,000
So this is not the set of challenges we really need to worry about.

160
0:07:03.32,000 --> 0:07:05,000
To tell you the kinds of societal challenges

161
0:07:06.108,000 --> 0:07:08,000
that are going to come up in the new machine age,

162
0:07:08.32,000 --> 0:07:11,000
I want to tell a story about two stereotypical American workers.

163
0:07:12.031,000 --> 0:07:13,000
And to make them really stereotypical,

164
0:07:13.799,000 --> 0:07:15,000
let's make them both white guys.

165
0:07:15.946,000 --> 0:07:18,000
And the first one is a college-educated

166
0:07:19.708,000 --> 0:07:22,000
professional, creative type, manager,

167
0:07:22.854,000 --> 0:07:24,000
engineer, doctor, lawyer, that kind of worker.

168
0:07:25.605,000 --> 0:07:27,000
We're going to call him "Ted."

169
0:07:28.024,000 --> 0:07:3,000
He's at the top of the American middle class.

170
0:07:30.297,000 --> 0:07:32,000
His counterpart is not college-educated

171
0:07:33.179,000 --> 0:07:36,000
and works as a laborer, works as a clerk,

172
0:07:36.243,000 --> 0:07:39,000
does low-level white collar or blue collar work in the economy.

173
0:07:39.555,000 --> 0:07:41,000
We're going to call that guy "Bill."

174
0:07:41.96,000 --> 0:07:43,000
And if you go back about 50 years,

175
0:07:44.039,000 --> 0:07:47,000
Bill and Ted were leading remarkably similar lives.

176
0:07:47.856,000 --> 0:07:49,000
For example, in 1960 they were both very likely

177
0:07:50.359,000 --> 0:07:53,000
to have full-time jobs, working at least 40 hours a week.

178
0:07:53.729,000 --> 0:07:56,000
But as the social researcher Charles Murray has documented,

179
0:07:57.025,000 --> 0:07:59,000
as we started to automate the economy,

180
0:07:59.993,000 --> 0:08:03,000
and 1960 is just about when computers started to be used by businesses,

181
0:08:04.14,000 --> 0:08:06,000
as we started to progressively inject technology

182
0:08:07.011,000 --> 0:08:09,000
and automation and digital stuff into the economy,

183
0:08:09.747,000 --> 0:08:12,000
the fortunes of Bill and Ted diverged a lot.

184
0:08:12.772,000 --> 0:08:14,000
Over this time frame, Ted has continued

185
0:08:14.891,000 --> 0:08:16,000
to hold a full-time job. Bill hasn't.

186
0:08:17.643,000 --> 0:08:21,000
In many cases, Bill has left the economy entirely,

187
0:08:21.914,000 --> 0:08:23,000
and Ted very rarely has.

188
0:08:24.178,000 --> 0:08:27,000
Over time, Ted's marriage has stayed quite happy.

189
0:08:27.443,000 --> 0:08:28,000
Bill's hasn't.

190
0:08:29.084,000 --> 0:08:32,000
And Ted's kids have grown up in a two-parent home,

191
0:08:32.406,000 --> 0:08:35,000
while Bill's absolutely have not over time.

192
0:08:35.626,000 --> 0:08:37,000
Other ways that Bill is dropping out of society?

193
0:08:38.03,000 --> 0:08:41,000
He's decreased his voting in presidential elections,

194
0:08:41.719,000 --> 0:08:44,000
and he's started to go to prison a lot more often.

195
0:08:45.712,000 --> 0:08:48,000
So I cannot tell a happy story about these social trends,

196
0:08:49.696,000 --> 0:08:51,000
and they don't show any signs of reversing themselves.

197
0:08:52.443,000 --> 0:08:54,000
They're also true no matter which ethnic group

198
0:08:55.416,000 --> 0:08:56,000
or demographic group we look at,

199
0:08:57.137,000 --> 0:08:59,000
and they're actually getting so severe

200
0:08:59.213,000 --> 0:09:,000
that they're in danger of overwhelming

201
0:09:00.984,000 --> 0:09:03,000
even the amazing progress we made with the Civil Rights Movement.

202
0:09:04.632,000 --> 0:09:06,000
And what my friends in Silicon Valley

203
0:09:07.144,000 --> 0:09:12,000
and Cambridge are overlooking is that they're Ted.

204
0:09:12.395,000 --> 0:09:15,000
They're living these amazingly busy, productive lives,

205
0:09:15.832,000 --> 0:09:17,000
and they've got all the benefits to show from that,

206
0:09:18.222,000 --> 0:09:2,000
while Bill is leading a very different life.

207
0:09:20.657,000 --> 0:09:22,000
They're actually both proof of how right Voltaire was

208
0:09:22.797,000 --> 0:09:24,000
when he talked about the benefits of work,

209
0:09:25.049,000 --> 0:09:28,000
and the fact that it saves us from not one but three great evils.

210
0:09:28.63,000 --> 0:09:28,000
["Work saves a man from three great evils: boredom, vice and need." — Voltaire]

211
0:09:29.627,000 --> 0:09:32,000
So with these challenges, what do we do about them?

212
0:09:32.963,000 --> 0:09:34,000
The economic playbook is surprisingly clear,

213
0:09:35.546,000 --> 0:09:38,000
surprisingly straightforward, in the short term especially.

214
0:09:38.686,000 --> 0:09:4,000
The robots are not going to take all of our jobs in the next year or two,

215
0:09:41.578,000 --> 0:09:45,000
so the classic Econ 101 playbook is going to work just fine:

216
0:09:46.046,000 --> 0:09:48,000
Encourage entrepreneurship,

217
0:09:48.198,000 --> 0:09:5,000
double down on infrastructure,

218
0:09:50.394,000 --> 0:09:51,000
and make sure we're turning out people

219
0:09:52.093,000 --> 0:09:55,000
from our educational system with the appropriate skills.

220
0:09:55.69,000 --> 0:09:58,000
But over the longer term, if we are moving into an economy

221
0:09:58.967,000 --> 0:10:,000
that's heavy on technology and light on labor,

222
0:10:01.619,000 --> 0:10:03,000
and we are, then we have to consider

223
0:10:04.047,000 --> 0:10:05,000
some more radical interventions,

224
0:10:05.831,000 --> 0:10:08,000
for example, something like a guaranteed minimum income.

225
0:10:09.03,000 --> 0:10:12,000
Now, that's probably making some folk in this room uncomfortable,

226
0:10:12.742,000 --> 0:10:15,000
because that idea is associated with the extreme left wing

227
0:10:16.599,000 --> 0:10:19,000
and with fairly radical schemes for redistributing wealth.

228
0:10:19.818,000 --> 0:10:2,000
I did a little bit of research on this notion,

229
0:10:21.771,000 --> 0:10:23,000
and it might calm some folk down to know that

230
0:10:24.226,000 --> 0:10:26,000
the idea of a net guaranteed minimum income

231
0:10:26.858,000 --> 0:10:29,000
has been championed by those frothing-at-the-mouth socialists

232
0:10:30.035,000 --> 0:10:35,000
Friedrich Hayek, Richard Nixon and Milton Friedman.

233
0:10:35.508,000 --> 0:10:36,000
And if you find yourself worried

234
0:10:37.387,000 --> 0:10:4,000
that something like a guaranteed income

235
0:10:40.696,000 --> 0:10:42,000
is going to stifle our drive to succeed

236
0:10:42.971,000 --> 0:10:43,000
and make us kind of complacent,

237
0:10:44.735,000 --> 0:10:46,000
you might be interested to know that social mobility,

238
0:10:47.525,000 --> 0:10:49,000
one of the things we really pride ourselves on in the United States,

239
0:10:50.2,000 --> 0:10:53,000
is now lower than it is in the northern European countries

240
0:10:53.54,000 --> 0:10:56,000
that have these very generous social safety nets.

241
0:10:56.739,000 --> 0:10:58,000
So the economic playbook is actually pretty straightforward.

242
0:10:59.531,000 --> 0:11:02,000
The societal one is a lot more challenging.

243
0:11:02.587,000 --> 0:11:04,000
I don't know what the playbook is

244
0:11:04.735,000 --> 0:11:07,000
for getting Bill to engage and stay engaged throughout life.

245
0:11:08.563,000 --> 0:11:1,000
I do know that education is a huge part of it.

246
0:11:11.067,000 --> 0:11:12,000
I witnessed this firsthand.

247
0:11:12.847,000 --> 0:11:15,000
I was a Montessori kid for the first few years of my education,

248
0:11:16.603,000 --> 0:11:17,000
and what that education taught me

249
0:11:18.132,000 --> 0:11:2,000
is that the world is an interesting place

250
0:11:20.223,000 --> 0:11:22,000
and my job is to go explore it.

251
0:11:22.864,000 --> 0:11:23,000
The school stopped in third grade,

252
0:11:24.565,000 --> 0:11:26,000
so then I entered the public school system,

253
0:11:26.633,000 --> 0:11:3,000
and it felt like I had been sent to the Gulag.

254
0:11:30.999,000 --> 0:11:32,000
With the benefit of hindsight, I now know the job

255
0:11:33.9,000 --> 0:11:35,000
was to prepare me for life as a clerk or a laborer,

256
0:11:36.414,000 --> 0:11:38,000
but at the time it felt like the job was to kind of

257
0:11:38.744,000 --> 0:11:41,000
bore me into some submission with what was going on around me.

258
0:11:42.568,000 --> 0:11:43,000
We have to do better than this.

259
0:11:43.916,000 --> 0:11:46,000
We cannot keep turning out Bills.

260
0:11:47.592,000 --> 0:11:49,000
So we see some green shoots that things are getting better.

261
0:11:49.936,000 --> 0:11:51,000
We see technology deeply impacting education

262
0:11:52.76,000 --> 0:11:54,000
and engaging people, from our youngest learners

263
0:11:55.288,000 --> 0:11:56,000
up to our oldest ones.

264
0:11:57.052,000 --> 0:11:59,000
We see very prominent business voices telling us

265
0:11:59.672,000 --> 0:12:02,000
we need to rethink some of the things that we've been holding dear for a while.

266
0:12:02.888,000 --> 0:12:04,000
And we see very serious and sustained

267
0:12:05.148,000 --> 0:12:07,000
and data-driven efforts to understand

268
0:12:07.952,000 --> 0:12:1,000
how to intervene in some of the most troubled communities that we have.

269
0:12:11.495,000 --> 0:12:13,000
So the green shoots are out there.

270
0:12:13.704,000 --> 0:12:14,000
I don't want to pretend for a minute

271
0:12:15.138,000 --> 0:12:16,000
that what we have is going to be enough.

272
0:12:17.08,000 --> 0:12:19,000
We're facing very tough challenges.

273
0:12:19.222,000 --> 0:12:22,000
To give just one example, there are about five million Americans

274
0:12:22.328,000 --> 0:12:24,000
who have been unemployed for at least six months.

275
0:12:25.142,000 --> 0:12:26,000
We're not going to fix things for them

276
0:12:26.484,000 --> 0:12:28,000
by sending them back to Montessori.

277
0:12:28.927,000 --> 0:12:3,000
And my biggest worry is that we're creating a world

278
0:12:31.282,000 --> 0:12:33,000
where we're going to have glittering technologies

279
0:12:33.831,000 --> 0:12:35,000
embedded in kind of a shabby society

280
0:12:36.136,000 --> 0:12:38,000
and supported by an economy that generates inequality

281
0:12:39.103,000 --> 0:12:4,000
instead of opportunity.

282
0:12:40.584,000 --> 0:12:42,000
But I actually don't think that's what we're going to do.

283
0:12:43.336,000 --> 0:12:44,000
I think we're going to do something a lot better

284
0:12:44.965,000 --> 0:12:46,000
for one very straightforward reason:

285
0:12:47.075,000 --> 0:12:48,000
The facts are getting out there.

286
0:12:49.043,000 --> 0:12:51,000
The realities of this new machine age

287
0:12:51.085,000 --> 0:12:54,000
and the change in the economy are becoming more widely known.

288
0:12:54.4,000 --> 0:12:56,000
If we wanted to accelerate that process, we could do things

289
0:12:57.251,000 --> 0:12:59,000
like have our best economists and policymakers

290
0:13:00.017,000 --> 0:13:02,000
play "Jeopardy!" against Watson.

291
0:13:02.436,000 --> 0:13:05,000
We could send Congress on an autonomous car road trip.

292
0:13:05.986,000 --> 0:13:06,000
And if we do enough of these kinds of things,

293
0:13:07.639,000 --> 0:13:1,000
the awareness is going to sink in that things are going to be different.

294
0:13:11.043,000 --> 0:13:12,000
And then we're off to the races,

295
0:13:12.814,000 --> 0:13:14,000
because I don't believe for a second

296
0:13:15.244,000 --> 0:13:17,000
that we have forgotten how to solve tough challenges

297
0:13:18.212,000 --> 0:13:22,000
or that we have become too apathetic or hard-hearted to even try.

298
0:13:22.562,000 --> 0:13:24,000
I started my talk with quotes from wordsmiths

299
0:13:24.956,000 --> 0:13:26,000
who were separated by an ocean and a century.

300
0:13:27.772,000 --> 0:13:29,000
Let me end it with words from politicians

301
0:13:29.924,000 --> 0:13:3,000
who were similarly distant.

302
0:13:31.655,000 --> 0:13:34,000
Winston Churchill came to my home of MIT in 1949,

303
0:13:34.988,000 --> 0:13:36,000
and he said, "If we are to bring the broad masses

304
0:13:37.136,000 --> 0:13:4,000
of the people in every land to the table of abundance,

305
0:13:40.846,000 --> 0:13:43,000
it can only be by the tireless improvement

306
0:13:43.876,000 --> 0:13:45,000
of all of our means of technical production."

307
0:13:46.849,000 --> 0:13:48,000
Abraham Lincoln realized there was one other ingredient.

308
0:13:49.468,000 --> 0:13:51,000
He said, "I am a firm believer in the people.

309
0:13:52.366,000 --> 0:13:54,000
If given the truth, they can be depended upon

310
0:13:54.699,000 --> 0:13:56,000
to meet any national crisis.

311
0:13:57.068,000 --> 0:13:59,000
The great point is to give them the plain facts."

312
0:13:59.852,000 --> 0:14:02,000
So the optimistic note, great point that I want to leave you with

313
0:14:02.962,000 --> 0:14:05,000
is that the plain facts of the machine age are becoming clear,

314
0:14:06.107,000 --> 0:14:08,000
and I have every confidence that we're going to use them

315
0:14:08.564,000 --> 0:14:1,000
to chart a good course into the challenging,

316
0:14:11.479,000 --> 0:14:13,000
abundant economy that we're creating.

317
0:14:14.012,000 --> 0:14:15,000
Thank you very much.

318
0:14:15.703,000 --> 0:14:19,000
(Applause)

