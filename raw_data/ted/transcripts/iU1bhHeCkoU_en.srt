1
0:00:12.931,000 --> 0:00:14,000
Chris Anderson: Christiane, great to have you here.

2
0:00:15.292,000 --> 0:00:16,000
So you've had this amazing viewpoint,

3
0:00:17.159,000 --> 0:00:2,000
and perhaps it's fair to say that in the last few years,

4
0:00:20.243,000 --> 0:00:23,000
there have been some alarming developments that you're seeing.

5
0:00:24.02,000 --> 0:00:25,000
What's alarmed you most?

6
0:00:25.608,000 --> 0:00:28,000
Christiane Amanpour: Well, just listening to the earlier speakers,

7
0:00:28.824,000 --> 0:00:3,000
I can frame it in what they've been saying:

8
0:00:31.32,000 --> 0:00:34,000
climate change, for instance -- cities, the threat to our environment

9
0:00:34.766,000 --> 0:00:35,000
and our lives.

10
0:00:36.44,000 --> 0:00:39,000
It basically also boils down to understanding the truth

11
0:00:40.358,000 --> 0:00:43,000
and to be able to get to the truth of what we're talking about

12
0:00:43.393,000 --> 0:00:45,000
in order to really be able to solve it.

13
0:00:45.509,000 --> 0:00:48,000
So if 99.9 percent of the science on climate

14
0:00:49.46,000 --> 0:00:52,000
is empirical, scientific evidence,

15
0:00:52.541,000 --> 0:00:56,000
but it's competing almost equally with a handful of deniers,

16
0:00:57.46,000 --> 0:00:58,000
that is not the truth;

17
0:00:58.711,000 --> 0:01:,000
that is the epitome of fake news.

18
0:01:01.233,000 --> 0:01:06,000
And so for me, the last few years -- certainly this last year --

19
0:01:06.359,000 --> 0:01:1,000
has crystallized the notion of fake news in a way that's truly alarming

20
0:01:10.643,000 --> 0:01:12,000
and not just some slogan to be thrown around.

21
0:01:13.326,000 --> 0:01:16,000
Because when you can't distinguish between the truth and fake news,

22
0:01:17.161,000 --> 0:01:2,000
you have a very much more difficult time trying to solve

23
0:01:21.076,000 --> 0:01:23,000
some of the great issues that we face.

24
0:01:24.512,000 --> 0:01:27,000
CA: Well, you've been involved in this question of,

25
0:01:27.957,000 --> 0:01:29,000
what is balance, what is truth, what is impartiality,

26
0:01:30.893,000 --> 0:01:31,000
for a long time.

27
0:01:32.172,000 --> 0:01:37,000
You were on the front lines reporting the Balkan Wars 25 years ago.

28
0:01:38.066,000 --> 0:01:41,000
And back then, you famously said,

29
0:01:41.502,000 --> 0:01:43,000
by calling out human right abuses,

30
0:01:44.147,000 --> 0:01:48,000
you said, "Look, there are some situations one simply cannot be neutral about,

31
0:01:48.5,000 --> 0:01:49,000
because when you're neutral,

32
0:01:49.904,000 --> 0:01:5,000
you are an accomplice."

33
0:01:53.243,000 --> 0:01:57,000
So, do you feel that today's journalists aren't heeding that advice

34
0:01:58.164,000 --> 0:01:59,000
about balance?

35
0:01:59.66,000 --> 0:02:03,000
CA: Well, look, I think for journalists, objectivity is the golden rule.

36
0:02:03.79,000 --> 0:02:07,000
But I think sometimes we don't understand what objectivity means.

37
0:02:08.23,000 --> 0:02:1,000
And I actually learned this very, very young in my career,

38
0:02:11.248,000 --> 0:02:12,000
which was during the Balkan Wars.

39
0:02:12.844,000 --> 0:02:13,000
I was young then.

40
0:02:14.084,000 --> 0:02:16,000
It was about 25 years ago.

41
0:02:16.647,000 --> 0:02:21,000
And what we faced was the wholesale violation, not just of human rights,

42
0:02:22.452,000 --> 0:02:24,000
but all the way to ethnic cleansing and genocide,

43
0:02:25.455,000 --> 0:02:29,000
and that has been adjudicated in the highest war crimes court

44
0:02:29.485,000 --> 0:02:3,000
in the world.

45
0:02:30.673,000 --> 0:02:31,000
So, we know what we were seeing.

46
0:02:32.35,000 --> 0:02:34,000
Trying to tell the world what we were seeing

47
0:02:34.911,000 --> 0:02:36,000
brought us accusations of bias,

48
0:02:37.71,000 --> 0:02:38,000
of siding with one side,

49
0:02:39.623,000 --> 0:02:4,000
of not seeing the whole side,

50
0:02:41.509,000 --> 0:02:43,000
and just, you know, trying to tell one story.

51
0:02:43.83,000 --> 0:02:47,000
I particularly and personally was accused of siding with,

52
0:02:48.161,000 --> 0:02:49,000
for instance, the citizens of Sarajevo --

53
0:02:50.167,000 --> 0:02:51,000
"siding with the Muslims,"

54
0:02:51.618,000 --> 0:02:54,000
because they were the minority who were being attacked

55
0:02:54.694,000 --> 0:02:57,000
by Christians on the Serb side

56
0:02:58.456,000 --> 0:02:59,000
in this area.

57
0:03:00.199,000 --> 0:03:01,000
And it worried me.

58
0:03:01.565,000 --> 0:03:03,000
It worried me that I was being accused of this.

59
0:03:03.78,000 --> 0:03:04,000
I thought maybe I was wrong,

60
0:03:05.146,000 --> 0:03:07,000
maybe I'd forgotten what objectivity was.

61
0:03:07.518,000 --> 0:03:1,000
But then I started to understand that what people wanted

62
0:03:10.549,000 --> 0:03:11,000
was actually not to do anything --

63
0:03:12.371,000 --> 0:03:13,000
not to step in,

64
0:03:13.812,000 --> 0:03:14,000
not to change the situation,

65
0:03:15.406,000 --> 0:03:16,000
not to find a solution.

66
0:03:16.879,000 --> 0:03:18,000
And so, their fake news at that time,

67
0:03:19.256,000 --> 0:03:2,000
their lie at that time --

68
0:03:20.662,000 --> 0:03:23,000
including our government's, our democratically elected government's,

69
0:03:24.216,000 --> 0:03:26,000
with values and principles of human rights --

70
0:03:26.512,000 --> 0:03:29,000
their lie was to say that all sides are equally guilty,

71
0:03:30.043,000 --> 0:03:32,000
that this has been centuries of ethnic hatred,

72
0:03:32.86,000 --> 0:03:33,000
whereas we knew that wasn't true,

73
0:03:34.766,000 --> 0:03:37,000
that one side had decided to kill, slaughter and ethnically cleanse

74
0:03:38.437,000 --> 0:03:39,000
another side.

75
0:03:39.618,000 --> 0:03:4,000
So that is where, for me,

76
0:03:41.138,000 --> 0:03:46,000
I understood that objectivity means giving all sides an equal hearing

77
0:03:46.468,000 --> 0:03:48,000
and talking to all sides,

78
0:03:48.597,000 --> 0:03:51,000
but not treating all sides equally,

79
0:03:52.243,000 --> 0:03:56,000
not creating a forced moral equivalence or a factual equivalence.

80
0:03:57.055,000 --> 0:04:01,000
And when you come up against that crisis point

81
0:04:01.558,000 --> 0:04:06,000
in situations of grave violations of international and humanitarian law,

82
0:04:07.253,000 --> 0:04:09,000
if you don't understand what you're seeing,

83
0:04:09.619,000 --> 0:04:11,000
if you don't understand the truth

84
0:04:11.803,000 --> 0:04:14,000
and if you get trapped in the fake news paradigm,

85
0:04:15.34,000 --> 0:04:16,000
then you are an accomplice.

86
0:04:17.658,000 --> 0:04:19,000
And I refuse to be an accomplice to genocide.

87
0:04:20.679,000 --> 0:04:23,000
(Applause)

88
0:04:26.402,000 --> 0:04:28,000
CH: So there have always been these propaganda battles,

89
0:04:29.204,000 --> 0:04:33,000
and you were courageous in taking the stand you took back then.

90
0:04:33.652,000 --> 0:04:36,000
Today, there's a whole new way, though,

91
0:04:37.403,000 --> 0:04:39,000
in which news seems to be becoming fake.

92
0:04:39.631,000 --> 0:04:4,000
How would you characterize that?

93
0:04:41.289,000 --> 0:04:43,000
CA: Well, look -- I am really alarmed.

94
0:04:43.397,000 --> 0:04:45,000
And everywhere I look,

95
0:04:45.623,000 --> 0:04:46,000
you know, we're buffeted by it.

96
0:04:47.484,000 --> 0:04:49,000
Obviously, when the leader of the free world,

97
0:04:49.71,000 --> 0:04:51,000
when the most powerful person in the entire world,

98
0:04:52.207,000 --> 0:04:54,000
which is the president of the United States --

99
0:04:54.477,000 --> 0:04:58,000
this is the most important, most powerful country in the whole world,

100
0:04:59.32,000 --> 0:05:03,000
economically, militarily, politically in every which way --

101
0:05:04.415,000 --> 0:05:09,000
and it seeks to, obviously, promote its values and power around the world.

102
0:05:09.456,000 --> 0:05:12,000
So we journalists, who only seek the truth --

103
0:05:13.456,000 --> 0:05:14,000
I mean, that is our mission --

104
0:05:15.001,000 --> 0:05:17,000
we go around the world looking for the truth

105
0:05:17.142,000 --> 0:05:18,000
in order to be everybody's eyes and ears,

106
0:05:19.139,000 --> 0:05:21,000
people who can't go out in various parts of the world

107
0:05:21.682,000 --> 0:05:24,000
to figure out what's going on about things that are vitally important

108
0:05:25.075,000 --> 0:05:26,000
to everybody's health and security.

109
0:05:27.055,000 --> 0:05:33,000
So when you have a major world leader accusing you of fake news,

110
0:05:33.765,000 --> 0:05:36,000
it has an exponential ripple effect.

111
0:05:37.632,000 --> 0:05:41,000
And what it does is, it starts to chip away

112
0:05:42.472,000 --> 0:05:44,000
at not just our credibility,

113
0:05:45.384,000 --> 0:05:47,000
but at people's minds --

114
0:05:48.372,000 --> 0:05:5,000
people who look at us, and maybe they're thinking,

115
0:05:50.76,000 --> 0:05:52,000
"Well, if the president of the United States says that,

116
0:05:53.453,000 --> 0:05:55,000
maybe somewhere there's a truth in there."

117
0:05:56.148,000 --> 0:06:,000
CH: Presidents have always been critical of the media --

118
0:06:00.356,000 --> 0:06:01,000
CA: Not in this way.

119
0:06:01.981,000 --> 0:06:02,000
CH: So, to what extent --

120
0:06:03.51,000 --> 0:06:04,000
(Laughter)

121
0:06:04.598,000 --> 0:06:07,000
(Applause)

122
0:06:07.742,000 --> 0:06:13,000
CH: I mean, someone a couple years ago looking at the avalanche of information

123
0:06:14.662,000 --> 0:06:17,000
pouring through Twitter and Facebook and so forth,

124
0:06:17.922,000 --> 0:06:18,000
might have said,

125
0:06:19.104,000 --> 0:06:21,000
"Look, our democracies are healthier than they've ever been.

126
0:06:21.969,000 --> 0:06:22,000
There's more news than ever.

127
0:06:23.514,000 --> 0:06:25,000
Of course presidents will say what they'll say,

128
0:06:25.749,000 --> 0:06:27,000
but everyone else can say what they will say.

129
0:06:28.006,000 --> 0:06:32,000
What's not to like? How is there an extra danger?"

130
0:06:32.185,000 --> 0:06:33,000
CA: So, I wish that was true.

131
0:06:34.992,000 --> 0:06:4,000
I wish that the proliferation of platforms upon which we get our information

132
0:06:41.109,000 --> 0:06:44,000
meant that there was a proliferation of truth and transparency

133
0:06:45.011,000 --> 0:06:46,000
and depth and accuracy.

134
0:06:46.903,000 --> 0:06:48,000
But I think the opposite has happened.

135
0:06:49.382,000 --> 0:06:51,000
You know, I'm a little bit of a Luddite,

136
0:06:51.496,000 --> 0:06:52,000
I will confess.

137
0:06:53.147,000 --> 0:06:56,000
Even when we started to talk about the information superhighway,

138
0:06:56.555,000 --> 0:06:57,000
which was a long time ago,

139
0:06:58.207,000 --> 0:07:,000
before social media, Twitter and all the rest of it,

140
0:07:00.882,000 --> 0:07:01,000
I was actually really afraid

141
0:07:02.73,000 --> 0:07:06,000
that that would put people into certain lanes and tunnels

142
0:07:06.775,000 --> 0:07:1,000
and have them just focusing on areas of their own interest

143
0:07:11.141,000 --> 0:07:13,000
instead of seeing the broad picture.

144
0:07:13.498,000 --> 0:07:17,000
And I'm afraid to say that with algorithms, with logarithms,

145
0:07:18.108,000 --> 0:07:19,000
with whatever the "-ithms" are

146
0:07:19.78,000 --> 0:07:23,000
that direct us into all these particular channels of information,

147
0:07:24.07,000 --> 0:07:25,000
that seems to be happening right now.

148
0:07:25.964,000 --> 0:07:27,000
I mean, people have written about this phenomenon.

149
0:07:28.532,000 --> 0:07:3,000
People have said that yes, the internet came,

150
0:07:30.754,000 --> 0:07:35,000
its promise was to exponentially explode our access to more democracy,

151
0:07:36.521,000 --> 0:07:37,000
more information,

152
0:07:38.259,000 --> 0:07:39,000
less bias,

153
0:07:40.175,000 --> 0:07:42,000
more varied information.

154
0:07:42.588,000 --> 0:07:44,000
And, in fact, the opposite has happened.

155
0:07:44.937,000 --> 0:07:48,000
And so that, for me, is incredibly dangerous.

156
0:07:48.979,000 --> 0:07:52,000
And again, when you are the president of this country and you say things,

157
0:07:53.518,000 --> 0:07:58,000
it also gives leaders in other undemocratic countries the cover

158
0:08:00.009,000 --> 0:08:02,000
to affront us even worse,

159
0:08:02.339,000 --> 0:08:04,000
and to really whack us -- and their own journalists --

160
0:08:05.223,000 --> 0:08:06,000
with this bludgeon of fake news.

161
0:08:08,000 --> 0:08:1,000
CH: To what extent is what happened, though,

162
0:08:10.208,000 --> 0:08:12,000
in part, just an unintended consequence,

163
0:08:12.298,000 --> 0:08:14,000
that the traditional media that you worked in

164
0:08:15.124,000 --> 0:08:17,000
had this curation-mediation role,

165
0:08:17.228,000 --> 0:08:19,000
where certain norms were observed,

166
0:08:19.278,000 --> 0:08:22,000
certain stories would be rejected because they weren't credible,

167
0:08:22.455,000 --> 0:08:28,000
but now that the standard for publication and for amplification

168
0:08:28.978,000 --> 0:08:31,000
is just interest, attention, excitement, click,

169
0:08:32.33,000 --> 0:08:33,000
"Did it get clicked on?"

170
0:08:33.517,000 --> 0:08:34,000
"Send it out there!"

171
0:08:34.696,000 --> 0:08:37,000
and that's what's -- is that part of what's caused the problem?

172
0:08:38.224,000 --> 0:08:41,000
CA: I think it's a big problem, and we saw this in the election of 2016,

173
0:08:41.843,000 --> 0:08:46,000
where the idea of "clickbait" was very sexy and very attractive,

174
0:08:46.974,000 --> 0:08:5,000
and so all these fake news sites and fake news items

175
0:08:51.304,000 --> 0:08:55,000
were not just haphazardly and by happenstance being put out there,

176
0:08:55.45,000 --> 0:08:59,000
there's been a whole industry in the creation of fake news

177
0:08:59.925,000 --> 0:09:01,000
in parts of Eastern Europe, wherever,

178
0:09:02.939,000 --> 0:09:05,000
and you know, it's planted in real space and in cyberspace.

179
0:09:06.223,000 --> 0:09:08,000
So I think that, also,

180
0:09:08.606,000 --> 0:09:13,000
the ability of our technology to proliferate this stuff

181
0:09:13.751,000 --> 0:09:16,000
at the speed of sound or light, just about --

182
0:09:17.286,000 --> 0:09:18,000
we've never faced that before.

183
0:09:19.293,000 --> 0:09:23,000
And we've never faced such a massive amount of information

184
0:09:24.184,000 --> 0:09:25,000
which is not curated

185
0:09:25.773,000 --> 0:09:3,000
by those whose profession leads them to abide by the truth,

186
0:09:31.093,000 --> 0:09:32,000
to fact-check

187
0:09:32.319,000 --> 0:09:36,000
and to maintain a code of conduct and a code of professional ethics.

188
0:09:37.177,000 --> 0:09:4,000
CH: Many people here may know people who work at Facebook

189
0:09:40.544,000 --> 0:09:42,000
or Twitter and Google and so on.

190
0:09:42.892,000 --> 0:09:45,000
They all seem like great people with good intention --

191
0:09:46.048,000 --> 0:09:47,000
let's assume that.

192
0:09:47.452,000 --> 0:09:5,000
If you could speak with the leaders of those companies,

193
0:09:51.151,000 --> 0:09:52,000
what would you say to them?

194
0:09:52.466,000 --> 0:09:53,000
CA: Well, you know what --

195
0:09:54.259,000 --> 0:09:56,000
I'm sure they are incredibly well-intentioned,

196
0:09:56.627,000 --> 0:10:01,000
and they certainly developed an unbelievable, game-changing system,

197
0:10:01.869,000 --> 0:10:04,000
where everybody's connected on this thing called Facebook.

198
0:10:05.104,000 --> 0:10:08,000
And they've created a massive economy for themselves

199
0:10:08.929,000 --> 0:10:1,000
and an amazing amount of income.

200
0:10:11.633,000 --> 0:10:12,000
I would just say,

201
0:10:12.837,000 --> 0:10:16,000
"Guys, you know, it's time to wake up and smell the coffee

202
0:10:17.095,000 --> 0:10:19,000
and look at what's happening to us right now."

203
0:10:19.821,000 --> 0:10:21,000
Mark Zuckerberg wants to create a global community.

204
0:10:22.777,000 --> 0:10:25,000
I want to know: What is that global community going to look like?

205
0:10:26.02,000 --> 0:10:3,000
I want to know where the codes of conduct actually are.

206
0:10:30.111,000 --> 0:10:31,000
Mark Zuckerberg said --

207
0:10:31.96,000 --> 0:10:33,000
and I don't blame him, he probably believed this --

208
0:10:34.702,000 --> 0:10:36,000
that it was crazy to think

209
0:10:37.082,000 --> 0:10:41,000
that the Russians or anybody else could be tinkering and messing around

210
0:10:41.215,000 --> 0:10:42,000
with this avenue.

211
0:10:42.482,000 --> 0:10:44,000
And what have we just learned in the last few weeks?

212
0:10:44.988,000 --> 0:10:46,000
That, actually, there has been a major problem in that regard,

213
0:10:47.97,000 --> 0:10:5,000
and now they're having to investigate it and figure it out.

214
0:10:51.112,000 --> 0:10:54,000
Yes, they're trying to do what they can now

215
0:10:54.415,000 --> 0:10:56,000
to prevent the rise of fake news,

216
0:10:56.597,000 --> 0:10:57,000
but, you know,

217
0:10:58.004,000 --> 0:11:03,000
it went pretty unrestricted for a long, long time.

218
0:11:03.119,000 --> 0:11:04,000
So I guess I would say, you know,

219
0:11:05.043,000 --> 0:11:07,000
you guys are brilliant at technology;

220
0:11:07.166,000 --> 0:11:08,000
let's figure out another algorithm.

221
0:11:09.081,000 --> 0:11:1,000
Can we not?

222
0:11:10.276,000 --> 0:11:12,000
CH: An algorithm that includes journalistic investigation --

223
0:11:13.187,000 --> 0:11:16,000
CA: I don't really know how they do it, but somehow, you know --

224
0:11:16.567,000 --> 0:11:17,000
filter out the crap!

225
0:11:18.41,000 --> 0:11:19,000
(Laughter)

226
0:11:19.584,000 --> 0:11:21,000
And not just the unintentional --

227
0:11:21.61,000 --> 0:11:24,000
(Applause)

228
0:11:24.888,000 --> 0:11:26,000
but the deliberate lies that are planted

229
0:11:27.118,000 --> 0:11:31,000
by people who've been doing this as a matter of warfare

230
0:11:31.467,000 --> 0:11:32,000
for decades.

231
0:11:32.793,000 --> 0:11:33,000
The Soviets, the Russians --

232
0:11:34.75,000 --> 0:11:39,000
they are the masters of war by other means, of hybrid warfare.

233
0:11:40.618,000 --> 0:11:41,000
And this is a --

234
0:11:42.689,000 --> 0:11:44,000
this is what they've decided to do.

235
0:11:45.697,000 --> 0:11:46,000
It worked in the United States,

236
0:11:47.326,000 --> 0:11:48,000
it didn't work in France,

237
0:11:48.671,000 --> 0:11:49,000
it hasn't worked in Germany.

238
0:11:50.368,000 --> 0:11:52,000
During the elections there, where they've tried to interfere,

239
0:11:53.333,000 --> 0:11:55,000
the president of France right now, Emmanuel Macron,

240
0:11:55.959,000 --> 0:11:57,000
took a very tough stand and confronted it head on,

241
0:11:58.506,000 --> 0:11:59,000
as did Angela Merkel.

242
0:11:59.688,000 --> 0:12:01,000
CH: There's some hope to be had from some of this, isn't there?

243
0:12:02.697,000 --> 0:12:03,000
That the world learns.

244
0:12:03.872,000 --> 0:12:04,000
We get fooled once,

245
0:12:05.214,000 --> 0:12:06,000
maybe we get fooled again,

246
0:12:06.57,000 --> 0:12:07,000
but maybe not the third time.

247
0:12:08.049,000 --> 0:12:09,000
Is that true?

248
0:12:09.241,000 --> 0:12:1,000
CA: I mean, let's hope.

249
0:12:10.421,000 --> 0:12:13,000
But I think in this regard that so much of it is also about technology,

250
0:12:13.832,000 --> 0:12:16,000
that the technology has to also be given some kind of moral compass.

251
0:12:17.301,000 --> 0:12:19,000
I know I'm talking nonsense, but you know what I mean.

252
0:12:20.141,000 --> 0:12:23,000
CH: We need a filter-the-crap algorithm with a moral compass --

253
0:12:23.873,000 --> 0:12:24,000
CA: There you go.

254
0:12:25.054,000 --> 0:12:26,000
CH: I think that's good.

255
0:12:26.23,000 --> 0:12:27,000
CA: No -- "moral technology."

256
0:12:27.925,000 --> 0:12:3,000
We all have moral compasses -- moral technology.

257
0:12:31.055,000 --> 0:12:33,000
CH: I think that's a great challenge. CA: You know what I mean.

258
0:12:34.058,000 --> 0:12:35,000
CH: Talk just a minute about leadership.

259
0:12:36.026,000 --> 0:12:39,000
You've had a chance to speak with so many people across the world.

260
0:12:39.186,000 --> 0:12:4,000
I think for some of us --

261
0:12:40.449,000 --> 0:12:42,000
I speak for myself, I don't know if others feel this --

262
0:12:43.165,000 --> 0:12:44,000
there's kind of been a disappointment of:

263
0:12:45.185,000 --> 0:12:46,000
Where are the leaders?

264
0:12:47.068,000 --> 0:12:49,000
So many of us have been disappointed --

265
0:12:49.406,000 --> 0:12:51,000
Aung San Suu Kyi, what's happened recently,

266
0:12:51.446,000 --> 0:12:53,000
it's like, "No! Another one bites the dust."

267
0:12:53.555,000 --> 0:12:54,000
You know, it's heartbreaking.

268
0:12:55.178,000 --> 0:12:56,000
(Laughter)

269
0:12:56.437,000 --> 0:12:58,000
Who have you met

270
0:12:58.482,000 --> 0:13:,000
who you have been impressed by, inspired by?

271
0:13:01.376,000 --> 0:13:03,000
CA: Well, you talk about the world in crisis,

272
0:13:03.904,000 --> 0:13:04,000
which is absolutely true,

273
0:13:05.282,000 --> 0:13:09,000
and those of us who spend our whole lives immersed in this crisis --

274
0:13:09.793,000 --> 0:13:11,000
I mean, we're all on the verge of a nervous breakdown.

275
0:13:12.81,000 --> 0:13:14,000
So it's pretty stressful right now.

276
0:13:15.51,000 --> 0:13:16,000
And you're right --

277
0:13:16.693,000 --> 0:13:19,000
there is this perceived and actual vacuum of leadership,

278
0:13:19.827,000 --> 0:13:21,000
and it's not me saying it, I ask all these --

279
0:13:22.701,000 --> 0:13:24,000
whoever I'm talking to, I ask about leadership.

280
0:13:25.178,000 --> 0:13:29,000
I was speaking to the outgoing president of Liberia today,

281
0:13:29.712,000 --> 0:13:3,000
[Ellen Johnson Sirleaf,]

282
0:13:31.546,000 --> 0:13:32,000
who --

283
0:13:32.724,000 --> 0:13:34,000
(Applause)

284
0:13:34.963,000 --> 0:13:35,000
in three weeks' time,

285
0:13:36.529,000 --> 0:13:39,000
will be one of the very rare heads of an African country

286
0:13:40.497,000 --> 0:13:42,000
who actually abides by the constitution

287
0:13:42.699,000 --> 0:13:45,000
and gives up power after her prescribed term.

288
0:13:46.335,000 --> 0:13:49,000
She has said she wants to do that as a lesson.

289
0:13:50.216,000 --> 0:13:52,000
But when I asked her about leadership,

290
0:13:52.272,000 --> 0:13:54,000
and I gave a quick-fire round of certain names,

291
0:13:54.979,000 --> 0:13:56,000
I presented her with the name of the new French president,

292
0:13:57.98,000 --> 0:13:58,000
Emmanuel Macron.

293
0:13:59.437,000 --> 0:14:,000
And she said --

294
0:14:00.797,000 --> 0:14:02,000
I said, "So what do you think when I say his name?"

295
0:14:03.327,000 --> 0:14:04,000
And she said,

296
0:14:05.578,000 --> 0:14:07,000
"Shaping up potentially to be

297
0:14:07.927,000 --> 0:14:11,000
a leader to fill our current leadership vacuum."

298
0:14:12.017,000 --> 0:14:13,000
I thought that was really interesting.

299
0:14:13.874,000 --> 0:14:15,000
Yesterday, I happened to have an interview with him.

300
0:14:16.354,000 --> 0:14:17,000
I'm very proud to say,

301
0:14:17.536,000 --> 0:14:2,000
I got his first international interview. It was great. It was yesterday.

302
0:14:20.979,000 --> 0:14:21,000
And I was really impressed.

303
0:14:22.295,000 --> 0:14:24,000
I don't know whether I should be saying that in an open forum,

304
0:14:25.247,000 --> 0:14:26,000
but I was really impressed.

305
0:14:26.726,000 --> 0:14:27,000
(Laughter)

306
0:14:28.867,000 --> 0:14:3,000
And it could be just because it was his first interview,

307
0:14:31.566,000 --> 0:14:33,000
but -- I asked questions, and you know what?

308
0:14:33.685,000 --> 0:14:34,000
He answered them!

309
0:14:34.917,000 --> 0:14:35,000
(Laughter)

310
0:14:36.874,000 --> 0:14:39,000
(Applause)

311
0:14:40.167,000 --> 0:14:41,000
There was no spin,

312
0:14:41.784,000 --> 0:14:43,000
there was no wiggle and waggle,

313
0:14:44.199,000 --> 0:14:46,000
there was no spend-five-minutes- to-come-back-to-the-point.

314
0:14:47.052,000 --> 0:14:48,000
I didn't have to keep interrupting,

315
0:14:48.744,000 --> 0:14:5,000
which I've become rather renowned for doing,

316
0:14:50.851,000 --> 0:14:52,000
because I want people to answer the question.

317
0:14:53.407,000 --> 0:14:55,000
And he answered me,

318
0:14:55.482,000 --> 0:14:57,000
and it was pretty interesting.

319
0:14:58.12,000 --> 0:14:59,000
And he said --

320
0:14:59.575,000 --> 0:15:,000
CH: Tell me what he said.

321
0:15:01.377,000 --> 0:15:02,000
CA: No, no, you go ahead.

322
0:15:02.621,000 --> 0:15:04,000
CH: You're the interrupter, I'm the listener.

323
0:15:04.873,000 --> 0:15:05,000
CA: No, no, go ahead.

324
0:15:06.055,000 --> 0:15:07,000
CH: What'd he say?

325
0:15:07.234,000 --> 0:15:1,000
CA: OK. You've talked about nationalism and tribalism here today.

326
0:15:10.336,000 --> 0:15:13,000
I asked him, "How did you have the guts to confront the prevailing winds

327
0:15:14.122,000 --> 0:15:18,000
of anti-globalization, nationalism, populism

328
0:15:18.681,000 --> 0:15:19,000
when you can see what happened in Brexit,

329
0:15:20.667,000 --> 0:15:22,000
when you could see what happened in the United States

330
0:15:23.246,000 --> 0:15:25,000
and what might have happened in many European elections

331
0:15:25.865,000 --> 0:15:26,000
at the beginning of 2017?"

332
0:15:27.606,000 --> 0:15:28,000
And he said,

333
0:15:29.597,000 --> 0:15:32,000
"For me, nationalism means war.

334
0:15:33.486,000 --> 0:15:34,000
We have seen it before,

335
0:15:35.183,000 --> 0:15:37,000
we have lived through it before on my continent,

336
0:15:37.465,000 --> 0:15:39,000
and I am very clear about that."

337
0:15:40.175,000 --> 0:15:43,000
So he was not going to, just for political expediency,

338
0:15:44.16,000 --> 0:15:47,000
embrace the, kind of, lowest common denominator

339
0:15:47.626,000 --> 0:15:51,000
that had been embraced in other political elections.

340
0:15:51.655,000 --> 0:15:55,000
And he stood against Marine Le Pen, who is a very dangerous woman.

341
0:15:56.928,000 --> 0:15:58,000
CH: Last question for you, Christiane.

342
0:16:00.093,000 --> 0:16:01,000
TED is about ideas worth spreading.

343
0:16:02.115,000 --> 0:16:06,000
If you could plant one idea into the minds of everyone here,

344
0:16:06.786,000 --> 0:16:07,000
what would that be?

345
0:16:08.007,000 --> 0:16:13,000
CA: I would say really be careful where you get your information from;

346
0:16:13.145,000 --> 0:16:18,000
really take responsibility for what you read, listen to and watch;

347
0:16:18.491,000 --> 0:16:22,000
make sure that you go to the trusted brands to get your main information,

348
0:16:23.402,000 --> 0:16:27,000
no matter whether you have a wide, eclectic intake,

349
0:16:28.115,000 --> 0:16:3,000
really stick with the brand names that you know,

350
0:16:31.134,000 --> 0:16:34,000
because in this world right now, at this moment right now,

351
0:16:34.75,000 --> 0:16:38,000
our crises, our challenges, our problems are so severe,

352
0:16:39.113,000 --> 0:16:42,000
that unless we are all engaged as global citizens

353
0:16:42.688,000 --> 0:16:43,000
who appreciate the truth,

354
0:16:44.615,000 --> 0:16:48,000
who understand science, empirical evidence and facts,

355
0:16:48.984,000 --> 0:16:51,000
then we are just simply going to be wandering along

356
0:16:52.507,000 --> 0:16:53,000
to a potential catastrophe.

357
0:16:54.492,000 --> 0:16:55,000
So I would say, the truth,

358
0:16:55.88,000 --> 0:16:57,000
and then I would come back to Emmanuel Macron

359
0:16:58.16,000 --> 0:16:59,000
and talk about love.

360
0:17:00.022,000 --> 0:17:04,000
I would say that there's not enough love going around.

361
0:17:04.515,000 --> 0:17:06,000
And I asked him to tell me about love.

362
0:17:07.231,000 --> 0:17:1,000
I said, "You know, your marriage is the subject of global obsession."

363
0:17:10.847,000 --> 0:17:11,000
(Laughter)

364
0:17:12.506,000 --> 0:17:13,000
"Can you tell me about love?

365
0:17:13.943,000 --> 0:17:14,000
What does it mean to you?"

366
0:17:15.281,000 --> 0:17:17,000
I've never asked a president or an elected leader about love.

367
0:17:18.246,000 --> 0:17:19,000
I thought I'd try it.

368
0:17:19.428,000 --> 0:17:22,000
And he said -- you know, he actually answered it.

369
0:17:23.367,000 --> 0:17:27,000
And he said, "I love my wife, she is part of me,

370
0:17:27.552,000 --> 0:17:28,000
we've been together for decades."

371
0:17:29.203,000 --> 0:17:3,000
But here's where it really counted,

372
0:17:30.912,000 --> 0:17:31,000
what really stuck with me.

373
0:17:32.439,000 --> 0:17:33,000
He said,

374
0:17:33.704,000 --> 0:17:36,000
"It is so important for me to have somebody at home

375
0:17:37.248,000 --> 0:17:38,000
who tells me the truth."

376
0:17:40.618,000 --> 0:17:42,000
So you see, I brought it home. It's all about the truth.

377
0:17:43.354,000 --> 0:17:44,000
(Laughter)

378
0:17:44.384,000 --> 0:17:46,000
CH: So there you go. Truth and love. Ideas worth spreading.

379
0:17:47.215,000 --> 0:17:49,000
Christiane Amanpour, thank you so much. That was great.

380
0:17:49.902,000 --> 0:17:5,000
(Applause)

381
0:17:50.994,000 --> 0:17:52,000
CA: Thank you. CH: That was really lovely.

382
0:17:53.352,000 --> 0:17:54,000
(Applause)

383
0:17:54.591,000 --> 0:17:55,000
CA: Thank you.

