1
0:00:,000 --> 0:00:07,000
Traductor: Laura Feijóo Revisor: Nerea García Garmendia

2
0:00:13.458,000 --> 0:00:16,000
He intentado que cambien de opinión durante los últimos 15 años.

3
0:00:17.917,000 --> 0:00:2,000
En mi trabajo aprovecho cultura pop y tecnología emergente

4
0:00:21.768,000 --> 0:00:22,000
para cambiar las normas culturales.

5
0:00:24.213,000 --> 0:00:27,000
He creado videojuegos que promueven los derechos humanos,

6
0:00:27.888,000 --> 0:00:3,000
he hecho animaciones para concienciar sobre leyes de inmigración injustas

7
0:00:32.577,000 --> 0:00:36,000
e incluso he creado aplicaciones de realidad aumentada

8
0:00:36.803,000 --> 0:00:38,000
para cambiar la percepción sobre las personas sin techo

9
0:00:39.536,000 --> 0:00:4,000
mucho antes de Pokémon Go.

10
0:00:41.5,000 --> 0:00:42,000
(Risas)

11
0:00:42.851,000 --> 0:00:46,000
Pero entonces comencé a preguntarme si un videojuego o una aplicación

12
0:00:46.893,000 --> 0:00:48,000
pueden llegar a cambiar actitudes y comportamientos

13
0:00:49.397,000 --> 0:00:51,000
y de ser así, ¿cómo se puede medir?

14
0:00:52.458,000 --> 0:00:54,000
¿Qué base científica hay tras ese proceso?

15
0:00:55.224,000 --> 0:00:58,000
Así que dejé de centrarme en crear contenidos y tecnología

16
0:00:59.208,000 --> 0:01:02,000
para pasar a medir los efectos neurobiológicos.

17
0:01:03.458,000 --> 0:01:04,000
Esto es lo que descubrí.

18
0:01:05.333,000 --> 0:01:08,000
La web, los dispositivos móviles, la realidad virtual y aumentada

19
0:01:09.226,000 --> 0:01:11,000
estaban reescribiendo nuestros sistemas nerviosos.

20
0:01:11.958,000 --> 0:01:14,000
Literalmente estaban cambiando la estructura de nuestro cerebro.

21
0:01:15.875,000 --> 0:01:19,000
La misma tecnología que había empleado para influir de manera positiva

22
0:01:20.875,000 --> 0:01:24,000
estaba erosionando funciones del cerebro necesarias para la empatía

23
0:01:25.268,000 --> 0:01:26,000
y la toma de decisiones.

24
0:01:27.167,000 --> 0:01:31,000
De hecho, nuestra dependencia de la web y los dispositivos móviles

25
0:01:31.309,000 --> 0:01:34,000
podría estar adueñándose de las facultades cognitivas y afectivas,

26
0:01:35.458,000 --> 0:01:38,000
volviéndonos social y emocionalmente incompetentes,

27
0:01:38.708,000 --> 0:01:41,000
y me sentí cómplice de esta deshumanización.

28
0:01:43.292,000 --> 0:01:47,000
Me di cuenta de que antes de continuar creando contenidos de carácter sociológico

29
0:01:47.934,000 --> 0:01:51,000
tenía que revertir los efectos dañinos de la tecnología.

30
0:01:52.917,000 --> 0:01:54,000
Para abordarlo me pregunté:

31
0:01:55.684,000 --> 0:01:58,000
"¿Cómo traducir los mecanismos de la empatía,

32
0:01:59.101,000 --> 0:02:02,000
los aspectos cognitivos, afectivos y motivacionales

33
0:02:02.768,000 --> 0:02:05,000
en una máquina que simule los ingredientes narrativos

34
0:02:05.798,000 --> 0:02:06,000
que nos hacen actuar?"

35
0:02:08.033,000 --> 0:02:11,000
Para responder a esta pregunta tuve que construír una máquina.

36
0:02:12.542,000 --> 0:02:13,000
(Risas)

37
0:02:14.292,000 --> 0:02:16,000
He desarrollado un laboratorio biométrico de código abierto,

38
0:02:17.184,000 --> 0:02:19,000
un sistema de IA al que llamo Limbic Lab.

39
0:02:20.708,000 --> 0:02:21,000
El laboratorio no solo captura

40
0:02:22.143,000 --> 0:02:26,000
la respuesta inconsciente del cerebro y el cuerpo ante la tecnología,

41
0:02:26.417,000 --> 0:02:28,000
sino que usa el aprendizaje automático para adaptar contenido

42
0:02:29.393,000 --> 0:02:31,000
basándose en estas respuestas biológicas.

43
0:02:32.267,000 --> 0:02:35,000
Mi objetivo es averiguar qué combinación de ingredientes narrativos

44
0:02:36.184,000 --> 0:02:38,000
son los más atractivos y estimulantes

45
0:02:38.351,000 --> 0:02:39,000
para audiencias específicas,

46
0:02:40.184,000 --> 0:02:45,000
para posibilitar que la justicia social y organizaciones educativas y culturales

47
0:02:45.226,000 --> 0:02:47,000
creen contenido digital más efectivo.

48
0:02:47.917,000 --> 0:02:49,000
El Limbic Lab consta de dos componentes:

49
0:02:50.768,000 --> 0:02:52,000
un motor narrativo y una máquina mediática.

50
0:02:54.375,000 --> 0:02:57,000
Mientras un sujeto mira o interactúa con contenido digital,

51
0:02:58.601,000 --> 0:03:01,000
la máquina internaliza y sincroniza datos de ondas cerebrales en tiempo real,

52
0:03:02.659,000 --> 0:03:05,000
datos biofísicos como ritmo cardíaco, circulación, temperatura corporal

53
0:03:06.393,000 --> 0:03:07,000
y contracción muscular,

54
0:03:08.101,000 --> 0:03:1,000
así como el seguimiento ocular y las expresiones faciales.

55
0:03:12.083,000 --> 0:03:15,000
La información se recoge en momentos críticos de la trama:

56
0:03:15.809,000 --> 0:03:18,000
una interacción inusual o un uso extraño del ángulo de la cámara.

57
0:03:19.492,000 --> 0:03:22,000
Como la escena final de "Juego de Tronos: La boda roja",

58
0:03:23.042,000 --> 0:03:25,000
cuando sorprendentemente,

59
0:03:25.351,000 --> 0:03:26,000
todo el mundo muere.

60
0:03:27.214,000 --> 0:03:28,000
(Risas)

61
0:03:29.212,000 --> 0:03:32,000
Los datos de la encuesta sobre creencias políticas,

62
0:03:32.226,000 --> 0:03:35,000
así como los datos psicográficos y demográficos de la persona,

63
0:03:35.393,000 --> 0:03:36,000
se integran en el sistema

64
0:03:37.184,000 --> 0:03:39,000
para obtener un conocimiento más profundo del individuo.

65
0:03:40.833,000 --> 0:03:41,000
Permítanme ponerles un ejemplo.

66
0:03:43.708,000 --> 0:03:47,000
Conectar las preferencias de TV con la opinión sobre justicia social

67
0:03:48.339,000 --> 0:03:52,000
revela que los estadounidenses a los que les preocupa la inmigración

68
0:03:52.851,000 --> 0:03:54,000
son más propensos a que les guste "The Walking Dead",

69
0:03:56.958,000 --> 0:03:58,000
y normalmente lo ven por el aumento de adrenalina,

70
0:03:59.488,000 --> 0:04:,000
que se puede medir.

71
0:04:01.792,000 --> 0:04:04,000
La firma biológica de una persona y su respuesta a la encuesta

72
0:04:05.726,000 --> 0:04:09,000
se combina en una base de datos para crear una huella mediática única.

73
0:04:10.625,000 --> 0:04:13,000
Después, nuestro modelo predictivo encuentra patrones entre estas huellas

74
0:04:14.777,000 --> 0:04:16,000
y me dice qué ingredientes narrativos

75
0:04:16.893,000 --> 0:04:19,000
tienen más posibilidades de propiciar un comportamiento altruista

76
0:04:20.538,000 --> 0:04:22,000
que aflicción y apatía.

77
0:04:23.417,000 --> 0:04:25,000
Cuantas más huellas añadamos a la base de datos,

78
0:04:25.691,000 --> 0:04:28,000
desde medios como televisión episódica hasta juegos,

79
0:04:28.851,000 --> 0:04:3,000
mejor será nuestro modelo predictivo.

80
0:04:32.417,000 --> 0:04:35,000
En resumen, estoy mapeando el primer genoma mediático.

81
0:04:36.268,000 --> 0:04:39,000
(Aplausos)

82
0:04:44.083,000 --> 0:04:47,000
Mientras que el genoma humano identifica todos los genes

83
0:04:47.268,000 --> 0:04:48,000
involucrados en la secuenciación del ADN,

84
0:04:49.917,000 --> 0:04:51,000
la creciente base de datos de huellas mediáticas

85
0:04:52.153,000 --> 0:04:56,000
me permitirá determinar el ADN mediático de una persona en concreto.

86
0:04:58.25,000 --> 0:05:,000
El motor narrativo de Limbic Lab

87
0:05:02.183,000 --> 0:05:04,000
ayuda a los creadores de contenido a redefinir su narración

88
0:05:04.958,000 --> 0:05:08,000
para que resuene con la audiencia objetivo a nivel individual.

89
0:05:11.042,000 --> 0:05:13,000
El otro componente del Limbic Lab,

90
0:05:13.226,000 --> 0:05:14,000
la máquina mediática,

91
0:05:15.25,000 --> 0:05:19,000
evaluará cómo los medios provocan una respuesta emocional y psicológica

92
0:05:19.75,000 --> 0:05:21,000
y extraerá escenas de la librería de contenido

93
0:05:22.208,000 --> 0:05:24,000
dirigidas al ADN mediático de una persona en concreto.

94
0:05:26.042,000 --> 0:05:29,000
Aplicar la inteligencia artificial a los datos biométricos

95
0:05:29.934,000 --> 0:05:31,000
crea una experiencia personalizada,

96
0:05:32.684,000 --> 0:05:37,000
que adapta el contenido a partir de respuestas inconscientes.

97
0:05:37.915,000 --> 0:05:4,000
Imagínense que las organizaciones sin ánimo de lucro y creadores de contenidos

98
0:05:41.824,000 --> 0:05:45,000
pudieran medir cómo se siente su audiencia en tiempo real

99
0:05:46.559,000 --> 0:05:48,000
y alterar el contenido sobre la marcha.

100
0:05:49,000 --> 0:05:52,000
Creo que este es el futuro de los medios.

101
0:05:53.273,000 --> 0:05:55,000
Hasta hoy, las estrategias mediáticas y de cambio social

102
0:05:55.934,000 --> 0:05:57,000
han intentado atraer a las masas,

103
0:05:58.637,000 --> 0:06:01,000
pero el futuro es contenido personalizado para cada individuo.

104
0:06:03.458,000 --> 0:06:05,000
A medida que la medición de consumo en tiempo real

105
0:06:06.053,000 --> 0:06:08,000
y la producción automatizada de contenidos parece ser la norma,

106
0:06:09.042,000 --> 0:06:12,000
pronto nos encontraremos consumiendo contenidos hechos a medida,

107
0:06:12.951,000 --> 0:06:16,000
usando una mezcla de psicografía, biométricas e IA.

108
0:06:18.25,000 --> 0:06:21,000
Es como medicina personalizada basada en nuestro ADN.

109
0:06:21.833,000 --> 0:06:23,000
Yo los llamo "biocontenidos".

110
0:06:24.682,000 --> 0:06:27,000
Actualmente estoy probando el Limbic Lab en un estudio piloto

111
0:06:28.133,000 --> 0:06:3,000
con el Norman Lear Center,

112
0:06:30.375,000 --> 0:06:33,000
que tiene acceso a las 50 mejores series de televisión.

113
0:06:34.125,000 --> 0:06:36,000
Pero me veo en un dilema ético.

114
0:06:37.127,000 --> 0:06:4,000
Si diseño una herramienta que se puede convertir en un arma,

115
0:06:40.952,000 --> 0:06:42,000
¿debería construirla?

116
0:06:43.75,000 --> 0:06:46,000
Al hacerlo en código abierto para fomentar el acceso y la inclusión

117
0:06:47.393,000 --> 0:06:5,000
también corro el riesgo de permitir a poderosos gobiernos

118
0:06:50.851,000 --> 0:06:52,000
y grandes compañías apropiarse de la plataforma

119
0:06:53.809,000 --> 0:06:57,000
para crear noticias falsas, marketing u otras formas de persuasión masiva.

120
0:06:59.375,000 --> 0:07:02,000
Para mí, por lo tanto, es crítico que mi investigación

121
0:07:02.726,000 --> 0:07:05,000
sea lo más transparente posible para la audiencia laica.

122
0:07:07.333,000 --> 0:07:09,000
Sin embargo, esto no es suficiente.

123
0:07:11.208,000 --> 0:07:12,000
Como creadores tecnológicos

124
0:07:12.875,000 --> 0:07:14,000
tenemos la responsabilidad

125
0:07:15.101,000 --> 0:07:18,000
no solo de reflexionar cómo la tecnología actual

126
0:07:18.397,000 --> 0:07:2,000
moldea nuestros valores y comportamiento,

127
0:07:21.934,000 --> 0:07:25,000
sino también cómo desafiar activamente la trayectoria de la tecnología futura.

128
0:07:26.917,000 --> 0:07:29,000
Espero que lleguemos a un compromiso ético

129
0:07:31,000 --> 0:07:33,000
para aprovechar la inteligencia del cuerpo

130
0:07:33.351,000 --> 0:07:36,000
para crear historias auténticas y justas

131
0:07:36.809,000 --> 0:07:38,000
que transformen los medios y la tecnología

132
0:07:39.226,000 --> 0:07:42,000
de armas peligrosas a medicina narrativa.

133
0:07:42.726,000 --> 0:07:43,000
Gracias.

134
0:07:44.018,000 --> 0:07:46,000
(Aplausos y ovaciones)

