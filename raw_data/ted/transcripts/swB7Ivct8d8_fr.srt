1
0:00:,000 --> 0:00:07,000
Traducteur: Cat Graham Relecteur: Claire Ghyselen

2
0:00:12.787,000 --> 0:00:14,000
Je vais commencer par poser une question effrayante :

3
0:00:15.659,000 --> 0:00:17,000
sommes-nous en route vers un futur sans emploi ?

4
0:00:18.987,000 --> 0:00:2,000
Les technologies comme les voitures autonomes

5
0:00:21.096,000 --> 0:00:22,000
font des progrès remarquables

6
0:00:22.965,000 --> 0:00:25,000
et provoquent une explosion d'intérêt pour cette question.

7
0:00:26.054,000 --> 0:00:28,000
Or, il s’agit là d’une question que nous nous posons

8
0:00:28.504,000 --> 0:00:3,000
depuis si longtemps que la vraie question à nous poser

9
0:00:31.372,000 --> 0:00:34,000
est de savoir si cette fois-ci, la situation est vraiment différente.

10
0:00:35.252,000 --> 0:00:37,000
La peur que l'automatisation remplace les travailleurs

11
0:00:38.237,000 --> 0:00:4,000
et crée potentiellement beaucoup de chômage

12
0:00:40.378,000 --> 0:00:43,000
remonte à au moins 200 ans, aux révoltes des Luddites en Angleterre.

13
0:00:44.29,000 --> 0:00:47,000
Depuis lors, cette préoccupation réapparaît régulièrement.

14
0:00:47.51,000 --> 0:00:49,000
Vous n’avez sans doute jamais entendu parler

15
0:00:50.071,000 --> 0:00:53,000
du memorandum sur les trois révolutions.

16
0:00:53.185,000 --> 0:00:55,000
C'est un rapport très important

17
0:00:55.478,000 --> 0:00:57,000
qui a été rédigé par un groupe de personnes brillantes,

18
0:00:58.069,000 --> 0:01:01,000
dont deux lauréats du prix Nobel.

19
0:01:01.138,000 --> 0:01:04,000
Présenté au Président des États-Unis,

20
0:01:04.385,000 --> 0:01:09,000
il avançait que les États-Unis étaient au bord de troubles sociaux

21
0:01:09.523,000 --> 0:01:12,000
car l'automatisation industrielle allait mettre des millions de personnes

22
0:01:13.029,000 --> 0:01:14,000
au chômage.

23
0:01:14.205,000 --> 0:01:17,000
Ce memorandum a été remis au président Lyndon Johnson

24
0:01:17.886,000 --> 0:01:18,000
en mars 1964.

25
0:01:19.711,000 --> 0:01:21,000
Cela fait maintenant plus de 50 ans.

26
0:01:21.927,000 --> 0:01:23,000
Bien sûr, ce n'est pas vraiment arrivé ainsi.

27
0:01:24.065,000 --> 0:01:26,000
L’histoire se répète ainsi plusieurs fois.

28
0:01:26.201,000 --> 0:01:3,000
On a sonné l'alarme régulièrement, toujours pour des fausses alertes.

29
0:01:30.347,000 --> 0:01:32,000
Le fait qu’il s’agissent de fausses alertes

30
0:01:32.416,000 --> 0:01:34,000
nous a rendus très conservateurs.

31
0:01:35.035,000 --> 0:01:37,000
Cela veut dire fondamentalement que, oui,

32
0:01:37.591,000 --> 0:01:39,000
la technologie peut ravager des industries entières.

33
0:01:40.163,000 --> 0:01:43,000
Elle peut anéantir des pans entiers de professions.

34
0:01:43.919,000 --> 0:01:44,000
Mais au même temps, bien sûr,

35
0:01:45.551,000 --> 0:01:47,000
le progrès va ouvrir de nouvelles possibilités.

36
0:01:47.926,000 --> 0:01:49,000
De nouvelles industries vont naître.

37
0:01:50.912,000 --> 0:01:52,000
Ces industries vont naturellement embaucher des gens.

38
0:01:53.794,000 --> 0:01:55,000
De nouveaux types de travail vont apparaître,

39
0:01:56.056,000 --> 0:01:59,000
des tâches que nous avons du mal à imaginer aujourd’hui.

40
0:01:59.266,000 --> 0:02:02,000
Telle est notre histoire jusqu'à présent, et c'est une histoire positive.

41
0:02:03.095,000 --> 0:02:06,000
Dans les faits, les nouveaux emplois créés

42
0:02:06.444,000 --> 0:02:08,000
sont généralement meilleurs que les anciens.

43
0:02:08.938,000 --> 0:02:1,000
Ils ont, par exemple, été plus impliquants.

44
0:02:11.618,000 --> 0:02:14,000
Ils sont mieux sécurisés et plus confortables,

45
0:02:15.071,000 --> 0:02:16,000
ils sont aussi payés davantage.

46
0:02:16.775,000 --> 0:02:2,000
Donc, une histoire positive. Jusqu'à présent, tout s'est bien passé.

47
0:02:21.292,000 --> 0:02:23,000
Mais il y a une classe de travailleurs

48
0:02:24.264,000 --> 0:02:26,000
pour laquelle l'histoire est assez différente.

49
0:02:27.938,000 --> 0:02:31,000
Pour ces travailleurs, la technologie a décimé leur travail,

50
0:02:32.168,000 --> 0:02:35,000
et n'a pas créé de nouvelles opportunités à la place.

51
0:02:35.395,000 --> 0:02:38,000
Et ces travailleurs, bien sûr, ce sont les chevaux.

52
0:02:38.95,000 --> 0:02:39,000
(Rires)

53
0:02:40.393,000 --> 0:02:42,000
Je vais poser une question provocante :

54
0:02:43.167,000 --> 0:02:46,000
est-il possible que dans le futur,

55
0:02:46.626,000 --> 0:02:5,000
une fraction significative des ressources humaines devienne obsolète

56
0:02:51.278,000 --> 0:02:52,000
comme les chevaux le furent ?

57
0:02:53.485,000 --> 0:02:56,000
Ça va vous faire réagir dans les tripes.

58
0:02:56.485,000 --> 0:02:57,000
Vous pourriez dire que c'est absurde.

59
0:02:58.302,000 --> 0:03:01,000
Comment peut-on comparer des humains aux chevaux ?

60
0:03:02.437,000 --> 0:03:03,000
Les chevaux sont évidemment limités.

61
0:03:04.396,000 --> 0:03:06,000
À l'arrivée des voitures, des camions et des tracteurs,

62
0:03:07.147,000 --> 0:03:09,000
les chevaux n'avaient nulle part où aller.

63
0:03:09.844,000 --> 0:03:11,000
Par contre, les humains sont intelligents.

64
0:03:12.204,000 --> 0:03:13,000
nous pouvons apprendre et nous adapter.

65
0:03:14.037,000 --> 0:03:15,000
Et en théorie, ça signifie

66
0:03:15.501,000 --> 0:03:17,000
qu'on peut toujours trouver quelque chose de neuf à faire,

67
0:03:18.376,000 --> 0:03:21,000
et qu'on peut continuer d'avoir du sens dans l'économie future.

68
0:03:21.706,000 --> 0:03:23,000
Il y a cependant un élément critique à comprendre.

69
0:03:24.79,000 --> 0:03:26,000
Les machines qui vont menacer les travailleurs

70
0:03:27.679,000 --> 0:03:3,000
ne ressemblent en rien aux voitures, camions et tracteurs

71
0:03:30.937,000 --> 0:03:31,000
qui ont remplacé les chevaux.

72
0:03:32.577,000 --> 0:03:36,000
L'avenir va être rempli des machines qui pensent, apprennent et s'adaptent.

73
0:03:37.412,000 --> 0:03:41,000
Cela signifie que la technologie commence désormais à empiéter

74
0:03:41.73,000 --> 0:03:43,000
sur cette capacité fondamentale qui fait de nous des humains,

75
0:03:44.619,000 --> 0:03:46,000
qui nous différencie des chevaux,

76
0:03:47.43,000 --> 0:03:49,000
cette caractéristique qui, jusqu'à présent,

77
0:03:49.688,000 --> 0:03:51,000
nous a permis de rester à la tête de la marche du progrès,

78
0:03:52.399,000 --> 0:03:53,000
de rester pertinent

79
0:03:53.572,000 --> 0:03:56,000
et qui est, en fait, indispensable à l'économie.

80
0:03:58.407,000 --> 0:04:,000
Qu'est-ce qui est donc vraiment si différent

81
0:04:00.926,000 --> 0:04:04,000
dans les technologies de l'information par rapport au passé ?

82
0:04:04.966,000 --> 0:04:06,000
Je voudrais souligner trois points fondamentaux.

83
0:04:07.641,000 --> 0:04:11,000
Le premier est que ce processus qui a lieu

84
0:04:12.074,000 --> 0:04:13,000
accélère de manière exponentielle.

85
0:04:14.42,000 --> 0:04:18,000
Vous connaissez tous la loi de Moore, mais il s'agit de bien davantage.

86
0:04:18.859,000 --> 0:04:21,000
Ça touche de nombreux niveaux, par exemple, les logiciels,

87
0:04:22.033,000 --> 0:04:25,000
les communications, les bandes passantes et ainsi de suite.

88
0:04:25.057,000 --> 0:04:26,000
La clé pour comprendre tout ça

89
0:04:27.065,000 --> 0:04:3,000
est que cette accélération a commencé il y a longtemps.

90
0:04:30.96,000 --> 0:04:31,000
En fait, ça dure depuis des décennies.

91
0:04:32.909,000 --> 0:04:34,000
Si vous mesurez à partir de la fin des années 50,

92
0:04:35.665,000 --> 0:04:37,000
quand les premier circuits intégrés ont été fabriqués,

93
0:04:38.19,000 --> 0:04:43,000
la puissance de calcul a été multipliée à la puissance 30 depuis lors.

94
0:04:44.127,000 --> 0:04:47,000
C'est un nombre extraordinaire pour n'importe quelle quantité.

95
0:04:47.815,000 --> 0:04:48,000
Nous devons en retirer le fait

96
0:04:49.305,000 --> 0:04:53,000
que nous sommes au point de vivre un saut quantique dans le progrès absolu.

97
0:04:54.086,000 --> 0:04:56,000
Les choses vont naturellement continuer à accélérer

98
0:04:57.085,000 --> 0:04:58,000
à partir de ce moment.

99
0:04:58.244,000 --> 0:05:,000
Alors que nous avons hâte de vivre les prochaines années,

100
0:05:00.934,000 --> 0:05:02,000
je pense que que nous allons vivre des choses

101
0:05:03.17,000 --> 0:05:04,000
auxquelles nous ne sommes pas préparés.

102
0:05:05.053,000 --> 0:05:06,000
Ça va nous époustoufler.

103
0:05:06.992,000 --> 0:05:07,000
Le deuxième élément crucial

104
0:05:08.318,000 --> 0:05:11,000
est que les machines, dans un sens restreint, commencent à penser.

105
0:05:12.188,000 --> 0:05:14,000
Je ne parle pas d'une intelligence artificielle de type humain

106
0:05:15.165,000 --> 0:05:17,000
ou d'intelligence artificielle de science-fiction.

107
0:05:17.653,000 --> 0:05:21,000
Je veux dire que les machines et les algorithmes prennent des décisions.

108
0:05:22.139,000 --> 0:05:25,000
Ils résolvent des problèmes, et plus important, ils apprennent.

109
0:05:26.023,000 --> 0:05:29,000
En fait, s'il y a une technologie vraiment centrale à cela,

110
0:05:29.35,000 --> 0:05:32,000
qui en est devenue la force motrice,

111
0:05:32.427,000 --> 0:05:35,000
c'est l'apprentissage des machines qui devient extrêmement puissante.

112
0:05:36.391,000 --> 0:05:38,000
C'est une technologie de rupture et évolutive.

113
0:05:39.561,000 --> 0:05:41,000
Un des meilleurs exemples que j'ai vus récemment

114
0:05:42.054,000 --> 0:05:44,000
est ce que le DeepMind de Google a été en mesure de faire

115
0:05:44.829,000 --> 0:05:45,000
avec son système AlphaGo.

116
0:05:46.406,000 --> 0:05:5,000
C'est le système qui a vaincu le meilleur joueur du monde

117
0:05:50.73,000 --> 0:05:51,000
à l'ancien jeu de go.

118
0:05:52.733,000 --> 0:05:53,000
À mes yeux de néophyte,

119
0:05:53.907,000 --> 0:05:56,000
il y a deux éléments caractéristiques au jeu de Go.

120
0:05:57.048,000 --> 0:05:59,000
Le premier est que pendant la partie,

121
0:05:59.368,000 --> 0:06:01,000
le nombre de configurations possibles sur le damier

122
0:06:02.258,000 --> 0:06:03,000
est fondamentalement infini.

123
0:06:03.693,000 --> 0:06:06,000
Il y a plus de possibilités que d'atomes dans l'univers.

124
0:06:07.98,000 --> 0:06:08,000
Ça signifie donc

125
0:06:09.188,000 --> 0:06:12,000
qu'on ne pourra jamais programmer un ordinateur pour gagner au go

126
0:06:12.785,000 --> 0:06:14,000
de la même manière que pour les échecs, par exemple,

127
0:06:15.265,000 --> 0:06:19,000
qui revient à utiliser une puissance de calcul brutale pour gagner.

128
0:06:19.563,000 --> 0:06:23,000
Bref, une approche plus sophistiquée et réfléchie, est nécessaire.

129
0:06:24.368,000 --> 0:06:27,000
La deuxième point qui distingue le go est le suivant :

130
0:06:27.663,000 --> 0:06:29,000
quand vous discutez avec des champions de go,

131
0:06:30.334,000 --> 0:06:34,000
ils vous disent qu'ils ne peuvent pas articuler clairement

132
0:06:34.843,000 --> 0:06:36,000
ce à quoi ils pensent en jouant.

133
0:06:37.082,000 --> 0:06:39,000
C'est souvent quelque chose de très intuitif,

134
0:06:39.299,000 --> 0:06:42,000
une impression furtive du mouvement qu'ils doivent faire.

135
0:06:42.645,000 --> 0:06:43,000
Compte tenu de ces deux qualités,

136
0:06:44.322,000 --> 0:06:47,000
je dirais que jouer du go à un niveau mondial

137
0:06:48.037,000 --> 0:06:51,000
doit être hors de portée de l'automatisation.

138
0:06:51.299,000 --> 0:06:55,000
Le fait que ce n'est pas le cas devrait nous alerter.

139
0:06:55.769,000 --> 0:06:58,000
La raison est qu'on a tendance à dessiner une ligne claire

140
0:06:59.71,000 --> 0:07:02,000
avec d'un côté tous les emplois et toutes les tâches

141
0:07:03.243,000 --> 0:07:09,000
perçues comme étant relativement routinières, répétitives et prévisibles.

142
0:07:09.391,000 --> 0:07:11,000
Ces emplois se trouvent dans divers secteurs industriels.

143
0:07:12.247,000 --> 0:07:15,000
Ça peut être des professions et des niveaux de compétences différents.

144
0:07:15.62,000 --> 0:07:18,000
Mais de par leur nature prévisible, on sait qu'à un moment donné,

145
0:07:19.35,000 --> 0:07:21,000
ils deviendront sensibles face à l'apprentissage automatique,

146
0:07:22.254,000 --> 0:07:23,000
et donc à l'automatisation.

147
0:07:23.673,000 --> 0:07:25,000
Ne nous y trompons pas, c'est beaucoup d'emplois.

148
0:07:26,000 --> 0:07:3,000
Sans doute à peu près de la moitié des emplois dans l'économie.

149
0:07:30.087,000 --> 0:07:32,000
De l'autre côté de cette ligne de démarcation,

150
0:07:32.295,000 --> 0:07:36,000
nous avons tous les emplois qui nécessitent une capacité

151
0:07:36.39,000 --> 0:07:38,000
perçue comme exclusivement humaine.

152
0:07:38.786,000 --> 0:07:4,000
Nous pensons que ces emplois seront préservés.

153
0:07:41.033,000 --> 0:07:43,000
Sur base de sur ce que je sais à propos du go,

154
0:07:43.322,000 --> 0:07:46,000
et je pensais aussi que ces emplois être du bon côté de la ligne,

155
0:07:47.025,000 --> 0:07:5,000
mais le fait que ce ne soit pas le cas, que Google ait résolu ce problème,

156
0:07:50.503,000 --> 0:07:52,000
suggère que cette ligne va être très dynamique.

157
0:07:52.707,000 --> 0:07:53,000
Elle va bouger.

158
0:07:53.91,000 --> 0:07:57,000
et engloutir de plus en plus d'emplois et tâches

159
0:07:58.069,000 --> 0:08:01,000
perçus actuellement comme étant préservés de l'automatisation.

160
0:08:01.921,000 --> 0:08:02,000
L'autre idée clé à comprendre

161
0:08:03.602,000 --> 0:08:08,000
est que cela n'affecte pas seulement les emplois peu rémunérés ou manuels,

162
0:08:08.74,000 --> 0:08:12,000
ou des emplois effectués par des personnes avec relativement peu d'éducation.

163
0:08:12.767,000 --> 0:08:13,000
De nombreuses preuves appuient le fait

164
0:08:14.611,000 --> 0:08:16,000
que ces technologies escaladent l'échelle des compétences.

165
0:08:17.523,000 --> 0:08:2,000
L'impact est déjà visible sur les emplois de spécialistes,

166
0:08:21.163,000 --> 0:08:25,000
des tâches effectuées par les comptables par exemple,

167
0:08:25.622,000 --> 0:08:26,000
les analystes financiers,

168
0:08:26.963,000 --> 0:08:27,000
les journalistes,

169
0:08:28.283,000 --> 0:08:3,000
les avocats, les radiologues et ainsi de suite.

170
0:08:30.66,000 --> 0:08:32,000
Donc, les nombreuses hypothèses que nous formulons

171
0:08:33.038,000 --> 0:08:35,000
sur le genre de professions, de tâches et d'emplois

172
0:08:35.89,000 --> 0:08:37,000
qui verront leur avenir compromis par l’automatisation,

173
0:08:38.733,000 --> 0:08:4,000
sont susceptibles de s’avérer erronées.

174
0:08:40.955,000 --> 0:08:41,000
Quand nous analysons ces tendances,

175
0:08:42.679,000 --> 0:08:44,000
elles nous montrent que nous pourrions très bien finir

176
0:08:45.295,000 --> 0:08:47,000
avec un futur où un chômage important est la norme.

177
0:08:48.254,000 --> 0:08:49,000
Ou au mieux,

178
0:08:49.43,000 --> 0:08:52,000
nous pourrions faire face à un sous-emploi larvé et des salaires stagnants,

179
0:08:53.235,000 --> 0:08:55,000
voire des salaires en baisse.

180
0:08:56.142,000 --> 0:08:58,000
Bien sûr, les inégalités augmenteront.

181
0:08:58.976,000 --> 0:09:03,000
Tout cela va entraîner une énorme pression sur la structure de la société.

182
0:09:04.944,000 --> 0:09:07,000
Au-delà de tout ceci, il y a un problème économique fondamental,

183
0:09:08.057,000 --> 0:09:13,000
qui se produit car l'emploi représente actuellement le principal mécanisme

184
0:09:13.276,000 --> 0:09:16,000
de distribution des revenus, et donc du pouvoir d'achat

185
0:09:16.845,000 --> 0:09:21,000
à tous ceux qui achètent les produits et les services que nous produisons.

186
0:09:22.831,000 --> 0:09:24,000
Une économie de marché dynamique est possible

187
0:09:25.37,000 --> 0:09:27,000
quand il y a beaucoup de consommateurs

188
0:09:27.514,000 --> 0:09:31,000
capables d'acheter les produits et services qui sont produits.

189
0:09:31.753,000 --> 0:09:34,000
Sans cela, on encourt le risque de stagnation économique,

190
0:09:35.598,000 --> 0:09:38,000
voire de déclin économique,

191
0:09:39.284,000 --> 0:09:41,000
car il n'y a tout simplement pas assez de clients

192
0:09:41.622,000 --> 0:09:43,000
pour acheter les produits et les services.

193
0:09:44.105,000 --> 0:09:45,000
Il est essentiel de se rendre compte

194
0:09:46.057,000 --> 0:09:53,000
que notre réussite commune dépend de l'accès à l'économie de marché.

195
0:09:53.698,000 --> 0:09:57,000
Pour visualiser ça, imaginez une personne vraiment exceptionnelle.

196
0:09:58.308,000 --> 0:10:,000
Imaginez Steve Jobs, au hasard,

197
0:10:01.32,000 --> 0:10:03,000
et abandonnez-le tout seul sur une île.

198
0:10:03.925,000 --> 0:10:05,000
Sur son île, il va tenter de se débrouiller,

199
0:10:06.243,000 --> 0:10:08,000
en ramassant des noix de coco, comme tout le monde.

200
0:10:08.805,000 --> 0:10:1,000
Il ne deviendra pas quelqu'un d'extraordinaire.

201
0:10:11.017,000 --> 0:10:14,000
La raison, bien sûr, c'est qu'il n'y a pas de marché

202
0:10:14.213,000 --> 0:10:16,000
où épanouir ses talents incroyables.

203
0:10:17.023,000 --> 0:10:2,000
L'accès au marché est donc crucial en tant qu'individu,

204
0:10:20.517,000 --> 0:10:24,000
tout comme pour l'ensemble du système en termes de durabilité.

205
0:10:25.063,000 --> 0:10:28,000
Donc la question devient : que pouvons-nous faire ?

206
0:10:29.285,000 --> 0:10:32,000
Je pense que nous pouvons envisager ça de façon utopique.

207
0:10:32.517,000 --> 0:10:35,000
Nous pouvons imaginer un avenir où nous devrons travailler moins,

208
0:10:35.61,000 --> 0:10:37,000
où nous aurons plus de temps pour nos loisirs,

209
0:10:38.233,000 --> 0:10:39,000
plus de temps à consacrer à nos familles,

210
0:10:40.185,000 --> 0:10:43,000
plus de temps pour faire des choses qu'on trouve enrichissantes,

211
0:10:43.464,000 --> 0:10:44,000
par exemple.

212
0:10:44.621,000 --> 0:10:45,000
C'est une vision formidable de l'avenir,

213
0:10:46.556,000 --> 0:10:49,000
que nous devrions essayer d'atteindre sans faute.

214
0:10:50.153,000 --> 0:10:53,000
En même temps, je pense cependant que nous devons rester réalistes

215
0:10:53.259,000 --> 0:10:55,000
et nous rendre compte que nous allons probablement

216
0:10:55.62,000 --> 0:10:58,000
affronter un problème grave de distribution des revenus.

217
0:10:59.178,000 --> 0:11:01,000
Beaucoup de gens vont rester sur le bord du chemin.

218
0:11:03.186,000 --> 0:11:05,000
Je pense que pour résoudre ce problème,

219
0:11:05.614,000 --> 0:11:07,000
nous devrons finalement trouver un moyen

220
0:11:07.736,000 --> 0:11:09,000
de découpler les revenus du travail traditionnel.

221
0:11:10.366,000 --> 0:11:12,000
Le meilleur moyen, et le plus direct, à ma connaissance,

222
0:11:13.256,000 --> 0:11:16,000
est de créer un revenu garanti, un revenu universel.

223
0:11:16.824,000 --> 0:11:18,000
L'idée fondamentale du revenu universel fait son chemin

224
0:11:19.522,000 --> 0:11:2,000
commence à attirer l'attention.

225
0:11:21.523,000 --> 0:11:23,000
Il y a beaucoup de projets pilotes,

226
0:11:23.796,000 --> 0:11:25,000
et des expériences en cours à travers le monde.

227
0:11:26.628,000 --> 0:11:29,000
Je pense que le revenu de base n'est pas la panacée.

228
0:11:29.852,000 --> 0:11:31,000
Ce n'est pas une solution réutilisable partout.

229
0:11:32.424,000 --> 0:11:33,000
Mais nous pouvons commencer par ça.

230
0:11:34.163,000 --> 0:11:36,000
C'est une idée que nous pouvons développer et affiner.

231
0:11:36.873,000 --> 0:11:39,000
Par exemple, j'ai beaucoup écrit au sujet de la possibilité

232
0:11:40.3,000 --> 0:11:44,000
d'associer des incitations explicites au revenu de base.

233
0:11:44.93,000 --> 0:11:45,000
Pour illustrer ça,

234
0:11:46.099,000 --> 0:11:48,000
imaginez que vous êtes un lycéen qui a du mal à s'en sortir

235
0:11:48.917,000 --> 0:11:5,000
et que vous risquez d'abandonner l'école.

236
0:11:52.289,000 --> 0:11:55,000
Et pourtant, supposons que vous sachiez qu'à un moment donné,

237
0:11:55.691,000 --> 0:11:56,000
quoi qu'il arrive,

238
0:11:56.939,000 --> 0:11:59,000
vous allez gagner le même revenu de base que tout le monde.

239
0:12:00.66,000 --> 0:12:03,000
À mon avis, cela crée une incitation très perverse

240
0:12:03.726,000 --> 0:12:05,000
de tout laisser tomber et d'abandonner l'école.

241
0:12:06.223,000 --> 0:12:08,000
Il ne faut donc pas structurer les choses de cette façon.

242
0:12:08.928,000 --> 0:12:13,000
À la place, offrons un revenu plus élevé aux diplômés du secondaire

243
0:12:14.092,000 --> 0:12:15,000
qu'à ceux qui ont abandonné le lycée.

244
0:12:16.329,000 --> 0:12:19,000
Nous pouvons prendre l'idée d'incitations incluses dans le revenu universel,

245
0:12:19.897,000 --> 0:12:2,000
et l'étendre à d'autres domaines.

246
0:12:21.522,000 --> 0:12:24,000
Nous pourrions créer une incitation pour travailler dans la communauté,

247
0:12:25.123,000 --> 0:12:26,000
pour aider les autres,

248
0:12:26.305,000 --> 0:12:29,000
ou encore pour avoir un impact positif sur l'environnement

249
0:12:29.393,000 --> 0:12:3,000
et ainsi de suite.

250
0:12:30.587,000 --> 0:12:33,000
En intégrant des incitations au sein d'un revenu de base,

251
0:12:33.622,000 --> 0:12:34,000
nous pouvons l'améliorer,

252
0:12:35.275,000 --> 0:12:37,000
et tout du moins, prendre quelques mesures

253
0:12:37.925,000 --> 0:12:39,000
vers la résolution d'un autre problème

254
0:12:40.374,000 --> 0:12:42,000
qui je le crains, va se poser à nous à l'avenir :

255
0:12:43.342,000 --> 0:12:46,000
comment allons-nous trouver sens et accomplissement,

256
0:12:47.118,000 --> 0:12:49,000
et qu'allons-nous faire de notre temps

257
0:12:49.46,000 --> 0:12:53,000
dans un monde où il y a moins de demande pour un travail traditionnel ?

258
0:12:54.201,000 --> 0:12:56,000
Donc en prolongeant et en raffinant un revenu universel,

259
0:12:57.03,000 --> 0:12:59,000
nous pouvons rendre cet avenir meilleur,

260
0:12:59.39,000 --> 0:13:02,000
et nous pouvons, peut-être, le rendre plus acceptable

261
0:13:03.322,000 --> 0:13:05,000
politiquement et socialement, et faisable.

262
0:13:05.876,000 --> 0:13:06,000
Naturellement, en agissant ainsi,

263
0:13:07.48,000 --> 0:13:1,000
nous augmentons les chances que cela arrive.

264
0:13:11.731,000 --> 0:13:13,000
Je pense que l'une des objections les plus fondamentales,

265
0:13:14.591,000 --> 0:13:15,000
presque instinctive,

266
0:13:16.217,000 --> 0:13:19,000
à l'idée d'un revenu universel disponible pour tous,

267
0:13:19.694,000 --> 0:13:22,000
et à l'expansion du filet de sécurité,

268
0:13:23.45,000 --> 0:13:26,000
est liée à notre peur de finir avec trop de personnes

269
0:13:26.73,000 --> 0:13:28,000
qui bénéficient de la manne économique,

270
0:13:28.996,000 --> 0:13:3,000
et trop peu pour en supporter la charge.

271
0:13:31.067,000 --> 0:13:33,000
Le message que j’essaye de faire passer,

272
0:13:33.925,000 --> 0:13:34,000
c'est que dans l'avenir,

273
0:13:35.31,000 --> 0:13:38,000
les machines vont être de plus en plus capables de supporter cette charge.

274
0:13:39.136,000 --> 0:13:41,000
Cela devrait nous donner plus de possibilités

275
0:13:41.276,000 --> 0:13:44,000
dans le choix des structures de notre société et de notre économie.

276
0:13:45.009,000 --> 0:13:48,000
Je pense qu'ultimement, ce ne sera plus un luxe,

277
0:13:48.475,000 --> 0:13:49,000
et que ça va devenir un impératif.

278
0:13:50.4,000 --> 0:13:52,000
La raison bien sûr, est que tout cela va créer

279
0:13:53.246,000 --> 0:13:55,000
un tel degré de pression sur la société,

280
0:13:55.284,000 --> 0:13:57,000
et parce que l'emploi est le mécanisme

281
0:13:57.822,000 --> 0:13:59,000
qui donne aux consommateurs leur pouvoir d'achat,

282
0:14:00.114,000 --> 0:14:02,000
qui leur permet de faire fonctionner l'économie.

283
0:14:02.383,000 --> 0:14:05,000
Si ce mécanisme s'érode à l'avenir,

284
0:14:05.922,000 --> 0:14:07,000
nous allons devoir le remplacer par autre chose

285
0:14:08.737,000 --> 0:14:12,000
sans quoi nous serons confrontés au risque que notre système ne soit pas pérenne.

286
0:14:12.939,000 --> 0:14:14,000
Selon moi, la ligne de flottaison,

287
0:14:15.345,000 --> 0:14:17,000
pour résoudre ces problèmes,

288
0:14:17.805,000 --> 0:14:2,000
et surtout trouver un moyen de construire une économie

289
0:14:21.229,000 --> 0:14:24,000
qui subviendra aux besoins de tous, à tous les niveaux de notre société,

290
0:14:25.151,000 --> 0:14:28,000
s’avérera l'un des plus importants défis auxquels nous sommes confrontés

291
0:14:28.715,000 --> 0:14:3,000
dans les années et les décennies à venir.

292
0:14:30.782,000 --> 0:14:31,000
Merci beaucoup.

293
0:14:32.054,000 --> 0:14:33,000
(Applaudissements)

