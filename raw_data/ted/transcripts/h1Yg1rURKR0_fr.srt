1
0:00:,000 --> 0:00:07,000
Traducteur: Elisabeth Buffard Relecteur: Ekaterina Atanasova

2
0:00:15.652,000 --> 0:00:17,000
Aujourd'hui nous parlons de persuasion morale.

3
0:00:18.303,000 --> 0:00:19,000
Qu'est-ce qui est moral et immoral

4
0:00:19.852,000 --> 0:00:21,000
dans le fait de changer les comportements des gens

5
0:00:22.268,000 --> 0:00:24,000
en ayant recours à la technologie et au design ?

6
0:00:24.619,000 --> 0:00:25,000
Et je ne sais pas à quoi vous vous attendez,

7
0:00:26.471,000 --> 0:00:28,000
mais pendant que je réfléchissais à la question,

8
0:00:28.519,000 --> 0:00:29,000
je me suis vite rendu compte

9
0:00:29.752,000 --> 0:00:32,000
que je ne suis pas en mesure de vous apporter des réponses.

10
0:00:33.086,000 --> 0:00:35,000
Je ne suis pas capable de vous dire ce qui est moral et immoral

11
0:00:35.402,000 --> 0:00:37,000
parce que nous vivons dans une société pluraliste.

12
0:00:38.318,000 --> 0:00:4,000
Mes valeurs peuvent être radicalement différentes

13
0:00:40.951,000 --> 0:00:41,000
de vos valeurs.

14
0:00:42.835,000 --> 0:00:45,000
Ce qui signifie que ce que je considère comme moral ou immoral d'après ça

15
0:00:46.254,000 --> 0:00:49,000
ne serait pas forcément ce que vous considdérez moral ou immoral.

16
0:00:49.985,000 --> 0:00:51,000
Mais je me suis aussi rendu compte qu'il y a une chose que je pouvais vous donner.

17
0:00:52.851,000 --> 0:00:55,000
Et c'est ce que ce type derrière moi a donné au monde,

18
0:00:55.91,000 --> 0:00:55,000
Socrate.

19
0:00:56.821,000 --> 0:00:57,000
Ce sont des questions.

20
0:00:58.268,000 --> 0:01:,000
Ce que je peux faire et ce que je souhaite faire avec vous

21
0:01:00.893,000 --> 0:01:02,000
c'est vous donner, comme cette question de départ,

22
0:01:02.913,000 --> 0:01:03,000
un ensemble de questions

23
0:01:04.228,000 --> 0:01:06,000
pour que vous trouviez par vous-mêmes

24
0:01:06.261,000 --> 0:01:07,000
couche après couche,

25
0:01:07.695,000 --> 0:01:09,000
comme quand on pèle un oignon

26
0:01:09.912,000 --> 0:01:11,000
pour arriver au coeur de ce en quoi vous croyez

27
0:01:12.128,000 --> 0:01:15,000
être la persuasion morale ou immorale.

28
0:01:15.46,000 --> 0:01:17,000
Et j'aimerais le faire avec deux ou trois exemples

29
0:01:18.328,000 --> 0:01:2,000
de technologies où les gens ont utilisé des éléments de jeux

30
0:01:21.311,000 --> 0:01:24,000
pour amener les gens à faire des choses.

31
0:01:24.628,000 --> 0:01:27,000
J'aimerais donc vous soumettre

32
0:01:28.094,000 --> 0:01:29,000
une première question très simple et très évidente :

33
0:01:29.627,000 --> 0:01:31,000
Quelles sont vos intentions si vous concevez quelque chose ?

34
0:01:32.445,000 --> 0:01:35,000
Et évidemment, il n'y a pas que les intentions manifestes,

35
0:01:35.678,000 --> 0:01:38,000
alors voici un autre exemple d'une de ces applications.

36
0:01:39.061,000 --> 0:01:41,000
Il y a deux ou trois de ces tableaux de bord écologiques en ce moment,

37
0:01:41.96,000 --> 0:01:42,000
des tableaux de bord installés dans des voitures

38
0:01:43.861,000 --> 0:01:45,000
qui essayent de vous motiver à adapter votre conduite pour économiser du carburant.

39
0:01:46.594,000 --> 0:01:47,000
Voici le Nissan MyLeaf,

40
0:01:48.211,000 --> 0:01:5,000
où votre style de conduite est comparé

41
0:01:50.508,000 --> 0:01:51,000
à celui d'autres gens,

42
0:01:52.227,000 --> 0:01:53,000
pour que vous puissiez rivaliser et être celui qui a

43
0:01:54.18,000 --> 0:01:55,000
la conduite la plus économe en carburant.

44
0:01:55.578,000 --> 0:01:57,000
Et ces trucs-là s'avèrent très efficaces,

45
0:01:57.844,000 --> 0:01:59,000
si efficaces qu'ils motivent les gens

46
0:02:00.461,000 --> 0:02:02,000
à adopter des styles de conduite à risque,

47
0:02:02.543,000 --> 0:02:03,000
comme de ne pas s'arrêter à un feu rouge.

48
0:02:04.285,000 --> 0:02:06,000
Parce que si vous le faites, vous devez arrêter et redémarrer le moteur,

49
0:02:06.506,000 --> 0:02:09,000
et ça consommerait pas mal de carburant, non ?

50
0:02:10.426,000 --> 0:02:14,000
Alors même si c'est une application très bien intentionnée,

51
0:02:14.771,000 --> 0:02:16,000
elle a manifestement un effet secondaire.

52
0:02:17.351,000 --> 0:02:19,000
Et voici un autre exemple de ces effets secondaires.

53
0:02:19.5,000 --> 0:02:2,000
Recommandable :

54
0:02:20.901,000 --> 0:02:23,000
un site qui permet aux parents de donner à leurs enfants de petits badges

55
0:02:24.55,000 --> 0:02:26,000
pour avoir fait les choses que les parents veulent que leurs enfants fassent,

56
0:02:26.75,000 --> 0:02:27,000
comme de lacer leurs chaussures.

57
0:02:28.085,000 --> 0:02:3,000
Et de prime abord, ça a l'air très sympa,

58
0:02:30.439,000 --> 0:02:31,000
très innocent et plein de bonnes intentions.

59
0:02:32.4,000 --> 0:02:35,000
Mais il s'avère, si vous examinez les recherches sur l'état d'esprit des gens,

60
0:02:36.284,000 --> 0:02:38,000
que se soucier des résultats,

61
0:02:38.319,000 --> 0:02:39,000
se soucier de la reconnaissance publique,

62
0:02:40.116,000 --> 0:02:43,000
se soucier de ce genre de marques de reconnaissance publique

63
0:02:43.501,000 --> 0:02:45,000
n'est pas forcément très utile

64
0:02:46.019,000 --> 0:02:48,000
pour votre bien-être psychologique à long terme.

65
0:02:48.216,000 --> 0:02:5,000
C'est mieux si vous vous souciez d'apprendre quelque chose.

66
0:02:51.05,000 --> 0:02:52,000
C'est mieux quand vous vous souciez de vous-même

67
0:02:52.883,000 --> 0:02:54,000
plutôt que de l'apparence que vous donnez aux autres.

68
0:02:55.869,000 --> 0:02:58,000
Ce genre d'outil destiné à vous motiver qu'on utilise

69
0:02:59.05,000 --> 0:03:,000
en fait pour lui-même

70
0:03:00.834,000 --> 0:03:02,000
a un effet secondaire à long terme

71
0:03:03.018,000 --> 0:03:04,000
dans la mesure où chaque fois qu'une technologie

72
0:03:04.735,000 --> 0:03:07,000
qui utilise quelque chose comme la reconnaissance ou le statut publics,

73
0:03:08.05,000 --> 0:03:1,000
nous l'entérinons en fait positivement

74
0:03:10.45,000 --> 0:03:13,000
comme quelque chose de bon et de normal dont se soucier,

75
0:03:13.884,000 --> 0:03:15,000
et de cette façon, on a potentiellement un effet préjudiciable

76
0:03:16.569,000 --> 0:03:2,000
au bien-être psychologique à long terme pour nous-mêmes en tant que culture.

77
0:03:20.651,000 --> 0:03:22,000
Et donc, c'est une deuxième question évidente :

78
0:03:23.119,000 --> 0:03:25,000
Quels sont les effets de ce que vous faites ?

79
0:03:25.751,000 --> 0:03:27,000
Les effets que vous avez avec le dispositif,

80
0:03:27.856,000 --> 0:03:28,000
comme l'économie de carburant

81
0:03:29.273,000 --> 0:03:31,000
de même que les effets des outils mêmes que vous utilisez

82
0:03:32.056,000 --> 0:03:34,000
pour amener les gens à faire des choses -

83
0:03:34.088,000 --> 0:03:35,000
la reconnaissance publique.

84
0:03:35.671,000 --> 0:03:37,000
C'est tout ? L'intention, l'effet ?

85
0:03:38.621,000 --> 0:03:39,000
Hé bien il y a des technologies

86
0:03:40.141,000 --> 0:03:41,000
qui combine manifestement les deux.

87
0:03:41.875,000 --> 0:03:43,000
Les effets à court terme et à long terme

88
0:03:44.24,000 --> 0:03:47,000
et une intention positive comme la liberté de Fred Stutzman,

89
0:03:47.292,000 --> 0:03:48,000
où le but de cette application

90
0:03:48.851,000 --> 0:03:51,000
est, en fait, nous sommes généralement tellement bombardés

91
0:03:52.122,000 --> 0:03:53,000
d'appels et de demandes d'autres personnes,

92
0:03:53.323,000 --> 0:03:55,000
avec ce dispositif, vous pouvez fermer la connectivité Internet

93
0:03:55.939,000 --> 0:03:58,000
du PC de votre choix pour une durée prédéfinie

94
0:03:59.323,000 --> 0:04:01,000
pour pouvoir vraiment travailler.

95
0:04:01.523,000 --> 0:04:02,000
Et je pense que la plupart d'entre nous conviendront,

96
0:04:02.856,000 --> 0:04:03,000
que c'est un truc bien intentionné

97
0:04:04.305,000 --> 0:04:06,000
et qui a également de bonnes conséquences.

98
0:04:06.422,000 --> 0:04:08,000
Pour reprendre les mots de Michel Foucault,

99
0:04:08.539,000 --> 0:04:1,000
« C'est une technologie du soi ».

100
0:04:10.756,000 --> 0:04:12,000
C'est une technologie qui permet à l'individu

101
0:04:13.107,000 --> 0:04:15,000
de déterminer sa propre trajectoire de vie,

102
0:04:15.455,000 --> 0:04:16,000
de se façonner.

103
0:04:17.339,000 --> 0:04:18,000
Mais le problème c'est,

104
0:04:18.455,000 --> 0:04:19,000
comme Foucault le souligne ,

105
0:04:20.256,000 --> 0:04:21,000
que chaque technologie du soi

106
0:04:22.055,000 --> 0:04:25,000
a pour revers une technologie de domination.

107
0:04:25.222,000 --> 0:04:29,000
Comme on le voit dans les démocraties libérales modernes d'aujourd'hui,

108
0:04:29.556,000 --> 0:04:31,000
la société, l'État,

109
0:04:31.675,000 --> 0:04:35,000
non seulement nous permet de déterminer notre moi, de le façonner,

110
0:04:36.054,000 --> 0:04:37,000
elle l'exige aussi de nous.

111
0:04:37.872,000 --> 0:04:39,000
Elle exige que nous nous auto-optimisions

112
0:04:40.206,000 --> 0:04:41,000
que nous nous contrôlions nous-mêmes,

113
0:04:41.756,000 --> 0:04:43,000
que nous nous gérions en permanence

114
0:04:44.205,000 --> 0:04:45,000
parce que c'est la seule façon

115
0:04:46.006,000 --> 0:04:48,000
de fonctionner pour une telle société libérale.

116
0:04:48.721,000 --> 0:04:52,000
Ces technologies veulent que nous restions dans le jeu

117
0:04:53.014,000 --> 0:04:55,000
que la société a mis au point pour nous.

118
0:04:55.656,000 --> 0:04:57,000
Elles veulent que nous y adaptions mieux encore.

119
0:04:58.121,000 --> 0:05:,000
Elles veulent que nous nous optimisions pour nous y adapter.

120
0:05:00.98,000 --> 0:05:03,000
Je ne dis pas que c'est forcément un mal.

121
0:05:04.51,000 --> 0:05:06,000
Je pense simplement que cet exemple

122
0:05:07.143,000 --> 0:05:09,000
nous indique une prise de conscience générale,

123
0:05:09.459,000 --> 0:05:12,000
que peu importe quelle technologie ou quelle conception on considère,

124
0:05:13.178,000 --> 0:05:18,000
même ce que nous considérons ainsi bien intentionné et aussi bon dans ses effets,

125
0:05:18.244,000 --> 0:05:19,000
comme la liberté de Stutzman,

126
0:05:19.477,000 --> 0:05:21,000
comporte certaines valeurs.

127
0:05:22.177,000 --> 0:05:23,000
Et nous pouvons nous interroger sur ces valeurs.

128
0:05:23.86,000 --> 0:05:24,000
Nous pouvons nous demander : est-ce une bonne chose

129
0:05:25.791,000 --> 0:05:28,000
que nous nous auto-optimisions en permanence

130
0:05:29.674,000 --> 0:05:3,000
pour nous adapter mieux à cette société ?

131
0:05:31.576,000 --> 0:05:32,000
Ou pour vous donner un autre exemple,

132
0:05:33.075,000 --> 0:05:34,000
que pensez-vous d'une technologie persuasive

133
0:05:34.959,000 --> 0:05:37,000
qui convainc les femmes musulmanes de porter leur foulard ?

134
0:05:38.659,000 --> 0:05:4,000
Est-ce une bonne ou une mauvaise technologie

135
0:05:40.943,000 --> 0:05:42,000
dans ses intentions ou ses effets ?

136
0:05:43.459,000 --> 0:05:44,000
Hé bien ça dépend essentiellement

137
0:05:44.859,000 --> 0:05:46,000
du type de valeurs que vous apportez

138
0:05:47.543,000 --> 0:05:49,000
pour rendre ce genre de jugements.

139
0:05:49.659,000 --> 0:05:51,000
Voilà une troisième question :

140
0:05:51.693,000 --> 0:05:52,000
Quelles valeurs utilisez-vous pour juger ?

141
0:05:53.245,000 --> 0:05:54,000
Et en parlant de valeurs,

142
0:05:55.094,000 --> 0:05:58,000
j'ai remarqué que dans le débat en ligne sur la persuasion morale,

143
0:05:58.38,000 --> 0:05:59,000
et quand je parle avec les gens,

144
0:06:00.178,000 --> 0:06:02,000
très souvent, il y a un préjugé bizarre.

145
0:06:02.967,000 --> 0:06:05,000
Et ce préjugé est que nous demandons,

146
0:06:06.227,000 --> 0:06:09,000
est-ce que ceci ou cela est « toujours» éthique ?

147
0:06:09.344,000 --> 0:06:11,000
C'est « toujours » acceptable ?

148
0:06:11.678,000 --> 0:06:12,000
Nous demandons des choses comme,

149
0:06:12.946,000 --> 0:06:14,000
Est-ce que ce formulaire de don à Oxfam,

150
0:06:15.212,000 --> 0:06:18,000
où le don mensuel régulier est la valeur prédéfinie par défaut

151
0:06:18.228,000 --> 0:06:2,000
et que les gens, peut-être sans que ce soit voulu,

152
0:06:20.312,000 --> 0:06:22,000
sont ainsi encouragés ou poussés

153
0:06:23.127,000 --> 0:06:25,000
à faire un don régulièrement au lieu d'un don unique,

154
0:06:25.524,000 --> 0:06:26,000
est-ce encore acceptable ?

155
0:06:26.89,000 --> 0:06:27,000
Est-ce encore éthique ?

156
0:06:28.276,000 --> 0:06:29,000
On prend les choses par le mauvais bout.

157
0:06:29.96,000 --> 0:06:3,000
Mais en fait, cette question

158
0:06:31.837,000 --> 0:06:31,000
« Est-ce encore éthique? »

159
0:06:32.747,000 --> 0:06:34,000
n'est qu'une façon de voir l'éthique.

160
0:06:35.077,000 --> 0:06:37,000
Parce que si vous regardez le début de l'éthique

161
0:06:37.668,000 --> 0:06:39,000
dans la culture occidentale,

162
0:06:39.893,000 --> 0:06:41,000
vous voyez une idée très différente

163
0:06:42.058,000 --> 0:06:43,000
de ce que l'éthique pourrait aussi bien être.

164
0:06:43.594,000 --> 0:06:47,000
Pour Aristote, l'éthique ne concernait pas la question,

165
0:06:47.692,000 --> 0:06:49,000
est-ce toujours bien ou est-ce mal ?

166
0:06:50.177,000 --> 0:06:53,000
L'éthique concernait la question de savoir comment vivre bien.

167
0:06:53.627,000 --> 0:06:55,000
Et il a mis cette notion dans le mot « arete»

168
0:06:55.789,000 --> 0:06:57,000
que nous traduisons à partir du grec ancien, par « vertu. »

169
0:06:58.71,000 --> 0:06:59,000
Mais il signifie en fait excellence.

170
0:07:00.335,000 --> 0:07:03,000
Cela signifie vivre votre plein potentiel

171
0:07:04.334,000 --> 0:07:06,000
d'être humain.

172
0:07:06.562,000 --> 0:07:07,000
Et c'est une idée,

173
0:07:07.746,000 --> 0:07:1,000
je crois, que Paul Richard Buchanan a joliment exprimée dans un essai récent

174
0:07:11.252,000 --> 0:07:13,000
lorsqu'il a dit, « Les produits sont des arguments vifs

175
0:07:13.703,000 --> 0:07:15,000
sur la façon dont nous devons vivre nos vies. »

176
0:07:15.801,000 --> 0:07:17,000
Nos modèles ne sont pas éthiques ou contraire à l'éthique

177
0:07:18.687,000 --> 0:07:22,000
dans la mesure où ils utilisent des moyens éthiques ou contraire à l'éthique pour nous persuader.

178
0:07:23.301,000 --> 0:07:24,000
Ils ont une composante morale

179
0:07:24.868,000 --> 0:07:28,000
seulement dans le genre de vision et d'aspiration à la belle vie

180
0:07:28.957,000 --> 0:07:3,000
qu'ils nous présentent.

181
0:07:31.653,000 --> 0:07:34,000
Et si vous examinez l'environnement conçu autour de nous

182
0:07:34.968,000 --> 0:07:35,000
à travers ce filtre,

183
0:07:36.164,000 --> 0:07:38,000
en vous demandant, « Quelle est la vision de la belle vie

184
0:07:38.385,000 --> 0:07:41,000
que nos produits, notre conception, nous présentent? «,

185
0:07:41.403,000 --> 0:07:43,000
alors ça vous donne souvent des frissons,

186
0:07:43.703,000 --> 0:07:45,000
en raison du peu que nous attendons l'un de l'autre,

187
0:07:46.055,000 --> 0:07:48,000
du peu que nous semblons réellement attendre

188
0:07:48.773,000 --> 0:07:51,000
de notre vie et de ce à quoi ressemble la belle vie.

189
0:07:52.356,000 --> 0:07:55,000
Donc, voilà la quatrième question, sur laquelle je voudrais vous laisser :

190
0:07:56.157,000 --> 0:07:57,000
Quelle vision de la belle vie

191
0:07:57.64,000 --> 0:08:,000
transparaissent dans vos conceptions ?

192
0:08:01.305,000 --> 0:08:02,000
Et en parlant de conception,

193
0:08:02.407,000 --> 0:08:05,000
vous remarquez que j'ai déjà élargi la discussion.

194
0:08:06.139,000 --> 0:08:1,000
Parce que nous ne parlons pas que de technologie persuasive ici,

195
0:08:10.874,000 --> 0:08:14,000
mais de toute conception que nous apportons dans le monde.

196
0:08:15.074,000 --> 0:08:16,000
Je ne sais pas si vous connaissez

197
0:08:16.456,000 --> 0:08:17,000
le grand chercheur en communication Paul Watzlawick

198
0:08:18.124,000 --> 0:08:19,000
qui, dans les années 1960, a soutenu que

199
0:08:19.972,000 --> 0:08:2,000
nous ne pouvons pas ne pas communiquer.

200
0:08:21.307,000 --> 0:08:23,000
Même si nous choisissons de garder le silence,

201
0:08:23.84,000 --> 0:08:27,000
nous avons choisi de garder le silence. Nous communiquons quelque chose en choisissant de garder le silence.

202
0:08:28.237,000 --> 0:08:3,000
Et de la même manière que nous ne pouvons pas ne pas communiquer,

203
0:08:30.841,000 --> 0:08:31,000
nous ne pouvons pas ne pas convaincre.

204
0:08:32.358,000 --> 0:08:34,000
Tout ce que nous faisons ou nous abstenons de faire,

205
0:08:34.657,000 --> 0:08:36,000
tout ce que nous apportons comme morceau de conception

206
0:08:37.523,000 --> 0:08:38,000
dans le monde

207
0:08:38.79,000 --> 0:08:4,000
a une composante persuasive.

208
0:08:41.074,000 --> 0:08:43,000
Il essaie d'affecter les gens.

209
0:08:43.19,000 --> 0:08:45,000
Il met en place une certaine vision de la belle vie

210
0:08:45.374,000 --> 0:08:46,000
là devant nous.

211
0:08:46.711,000 --> 0:08:47,000
Et c'est ce que Peter-Paul Verbeek,

212
0:08:48.697,000 --> 0:08:5,000
le philosophe néerlandais de la technologie, dit.

213
0:08:50.843,000 --> 0:08:54,000
Peu importe que nous en tant que concepteurs en ayons l'intention ou pas,

214
0:08:55.409,000 --> 0:08:56,000
nous matérialisons la moralité.

215
0:08:57.173,000 --> 0:09:,000
Nous rendons certaines choses plus difficiles et plus faciles à faire.

216
0:09:00.224,000 --> 0:09:01,000
Nous organisons l'existence des gens.

217
0:09:02.174,000 --> 0:09:04,000
Nous mettons une certaine vision de ce qui est bon ou mauvais

218
0:09:04.924,000 --> 0:09:07,000
ou normal ou habituel devant les gens

219
0:09:08.292,000 --> 0:09:1,000
par tout ce que nous mettons dans le monde.

220
0:09:10.841,000 --> 0:09:13,000
Même quelque chose d'aussi anodin que l'arrangement des chaises à l'école

221
0:09:14.357,000 --> 0:09:15,000
est une technologie persuasive.

222
0:09:15.791,000 --> 0:09:17,000
Parce qu'il présente et matérialise

223
0:09:18.607,000 --> 0:09:19,000
une certaine vision de la belle vie,

224
0:09:20.541,000 --> 0:09:23,000
la belle vie dans laquelle l'enseignement et l'apprentissage et l'écoute

225
0:09:24.023,000 --> 0:09:26,000
se résume à une personne qui enseigne, et les autres qui l'écoutent,

226
0:09:26.958,000 --> 0:09:29,000
dans laquelle l'apprentissage se fait en étant assis,

227
0:09:30.71,000 --> 0:09:32,000
dans laquelle vous apprenez par vous-même,

228
0:09:32.94,000 --> 0:09:34,000
dans laquelle vous n'êtes pas censé changer ces règles

229
0:09:35.19,000 --> 0:09:38,000
parce que les chaises sont fixées au sol.

230
0:09:38.44,000 --> 0:09:41,000
Et même quelque chose d'aussi anodin qu'une seule chaise design,

231
0:09:41.823,000 --> 0:09:42,000
comme celle-ci par Arne Jacobsen,

232
0:09:43.124,000 --> 0:09:44,000
est une technologie persuasive.

233
0:09:44.825,000 --> 0:09:47,000
Parce que, une fois encore, elle communique une idée de la belle vie.

234
0:09:48.24,000 --> 0:09:49,000
Une belle vie,

235
0:09:49.739,000 --> 0:09:51,000
une vie à la quelle vous consentez en tant que concepteur

236
0:09:51.94,000 --> 0:09:53,000
en disant, « Dans la belle vie,

237
0:09:54.027,000 --> 0:09:58,000
les biens sont produits aussi durablement ou non que cette chaise.

238
0:09:58.041,000 --> 0:10:,000
Les travailleurs sont traités aussi bien ou mal

239
0:10:00.663,000 --> 0:10:02,000
qu'on été traités les travailleurs qui ont construit cette chaise. »

240
0:10:03.307,000 --> 0:10:05,000
La belle vie est une vie où la conception est importante

241
0:10:05.64,000 --> 0:10:07,000
parce que de toute évidence, quelqu'un a pris le temps et a dépensé l'argent

242
0:10:08.374,000 --> 0:10:09,000
pour ce genre de chaise bien conçue,

243
0:10:10.238,000 --> 0:10:11,000
où la tradition est importante

244
0:10:11.657,000 --> 0:10:12,000
parce que c'est un classique traditionnel

245
0:10:13.458,000 --> 0:10:14,000
et quelqu'un s'est soucié de ça,

246
0:10:14.97,000 --> 0:10:15,000
et où il y a quelque chose comme la consommation flagrante,

247
0:10:16.922,000 --> 0:10:17,000
où 'il est bien et normal

248
0:10:18.49,000 --> 0:10:21,000
de dépenser une gigantesque somme d'argent pour une telle chaise

249
0:10:21.509,000 --> 0:10:24,000
pour signaler votre statut social à d'autres personnes.

250
0:10:24.924,000 --> 0:10:27,000
Donc c'est le genre de couches, le genre de questions

251
0:10:28.091,000 --> 0:10:29,000
que je voulais vous faire traverser aujourd'hui,

252
0:10:29.844,000 --> 0:10:31,000
la question de ce que sont les intentions

253
0:10:31.992,000 --> 0:10:33,000
que vous apportez lorsque vous concevez une chose.

254
0:10:34.458,000 --> 0:10:37,000
Quels sont les effets, prévus et involontaires, que vous avez ?

255
0:10:37.958,000 --> 0:10:38,000
Quelles sont les valeurs que vous utilisez

256
0:10:39.523,000 --> 0:10:4,000
pour les juger ?

257
0:10:40.875,000 --> 0:10:41,000
Quelles sont les vertus, les aspirations

258
0:10:42.342,000 --> 0:10:44,000
que vous exprimez réellement dans cette chose ?

259
0:10:45.061,000 --> 0:10:47,000
Et comment cela s'applique-t-il,

260
0:10:47.156,000 --> 0:10:48,000
non seulement à la technologie persuasive

261
0:10:49.148,000 --> 0:10:51,000
mais à tout ce que vous concevez ?

262
0:10:51.482,000 --> 0:10:52,000
Est-ce qu'on s'arrête là ?

263
0:10:53.384,000 --> 0:10:54,000
Je ne le pense pas.

264
0:10:55.017,000 --> 0:10:59,000
Je pense que toutes ces choses sont finalement informés

265
0:10:59.482,000 --> 0:11:,000
par le cur de tout cela,

266
0:11:01.2,000 --> 0:11:04,000
et ce n'est rien d'autre que la vie elle-même.

267
0:11:04.315,000 --> 0:11:06,000
Pourquoi, lorsque la question de ce qu'est la belle vie

268
0:11:07.215,000 --> 0:11:09,000
informe tout ce que nous concevons,

269
0:11:09.566,000 --> 0:11:11,000
devrions-nous nous arrêter à la conception et ne pas nous demander,

270
0:11:12.149,000 --> 0:11:14,000
comment cela s'applique-t-il à notre propre vie ?

271
0:11:14.882,000 --> 0:11:16,000
« Pourquoi la lampe ou la maison devrait-elle être un objet d'art,

272
0:11:17.617,000 --> 0:11:18,000
mais pas notre vie ? »

273
0:11:18.848,000 --> 0:11:19,000
comme le dit Michel Foucault.

274
0:11:20.464,000 --> 0:11:23,000
Juste pour vous donner un exemple concret de Buster Benson.

275
0:11:24.015,000 --> 0:11:26,000
Voici Buster en train de construire un appareil de musculation

276
0:11:26.53,000 --> 0:11:28,000
au bureau de sa nouvelle compagnie Habit Labs,

277
0:11:28.983,000 --> 0:11:3,000
où ils essayaient de construire d'autres applications

278
0:11:31,000 --> 0:11:32,000
comme Health Month (le mois de la santé) pour les gens.

279
0:11:32.982,000 --> 0:11:34,000
Et pourquoi construit-il un truc pareil?

280
0:11:35.562,000 --> 0:11:37,000
Bien, voici l'ensemble des axiomes

281
0:11:37.567,000 --> 0:11:4,000
que Habit Labs, la compagnie de Buster, a établi pour eux-mêmes

282
0:11:40.77,000 --> 0:11:43,000
sur la façon dont ils voulaient travailler en équipe

283
0:11:43.891,000 --> 0:11:44,000
quand ils construisent ces applications,

284
0:11:45.715,000 --> 0:11:47,000
un ensemble de principes moraux qu'ils se fixent

285
0:11:47.767,000 --> 0:11:48,000
pour travailler ensemble,

286
0:11:49.515,000 --> 0:11:5,000
et l'un d'eux étant,

287
0:11:50.913,000 --> 0:11:53,000
« Nous prenons soin de notre propre santé et gérons notre propre épuisement. »

288
0:11:53.995,000 --> 0:11:56,000
Parce qu'en fin de compte, comment pouvez-vous vous poser la question à vous-même

289
0:11:57.745,000 --> 0:11:58,000
et comment pouvez-vous trouver une réponse

290
0:11:59.212,000 --> 0:12:01,000
quant à quelle vision de la belle vie

291
0:12:01.512,000 --> 0:12:04,000
vous voulez transmettre et créer avec vos conceptions

292
0:12:04.613,000 --> 0:12:05,000
sans poser la question,

293
0:12:06.295,000 --> 0:12:07,000
quelle vision de la belle vie

294
0:12:07.779,000 --> 0:12:09,000
voulez-vous vivre vous-même ?

295
0:12:10.679,000 --> 0:12:14,000
Et sur ce, je vous remercie.

296
0:12:14.929,000 --> 0:12:16,000
(Applaudissements)

