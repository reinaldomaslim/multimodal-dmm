1
0:00:,000 --> 0:00:07,000
Translator: Thu-Huong Ha Reviewer: Morton Bast

2
0:00:15.684,000 --> 0:00:16,000
In Oxford in the 1950s,

3
0:00:17.546,000 --> 0:00:2,000
there was a fantastic doctor, who was very unusual,

4
0:00:21.314,000 --> 0:00:23,000
named Alice Stewart.

5
0:00:23.346,000 --> 0:00:26,000
And Alice was unusual partly because, of course,

6
0:00:26.489,000 --> 0:00:29,000
she was a woman, which was pretty rare in the 1950s.

7
0:00:29.969,000 --> 0:00:31,000
And she was brilliant, she was one of the,

8
0:00:32.08,000 --> 0:00:36,000
at the time, the youngest Fellow to be elected to the Royal College of Physicians.

9
0:00:36.896,000 --> 0:00:39,000
She was unusual too because she continued to work after she got married,

10
0:00:40.653,000 --> 0:00:42,000
after she had kids,

11
0:00:42.748,000 --> 0:00:45,000
and even after she got divorced and was a single parent,

12
0:00:45.756,000 --> 0:00:47,000
she continued her medical work.

13
0:00:48.039,000 --> 0:00:52,000
And she was unusual because she was really interested in a new science,

14
0:00:52.159,000 --> 0:00:54,000
the emerging field of epidemiology,

15
0:00:54.783,000 --> 0:00:57,000
the study of patterns in disease.

16
0:00:58.271,000 --> 0:01:,000
But like every scientist, she appreciated

17
0:01:00.439,000 --> 0:01:02,000
that to make her mark, what she needed to do

18
0:01:02.695,000 --> 0:01:06,000
was find a hard problem and solve it.

19
0:01:07.213,000 --> 0:01:09,000
The hard problem that Alice chose

20
0:01:09.757,000 --> 0:01:12,000
was the rising incidence of childhood cancers.

21
0:01:13.155,000 --> 0:01:15,000
Most disease is correlated with poverty,

22
0:01:15.345,000 --> 0:01:17,000
but in the case of childhood cancers,

23
0:01:17.614,000 --> 0:01:19,000
the children who were dying seemed mostly to come

24
0:01:20.218,000 --> 0:01:22,000
from affluent families.

25
0:01:22.663,000 --> 0:01:23,000
So, what, she wanted to know,

26
0:01:24.406,000 --> 0:01:27,000
could explain this anomaly?

27
0:01:27.488,000 --> 0:01:29,000
Now, Alice had trouble getting funding for her research.

28
0:01:30.271,000 --> 0:01:31,000
In the end, she got just 1,000 pounds

29
0:01:32.262,000 --> 0:01:34,000
from the Lady Tata Memorial prize.

30
0:01:34.517,000 --> 0:01:36,000
And that meant she knew she only had one shot

31
0:01:37.06,000 --> 0:01:39,000
at collecting her data.

32
0:01:39.102,000 --> 0:01:41,000
Now, she had no idea what to look for.

33
0:01:41.579,000 --> 0:01:44,000
This really was a needle in a haystack sort of search,

34
0:01:44.695,000 --> 0:01:46,000
so she asked everything she could think of.

35
0:01:47.317,000 --> 0:01:48,000
Had the children eaten boiled sweets?

36
0:01:49.15,000 --> 0:01:51,000
Had they consumed colored drinks?

37
0:01:51.223,000 --> 0:01:52,000
Did they eat fish and chips?

38
0:01:52.87,000 --> 0:01:54,000
Did they have indoor or outdoor plumbing?

39
0:01:54.878,000 --> 0:01:57,000
What time of life had they started school?

40
0:01:58.294,000 --> 0:02:01,000
And when her carbon copied questionnaire started to come back,

41
0:02:01.662,000 --> 0:02:03,000
one thing and one thing only jumped out

42
0:02:04.582,000 --> 0:02:06,000
with the statistical clarity of a kind that

43
0:02:07.118,000 --> 0:02:09,000
most scientists can only dream of.

44
0:02:09.958,000 --> 0:02:1,000
By a rate of two to one,

45
0:02:11.878,000 --> 0:02:13,000
the children who had died

46
0:02:13.959,000 --> 0:02:19,000
had had mothers who had been X-rayed when pregnant.

47
0:02:20.254,000 --> 0:02:24,000
Now that finding flew in the face of conventional wisdom.

48
0:02:24.759,000 --> 0:02:25,000
Conventional wisdom held

49
0:02:26.666,000 --> 0:02:29,000
that everything was safe up to a point, a threshold.

50
0:02:30.663,000 --> 0:02:32,000
It flew in the face of conventional wisdom,

51
0:02:32.99,000 --> 0:02:35,000
which was huge enthusiasm for the cool new technology

52
0:02:36.448,000 --> 0:02:39,000
of that age, which was the X-ray machine.

53
0:02:40.094,000 --> 0:02:44,000
And it flew in the face of doctors' idea of themselves,

54
0:02:44.318,000 --> 0:02:47,000
which was as people who helped patients,

55
0:02:48.126,000 --> 0:02:5,000
they didn't harm them.

56
0:02:50.822,000 --> 0:02:53,000
Nevertheless, Alice Stewart rushed to publish

57
0:02:54.51,000 --> 0:02:57,000
her preliminary findings in The Lancet in 1956.

58
0:02:58.094,000 --> 0:03:02,000
People got very excited, there was talk of the Nobel Prize,

59
0:03:02.102,000 --> 0:03:04,000
and Alice really was in a big hurry

60
0:03:04.222,000 --> 0:03:07,000
to try to study all the cases of childhood cancer she could find

61
0:03:08.013,000 --> 0:03:1,000
before they disappeared.

62
0:03:10.166,000 --> 0:03:14,000
In fact, she need not have hurried.

63
0:03:14.51,000 --> 0:03:18,000
It was fully 25 years before the British and medical --

64
0:03:18.701,000 --> 0:03:2,000
British and American medical establishments

65
0:03:21.573,000 --> 0:03:27,000
abandoned the practice of X-raying pregnant women.

66
0:03:27.677,000 --> 0:03:32,000
The data was out there, it was open, it was freely available,

67
0:03:33.158,000 --> 0:03:37,000
but nobody wanted to know.

68
0:03:37.382,000 --> 0:03:39,000
A child a week was dying,

69
0:03:40.066,000 --> 0:03:42,000
but nothing changed.

70
0:03:42.799,000 --> 0:03:48,000
Openness alone can't drive change.

71
0:03:49.054,000 --> 0:03:54,000
So for 25 years Alice Stewart had a very big fight on her hands.

72
0:03:54.671,000 --> 0:03:57,000
So, how did she know that she was right?

73
0:03:57.918,000 --> 0:04:,000
Well, she had a fantastic model for thinking.

74
0:04:01.581,000 --> 0:04:03,000
She worked with a statistician named George Kneale,

75
0:04:03.826,000 --> 0:04:05,000
and George was pretty much everything that Alice wasn't.

76
0:04:06.21,000 --> 0:04:09,000
So, Alice was very outgoing and sociable,

77
0:04:09.279,000 --> 0:04:11,000
and George was a recluse.

78
0:04:11.737,000 --> 0:04:15,000
Alice was very warm, very empathetic with her patients.

79
0:04:15.751,000 --> 0:04:19,000
George frankly preferred numbers to people.

80
0:04:19.79,000 --> 0:04:22,000
But he said this fantastic thing about their working relationship.

81
0:04:23.768,000 --> 0:04:29,000
He said, "My job is to prove Dr. Stewart wrong."

82
0:04:30.104,000 --> 0:04:33,000
He actively sought disconfirmation.

83
0:04:33.661,000 --> 0:04:35,000
Different ways of looking at her models,

84
0:04:35.998,000 --> 0:04:38,000
at her statistics, different ways of crunching the data

85
0:04:39.255,000 --> 0:04:42,000
in order to disprove her.

86
0:04:42.318,000 --> 0:04:47,000
He saw his job as creating conflict around her theories.

87
0:04:47.942,000 --> 0:04:5,000
Because it was only by not being able to prove

88
0:04:51.038,000 --> 0:04:53,000
that she was wrong,

89
0:04:53.406,000 --> 0:04:56,000
that George could give Alice the confidence she needed

90
0:04:56.527,000 --> 0:04:58,000
to know that she was right.

91
0:04:59.509,000 --> 0:05:03,000
It's a fantastic model of collaboration --

92
0:05:04.184,000 --> 0:05:09,000
thinking partners who aren't echo chambers.

93
0:05:09.191,000 --> 0:05:11,000
I wonder how many of us have,

94
0:05:11.543,000 --> 0:05:17,000
or dare to have, such collaborators.

95
0:05:18.462,000 --> 0:05:21,000
Alice and George were very good at conflict.

96
0:05:22.239,000 --> 0:05:25,000
They saw it as thinking.

97
0:05:25.375,000 --> 0:05:29,000
So what does that kind of constructive conflict require?

98
0:05:29.648,000 --> 0:05:32,000
Well, first of all, it requires that we find people

99
0:05:33.023,000 --> 0:05:35,000
who are very different from ourselves.

100
0:05:35.671,000 --> 0:05:39,000
That means we have to resist the neurobiological drive,

101
0:05:40.007,000 --> 0:05:44,000
which means that we really prefer people mostly like ourselves,

102
0:05:44.511,000 --> 0:05:46,000
and it means we have to seek out people

103
0:05:46.735,000 --> 0:05:48,000
with different backgrounds, different disciplines,

104
0:05:49.207,000 --> 0:05:53,000
different ways of thinking and different experience,

105
0:05:53.358,000 --> 0:05:56,000
and find ways to engage with them.

106
0:05:57.223,000 --> 0:06:01,000
That requires a lot of patience and a lot of energy.

107
0:06:01.867,000 --> 0:06:02,000
And the more I've thought about this,

108
0:06:03.678,000 --> 0:06:08,000
the more I think, really, that that's a kind of love.

109
0:06:08.839,000 --> 0:06:11,000
Because you simply won't commit that kind of energy

110
0:06:11.908,000 --> 0:06:15,000
and time if you don't really care.

111
0:06:16.599,000 --> 0:06:2,000
And it also means that we have to be prepared to change our minds.

112
0:06:21.059,000 --> 0:06:23,000
Alice's daughter told me

113
0:06:23.423,000 --> 0:06:26,000
that every time Alice went head-to-head with a fellow scientist,

114
0:06:26.535,000 --> 0:06:3,000
they made her think and think and think again.

115
0:06:30.719,000 --> 0:06:34,000
"My mother," she said, "My mother didn't enjoy a fight,

116
0:06:34.737,000 --> 0:06:39,000
but she was really good at them."

117
0:06:39.879,000 --> 0:06:43,000
So it's one thing to do that in a one-to-one relationship.

118
0:06:44.049,000 --> 0:06:47,000
But it strikes me that the biggest problems we face,

119
0:06:47.336,000 --> 0:06:49,000
many of the biggest disasters that we've experienced,

120
0:06:50.21,000 --> 0:06:51,000
mostly haven't come from individuals,

121
0:06:52.161,000 --> 0:06:53,000
they've come from organizations,

122
0:06:54.049,000 --> 0:06:56,000
some of them bigger than countries,

123
0:06:56.057,000 --> 0:06:58,000
many of them capable of affecting hundreds,

124
0:06:58.317,000 --> 0:07:02,000
thousands, even millions of lives.

125
0:07:02.32,000 --> 0:07:06,000
So how do organizations think?

126
0:07:06.758,000 --> 0:07:1,000
Well, for the most part, they don't.

127
0:07:10.784,000 --> 0:07:12,000
And that isn't because they don't want to,

128
0:07:13.777,000 --> 0:07:15,000
it's really because they can't.

129
0:07:16.182,000 --> 0:07:19,000
And they can't because the people inside of them

130
0:07:19.529,000 --> 0:07:23,000
are too afraid of conflict.

131
0:07:23.737,000 --> 0:07:25,000
In surveys of European and American executives,

132
0:07:26.601,000 --> 0:07:28,000
fully 85 percent of them acknowledged

133
0:07:29.571,000 --> 0:07:32,000
that they had issues or concerns at work

134
0:07:33.088,000 --> 0:07:36,000
that they were afraid to raise.

135
0:07:36.721,000 --> 0:07:39,000
Afraid of the conflict that that would provoke,

136
0:07:39.88,000 --> 0:07:41,000
afraid to get embroiled in arguments

137
0:07:42.248,000 --> 0:07:44,000
that they did not know how to manage,

138
0:07:44.279,000 --> 0:07:48,000
and felt that they were bound to lose.

139
0:07:48.856,000 --> 0:07:54,000
Eighty-five percent is a really big number.

140
0:07:55.033,000 --> 0:07:57,000
It means that organizations mostly can't do

141
0:07:57.848,000 --> 0:07:59,000
what George and Alice so triumphantly did.

142
0:08:00.176,000 --> 0:08:04,000
They can't think together.

143
0:08:04.575,000 --> 0:08:06,000
And it means that people like many of us,

144
0:08:06.816,000 --> 0:08:08,000
who have run organizations,

145
0:08:09,000 --> 0:08:12,000
and gone out of our way to try to find the very best people we can,

146
0:08:12.567,000 --> 0:08:18,000
mostly fail to get the best out of them.

147
0:08:18.84,000 --> 0:08:21,000
So how do we develop the skills that we need?

148
0:08:22.176,000 --> 0:08:26,000
Because it does take skill and practice, too.

149
0:08:26.259,000 --> 0:08:29,000
If we aren't going to be afraid of conflict,

150
0:08:29.673,000 --> 0:08:31,000
we have to see it as thinking,

151
0:08:31.832,000 --> 0:08:35,000
and then we have to get really good at it.

152
0:08:36.168,000 --> 0:08:4,000
So, recently, I worked with an executive named Joe,

153
0:08:40.432,000 --> 0:08:43,000
and Joe worked for a medical device company.

154
0:08:43.904,000 --> 0:08:45,000
And Joe was very worried about the device that he was working on.

155
0:08:46.879,000 --> 0:08:49,000
He thought that it was too complicated

156
0:08:49.904,000 --> 0:08:5,000
and he thought that its complexity

157
0:08:51.768,000 --> 0:08:55,000
created margins of error that could really hurt people.

158
0:08:56.035,000 --> 0:09:,000
He was afraid of doing damage to the patients he was trying to help.

159
0:09:00.175,000 --> 0:09:02,000
But when he looked around his organization,

160
0:09:02.48,000 --> 0:09:06,000
nobody else seemed to be at all worried.

161
0:09:06.941,000 --> 0:09:08,000
So, he didn't really want to say anything.

162
0:09:09.496,000 --> 0:09:11,000
After all, maybe they knew something he didn't.

163
0:09:11.68,000 --> 0:09:13,000
Maybe he'd look stupid.

164
0:09:14.264,000 --> 0:09:16,000
But he kept worrying about it,

165
0:09:16.47,000 --> 0:09:19,000
and he worried about it so much that he got to the point

166
0:09:19.516,000 --> 0:09:21,000
where he thought the only thing he could do

167
0:09:21.675,000 --> 0:09:25,000
was leave a job he loved.

168
0:09:25.805,000 --> 0:09:29,000
In the end, Joe and I found a way

169
0:09:29.805,000 --> 0:09:3,000
for him to raise his concerns.

170
0:09:31.66,000 --> 0:09:33,000
And what happened then is what almost always

171
0:09:34.531,000 --> 0:09:35,000
happens in this situation.

172
0:09:36.125,000 --> 0:09:39,000
It turned out everybody had exactly the same

173
0:09:39.346,000 --> 0:09:4,000
questions and doubts.

174
0:09:41.092,000 --> 0:09:45,000
So now Joe had allies. They could think together.

175
0:09:45.124,000 --> 0:09:48,000
And yes, there was a lot of conflict and debate

176
0:09:48.388,000 --> 0:09:52,000
and argument, but that allowed everyone around the table

177
0:09:52.692,000 --> 0:09:56,000
to be creative, to solve the problem,

178
0:09:56.772,000 --> 0:10:,000
and to change the device.

179
0:10:01.1,000 --> 0:10:04,000
Joe was what a lot of people might think of

180
0:10:04.476,000 --> 0:10:06,000
as a whistle-blower,

181
0:10:06.748,000 --> 0:10:08,000
except that like almost all whistle-blowers,

182
0:10:09.463,000 --> 0:10:11,000
he wasn't a crank at all,

183
0:10:11.836,000 --> 0:10:14,000
he was passionately devoted to the organization

184
0:10:15.284,000 --> 0:10:18,000
and the higher purposes that that organization served.

185
0:10:18.732,000 --> 0:10:21,000
But he had been so afraid of conflict,

186
0:10:22.548,000 --> 0:10:27,000
until finally he became more afraid of the silence.

187
0:10:27.628,000 --> 0:10:28,000
And when he dared to speak,

188
0:10:29.487,000 --> 0:10:32,000
he discovered much more inside himself

189
0:10:32.885,000 --> 0:10:37,000
and much more give in the system than he had ever imagined.

190
0:10:38.127,000 --> 0:10:41,000
And his colleagues don't think of him as a crank.

191
0:10:41.458,000 --> 0:10:46,000
They think of him as a leader.

192
0:10:46.586,000 --> 0:10:5,000
So, how do we have these conversations more easily

193
0:10:50.954,000 --> 0:10:51,000
and more often?

194
0:10:52.867,000 --> 0:10:53,000
Well, the University of Delft

195
0:10:54.853,000 --> 0:10:56,000
requires that its PhD students

196
0:10:57.25,000 --> 0:11:,000
have to submit five statements that they're prepared to defend.

197
0:11:01.163,000 --> 0:11:04,000
It doesn't really matter what the statements are about,

198
0:11:04.547,000 --> 0:11:07,000
what matters is that the candidates are willing and able

199
0:11:08.339,000 --> 0:11:1,000
to stand up to authority.

200
0:11:10.942,000 --> 0:11:12,000
I think it's a fantastic system,

201
0:11:13.306,000 --> 0:11:15,000
but I think leaving it to PhD candidates

202
0:11:15.819,000 --> 0:11:19,000
is far too few people, and way too late in life.

203
0:11:20.124,000 --> 0:11:23,000
I think we need to be teaching these skills

204
0:11:23.29,000 --> 0:11:27,000
to kids and adults at every stage of their development,

205
0:11:27.37,000 --> 0:11:29,000
if we want to have thinking organizations

206
0:11:29.819,000 --> 0:11:32,000
and a thinking society.

207
0:11:33.466,000 --> 0:11:38,000
The fact is that most of the biggest catastrophes that we've witnessed

208
0:11:39.084,000 --> 0:11:45,000
rarely come from information that is secret or hidden.

209
0:11:45.475,000 --> 0:11:49,000
It comes from information that is freely available and out there,

210
0:11:49.779,000 --> 0:11:51,000
but that we are willfully blind to,

211
0:11:52.163,000 --> 0:11:55,000
because we can't handle, don't want to handle,

212
0:11:55.291,000 --> 0:11:59,000
the conflict that it provokes.

213
0:11:59.698,000 --> 0:12:01,000
But when we dare to break that silence,

214
0:12:02.627,000 --> 0:12:04,000
or when we dare to see,

215
0:12:05.284,000 --> 0:12:07,000
and we create conflict,

216
0:12:07.539,000 --> 0:12:09,000
we enable ourselves and the people around us

217
0:12:10.164,000 --> 0:12:14,000
to do our very best thinking.

218
0:12:14.41,000 --> 0:12:17,000
Open information is fantastic,

219
0:12:17.786,000 --> 0:12:2,000
open networks are essential.

220
0:12:20.97,000 --> 0:12:21,000
But the truth won't set us free

221
0:12:22.947,000 --> 0:12:25,000
until we develop the skills and the habit and the talent

222
0:12:26.711,000 --> 0:12:3,000
and the moral courage to use it.

223
0:12:30.848,000 --> 0:12:33,000
Openness isn't the end.

224
0:12:34.608,000 --> 0:12:36,000
It's the beginning.

225
0:12:37.25,000 --> 0:12:48,000
(Applause)

