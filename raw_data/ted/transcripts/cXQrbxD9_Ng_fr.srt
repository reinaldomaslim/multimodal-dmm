1
0:00:,000 --> 0:00:07,000
Traducteur: Mathieu Bastien Relecteur: Mohand Habchi

2
0:00:12.328,000 --> 0:00:14,000
L'écrivain George Eliot nous a averti

3
0:00:15.277,000 --> 0:00:17,000
que de toutes les formes d'erreurs,

4
0:00:17.344,000 --> 0:00:19,000
la prophétie est la plus gratuite.

5
0:00:19.707,000 --> 0:00:2,000
Celui en qui nous verrons tous

6
0:00:21.555,000 --> 0:00:25,000
son homologue du vingtième siècle, Yogi Berra, disait de même :

7
0:00:25.857,000 --> 0:00:26,000
« Il est difficile de faire des prédictions,

8
0:00:27.722,000 --> 0:00:29,000
surtout concernant l'avenir. »

9
0:00:30.458,000 --> 0:00:31,000
Je vais ignorer leurs mises en garde

10
0:00:32.269,000 --> 0:00:33,000
et faire une prévision bien spécifique.

11
0:00:34.242,000 --> 0:00:36,000
Dans ce monde que nous créons si rapidement,

12
0:00:36.882,000 --> 0:00:37,000
nous allons voir de plus en plus de choses

13
0:00:38.595,000 --> 0:00:39,000
qui ressemblent à de la science-fiction

14
0:00:40.32,000 --> 0:00:43,000
et de moins en moins choses qui ressemblent à des postes de travail.

15
0:00:43.436,000 --> 0:00:45,000
Nos voitures vont trés rapidement commencer à se conduire toutes seules

16
0:00:46.188,000 --> 0:00:48,000
ce qui signifie que nous aurons besoin de moins de chauffeurs routiers.

17
0:00:48.884,000 --> 0:00:5,000
Siri et Watson seront bientôt connectés

18
0:00:51.005,000 --> 0:00:53,000
ce qui nous permettra de faire faire par des machines

19
0:00:53.602,000 --> 0:00:55,000
une bonne partie du travail actuel des centres d'appel

20
0:00:55.828,000 --> 0:00:57,000
et des spécialistes en diagnostic et solutions.

21
0:00:58.732,000 --> 0:01:,000
R2D2 est déjà là,

22
0:01:00.988,000 --> 0:01:03,000
peint en orange ; il travaille déjà pour nous

23
0:01:04.228,000 --> 0:01:06,000
à transporter des palettes dans des hangars,

24
0:01:06.777,000 --> 0:01:08,000
ce qui signifie qu'on a besoin de moins de personnel

25
0:01:08.852,000 --> 0:01:09,000
dans ces mêmes rayons.

26
0:01:10.818,000 --> 0:01:13,000
Bien. Cela fait près de deux cents ans

27
0:01:14.62,000 --> 0:01:16,000
qu'on annonce exactement ce que je suis en train de vous dire :

28
0:01:16.803,000 --> 0:01:18,000
que l'ère du chômage technologique approche.

29
0:01:19.62,000 --> 0:01:21,000
Les Luddites brisaient des métiers à tisser

30
0:01:22.035,000 --> 0:01:23,000
en Grande-Bretagne il y a déjà deux siècles.

31
0:01:23.931,000 --> 0:01:25,000
Or, ces prédictions étaient fausses.

32
0:01:25.963,000 --> 0:01:27,000
Les économies de nos pays développés ont bénéficié

33
0:01:28.78,000 --> 0:01:29,000
d'un quasi plein emploi.

34
0:01:30.714,000 --> 0:01:32,000
Ce qui nous amène à une question cruciale :

35
0:01:32.813,000 --> 0:01:34,000
qu'est-ce qui fait la différence cette fois-ci, si différence il y a ?

36
0:01:35.739,000 --> 0:01:37,000
La raison qui fait la différence est que, rien que ces dernières années,

37
0:01:38.735,000 --> 0:01:39,000
nos machines ont commencé à déployer des capacités

38
0:01:40.63,000 --> 0:01:42,000
totalement inédites jusqu'ici :

39
0:01:43.255,000 --> 0:01:46,000
compréhension, parole, ouïe, vue,

40
0:01:46.515,000 --> 0:01:5,000
réponse, écriture... et elles en acquièrent encore de nouvelles.

41
0:01:50.728,000 --> 0:01:52,000
Par exemple, les robots humanoïdes mobiles

42
0:01:53.298,000 --> 0:01:54,000
restent incroyablement primitifs,

43
0:01:55.245,000 --> 0:01:56,000
mais le département de recherche du ministère de la Défence

44
0:01:57.083,000 --> 0:01:58,000
vient de lancer un concours

45
0:01:58.598,000 --> 0:02:,000
pour les amener à accomplir des choses similaires.

46
0:02:00.912,000 --> 0:02:01,000
Et si on doit en juger par les éditions précédentes,

47
0:02:02.645,000 --> 0:02:04,000
ce concours sera une réussite.

48
0:02:05.044,000 --> 0:02:08,000
Quand je dresse un panorama, je me dis que nous connaîtrons bientôt le jour

49
0:02:08.68,000 --> 0:02:1,000
où des androïdes

50
0:02:10.856,000 --> 0:02:12,000
feront une bonne partie du travail que nous faisons aujourd'hui.

51
0:02:13.737,000 --> 0:02:16,000
Nous créons un monde dans lequel il va y avoir

52
0:02:17.495,000 --> 0:02:2,000
de plus en plus de technologie et de moins en moins d'emplois.

53
0:02:21.18,000 --> 0:02:23,000
C'est un monde que Erik Brynjolfsson et moi-même

54
0:02:23.429,000 --> 0:02:24,000
appelons « la nouvelle ère des machines. »

55
0:02:24.92,000 --> 0:02:26,000
Ce qu'il faut garder à l'esprit

56
0:02:27.053,000 --> 0:02:29,000
c'est qu'il s'agit d'une excellente nouvelle.

57
0:02:29.602,000 --> 0:02:32,000
C'est la meilleure nouvelle économique de la planète en ce moment.

58
0:02:32.919,000 --> 0:02:35,000
Mais on ne peut pas dire que la concurrence soit rude en la matière, n'est-ce pas ?

59
0:02:36.448,000 --> 0:02:37,000
C'est la meilleure nouvelle économique actuelle

60
0:02:38.347,000 --> 0:02:39,000
pour deux raisons principales.

61
0:02:39.963,000 --> 0:02:41,000
La première, c'est que le progrès technologique est ce qui nous permet

62
0:02:42.948,000 --> 0:02:45,000
de poursuivre sur cette incroyable lancée qui est la nôtre

63
0:02:46.685,000 --> 0:02:48,000
et par laquelle la production augmente avec le temps

64
0:02:49.206,000 --> 0:02:52,000
tandis que les prix baissent

65
0:02:52.532,000 --> 0:02:56,000
et que le volume et la qualité ne cessent d'exploser.

66
0:02:56.736,000 --> 0:02:58,000
Certes, certains voient en cela

67
0:02:58.737,000 --> 0:02:59,000
du matérialisme superficiel.

68
0:03:00.143,000 --> 0:03:02,000
Mais ce n'est pas comme ça qu'il faut le voir.

69
0:03:02.561,000 --> 0:03:04,000
L'abondance :

70
0:03:05.056,000 --> 0:03:08,000
voila ce que que l'on veut voir de la part de notre système économique.

71
0:03:08.478,000 --> 0:03:11,000
La deuxième raison pour laquelle la nouvelle ère des machines

72
0:03:11.694,000 --> 0:03:13,000
est une si bonne nouvelle est que, une fois que les androïdes

73
0:03:14,000 --> 0:03:17,000
commenceront à travailler, nous n'aurons plus besoin de le faire,

74
0:03:17.252,000 --> 0:03:2,000
ce qui nous libérera des corvées et des durs labeurs.

75
0:03:21.008,000 --> 0:03:23,000
Quand je parle de ça avec mes amis

76
0:03:23.032,000 --> 0:03:25,000
à Cambridge et à Silicon Valley, ils disent :

77
0:03:25.584,000 --> 0:03:27,000
« Génial. Plus de corvées, plus de durs labeurs.

78
0:03:27.857,000 --> 0:03:29,000
Ça nous donne la possibilité d'imaginer

79
0:03:29.908,000 --> 0:03:31,000
une société entièrement différente,

80
0:03:32.201,000 --> 0:03:34,000
une société où les créateurs, découvreurs,

81
0:03:35.113,000 --> 0:03:36,000
acteurs et innovateurs

82
0:03:36.942,000 --> 0:03:39,000
se réunissent avec leurs clients et leurs bailleurs de fonds

83
0:03:40.451,000 --> 0:03:42,000
pour évoquer et envisager divers sujets,

84
0:03:43.13,000 --> 0:03:45,000
s'inspirer mutuellement et confronter leurs idées. »

85
0:03:45.208,000 --> 0:03:49,000
Une société qui, dans le fond, ressemble beaucoup à une conférence TED.

86
0:03:49.783,000 --> 0:03:51,000
Et il y a en ça une grande part de vérité.

87
0:03:52.266,000 --> 0:03:55,000
Nous voyons une incroyable éclosion prendre forme.

88
0:03:55.289,000 --> 0:03:57,000
Dans un monde où générer un objet

89
0:03:57.291,000 --> 0:04:,000
est tout aussi facile que d'imprimer un document,

90
0:04:00.698,000 --> 0:04:02,000
les possibilités qui s'offrent à nous sont fascinantes.

91
0:04:02.787,000 --> 0:04:05,000
Ceux qui étaient naguère des artisans et des amateurs

92
0:04:06.464,000 --> 0:04:07,000
sont de nos jours des concepteurs et ont à leur actif

93
0:04:08.331,000 --> 0:04:1,000
des tonnes d'innovations.

94
0:04:10.721,000 --> 0:04:12,000
Des artistes qui se sentaient limités

95
0:04:13.003,000 --> 0:04:16,000
peuvent maintenant faire des choses qui ne leur avaient jamais été possibles

96
0:04:16.171,000 --> 0:04:17,000
auparavant.

97
0:04:18.067,000 --> 0:04:2,000
Nous sommes donc dans une période florissante.

98
0:04:20.184,000 --> 0:04:22,000
Et plus j'observe, plus je suis convaincu

99
0:04:23.116,000 --> 0:04:26,000
que cette citation du physicien Freeman Dyson

100
0:04:26.19,000 --> 0:04:28,000
n'est pas hyperbolique du tout.

101
0:04:28.223,000 --> 0:04:3,000
Il s'agit là d'un constat.

102
0:04:31.013,000 --> 0:04:33,000
Nous vivons au cours d'une période fascinante.

103
0:04:33.742,000 --> 0:04:35,000
Ce qui soulève une autre grande question :

104
0:04:36.533,000 --> 0:04:38,000
qu'est-ce qui pourrait bien mal tourner dans cette nouvelle ère des machines ?

105
0:04:39.509,000 --> 0:04:42,000
Hein ? Persévère, prospère, puis rentre à la maison.

106
0:04:42.871,000 --> 0:04:44,000
Nous allons faire face à deux séries de défis particulièrement épineux

107
0:04:45.537,000 --> 0:04:47,000
à mesure que nous nous enfonçons dans le futur que nous sommes en train de créer.

108
0:04:48.33,000 --> 0:04:51,000
Les premiers sont d'ordre économique et joliment résumés

109
0:04:51.58,000 --> 0:04:53,000
par un échange apocryphe

110
0:04:54.12,000 --> 0:04:57,000
entre Henry Ford II et Walter Reuther,

111
0:04:57.712,000 --> 0:04:59,000
qui était à la tête du syndicat des ouvriers de l'automobile.

112
0:05:00.457,000 --> 0:05:02,000
Alors qu'ils faisaient la tournée des nouvelles usines modernes

113
0:05:02.64,000 --> 0:05:04,000
Ford, se tourna vers Reuther et lui dit d'un air jovial :

114
0:05:05.39,000 --> 0:05:07,000
« Hé Walter, comment tu vas t'y prendre pour faire payer

115
0:05:07.552,000 --> 0:05:08,000
les cotisations syndicales à ces robots ? »

116
0:05:09.366,000 --> 0:05:1,000
Et Reuther réplique : « Hé Henry,

117
0:05:11.311,000 --> 0:05:15,000
comment tu vas t'y prendre pour leur faire acheter des voitures ? »

118
0:05:15.853,000 --> 0:05:18,000
Le problème de Reuther dans cette anecdote

119
0:05:18.864,000 --> 0:05:22,000
est qu'il est difficile de proposer sa force de travail

120
0:05:22.973,000 --> 0:05:23,000
dans une économie pleine de machines,

121
0:05:24.608,000 --> 0:05:26,000
et c'est clairement se que disent les statistiques.

122
0:05:26.832,000 --> 0:05:28,000
Si on regarde les dernières décennies,

123
0:05:29.224,000 --> 0:05:32,000
le retour sur capital, -- c'est-à-dire les profits des entreprises,

124
0:05:32.888,000 --> 0:05:33,000
a augmenté. Et on voit qu'il est maintenant

125
0:05:34.572,000 --> 0:05:36,000
à son plus haut niveau jamais atteint.

126
0:05:36.659,000 --> 0:05:38,000
Si on regarde le retour sur travail, c'est à dire

127
0:05:39.36,000 --> 0:05:4,000
le total des salaires dans l'économie,

128
0:05:41.244,000 --> 0:05:43,000
on voit qu'il se trouve à son niveau le plus bas

129
0:05:43.791,000 --> 0:05:46,000
et qu'il continue à dégringoler à vive allure.

130
0:05:46.856,000 --> 0:05:47,000
C'est clairement une mauvaise nouvelle pour Reuther.

131
0:05:48.626,000 --> 0:05:51,000
On pourrait croire que c'est une bonne nouvelle pour Ford,

132
0:05:52.024,000 --> 0:05:54,000
mais en fait non. Si on veut vendre

133
0:05:54.328,000 --> 0:05:57,000
de grandes quantités de marchandises relativement chères,

134
0:05:57.672,000 --> 0:06:,000
ce qu'il faut c'est une classe moyenne large, stable et prospère.

135
0:06:01.46,000 --> 0:06:03,000
Nous avons connu cela en Amérique

136
0:06:03.684,000 --> 0:06:05,000
pendant presque toute la période d'après-guerre.

137
0:06:06.317,000 --> 0:06:1,000
Mais la classe moyenne fait aujourd'hui face à une grande menace.

138
0:06:10.669,000 --> 0:06:11,000
Nous avons tous la tête pleine de ces statistiques,

139
0:06:12.08,000 --> 0:06:14,000
mais je vais en reprendre juste une :

140
0:06:14.439,000 --> 0:06:16,000
le revenu médian en Amérique a baissé

141
0:06:17.206,000 --> 0:06:18,000
sur les 15 dernières années,

142
0:06:18.897,000 --> 0:06:19,000
et nous courrons le risque de tomber dans

143
0:06:20.612,000 --> 0:06:23,000
un cercle vicieux où l'inégalité et la polarisation

144
0:06:24.537,000 --> 0:06:27,000
continuent à s'accroître avec le temps.

145
0:06:27.717,000 --> 0:06:29,000
Les phénomènes de société qui accompagnent

146
0:06:30.116,000 --> 0:06:32,000
ce genre d'inégalités méritent notre attention.

147
0:06:32.692,000 --> 0:06:33,000
Il s'agit d'une série de changements de société

148
0:06:34.36,000 --> 0:06:35,000
qui ne me préoccupent pas tant que ça

149
0:06:36.304,000 --> 0:06:38,000
et que des images comme celle-ci rendent bien.

150
0:06:38.655,000 --> 0:06:39,000
Ce n'est pas le genre de problèmes de société

151
0:06:40.477,000 --> 0:06:42,000
qui me préoccupe.

152
0:06:42.941,000 --> 0:06:44,000
Les dystopies sur ce qui se passera

153
0:06:45.084,000 --> 0:06:48,000
quand nos machines deviendront conscientes et décideront

154
0:06:48.567,000 --> 0:06:51,000
de se soulever et de nous attaquer ne manquent pas.

155
0:06:51.743,000 --> 0:06:52,000
Je commencerai à me faire du souci là-dessus

156
0:06:53.49,000 --> 0:06:56,000
le jour où mon ordinateur reconnaîtra mon imprimante.

157
0:06:56.719,000 --> 0:06:59,000
(Rires) (Applaudissements)

158
0:07:00.348,000 --> 0:07:02,000
Il ne s'agit donc pas des défis dont nous devons nous soucier.

159
0:07:03.32,000 --> 0:07:05,000
Pour vous aborder les défis de société

160
0:07:06.108,000 --> 0:07:08,000
auxquels nous serons confrontés dans la nouvelle ère des machines,

161
0:07:08.32,000 --> 0:07:11,000
je vais vous raconter une histoire sur deux travailleurs américains typiques.

162
0:07:12.031,000 --> 0:07:13,000
Pour en faire de vrais stéréotypes,

163
0:07:13.799,000 --> 0:07:15,000
disons qu'ils sont tous les deux blancs.

164
0:07:15.946,000 --> 0:07:18,000
Le premier a un diplôme universitaire,

165
0:07:19.708,000 --> 0:07:22,000
il est du type créatif, du genre manager,

166
0:07:22.854,000 --> 0:07:24,000
ingénieur, docteur, avocat... ce genre-là.

167
0:07:25.605,000 --> 0:07:27,000
On va l'appeler Ted.

168
0:07:28.024,000 --> 0:07:3,000
Il représente le haut de la classe moyenne américaine.

169
0:07:30.297,000 --> 0:07:32,000
L'autre n'a pas de diplôme universitaire,

170
0:07:33.179,000 --> 0:07:36,000
il est ouvrier, employé de bureau,

171
0:07:36.243,000 --> 0:07:39,000
a un emploi dans un secteur tertiaire de bas-niveau ou secondaire.

172
0:07:39.555,000 --> 0:07:41,000
On va appeler ce gars-là Bill.

173
0:07:41.96,000 --> 0:07:43,000
Si vous remontez 50 ans en arrière,

174
0:07:44.039,000 --> 0:07:47,000
Bill et Ted menaient des vies remarquablement semblables.

175
0:07:47.856,000 --> 0:07:49,000
Par exemple, en 1960, ils avaient tous les deux toutes les chances

176
0:07:50.359,000 --> 0:07:53,000
d'avoir un emploi à plein temps, d'au moins 40 heures par semaine.

177
0:07:53.729,000 --> 0:07:56,000
Mais comme l'a démontré, documents à l'appui, le sociologue Charles Murray,

178
0:07:57.025,000 --> 0:07:59,000
à mesure que nous avons automatisé l'économie,

179
0:07:59.993,000 --> 0:08:03,000
et 1960 n'est que le point de départ de l'utilisation des ordinateurs par les entreprises,

180
0:08:04.14,000 --> 0:08:06,000
à mesure que nous avons commencé à injecter progressivement de la technologie,

181
0:08:07.011,000 --> 0:08:09,000
des automates et des outils numériques dans l'économie,

182
0:08:09.747,000 --> 0:08:12,000
le sort de Bill et celui de Ted ont beaucoup divergé.

183
0:08:12.772,000 --> 0:08:14,000
Sur toute cette échelle de temps, Ted a gardé

184
0:08:14.891,000 --> 0:08:16,000
un emploi à plein temps. Mais pas Bill.

185
0:08:17.643,000 --> 0:08:21,000
Dans de nombreux cas, Bill a entièrement disparu de l'économie,

186
0:08:21.914,000 --> 0:08:23,000
alors que Ted presque jamais.

187
0:08:24.178,000 --> 0:08:27,000
Avec le temps, le couple de Ted a bien tenu.

188
0:08:27.443,000 --> 0:08:28,000
Pas celui de Bill.

189
0:08:29.084,000 --> 0:08:32,000
Les enfants de Ted ont grandi dans un foyer à deux parents,

190
0:08:32.406,000 --> 0:08:35,000
alors que ceux de Bill, tout au contraire, à mesure qu'on avance dans le temps.

191
0:08:35.626,000 --> 0:08:37,000
D'autres formes d'exclusion sociale de Bill ?

192
0:08:38.03,000 --> 0:08:41,000
Son abstention aux élections présidentielles a augmenté,

193
0:08:41.719,000 --> 0:08:44,000
et il a commencé à aller en prison bien plus souvent.

194
0:08:45.712,000 --> 0:08:48,000
Je ne peux pas raconter une histoire heureuse sur ces tendances sociales

195
0:08:49.696,000 --> 0:08:51,000
de même qu'elles ne montrent aucun signe d'inversion.

196
0:08:52.443,000 --> 0:08:54,000
Elles restent vraies quel que soit le groupe ethnique

197
0:08:55.416,000 --> 0:08:56,000
ou démographique observé,

198
0:08:57.137,000 --> 0:08:59,000
et elles prennent une telle ampleur

199
0:08:59.213,000 --> 0:09:,000
qu'elles risquent même d'effacer

200
0:09:00.984,000 --> 0:09:03,000
les incroyables progrès réalisés grâce au mouvement des droits civiques.

201
0:09:04.632,000 --> 0:09:06,000
Ce que mes amis à Silicon Valley et à Cambridge

202
0:09:07.144,000 --> 0:09:12,000
refusent de voir c'est qu'ils sont Ted.

203
0:09:12.395,000 --> 0:09:15,000
Ils vivent une vie pleine, épatante, productive,

204
0:09:15.832,000 --> 0:09:17,000
avec tous les avantages qui vont avec,

205
0:09:18.222,000 --> 0:09:2,000
alors que Bill lui mène une vie bien différente.

206
0:09:20.657,000 --> 0:09:22,000
Tous deux démontrent que Voltaire ne s'était pas trompé

207
0:09:22.797,000 --> 0:09:24,000
lorsqu'il parlait des bénéfices du travail

208
0:09:25.049,000 --> 0:09:28,000
et du fait qu'il nous éloigne non pas d'un mais de trois grands maux.

209
0:09:28.63,000 --> 0:09:28,000
[« Le travail éloigne de nous trois grands maux : l'ennui, le vice et le besoin. »]

210
0:09:29.627,000 --> 0:09:32,000
Ces défis, qu'est-ce qu'on en fait ?

211
0:09:32.963,000 --> 0:09:34,000
Le scénario économique est étonnamment clair là-dessus,

212
0:09:35.546,000 --> 0:09:38,000
étonnamment direct, et encore plus catégorique à court terme.

213
0:09:38.686,000 --> 0:09:4,000
Les robots ne vont pas nous voler tous nos emplois dans les deux ans à venir,

214
0:09:41.578,000 --> 0:09:45,000
donc la théorie économique classique suffira à :

215
0:09:46.046,000 --> 0:09:48,000
encourager l'entrepreneuriat,

216
0:09:48.198,000 --> 0:09:5,000
doubler la mise sur les infrastructures

217
0:09:50.394,000 --> 0:09:51,000
et s'assurer que notre système éducatif

218
0:09:52.093,000 --> 0:09:55,000
produise des individus avec les compétences appropriées.

219
0:09:55.69,000 --> 0:09:58,000
Mais sur le long terme, si on se dirige vers une économie

220
0:09:58.967,000 --> 0:10:,000
à haute teneur en technologie et faible teneur en force de travail,

221
0:10:01.619,000 --> 0:10:03,000
comme c'est le cas, alors il nous faut envisager

222
0:10:04.047,000 --> 0:10:05,000
des interventions plus radicales,

223
0:10:05.831,000 --> 0:10:08,000
par exemple, quelque chose comme un revenu minimum garanti.

224
0:10:09.03,000 --> 0:10:12,000
Certains dans cette pièce pourraient se sentir mal à l'aise en entendant ça,

225
0:10:12.742,000 --> 0:10:15,000
parce que cette idée est associée à l'extrême gauche

226
0:10:16.599,000 --> 0:10:19,000
et à des programmes de redistribution des richesses plutôt radicaux.

227
0:10:19.818,000 --> 0:10:2,000
Je me suis penché sur cette notion

228
0:10:21.771,000 --> 0:10:23,000
et ça pourrait calmer certains esprits de savoir

229
0:10:24.226,000 --> 0:10:26,000
que l'idée d'un revenu net minimum garanti

230
0:10:26.858,000 --> 0:10:29,000
a été défendue par ces socialistes enragés que sont

231
0:10:30.035,000 --> 0:10:35,000
Friedrich Hayek, Richard Nixon et Milton Friedman.

232
0:10:35.508,000 --> 0:10:36,000
Et si vous en venez à vous faire du souci

233
0:10:37.387,000 --> 0:10:4,000
en pensant qu'un tel revenu garanti

234
0:10:40.696,000 --> 0:10:42,000
pourrait nous enlever l'envie de réussir

235
0:10:42.971,000 --> 0:10:43,000
et nous rendre fainéants,

236
0:10:44.735,000 --> 0:10:46,000
vous serez peut-être curieux d'entendre que la mobilité sociale,

237
0:10:47.525,000 --> 0:10:49,000
une des choses qui fait notre fierté aux Etats-Unis,

238
0:10:50.2,000 --> 0:10:53,000
est aujourd'hui inférieure à ce qu'elle est dans les pays d'Europe du Nord

239
0:10:53.54,000 --> 0:10:56,000
qui ont ces minima sociaux si généreux.

240
0:10:56.739,000 --> 0:10:58,000
Le scénario économique est bien simple et direct.

241
0:10:59.531,000 --> 0:11:02,000
Celui qui traite de la société pose bien plus de questions.

242
0:11:02.587,000 --> 0:11:04,000
Je ne sais pas quel scénario peut donner à Bill

243
0:11:04.735,000 --> 0:11:07,000
l'opportunité de trouver un emploi et de le conserver toute sa vie.

244
0:11:08.563,000 --> 0:11:1,000
Ce que je sais c'est que l'éducation joue un grand rôle.

245
0:11:11.067,000 --> 0:11:12,000
J'en ai fait l'expérience moi-même.

246
0:11:12.847,000 --> 0:11:15,000
J'ai été un enfant Montessori pendant les premières années de ma scolarité,

247
0:11:16.603,000 --> 0:11:17,000
et ce que cette éducation m'a appris

248
0:11:18.132,000 --> 0:11:2,000
c'est que le monde est un lieu intéressant

249
0:11:20.223,000 --> 0:11:22,000
et que mon rôle est de l'explorer.

250
0:11:22.864,000 --> 0:11:23,000
L'école s'arrêtait à la troisième année,

251
0:11:24.565,000 --> 0:11:26,000
alors je suis entré dans le système éducatif public

252
0:11:26.633,000 --> 0:11:3,000
et j'ai eu l'impression d'être envoyé au goulag.

253
0:11:30.999,000 --> 0:11:32,000
Avec le recul, je sais que le but

254
0:11:33.9,000 --> 0:11:35,000
était de me préparer à une vie d'employé de bureau ou d'ouvrier,

255
0:11:36.414,000 --> 0:11:38,000
mais à l'époque j'avais l'impression que le but

256
0:11:38.744,000 --> 0:11:41,000
était de me noyer d'ennui jusqu'à ce que je me fonde dans le moule.

257
0:11:42.568,000 --> 0:11:43,000
Nous devons faire mieux que ça.

258
0:11:43.916,000 --> 0:11:46,000
Nous ne pouvons pas continuer à produire des Bill.

259
0:11:47.592,000 --> 0:11:49,000
Nous voyons les prémisses d'une amélioration.

260
0:11:49.936,000 --> 0:11:51,000
Nous voyons l'impact profond que la technologie a sur l'éducation

261
0:11:52.76,000 --> 0:11:54,000
et sur le recrutement du personnel, du plus bas

262
0:11:55.288,000 --> 0:11:56,000
au plus haut niveau d'instruction.

263
0:11:57.052,000 --> 0:11:59,000
Nous entendons les voix de milieux d'affaires à succès nous dire

264
0:11:59.672,000 --> 0:12:02,000
que nous devons repenser certaines des choses qui nous tiennent le plus à cœur.

265
0:12:02.888,000 --> 0:12:04,000
Et ce à quoi l'on assiste, est le déploiement d’efforts soutenus et sérieux,

266
0:12:05.148,000 --> 0:12:07,000
afin de trouver, grâce aux données disponibles,

267
0:12:07.952,000 --> 0:12:1,000
le moyen d'intervenir auprès de certaines de nos populations les plus sensibles.

268
0:12:11.495,000 --> 0:12:13,000
Les signes encourageants sont donc là.

269
0:12:13.704,000 --> 0:12:14,000
Je ne veux pas avoir l'air de dire, ne serait-ce qu'un instant,

270
0:12:15.138,000 --> 0:12:16,000
que ce que nous avons suffira.

271
0:12:17.08,000 --> 0:12:19,000
Nous sommes confrontés à des défis de taille.

272
0:12:19.222,000 --> 0:12:22,000
Pour donner un seul exemple, il y a environ 5 millions d'Américains.

273
0:12:22.328,000 --> 0:12:24,000
qui sont au chômage depuis au moins six mois.

274
0:12:25.142,000 --> 0:12:26,000
Nous n'arriverons pas à régler leurs problèmes

275
0:12:26.484,000 --> 0:12:28,000
en les renvoyant au Montessori.

276
0:12:28.927,000 --> 0:12:3,000
Et ma plus grosse préoccupation, est que nous créions un monde

277
0:12:31.282,000 --> 0:12:33,000
regorgeant de technologies reluisantes,

278
0:12:33.831,000 --> 0:12:35,000
mais incorporées dans une société vétuste,

279
0:12:36.136,000 --> 0:12:38,000
soutenue par une économie qui génère de l'inégalité

280
0:12:39.103,000 --> 0:12:4,000
au lieu de générer des opportunités.

281
0:12:40.584,000 --> 0:12:42,000
Mais en réalité je ne crois pas que nous allons faire ça.

282
0:12:43.336,000 --> 0:12:44,000
Je crois que nous allons faire bien mieux

283
0:12:44.965,000 --> 0:12:46,000
pour une raison très simple :

284
0:12:47.075,000 --> 0:12:48,000
ces choses commencent à se savoir.

285
0:12:49.043,000 --> 0:12:51,000
Les réalités de cette nouvelle ère des machines

286
0:12:51.085,000 --> 0:12:54,000
et les changement économiques commencent à mieux être compris.

287
0:12:54.4,000 --> 0:12:56,000
Si on voulait accélérer le processus, on pourrait par exemple

288
0:12:57.251,000 --> 0:12:59,000
opposer nos meilleurs économistes et dirigeants

289
0:13:00.017,000 --> 0:13:02,000
à Watson au « Jeopardy ».

290
0:13:02.436,000 --> 0:13:05,000
On pourrait envoyer le Parlement en voyage à bord d'une voiture automate.

291
0:13:05.986,000 --> 0:13:06,000
Si on faisait assez de choses comme ça,

292
0:13:07.639,000 --> 0:13:1,000
on parviendrait à ancrer dans l'esprit des gens que les choses vont changer.

293
0:13:11.043,000 --> 0:13:12,000
Et dés lors, tout est possible,

294
0:13:12.814,000 --> 0:13:14,000
car je ne crois pas un instant

295
0:13:15.244,000 --> 0:13:17,000
que nous ayons oublié comment surmonter des défis de taille,

296
0:13:18.212,000 --> 0:13:22,000
ou que nous soyons devenus trop apathiques ou insensibles pour nous y mettre.

297
0:13:22.562,000 --> 0:13:24,000
J'ai commencé ma présentation par des citations de gens de lettres

298
0:13:24.956,000 --> 0:13:26,000
que séparent un océan et un siècle.

299
0:13:27.772,000 --> 0:13:29,000
Je finirai, si vous le permettez, par les mots

300
0:13:29.924,000 --> 0:13:3,000
d'hommes politiques tout aussi distants.

301
0:13:31.655,000 --> 0:13:34,000
Winston Churchill est venu au MIT, mon foyer, en 1949

302
0:13:34.988,000 --> 0:13:36,000
et a dit : « Si vous devons amener les masses

303
0:13:37.136,000 --> 0:13:4,000
du peuple de chaque terre à la table de l'abondance,

304
0:13:40.846,000 --> 0:13:43,000
ce ne sera que par l'amélioration incessante

305
0:13:43.876,000 --> 0:13:45,000
de tous nos moyens techniques de production. »

306
0:13:46.849,000 --> 0:13:48,000
Abraham Lincoln s'était rendu compte qu'il y avait un autre ingrédient.

307
0:13:49.468,000 --> 0:13:51,000
Il a dit : « J'ai une grande confiance dans le peuple.

308
0:13:52.366,000 --> 0:13:54,000
Si la vérité lui est donnée, on peut lui faire confiance

309
0:13:54.699,000 --> 0:13:56,000
pour surmonter n'importe quelle crise nationale.

310
0:13:57.068,000 --> 0:13:59,000
L'essentiel est de lui présenter les faits tels qu'ils sont. »

311
0:13:59.852,000 --> 0:14:02,000
La note optimiste, essentiel sur laquelle je vous quitterai,

312
0:14:02.962,000 --> 0:14:05,000
est que les faits concernant l'ère des machines apparaissent de plus en plus tels qu'ils sont

313
0:14:06.107,000 --> 0:14:08,000
et j'ai toute confiance de croire que nous les utiliserons

314
0:14:08.564,000 --> 0:14:1,000
pour nous guider à bon port dans l'économie

315
0:14:11.479,000 --> 0:14:13,000
d'exigence et d'abondance que nous sommes en train de créer.

316
0:14:14.012,000 --> 0:14:15,000
Merci beaucoup.

317
0:14:15.703,000 --> 0:14:19,000
(Applaudissements)

