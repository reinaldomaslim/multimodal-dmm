1
0:00:,000 --> 0:00:07,000
Traducteur: Natalie Thibault Relecteur: Morgane Quilfen

2
0:00:12.58,000 --> 0:00:15,000
Il est probable que vous ayez, comme bien des gens,

3
0:00:15.66,000 --> 0:00:18,000
l'impression que la polarisation s'aggrave dans notre pays,

4
0:00:19.34,000 --> 0:00:22,000
et que la division entre la droite et la gauche

5
0:00:22.82,000 --> 0:00:25,000
est la plus grande que nous ayons vue et vécue au cours de nos vies.

6
0:00:26.38,000 --> 0:00:31,000
Vous vous demandez peut-être si cette idée a été prouvée par des recherches.

7
0:00:32.38,000 --> 0:00:36,000
Alors, pour résumer, la réponse est oui, malheureusement.

8
0:00:38.74,000 --> 0:00:4,000
D'étude en étude, nous constatons

9
0:00:40.78,000 --> 0:00:43,000
que les libéraux et les conservateurs sont plus éloignés que jamais.

10
0:00:45.26,000 --> 0:00:49,000
Ils s'enferment de plus en plus dans un genre de silo idéologique,

11
0:00:50.06,000 --> 0:00:54,000
s'informent auprès de médias différents, ne parlent qu'à ceux qui pensent comme eux

12
0:00:54.22,000 --> 0:00:57,000
et choisissent de plus de plus de vivre dans différentes régions du pays.

13
0:00:58.54,000 --> 0:01:01,000
Mais à mon avis, ce qui est le plus alarmant dans tout cela

14
0:01:01.78,000 --> 0:01:04,000
est de voir l'animosité grandissante, tant d'un côté que de l'autre.

15
0:01:06.26,000 --> 0:01:07,000
Libéraux et conservateurs,

16
0:01:07.94,000 --> 0:01:08,000
démocrates et républicains,

17
0:01:09.86,000 --> 0:01:12,000
ils semblent se déplaire de plus en plus.

18
0:01:14.14,000 --> 0:01:16,000
Nous le constatons de différentes manières.

19
0:01:16.18,000 --> 0:01:19,000
Ils ne deviennent pas amis. Ils ne se fréquentent pas.

20
0:01:19.86,000 --> 0:01:22,000
Si jamais ça arrive, dès qu'ils le réalisent, ils s'attirent moins,

21
0:01:23.16,000 --> 0:01:26,000
et, de plus en plus, ils ne veulent pas voir leurs enfants se marier

22
0:01:26.346,000 --> 0:01:27,000
avec quelqu'un de l'autre parti ;

23
0:01:28.02,000 --> 0:01:29,000
c'est une statistique surprenante.

24
0:01:31.3,000 --> 0:01:33,000
Dans mon laboratoire, avec les étudiants avec qui je travaille,

25
0:01:34.3,000 --> 0:01:37,000
nous parlons souvent de modèles sociaux --

26
0:01:37.78,000 --> 0:01:4,000
je suis un amateur de cinéma et souvent je dis :

27
0:01:41.34,000 --> 0:01:43,000
dans quel genre de film sommes-nous ici, avec ce modèle-ci ?

28
0:01:44.9,000 --> 0:01:47,000
De quel genre de film s'agit-il, en parlant de polarisation politique ?

29
0:01:48.9,000 --> 0:01:5,000
Cela pourrait être un film catastrophe.

30
0:01:52.7,000 --> 0:01:53,000
Ça ressemble bien à une catastrophe.

31
0:01:54.74,000 --> 0:01:56,000
Ça pourrait être un film de guerre.

32
0:01:57.46,000 --> 0:01:58,000
Ça marche aussi.

33
0:01:59.3,000 --> 0:02:02,000
Mais ce qui me vient toujours en tête, c'est les films de zombies.

34
0:02:03.14,000 --> 0:02:04,000
(Rires)

35
0:02:04.62,000 --> 0:02:06,000
N'est-ce pas ? Vous voyez le genre !

36
0:02:06.94,000 --> 0:02:08,000
Il y a des gens qui errent en groupes,

37
0:02:09.31,000 --> 0:02:1,000
ne réfléchissant plus d'eux-mêmes,

38
0:02:11.08,000 --> 0:02:12,000
captifs de cette mentalité collective

39
0:02:12.846,000 --> 0:02:15,000
qui leur dicte de propager leur maladie et de détruire la société.

40
0:02:17.3,000 --> 0:02:19,000
Et vous vous dites sans doute, tout comme moi,

41
0:02:19.66,000 --> 0:02:22,000
que vous êtes du côté des bons dans ce film de zombies apocalyptique

42
0:02:23.14,000 --> 0:02:26,000
et que toute la haine et la polarisation est propagée par les autres,

43
0:02:26.86,000 --> 0:02:28,000
parce qu'on est Brad Pitt, n'est-ce pas ?

44
0:02:29.58,000 --> 0:02:31,000
Un libre penseur, juste et vertueux,

45
0:02:32.5,000 --> 0:02:34,000
tentant de nous accrocher à ce qui nous est cher,

46
0:02:34.82,000 --> 0:02:37,000
et non pas un simple soldat dans l'armée des morts-vivants.

47
0:02:38.42,000 --> 0:02:39,000
Pas cela.

48
0:02:39.9,000 --> 0:02:4,000
Jamais cela.

49
0:02:41.9,000 --> 0:02:42,000
Mais voici le problème :

50
0:02:43.42,000 --> 0:02:45,000
dans quel film pensez-vous qu'ils croient jouer ?

51
0:02:47.3,000 --> 0:02:48,000
N'est-ce pas ?

52
0:02:48.54,000 --> 0:02:5,000
Oui, ils sont convaincus qu'ils sont du côté des bons

53
0:02:51.1,000 --> 0:02:52,000
dans ce film de zombies, n'est-ce pas ?

54
0:02:52.98,000 --> 0:02:54,000
Et soyez certains qu'ils se prennent pour Brad Pitt

55
0:02:55.98,000 --> 0:02:57,000
et que ce sont nous, les zombies.

56
0:03:00.94,000 --> 0:03:02,000
Mais qui peut dire qu'ils ont tort ?

57
0:03:04.26,000 --> 0:03:07,000
Je crois que la vérité est qu'on est tous impliqués là-dedans.

58
0:03:08.06,000 --> 0:03:11,000
La bonne nouvelle est qu'on peut tous faire partie de la solution.

59
0:03:12.1,000 --> 0:03:14,000
Donc, qu'allons-nous faire ?

60
0:03:15.14,000 --> 0:03:19,000
Que pouvons-nous faire pour nous attaquer à la polarisation au quotidien ?

61
0:03:19.42,000 --> 0:03:22,000
Que pouvons-nous faire pour mieux communiquer et échanger

62
0:03:23.26,000 --> 0:03:24,000
avec nos adversaires politiques ?

63
0:03:25.54,000 --> 0:03:29,000
En fait, voilà les questions qui fascinent mon collègue Matt Feinbert et moi-même

64
0:03:29.7,000 --> 0:03:3,000
depuis quelques années maintenant

65
0:03:31.582,000 --> 0:03:33,000
et nous avons entamé des recherches sur ce sujet.

66
0:03:34.74,000 --> 0:03:36,000
L'une des premières choses que nous avons découvertes

67
0:03:37.74,000 --> 0:03:4,000
et qui à mon sens est très utile pour comprendre la polarisation,

68
0:03:41.22,000 --> 0:03:42,000
est la réalisation

69
0:03:42.46,000 --> 0:03:46,000
que l'écart politique dans notre pays s'appuie sur une division morale profonde.

70
0:03:46.9,000 --> 0:03:5,000
L'une des découvertes les plus importantes en histoire de la psychologie politique

71
0:03:51.7,000 --> 0:03:54,000
est ce modèle identifié par Jon Haidt et Jesse Graham,

72
0:03:55.42,000 --> 0:03:56,000
deux psychologues,

73
0:03:56.66,000 --> 0:03:59,000
démontrant que les libéraux et les conservateurs ont tendance à appuyer

74
0:04:00.07,000 --> 0:04:02,000
des valeurs différentes à différents degrés.

75
0:04:02.42,000 --> 0:04:06,000
Ainsi, par exemple, on constate que les libéraux adhèrent à des valeurs

76
0:04:06.66,000 --> 0:04:1,000
comme l'égalité, la justice, la prise en charge et la protection contre le mal,

77
0:04:11.54,000 --> 0:04:13,000
de façon plus prononcée que les conservateurs.

78
0:04:13.78,000 --> 0:04:17,000
Les conservateurs, quant à eux, appuient des valeurs comme la loyauté,

79
0:04:18.13,000 --> 0:04:22,000
le patriotisme, le respect pour l'autorité et la pureté morale,

80
0:04:22.54,000 --> 0:04:24,000
de manière plus forte que les libéraux.

81
0:04:25.74,000 --> 0:04:29,000
Matt et moi nous demandions si cette division morale

82
0:04:29.82,000 --> 0:04:32,000
ne pourrait pas être utile pour comprendre

83
0:04:32.94,000 --> 0:04:34,000
comment les libéraux et les conservateurs se parlent

84
0:04:35.416,000 --> 0:04:37,000
et pourquoi ils ne semblent pas vraiment s'écouter

85
0:04:37.846,000 --> 0:04:38,000
quand ils se parlent.

86
0:04:39.06,000 --> 0:04:4,000
Nous avons donc mené une étude,

87
0:04:41.06,000 --> 0:04:44,000
pour laquelle nous avons recruté des libéraux

88
0:04:44.18,000 --> 0:04:46,000
qui devaient écrire une dissertation persuasive

89
0:04:46.66,000 --> 0:04:5,000
en faveur du mariage gay et qui pourrait convaincre un conservateur.

90
0:04:51.62,000 --> 0:04:54,000
Nous avons découvert que les libéraux utilisaient des arguments

91
0:04:54.9,000 --> 0:04:58,000
basés sur des valeurs libérales, comme l'égalité et la justice.

92
0:04:59.1,000 --> 0:05:,000
Ils disaient des choses comme :

93
0:05:00.84,000 --> 0:05:03,000
« Tout le monde devrait avoir le droit d'aimer la personne de leur choix... »

94
0:05:04.576,000 --> 0:05:06,000
et « ils » - les homosexuels américains -

95
0:05:06.86,000 --> 0:05:08,000
« méritent les mêmes droits que tous les autres Américains. »

96
0:05:10.18,000 --> 0:05:13,000
Dans l'ensemble, nous avons constaté que 69% des libéraux

97
0:05:13.42,000 --> 0:05:18,000
ont invoqué une ou plusieurs des valeurs morales libérales dans leur essai,

98
0:05:18.82,000 --> 0:05:21,000
alors que seulement 9% ont fait appel à des valeurs morales plus conservatrices

99
0:05:22.58,000 --> 0:05:25,000
et ce, même s'ils avaient pour but de convaincre des conservateurs.

100
0:05:26.02,000 --> 0:05:28,000
Puis nous avons demandé à des conservateurs

101
0:05:28.48,000 --> 0:05:29,000
d'écrire un essai persuasif

102
0:05:30.31,000 --> 0:05:33,000
pour l'adoption de l'anglais comme langue officielle des États-Unis,

103
0:05:33.506,000 --> 0:05:35,000
une position politique traditionnellement conservatrice,

104
0:05:36.176,000 --> 0:05:37,000
ils n'ont guère fait mieux.

105
0:05:38.06,000 --> 0:05:39,000
59% d'entre eux ont usé d'arguments

106
0:05:39.726,000 --> 0:05:41,000
s'appuyant sur des valeurs morales conservatrices,

107
0:05:42.33,000 --> 0:05:44,000
et seuls 8% ont fait appel à une valeur morale libérale,

108
0:05:44.946,000 --> 0:05:47,000
même si leur tâche était de convaincre spécifiquement des libéraux.

109
0:05:49.3,000 --> 0:05:53,000
Maintenant vous pouvez voir pourquoi on est dans le pétrin.

110
0:05:54.1,000 --> 0:05:57,000
Les valeurs morales des gens sont leurs croyances les plus profondes.

111
0:05:57.62,000 --> 0:06:,000
Les gens sont prêts à se battre et à mourir pour ces valeurs.

112
0:06:01.51,000 --> 0:06:03,000
Qui sacrifierait cela simplement pour s'entendre avec vous

113
0:06:04.26,000 --> 0:06:07,000
sur un sujet sur lequel ils ne souhaitent pas vraiment se mettre d'accord ?

114
0:06:07.82,000 --> 0:06:1,000
Si en tentant de convaincre votre oncle républicain,

115
0:06:11.08,000 --> 0:06:13,000
vous cherchez non seulement à le faire changer d'avis

116
0:06:13.616,000 --> 0:06:15,000
mais à lui faire renier ses valeurs profondes,

117
0:06:15.806,000 --> 0:06:16,000
vous n'accomplirez rien.

118
0:06:17.9,000 --> 0:06:18,000
Que doit-on faire, alors ?

119
0:06:20.02,000 --> 0:06:24,000
Nous croyons que c'est une technique que nous appelons le recadrage moral

120
0:06:24.34,000 --> 0:06:26,000
et que nous avons étudiée dans une série d'expériences.

121
0:06:26.98,000 --> 0:06:27,000
Dans l'une de ces expériences,

122
0:06:28.5,000 --> 0:06:31,000
nous avons recruté des libéraux et des conservateurs

123
0:06:31.66,000 --> 0:06:33,000
et leur avons fait lire un de trois essais

124
0:06:33.98,000 --> 0:06:36,000
avant de sonder leurs opinions en matière d'environnement.

125
0:06:37.46,000 --> 0:06:38,000
Le premier essai

126
0:06:38.98,000 --> 0:06:41,000
était un essai pro-environnement assez conventionnel

127
0:06:42.38,000 --> 0:06:46,000
qui faisait appel aux valeurs libérales de soin et de protection contre le mal.

128
0:06:46.42,000 --> 0:06:48,000
On y disait des choses comme : « De plusieurs manières,

129
0:06:48.986,000 --> 0:06:5,000
nous nuisons aux endroits dans lesquels nous vivons, »

130
0:06:51.82,000 --> 0:06:53,000
puis, « il est essentiel que nous prenions des mesures

131
0:06:54.66,000 --> 0:06:56,000
pour prévenir l'aggravation de la destruction

132
0:06:56.87,000 --> 0:06:57,000
que subit notre planète. »

133
0:06:58.87,000 --> 0:06:59,000
Un autre groupe de participants

134
0:07:00.38,000 --> 0:07:02,000
devait lire un essai très différent,

135
0:07:02.62,000 --> 0:07:06,000
qui était conçu pour exploiter la valeur conservatrice de pureté morale.

136
0:07:08.01,000 --> 0:07:09,000
C'était aussi un essai pro-environnement,

137
0:07:09.98,000 --> 0:07:1,000
mais il incluait des trucs comme :

138
0:07:11.626,000 --> 0:07:15,000
« Préserver la pureté de nos forêts, de notre eau et de notre ciel est vital. »

139
0:07:16.66,000 --> 0:07:17,000
« Nous devons considérer la pollution

140
0:07:18.426,000 --> 0:07:19,000
de nos lieux de vie comme une disgrâce. »

141
0:07:20.98,000 --> 0:07:22,000
puis, « réduire la pollution peut nous aider

142
0:07:23.09,000 --> 0:07:26,000
à préserver ce qui est pur et beau dans les endroits où nous vivons. »

143
0:07:27.7,000 --> 0:07:28,000
Et le troisième groupe

144
0:07:29.14,000 --> 0:07:3,000
devait lire un essai non politique.

145
0:07:30.82,000 --> 0:07:33,000
Il s'agissait d'un groupe nous permettant d'établir une base de comparaison.

146
0:07:34.41,000 --> 0:07:36,000
Ce que nous avons découvert en sondant les gens

147
0:07:36.683,000 --> 0:07:38,000
sur leurs opinions environnementales après coup,

148
0:07:39.006,000 --> 0:07:41,000
est que que le choix de l'essai n'importe pas aux libéraux,

149
0:07:41.786,000 --> 0:07:43,000
car ils avaient déjà de fortes opinions pro-environnement,

150
0:07:44.7,000 --> 0:07:46,000
étant déjà persuadés qu'il faut protéger la Terre.

151
0:07:47.04,000 --> 0:07:48,000
Les conservateurs, par contre,

152
0:07:48.476,000 --> 0:07:51,000
ont beaucoup mieux réagi aux politiques progressives

153
0:07:52.35,000 --> 0:07:54,000
en matière de protection environnementale

154
0:07:54.38,000 --> 0:07:56,000
après avoir lu l'essai parlant de pureté

155
0:07:56.46,000 --> 0:07:58,000
plutôt que l'un des deux autres essais.

156
0:07:59.78,000 --> 0:08:02,000
On a même constaté que les conservateurs ayant lu l'essai de la pureté

157
0:08:03.106,000 --> 0:08:04,000
étaient plus enclins à dire

158
0:08:04.476,000 --> 0:08:06,000
qu'ils croyaient au réchauffement climatique

159
0:08:06.62,000 --> 0:08:07,000
et que ça les inquiétait,

160
0:08:08.549,000 --> 0:08:1,000
même si l'essai de la pureté n'en faisait pas mention.

161
0:08:11.14,000 --> 0:08:13,000
Il s'agit simplement d'un enjeu relié à l'environnement.

162
0:08:13.836,000 --> 0:08:16,000
Mais ça démontre l'effet robuste qu'a eu le recadrement moral.

163
0:08:17.78,000 --> 0:08:2,000
Nous avons continué d'étudier cela avec de nombreuses questions politiques.

164
0:08:21.54,000 --> 0:08:24,000
Ainsi, si vous voulez faire plier des conservateurs,

165
0:08:25.3,000 --> 0:08:28,000
sur des questions comme le mariage gay ou l'assurance-maladie,

166
0:08:28.42,000 --> 0:08:31,000
il s'agit de lier ces enjeux libéraux à des valeurs plus conservatrices,

167
0:08:31.9,000 --> 0:08:33,000
comme le patriotisme et la pureté morale.

168
0:08:35.62,000 --> 0:08:37,000
On a aussi étudié cela dans le sens inverse.

169
0:08:37.74,000 --> 0:08:4,000
Pour faire pencher les libéraux à droite sur des politiques conservatrices,

170
0:08:41.58,000 --> 0:08:45,000
comme le budget alloué à l'armée ou l'anglais comme langue officielle,

171
0:08:46.22,000 --> 0:08:47,000
vous serez plus persuasif

172
0:08:47.9,000 --> 0:08:5,000
si vous liez ces questions conservatrices à des valeurs morales libérales

173
0:08:51.376,000 --> 0:08:52,000
comme l'égalité et la justice.

174
0:08:54.46,000 --> 0:08:56,000
Toutes ces recherches nous démontrent la même chose :

175
0:08:57.34,000 --> 0:08:59,000
si vous voulez convaincre quelqu'un à propos d'une politique,

176
0:09:00.3,000 --> 0:09:03,000
il est utile de lier cette politique aux valeurs morales profondes de celui-ci.

177
0:09:05.34,000 --> 0:09:07,000
Présenté de cette manière,

178
0:09:07.54,000 --> 0:09:08,000
ça semble si évident, non ?

179
0:09:09.06,000 --> 0:09:1,000
À quoi bon venir ici ce soir ?

180
0:09:10.86,000 --> 0:09:11,000
Pourquoi --

181
0:09:12.1,000 --> 0:09:13,000
(Rires)

182
0:09:13.66,000 --> 0:09:15,000
C'est incroyablement intuitif.

183
0:09:17.22,000 --> 0:09:2,000
Et malgré cela, ça demeure quelque chose de très difficile à faire.

184
0:09:20.54,000 --> 0:09:23,000
Vous savez, lorsque nous tentons de convaincre quelqu'un sur un enjeu,

185
0:09:24.42,000 --> 0:09:26,000
nous avons tendance à leur parler comme à un miroir.

186
0:09:27.18,000 --> 0:09:31,000
En fait, plutôt que de persuader, nous répétons nos propres arguments,

187
0:09:31.58,000 --> 0:09:33,000
nos propres raisons d'adhérer à notre position.

188
0:09:35.22,000 --> 0:09:39,000
En retravaillant ces arguments moraux « recadrés »; nous répétons sans cesse :

189
0:09:39.66,000 --> 0:09:41,000
« Empathie et respect, empathie et respect. »

190
0:09:42.86,000 --> 0:09:43,000
Si on peut y adhérer,

191
0:09:44.34,000 --> 0:09:45,000
on peut établir une connexion

192
0:09:46.02,000 --> 0:09:48,000
et peut-être espérer convaincre quelqu'un dans ce pays.

193
0:09:49.38,000 --> 0:09:51,000
Ainsi, en repensant

194
0:09:51.82,000 --> 0:09:53,000
au film dans lequel nous jouons,

195
0:09:54.76,000 --> 0:09:55,000
je me suis peut-être laissé emporter,

196
0:09:56.53,000 --> 0:09:58,000
peut-être que ce n'est pas un film de zombies,

197
0:09:59.34,000 --> 0:10:,000
mais plutôt un film de flics.

198
0:10:01.86,000 --> 0:10:03,000
(Rires)

199
0:10:03.9,000 --> 0:10:05,000
Jouez le jeu, pour voir où ça nous mène.

200
0:10:05.94,000 --> 0:10:06,000
(Rires)

201
0:10:08.3,000 --> 0:10:1,000
Vous voyez le genre : il y a un flic noir et un blanc,

202
0:10:11.02,000 --> 0:10:13,000
ou alors un désorganisé et un minutieux.

203
0:10:13.18,000 --> 0:10:15,000
Peu importe le scénario, ils ne s'entendent pas

204
0:10:15.396,000 --> 0:10:16,000
en raison de cette différence.

205
0:10:17.34,000 --> 0:10:2,000
Mais au bout du compte, quand ils doivent faire équipe et collaborer,

206
0:10:20.58,000 --> 0:10:21,000
la solidarité qu'ils ressentent

207
0:10:22.54,000 --> 0:10:25,000
est plus puissante en raison de ce fossé qu'ils ont dû franchir.

208
0:10:27.1,000 --> 0:10:28,000
Souvenez-vous que dans ces films,

209
0:10:29.1,000 --> 0:10:31,000
c'est toujours pire au deuxième acte

210
0:10:32.02,000 --> 0:10:34,000
quand nos deux flics sont plus éloignés que jamais.

211
0:10:35.26,000 --> 0:10:37,000
Peut-être sommes-nous à cette étape,

212
0:10:37.35,000 --> 0:10:39,000
notre pays est au second acte d'un film de flics --

213
0:10:39.826,000 --> 0:10:41,000
(Rires)

214
0:10:42.42,000 --> 0:10:45,000
déchiré, mais sur le point de se réunifier.

215
0:10:47.22,000 --> 0:10:48,000
Ça semble bien,

216
0:10:48.9,000 --> 0:10:49,000
mais si nous voulons que ça se produise,

217
0:10:50.816,000 --> 0:10:52,000
je crois que la responsabilité commence avec nous.

218
0:10:54.34,000 --> 0:10:56,000
Voici donc ce que je vous demande :

219
0:10:57.3,000 --> 0:10:59,000
réunifions notre pays.

220
0:11:00.9,000 --> 0:11:03,000
Faisons-le, en dépit de la classe politique,

221
0:11:03.98,000 --> 0:11:05,000
des médias, de Facebook et Twitter,

222
0:11:06.86,000 --> 0:11:07,000
du redécoupage électoral

223
0:11:08.42,000 --> 0:11:1,000
et tout cela, toutes ces choses qui nous divisent.

224
0:11:12.18,000 --> 0:11:14,000
Faisons-le parce que c'est la chose à faire.

225
0:11:15.74,000 --> 0:11:19,000
Faisons-le parce que la haine et le mépris

226
0:11:20.18,000 --> 0:11:22,000
qui nous habitent et nous traversent au quotidien

227
0:11:23.22,000 --> 0:11:26,000
nous rendent laids, nous corrompent,

228
0:11:26.42,000 --> 0:11:29,000
et menacent l'étoffe fondamentale de notre société.

229
0:11:31.78,000 --> 0:11:33,000
Nous nous devons cela, à nous et à notre pays :

230
0:11:34.46,000 --> 0:11:36,000
tendre la main et tenter un rapprochement.

231
0:11:37.82,000 --> 0:11:4,000
Nous ne pouvons plus nous permettre de continuer à les haïr,

232
0:11:42.02,000 --> 0:11:44,000
ni de les laisser nous haïr à leur tour.

233
0:11:45.7,000 --> 0:11:46,000
Empathie et respect.

234
0:11:47.7,000 --> 0:11:48,000
Empathie et respect.

235
0:11:49.74,000 --> 0:11:52,000
Quand on y pense, c'est le minimum que l'on doit à nos concitoyens.

236
0:11:54.22,000 --> 0:11:55,000
Merci.

237
0:11:55.46,000 --> 0:11:59,000
(Applaudissements)

