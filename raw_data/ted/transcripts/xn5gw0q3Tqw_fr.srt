1
0:00:,000 --> 0:00:07,000
Traducteur: Claire Ghyselen Relecteur: Morgane Quilfen

2
0:00:12.461,000 --> 0:00:15,000
Bryn Freedman : Vous avez dit qu'au XXe siècle,

3
0:00:15.896,000 --> 0:00:17,000
le pouvoir mondial appartenait aux gouvernements.

4
0:00:18.741,000 --> 0:00:2,000
Qu'au début de ce siècle numérique,

5
0:00:21.084,000 --> 0:00:22,000
il avait glissé vers les entreprises

6
0:00:22.986,000 --> 0:00:25,000
et que dans un futur proche, il serait entre les mains des individus.

7
0:00:26.948,000 --> 0:00:27,000
J'ai interviewé beaucoup de personnes

8
0:00:28.758,000 --> 0:00:29,000
qui disent que vous vous trompez

9
0:00:30.634,000 --> 0:00:32,000
et qui misent plutôt sur les entreprises.

10
0:00:32.777,000 --> 0:00:33,000
Pourquoi pensez-vous avoir raison

11
0:00:34.46,000 --> 0:00:36,000
et pourquoi les individus vont-ils se l'approprier ?

12
0:00:37.419,000 --> 0:00:4,000
Fade Chehadé : Les entreprises satisfont les besoins des individus,

13
0:00:40.558,000 --> 0:00:41,000
et nous, en tant que citoyens,

14
0:00:42.049,000 --> 0:00:45,000
nous devons comprendre que nous avons un rôle essentiel

15
0:00:45.914,000 --> 0:00:48,000
dans la manière dont la gouvernance du monde sera façonnée dans le futur.

16
0:00:49.64,000 --> 0:00:53,000
C'est vrai, actuellement les frictions ont lieu entre des gouvernements

17
0:00:53.885,000 --> 0:00:56,000
qui ont perdu beaucoup de leur pouvoir au profit des entreprises

18
0:00:57.009,000 --> 0:01:01,000
car Internet n'est pas fondé sur le système de l'État-nation

19
0:01:01.267,000 --> 0:01:03,000
sur lequel les États légitimisent leur pouvoir.

20
0:01:03.477,000 --> 0:01:04,000
L'Internet est une entité transnationale.

21
0:01:05.452,000 --> 0:01:07,000
L'Internet n'est ni international, ni national,

22
0:01:08.299,000 --> 0:01:1,000
ce qui a rendu les entreprises très puissantes.

23
0:01:12.028,000 --> 0:01:13,000
Elles façonnent notre économie.

24
0:01:13.926,000 --> 0:01:14,000
Elles façonnent notre société.

25
0:01:15.832,000 --> 0:01:16,000
Les autorités ne savent pas quoi faire.

26
0:01:17.695,000 --> 0:01:18,000
Maintenant, elles sont réactives.

27
0:01:19.649,000 --> 0:01:22,000
Je crains que si nous, citoyens,

28
0:01:22.967,000 --> 0:01:26,000
qui sommes l'élément le plus important,

29
0:01:27.715,000 --> 0:01:28,000
si nous n'assumons pas notre rôle,

30
0:01:29.337,000 --> 0:01:3,000
vous avez raison.

31
0:01:30.508,000 --> 0:01:34,000
Mes détracteurs, les partisans des entreprises, ont raison.

32
0:01:35.287,000 --> 0:01:36,000
Cela va se produire.

33
0:01:36.462,000 --> 0:01:39,000
BF : Vous dites que les individus vont obliger les entreprises

34
0:01:40.318,000 --> 0:01:42,000
ou que les entreprises vont être obligées de réagir

35
0:01:42.85,000 --> 0:01:45,000
ou craignez-vous que ce ne soit pas le cas ?

36
0:01:46.247,000 --> 0:01:47,000
FC : Je pense que si.

37
0:01:47.643,000 --> 0:01:48,000
Rappelez-vous, il y a deux semaines,

38
0:01:49.517,000 --> 0:01:53,000
une petite entreprise nommée Skip a gagné contre Uber, Lyft et les autres.

39
0:01:53.953,000 --> 0:01:57,000
Elle a obtenu la licence pour le marché des trottinettes à San Francisco.

40
0:01:59.232,000 --> 0:02:01,000
Si vous voulez savoir pourquoi Skip a gagné,

41
0:02:01.402,000 --> 0:02:03,000
c'est parce qu'elle a écouté les habitants de San Francisco,

42
0:02:04.342,000 --> 0:02:06,000
qui en avaient marre des trottinettes abandonnées partout,

43
0:02:07.215,000 --> 0:02:09,000
et que l'entreprise est allée à la mairie et leur a dit :

44
0:02:09.913,000 --> 0:02:11,000
« Nous allons déployer le service,

45
0:02:12.103,000 --> 0:02:15,000
mais nous répondrons aux exigences des citoyens

46
0:02:15.183,000 --> 0:02:18,000
et nous allons nous organiser autour d'un ensemble de règles. »

47
0:02:18.283,000 --> 0:02:21,000
Ils ont autogéré leur conduite et ont obtenu le contrat

48
0:02:21.667,000 --> 0:02:23,000
face à des entreprises très puissantes.

49
0:02:23.731,000 --> 0:02:26,000
BF : En parlant de règles et d'autogestion,

50
0:02:27.322,000 --> 0:02:31,000
vous avez passé une vie entière à créer des règles et des normes

51
0:02:31.366,000 --> 0:02:32,000
pour Internet.

52
0:02:33.088,000 --> 0:02:34,000
Cette époque est-elle révolue ?

53
0:02:34.854,000 --> 0:02:36,000
Qui va orienter, contrôler

54
0:02:37.637,000 --> 0:02:39,000
et créer ces normes ?

55
0:02:39.812,000 --> 0:02:44,000
FC : Les règles qui régissent les couches technologiques d'Internet

56
0:02:45.196,000 --> 0:02:47,000
sont maintenant bien en place.

57
0:02:47.903,000 --> 0:02:5,000
J'ai mis quelques années à établir ces règles

58
0:02:51.379,000 --> 0:02:55,000
pour encadrer ce qui fait d'Internet un réseau.

59
0:02:55.52,000 --> 0:02:57,000
Le système de noms de domaine, les adresses IP,

60
0:02:58.029,000 --> 0:02:59,000
tout cela est en place.

61
0:02:59.769,000 --> 0:03:03,000
Mais nous entrons à présent dans les couches supérieures d'Internet,

62
0:03:04.127,000 --> 0:03:06,000
les problèmes qui nous affectent vous et moi tous les jours,

63
0:03:06.977,000 --> 0:03:08,000
comme le respect de la vie privée ou la sécurité.

64
0:03:10.993,000 --> 0:03:15,000
Le système de règles pour gérer ça n'existe malheureusement pas.

65
0:03:17.109,000 --> 0:03:18,000
Nous avons donc un problème.

66
0:03:18.737,000 --> 0:03:21,000
Nous avons un système de coopération et de gouvernance

67
0:03:22.411,000 --> 0:03:24,000
qui doit être créé maintenant

68
0:03:25.269,000 --> 0:03:28,000
pour que les entreprises, les gouvernements et les citoyens

69
0:03:29.074,000 --> 0:03:32,000
s'accordent sur l'évolution du monde numérique.

70
0:03:32.39,000 --> 0:03:35,000
BF : Qu'est-ce qui motive une entreprise ?

71
0:03:35.596,000 --> 0:03:37,000
Par exemple, une entreprise comme Facebook

72
0:03:37.615,000 --> 0:03:39,000
prétend prendre les intérêts de ses utilisateurs au sérieux,

73
0:03:40.564,000 --> 0:03:42,000
mais je pense que beaucoup ne sont pas d'accord.

74
0:03:43.063,000 --> 0:03:49,000
FC : C'est compliqué de vérifier comment ces entreprises réagissent

75
0:03:49.109,000 --> 0:03:52,000
à la position des citoyens envers leurs technologies.

76
0:03:52.991,000 --> 0:03:55,000
Certaines, il y a deux ou trois ans, s'en fichaient complètement.

77
0:03:56.499,000 --> 0:03:59,000
Dans les conseils d'administration, j'entends souvent :

78
0:03:59.708,000 --> 0:04:,000
« On n'est qu'une plateforme technologique,

79
0:04:01.704,000 --> 0:04:02,000
ce n'est pas notre problème

80
0:04:03.17,000 --> 0:04:07,000
si elle pousse des familles à tuer leurs filles au Pakistan.

81
0:04:07.635,000 --> 0:04:09,000
Ce n'est pas mon problème, c'est le leur.

82
0:04:09.946,000 --> 0:04:1,000
C'est juste une plateforme. »

83
0:04:12.629,000 --> 0:04:14,000
Je pense que nous entrons dans une ère

84
0:04:15.178,000 --> 0:04:17,000
où les entreprises réalisent

85
0:04:17.893,000 --> 0:04:19,000
qu'il n'est plus possible de continuer ainsi

86
0:04:20.483,000 --> 0:04:22,000
et elles commencent à voir les réactions négatives

87
0:04:22.853,000 --> 0:04:24,000
des gens, des utilisateurs, des citoyens

88
0:04:25.862,000 --> 0:04:27,000
et aussi des gouvernements, qui commencent à dire :

89
0:04:28.5,000 --> 0:04:29,000
« Ça doit cesser ! »

90
0:04:30.087,000 --> 0:04:35,000
Une forme de maturité commence à s'installer,

91
0:04:35.54,000 --> 0:04:37,000
notamment dans la Silicon Valley,

92
0:04:38.038,000 --> 0:04:42,000
où les gens commencent à se dire : « Nous avons un rôle à jouer. »

93
0:04:42.595,000 --> 0:04:44,000
Quand je parle à ces dirigeants, je leur dis :

94
0:04:45.165,000 --> 0:04:48,000
« Vous pouvez être le PDG d'une entreprise florissante,

95
0:04:49.042,000 --> 0:04:51,000
mais vous pouvez aussi être responsable. »

96
0:04:51.629,000 --> 0:04:52,000
C'est ça le mot essentiel.

97
0:04:52.906,000 --> 0:04:55,000
« Vous pouvez être responsable du pouvoir qu'on vous a confié

98
0:04:56.482,000 --> 0:04:59,000
pour orienter la vie et l'économie de milliards de personnes.

99
0:05:00.967,000 --> 0:05:02,000
Que souhaitez-vous être ? »

100
0:05:03.531,000 --> 0:05:05,000
Et la réponse n'est pas l'un ou l'autre.

101
0:05:06.568,000 --> 0:05:08,000
C'est notre problème actuellement.

102
0:05:09.073,000 --> 0:05:13,000
Lorsqu'un adulte comme Brad Smith, le président de Microsoft,

103
0:05:13.101,000 --> 0:05:14,000
déclarait il y a quelques mois :

104
0:05:14.689,000 --> 0:05:16,000
« Il nous faut de nouvelles conventions de Genève

105
0:05:17.581,000 --> 0:05:19,000
pour gérer la sécurité de l'espace numérique »,

106
0:05:20.294,000 --> 0:05:23,000
de nombreux dirigeants de Silicon Valley

107
0:05:23.985,000 --> 0:05:26,000
se sont élevés contre lui.

108
0:05:27.302,000 --> 0:05:28,000
« Des conventions de Genève ?

109
0:05:28.882,000 --> 0:05:31,000
Nous n'en avons pas besoin. Nous nous auto-régulons. »

110
0:05:32.173,000 --> 0:05:34,000
Mais cet état d'esprit change,

111
0:05:34.239,000 --> 0:05:37,000
et je constate que de plus en plus de dirigeants

112
0:05:37.519,000 --> 0:05:38,000
nous demandent de l'aide.

113
0:05:39.201,000 --> 0:05:41,000
Le nœud du problème est celui-ci :

114
0:05:41.909,000 --> 0:05:43,000
qui va aider ces dirigeants à faire le bon choix ?

115
0:05:45.206,000 --> 0:05:47,000
BF : Donc, qui va les aider ?

116
0:05:47.475,000 --> 0:05:51,000
J'aimerais vous interviewer durant une heure,

117
0:05:51.655,000 --> 0:05:56,000
mais quelles sont vos peurs et vos espoirs

118
0:05:56.832,000 --> 0:05:57,000
concernant ce problème ?

119
0:06:01.181,000 --> 0:06:07,000
FC : Mon plus grand espoir est que nous devenions tous responsables

120
0:06:07.744,000 --> 0:06:08,000
de ce nouveau monde numérique.

121
0:06:09.358,000 --> 0:06:1,000
C'est mon plus grand espoir

122
0:06:10.763,000 --> 0:06:14,000
car je pense que souvent, nous rejetons la faute sur les autres.

123
0:06:15.761,000 --> 0:06:17,000
« C'est la faute des PDG. Ils se comportent ainsi. »

124
0:06:18.196,000 --> 0:06:19,000
« Les gouvernements ne font pas assez. »

125
0:06:20.11,000 --> 0:06:21,000
Mais qu'en est-il de nous ?

126
0:06:21.948,000 --> 0:06:26,000
Comment prenons-nous nos responsabilités

127
0:06:26.964,000 --> 0:06:28,000
dans l'espace numérique qui nous entoure ?

128
0:06:29.297,000 --> 0:06:32,000
L'une des choses que je répète aux présidents d'université

129
0:06:33.114,000 --> 0:06:36,000
est qu'il faut que les étudiants en ingénierie, science et informatique,

130
0:06:36.878,000 --> 0:06:38,000
ceux qui écriront les prochaines lignes de code

131
0:06:39.437,000 --> 0:06:41,000
ou concevront les futurs appareils de l'IdO,

132
0:06:41.75,000 --> 0:06:45,000
développent un sens des responsabilités et de la gestion

133
0:06:46.631,000 --> 0:06:47,000
dans ce qu'ils créent.

134
0:06:48.134,000 --> 0:06:5,000
J'ai suggéré la création d'un nouveau serment,

135
0:06:50.564,000 --> 0:06:51,000
semblable au serment d'Hippocrate,

136
0:06:52.287,000 --> 0:06:54,000
liant chaque étudiant commençant un parcours d'ingénieur

137
0:06:55.209,000 --> 0:06:58,000
à un serment technocratique, un serment de sagesse,

138
0:06:58.864,000 --> 0:07:,000
ou un serment d'engagement envers le reste de la communauté.

139
0:07:01.771,000 --> 0:07:03,000
C'est mon plus grand espoir, que nous grandissions tous.

140
0:07:04.501,000 --> 0:07:08,000
Les gouvernements et les entreprises lutteront pour ce jeu de pouvoir,

141
0:07:09.438,000 --> 0:07:1,000
mais nous ?

142
0:07:10.996,000 --> 0:07:14,000
Si nous ne jouons pas à cette table du pouvoir,

143
0:07:15.472,000 --> 0:07:17,000
je pense que cela se terminera mal.

144
0:07:18.395,000 --> 0:07:19,000
Ma plus grande peur ?

145
0:07:21.392,000 --> 0:07:23,000
Ma plus grande peur, en pratique aujourd'hui,

146
0:07:24.28,000 --> 0:07:26,000
ce qui m'empêche de dormir,

147
0:07:26.543,000 --> 0:07:31,000
c'est la guerre entre l'Occident, le monde libéral,

148
0:07:33.304,000 --> 0:07:34,000
et la Chine,

149
0:07:34.837,000 --> 0:07:36,000
dans le domaine de l'intelligence artificielle.

150
0:07:37.138,000 --> 0:07:39,000
Une vraie guerre se déroule actuellement

151
0:07:39.368,000 --> 0:07:44,000
et pour ceux qui ont vécu à l'époque de la non-prolifération nucléaire

152
0:07:44.393,000 --> 0:07:46,000
et ont vu comment les gens se sont mis d'accord

153
0:07:46.811,000 --> 0:07:48,000
pour retirer certains éléments dangereux de la table,

154
0:07:50.787,000 --> 0:07:53,000
eh bien, la Fondation Carnegie vient de terminer une étude.

155
0:07:54.49,000 --> 0:07:56,000
Ils ont échangé avec tous les pays ayant des armes nucléaires

156
0:07:57.371,000 --> 0:07:58,000
et leur ont demandé :

157
0:07:59.046,000 --> 0:08:02,000
« Quelle arme numérique

158
0:08:03.019,000 --> 0:08:07,000
qui vise les écoles et hôpitaux d'autres pays retireriez-vous ? »

159
0:08:07.828,000 --> 0:08:08,000
La réponse,

160
0:08:09.051,000 --> 0:08:11,000
de toutes les puissances nucléaires,

161
0:08:11.917,000 --> 0:08:11,000
a été :

162
0:08:13.347,000 --> 0:08:14,000
« Aucune. »

163
0:08:15.693,000 --> 0:08:16,000
C'est cela qui m'inquiète...

164
0:08:18.161,000 --> 0:08:2,000
La militarisation de l'espace numérique

165
0:08:21.065,000 --> 0:08:22,000
et la course pour y parvenir.

166
0:08:22.741,000 --> 0:08:24,000
BF : Il semble que vous ayez beaucoup de travail.

167
0:08:25.56,000 --> 0:08:26,000
Et nous aussi.

168
0:08:27.125,000 --> 0:08:29,000
Fadi, merci beaucoup. Merci pour cette intervention.

169
0:08:29.825,000 --> 0:08:3,000
FC : Merci à vous.

170
0:08:31.04,000 --> 0:08:33,000
(Applaudissements)

