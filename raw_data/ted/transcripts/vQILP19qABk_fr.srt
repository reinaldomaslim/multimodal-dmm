1
0:00:,000 --> 0:00:07,000
Traducteur: Eléa Weibel Relecteur: Morgane Quilfen

2
0:00:12.82,000 --> 0:00:16,000
Roy Price est un homme que la plupart d'entre vous ne connaissent sûrement pas,

3
0:00:17.12,000 --> 0:00:19,000
même s'il est peut-être responsable

4
0:00:19.64,000 --> 0:00:25,000
de 22 minutes quelque peu médiocres que vous avez vécues le 19 avril 2013.

5
0:00:26.56,000 --> 0:00:29,000
Il a pu être responsable de 22 minutes divertissantes,

6
0:00:29.76,000 --> 0:00:3,000
mais pas pour beaucoup d'entre vous.

7
0:00:32.04,000 --> 0:00:33,000
Cela est lié à une décision

8
0:00:33.964,000 --> 0:00:34,000
que Roy a prise, il y a trois ans de ça.

9
0:00:35.952,000 --> 0:00:39,000
Vous voyez, Roy Price est cadre supérieur à Amazon Studios,

10
0:00:40.841,000 --> 0:00:42,000
la compagnie de production de télévision d'Amazon.

11
0:00:43.88,000 --> 0:00:45,000
C'est un homme mince de 47 ans avec des cheveux en bataille,

12
0:00:47.156,000 --> 0:00:5,000
qui a écrit sur Twitter pour se décrire « films, télé, technologie, tacos ».

13
0:00:51.995,000 --> 0:00:55,000
Et Roy Price joue un rôle important, parce que c'est à lui

14
0:00:57.195,000 --> 0:01:,000
de choisir les séries, le contenu original créé par Amazon.

15
0:01:01.276,000 --> 0:01:03,000
Et, évidemment, c'est un domaine très compétitif.

16
0:01:03.636,000 --> 0:01:05,000
Vu qu'il existe déjà tellement de séries télés,

17
0:01:06.4,000 --> 0:01:08,000
Roy ne peut pas choisir n'importe quelle série.

18
0:01:08.596,000 --> 0:01:11,000
Il doit trouver des séries vraiment, vraiment exceptionnelles.

19
0:01:12.716,000 --> 0:01:14,000
Autrement dit, il doit trouver des séries

20
0:01:15.556,000 --> 0:01:17,000
sur l'extrême droite de cette courbe.

21
0:01:17.956,000 --> 0:01:19,000
Cette courbe représente la distribution des notes

22
0:01:20.636,000 --> 0:01:24,000
attribuées à 2 500 séries télés sur le site IMDB,

23
0:01:25.036,000 --> 0:01:27,000
ces notes allant de 1 à 10,

24
0:01:27.956,000 --> 0:01:29,000
et l'ordonnée montre combien de séries obtiennent cette note.

25
0:01:30.956,000 --> 0:01:34,000
Donc, si votre série obtient une note de neuf points ou plus, ça cartonne.

26
0:01:35.676,000 --> 0:01:36,000
Elle est meilleure que 98 % des autres.

27
0:01:37.516,000 --> 0:01:38,000
Ce sont des séries comme

28
0:01:38.686,000 --> 0:01:4,000
« Breaking Bad », « Game of Thrones », « Sur écoute »,

29
0:01:41.436,000 --> 0:01:43,000
des séries auxquelles on devient accro,

30
0:01:43.756,000 --> 0:01:45,000
où après avoir regardé une saison, votre cerveau vous dit :

31
0:01:46.536,000 --> 0:01:47,000
« Il me faut plus d'épisodes ! »

32
0:01:49.04,000 --> 0:01:5,000
Ce genre d'émission.

33
0:01:50.92,000 --> 0:01:52,000
Pour être clair, du côté gauche,

34
0:01:53.47,000 --> 0:01:56,000
on retrouve une émission appelé « Toddlers & Tiaras » ;

35
0:01:56.636,000 --> 0:01:57,000
(Rires)

36
0:01:59.316,000 --> 0:02:,000
ce qui illustre bien

37
0:02:00.706,000 --> 0:02:02,000
ce à quoi on a affaire de ce côté de la courbe.

38
0:02:03.716,000 --> 0:02:06,000
Roy Price ne s'inquiète pas d'être placé du côté gauche de la courbe,

39
0:02:07.281,000 --> 0:02:09,000
parce que je pense qu'il faudrait être un génie

40
0:02:10.236,000 --> 0:02:12,000
pour faire pire que « Toddlers & Tiaras ».

41
0:02:12.286,000 --> 0:02:15,000
Il fait attention à cette partie au milieu,

42
0:02:15.91,000 --> 0:02:16,000
la partie moyenne de la télé,

43
0:02:17.756,000 --> 0:02:19,000
les séries qui ne sont ni bonnes ni mauvaises,

44
0:02:20.176,000 --> 0:02:21,000
mais ne vous font pas vibrer.

45
0:02:22.321,000 --> 0:02:25,000
Il doit s'assurer qu'il est vraiment du bon côté.

46
0:02:27.2,000 --> 0:02:28,000
Donc, on lui met la pression,

47
0:02:28.796,000 --> 0:02:3,000
et bien sûr c'est aussi la première fois

48
0:02:30.996,000 --> 0:02:32,000
qu'Amazon fait quelque chose comme ça,

49
0:02:33.196,000 --> 0:02:36,000
donc Roy Price ne veut pas prendre de risque.

50
0:02:36.556,000 --> 0:02:38,000
Il veut être à la tête d'un succès.

51
0:02:39.036,000 --> 0:02:4,000
Il lui faut un succès garanti,

52
0:02:40.836,000 --> 0:02:42,000
donc il décide d'organiser une compétition.

53
0:02:43.436,000 --> 0:02:46,000
Il prend plein d'idées de séries télés,

54
0:02:46.596,000 --> 0:02:48,000
les évalue et, parmi ces idées,

55
0:02:48.916,000 --> 0:02:51,000
il retient huit idées de séries.

56
0:02:52.696,000 --> 0:02:55,000
Ensuite, il se lance dans la création du premier épisode de chacune des séries

57
0:02:56.356,000 --> 0:02:58,000
et les met en ligne gratuitement pour tout le monde.

58
0:02:59.436,000 --> 0:03:01,000
Et quand Amazon offre quelque chose de gratuit,

59
0:03:01.716,000 --> 0:03:02,000
on le prend, n'est-ce pas ?

60
0:03:03.276,000 --> 0:03:07,000
Donc, des millions de gens regardent ces épisodes.

61
0:03:08.436,000 --> 0:03:11,000
Ils ne se rendent pas compte que, lorsqu'ils regardent leurs séries,

62
0:03:11.68,000 --> 0:03:13,000
ils sont en train d'être regardés eux-mêmes.

63
0:03:14,000 --> 0:03:16,000
Roy Price et son équipe les surveillent

64
0:03:16.36,000 --> 0:03:17,000
et enregistrent tout.

65
0:03:17.756,000 --> 0:03:2,000
Ils enregistrent quand quelqu'un appuie sur lecture ou sur pause,

66
0:03:21.16,000 --> 0:03:23,000
les parties sautées, les parties re-regardées.

67
0:03:23.72,000 --> 0:03:25,000
Ils rassemblent des millions de données,

68
0:03:26,000 --> 0:03:28,000
car ils veulent avoir ces données

69
0:03:28.12,000 --> 0:03:3,000
pour ensuite décider quelle série sera réalisée.

70
0:03:30.836,000 --> 0:03:31,000
Donc ils rassemblent ces données,

71
0:03:32.64,000 --> 0:03:34,000
ils traitent ces données, et une réponse en est déduite,

72
0:03:35.546,000 --> 0:03:36,000
la réponse est :

73
0:03:36.74,000 --> 0:03:37,000
« Amazon devrait réaliser un sitcom

74
0:03:38.59,000 --> 0:03:4,000
sur quatre sénateurs républicains américains. »

75
0:03:41.17,000 --> 0:03:42,000
(Rires)

76
0:03:42.32,000 --> 0:03:43,000
Et elle a été réalisée.

77
0:03:43.706,000 --> 0:03:45,000
Quelqu'un connaît le nom de cette série ?

78
0:03:46.72,000 --> 0:03:47,000
(Public) : « Alpha House. »

79
0:03:48.04,000 --> 0:03:49,000
Exactement, « Alpha House »,

80
0:03:49.49,000 --> 0:03:52,000
mais on dirait que presque personne ne se souvient de cette série

81
0:03:53.64,000 --> 0:03:54,000
car elle n'a pas eu un très grand succès.

82
0:03:55.596,000 --> 0:03:56,000
En réalité, c'est une série moyenne,

83
0:03:57.396,000 --> 0:04:01,000
littéralement en fait, car 7,4 représente la moyenne de la courbe

84
0:04:02,000 --> 0:04:04,000
et « Alpha House » tombe sur 7,5,

85
0:04:04.44,000 --> 0:04:06,000
elle est juste au-dessus de la moyenne,

86
0:04:06.476,000 --> 0:04:09,000
mais ce n'est certainement pas Roy Price et son équipe espéraient.

87
0:04:10.32,000 --> 0:04:12,000
Cependant, au même moment,

88
0:04:13.2,000 --> 0:04:14,000
dans une autre entreprise,

89
0:04:14.8,000 --> 0:04:18,000
un autre cadre a trouver une bonne série grâce à l'analyse des données,

90
0:04:19.036,000 --> 0:04:2,000
et il s'appelle Ted,

91
0:04:20.64,000 --> 0:04:23,000
Ted Sarandos, directeur de l'acquisition des programmes de Netflix.

92
0:04:24.08,000 --> 0:04:26,000
Et comme Roy, il est toujours à la recherche

93
0:04:26.27,000 --> 0:04:27,000
d'une excellente série,

94
0:04:27.756,000 --> 0:04:29,000
et il utilise aussi des données,

95
0:04:29.796,000 --> 0:04:3,000
sauf qu'il s'y prend un peu différemment.

96
0:04:31.835,000 --> 0:04:34,000
Au lieu d'organiser une compétition, lui et son équipe

97
0:04:35.6,000 --> 0:04:38,000
ont pris les données qu'ils avaient déjà sur les utilisateurs de Netflix,

98
0:04:39.16,000 --> 0:04:4,000
comme les notes attribuées aux séries,

99
0:04:40.98,000 --> 0:04:43,000
leur historique, leurs séries préférées et tout ça.

100
0:04:43.996,000 --> 0:04:45,000
Puis ils utilisent ces données pour découvrir

101
0:04:46.106,000 --> 0:04:48,000
pleins de petites infos sur le public :

102
0:04:48.56,000 --> 0:04:51,000
le genre de séries, de producteurs, d'acteurs ils apprécient.

103
0:04:52.136,000 --> 0:04:54,000
Et au moment où ils ont tous les éléments nécessaires,

104
0:04:54.72,000 --> 0:04:55,000
ils ont accompli un acte de foi

105
0:04:56.46,000 --> 0:04:58,000
et ont décidé de créer

106
0:04:58.56,000 --> 0:05:,000
non pas un sitcom sur quatre sénateurs

107
0:05:01.036,000 --> 0:05:03,000
mais une série dramatique sur un seul sénateur.

108
0:05:04.76,000 --> 0:05:05,000
Vous connaissez cette série ?

109
0:05:06.41,000 --> 0:05:07,000
(Rires)

110
0:05:07.73,000 --> 0:05:1,000
Oui ! « House of Cards » et, bien sûr, Netflix a eu un grand succès,

111
0:05:11.52,000 --> 0:05:13,000
au moins pour les deux premières saisons.

112
0:05:13.68,000 --> 0:05:16,000
(Rires) (Applaudissements)

113
0:05:17.69,000 --> 0:05:2,000
« House of Cards » a obtenu une note de 9,1 sur cette courbe,

114
0:05:20.86,000 --> 0:05:22,000
donc, exactement ce qu'ils voulaient.

115
0:05:24.066,000 --> 0:05:26,000
Évidemment, la question est : que s'est-il passé ?

116
0:05:26.44,000 --> 0:05:28,000
On a deux entreprises concurrentes maîtrisant les données.

117
0:05:29.196,000 --> 0:05:31,000
Elles lient ces millions de points de données

118
0:05:32.06,000 --> 0:05:34,000
et ça marche superbement pour une,

119
0:05:34.45,000 --> 0:05:35,000
mais pas pour l'autre.

120
0:05:36.33,000 --> 0:05:37,000
Alors, pourquoi ?

121
0:05:37.58,000 --> 0:05:4,000
La logique nous dit que ça devrait marcher à tous les coups.

122
0:05:41.08,000 --> 0:05:43,000
Si vous rassemblez des millions de données

123
0:05:43.54,000 --> 0:05:44,000
sur une décision à prendre,

124
0:05:45.3,000 --> 0:05:47,000
vous devriez être capable de prendre la bonne décision.

125
0:05:47.93,000 --> 0:05:49,000
On peut se fier à plus de 200 ans de statistiques.

126
0:05:50.286,000 --> 0:05:52,000
On l'amplifie à l'aide des meilleurs ordinateurs.

127
0:05:53.24,000 --> 0:05:56,000
La moindre des choses à laquelle on s'attend, c'est une bonne série, non ?

128
0:05:57.89,000 --> 0:05:59,000
Et si l'analyse des données ne fonctionne pas comme ça,

129
0:06:01.53,000 --> 0:06:02,000
on peut commencer à s'inquiéter,

130
0:06:03.61,000 --> 0:06:06,000
parce que nous vivons à une époque où on utilise de plus en plus ces données

131
0:06:07.6,000 --> 0:06:1,000
pour prendre des décisions sérieuses en dehors du monde de la télévision.

132
0:06:12.76,000 --> 0:06:15,000
Est-ce-que quelqu'un ici connaît l'entreprise Multi-Health Systems ?

133
0:06:17.07,000 --> 0:06:18,000
Personne, tant mieux.

134
0:06:18.76,000 --> 0:06:2,000
Multi-Health Systems est une entreprise de logiciels,

135
0:06:21.996,000 --> 0:06:26,000
et j'espère que personne du public n'aura à utiliser ce logiciel,

136
0:06:28.036,000 --> 0:06:29,000
car si c'est le cas, vous êtes en prison.

137
0:06:30.156,000 --> 0:06:3,000
(Rires)

138
0:06:31.36,000 --> 0:06:34,000
Si un prisonnier des États-Unis demande une libération conditionnelle,

139
0:06:34.92,000 --> 0:06:38,000
il est très probable que le logiciel d'analyse de données de cette compagnie

140
0:06:39.236,000 --> 0:06:41,000
sera utilisé pour savoir s'il devrait l'obtenir.

141
0:06:42.88,000 --> 0:06:44,000
C'est le même principe qu'Amazon et Netflix,

142
0:06:45.47,000 --> 0:06:49,000
sauf que au lieu de voir si une série télé devrait sortir,

143
0:06:50.12,000 --> 0:06:52,000
on décide si la personne devrait sortir.

144
0:06:53.04,000 --> 0:06:58,000
Si une série télé médiocre de 22 minutes peut être mauvaise,

145
0:06:58.55,000 --> 0:07:,000
je suppose que passer plus longtemps en prison est pire.

146
0:07:02.36,000 --> 0:07:05,000
Et malheureusement, il existe des preuves que cette analyse de données,

147
0:07:06.52,000 --> 0:07:09,000
malgré leur abondance, ne donne pas toujours des résultats optimaux.

148
0:07:10.76,000 --> 0:07:12,000
Mais, ce n'est pas parce que Multi-Health Systems

149
0:07:13.506,000 --> 0:07:14,000
ignore que faire de ces données.

150
0:07:15.163,000 --> 0:07:17,000
Même en maîtrisant les données, on peut se tromper.

151
0:07:17.546,000 --> 0:07:19,000
Oui, parfois même Google se trompe.

152
0:07:20.68,000 --> 0:07:22,000
En 2009, Google a annoncé qu'ils étaient capables,

153
0:07:23.56,000 --> 0:07:24,000
à l'aide de l'analyse des données,

154
0:07:25.2,000 --> 0:07:28,000
de prédire les épidémies d'influenza, la mauvaise grippe,

155
0:07:29.34,000 --> 0:07:32,000
en analysant les données des recherches sur leur site.

156
0:07:33.12,000 --> 0:07:36,000
Ça a bien marché, et ça a fait le buzz aux infos

157
0:07:36.98,000 --> 0:07:38,000
y compris l'apogée des réussites scientifiques :

158
0:07:39.216,000 --> 0:07:4,000
un article dans le journal « Nature ».

159
0:07:41.64,000 --> 0:07:44,000
Ça marchait à tous les coups, année après année,

160
0:07:45.31,000 --> 0:07:46,000
jusqu'à l'année où ça a échoué.

161
0:07:46.96,000 --> 0:07:48,000
Et personne ne savait pourquoi.

162
0:07:49.28,000 --> 0:07:5,000
Cette année-là, ça n'a pas marché

163
0:07:50.996,000 --> 0:07:51,000
et, bien sûr, ça a refait le buzz,

164
0:07:52.956,000 --> 0:07:53,000
y compris la rétraction

165
0:07:54.58,000 --> 0:07:56,000
de la publication dans le journal « Nature ».

166
0:07:58.48,000 --> 0:08:,000
Même les entreprises maîtrisant ces données,

167
0:08:00.72,000 --> 0:08:01,000
comme Amazon et Google,

168
0:08:01.84,000 --> 0:08:02,000
font parfois des erreurs.

169
0:08:04,000 --> 0:08:06,000
Et malgré tous ces échecs,

170
0:08:06.94,000 --> 0:08:09,000
les données arrivent de plus en plus dans nos décisions de tous les jours :

171
0:08:10.8,000 --> 0:08:11,000
dans le monde professionnel,

172
0:08:12.67,000 --> 0:08:13,000
le monde du droit,

173
0:08:14.52,000 --> 0:08:15,000
le monde de la médécine.

174
0:08:16.39,000 --> 0:08:18,000
Donc, il faut nous assurer que ces données nous aident.

175
0:08:19.696,000 --> 0:08:21,000
Moi-même, j'ai beaucoup vu ce problème avec les données

176
0:08:22.862,000 --> 0:08:24,000
car je travaille dans l'informatique génomique,

177
0:08:25.059,000 --> 0:08:27,000
un secteur rempli de personnes très intelligentes

178
0:08:27.448,000 --> 0:08:29,000
qui utilisent un grand nombre de données

179
0:08:29.528,000 --> 0:08:3,000
pour prendre des décisions sérieuses

180
0:08:31.268,000 --> 0:08:34,000
comme choisir un traitement pour cancer, développer un médicament.

181
0:08:35.52,000 --> 0:08:37,000
Au cours des années, j'ai remarqué un modèle,

182
0:08:37.926,000 --> 0:08:39,000
ou même une règle, sur la différence

183
0:08:40.42,000 --> 0:08:42,000
entre des bonnes décisions à l'aide des données

184
0:08:43.15,000 --> 0:08:44,000
et des mauvaises décisions,

185
0:08:44.72,000 --> 0:08:46,000
et je trouve que ce modèle vaut la peine d'être partagé,

186
0:08:47.39,000 --> 0:08:48,000
ça se présente comme ceci.

187
0:08:50.52,000 --> 0:08:52,000
Quand il faut résoudre un problème compliqué,

188
0:08:52.685,000 --> 0:08:53,000
il y a deux étapes essentielles.

189
0:08:54.45,000 --> 0:08:57,000
Un : il faut diviser le problème en plusieurs parties

190
0:08:57.77,000 --> 0:08:59,000
pour pouvoir les analyser de manière profonde,

191
0:09:00.28,000 --> 0:09:02,000
et puis deux : bien sûr,

192
0:09:02.32,000 --> 0:09:04,000
il s'agit de remettre ces pièces ensemble

193
0:09:04.99,000 --> 0:09:05,000
pour conclure.

194
0:09:06.3,000 --> 0:09:08,000
Et parfois il faut réessayer,

195
0:09:08.67,000 --> 0:09:09,000
mais c'est toujours ces deux choses :

196
0:09:10.456,000 --> 0:09:12,000
déconstruire le problème et le remonter.

197
0:09:14.28,000 --> 0:09:15,000
Et la partie clé

198
0:09:15.93,000 --> 0:09:17,000
est que l'analyse de ces données

199
0:09:18.81,000 --> 0:09:2,000
n'est valable que pour la première partie.

200
0:09:21.29,000 --> 0:09:23,000
Les données et l'analyse, peu importe leur puissance,

201
0:09:23.776,000 --> 0:09:25,000
n'aideront qu'à déconstruire le problème

202
0:09:25.976,000 --> 0:09:27,000
pour comprendre les éléments qui le composent.

203
0:09:28.116,000 --> 0:09:31,000
Ça n'aidera pas à remettre les pièces ensemble

204
0:09:31.6,000 --> 0:09:32,000
pour en arriver à une conclusion.

205
0:09:33.52,000 --> 0:09:35,000
Il existe un outil qui fait ça, que nous possédons tous :

206
0:09:36.28,000 --> 0:09:36,000
le cerveau.

207
0:09:37.6,000 --> 0:09:38,000
Si notre cerveau est bon pour une chose,

208
0:09:39.57,000 --> 0:09:41,000
c'est assembler divers éléments ensemble,

209
0:09:41.836,000 --> 0:09:42,000
même avec des pièces manquantes,

210
0:09:43.87,000 --> 0:09:44,000
et arriver à une bonne conclusion,

211
0:09:45.496,000 --> 0:09:47,000
surtout si c'est le cerveau d'un expert.

212
0:09:48.42,000 --> 0:09:5,000
Et c'est grâce à ça que Netflix a eu un tel succès :

213
0:09:51.1,000 --> 0:09:54,000
ils ont utilisé les données et les cerveaux au moment où il fallait.

214
0:09:54.72,000 --> 0:09:57,000
Ils ont d'abord utilisé les données pour comprendre leur public,

215
0:09:58.29,000 --> 0:10:,000
ce qu'ils n'auraient pas été capables de comprendre sans ça,

216
0:10:01.696,000 --> 0:10:03,000
mais la décision de prendre toutes ces informations

217
0:10:04.36,000 --> 0:10:07,000
et les remettre ensemble pour créer une série comme « House of Cards »,

218
0:10:07.7,000 --> 0:10:08,000
n'était pas dans les données.

219
0:10:09.1,000 --> 0:10:12,000
Ted Sarandos et son équipe ont décidé d'autoriser la création de cette série,

220
0:10:13.11,000 --> 0:10:15,000
ce qui voulait aussi dire qu'ils prenaient

221
0:10:15.565,000 --> 0:10:17,000
un grand risque personnel avec cette décision.

222
0:10:18.44,000 --> 0:10:21,000
À l'inverse, Amazon a fait cela dans le mauvais ordre.

223
0:10:21.48,000 --> 0:10:23,000
Ils ont utilisé beaucoup de données pour faire leur choix,

224
0:10:24.24,000 --> 0:10:26,000
en organisant une compétition d'idées de séries,

225
0:10:26.69,000 --> 0:10:29,000
puis en choisissant de produire « Alpha House ».

226
0:10:30.4,000 --> 0:10:32,000
C'était bien sûr prudent comme décision de leur part,

227
0:10:32.92,000 --> 0:10:34,000
car ils pouvaient accuser les donnés et dire :

228
0:10:35.39,000 --> 0:10:36,000
« C'est ce que disaient les données. »

229
0:10:37.196,000 --> 0:10:4,000
Mais ça ne leur a pas donné les résultats exceptionnels qu'ils espéraient.

230
0:10:42.12,000 --> 0:10:46,000
Les données sont extrêmement utiles pour prendre de meilleures décisions

231
0:10:47.11,000 --> 0:10:49,000
mais je pense qu'il y a un problème

232
0:10:49.52,000 --> 0:10:51,000
quand les données nous mènent à ces décisions.

233
0:10:52.1,000 --> 0:10:55,000
Peu importe leur puissance, les données ne sont qu'un outil,

234
0:10:55.92,000 --> 0:10:58,000
et pour toujours garder ça en tête, j'ai trouvé un outil très utile.

235
0:10:59.28,000 --> 0:11:,000
La plupart d'entre vous...

236
0:11:00.56,000 --> 0:11:01,000
(Rires)

237
0:11:01.72,000 --> 0:11:02,000
Avant les données,

238
0:11:02.97,000 --> 0:11:04,000
on utilisait cet outil pour prendre des décisions.

239
0:11:05.73,000 --> 0:11:06,000
(Rires)

240
0:11:07.16,000 --> 0:11:08,000
Vous le connaissez,

241
0:11:08.596,000 --> 0:11:09,000
ce jouet s'appelle la Magic 8 Ball

242
0:11:10.483,000 --> 0:11:11,000
et il est génial,

243
0:11:11.716,000 --> 0:11:13,000
car si vous avez un choix à faire, une question fermée,

244
0:11:14.64,000 --> 0:11:16,000
il suffit de secouer la boule pour obtenir une réponse --

245
0:11:18.4,000 --> 0:11:2,000
« Très Probable » -- juste ici, une réponse en temps réel.

246
0:11:21.23,000 --> 0:11:23,000
J'en ferai la démonstration plus tard.

247
0:11:23.566,000 --> 0:11:23,000
(Rires)

248
0:11:24.57,000 --> 0:11:27,000
Le truc c'est que, évidemment -- j'ai pris des décisions dans la vie

249
0:11:28.21,000 --> 0:11:3,000
où, en rétrospective, j'aurais dû écouter la boule.

250
0:11:31.12,000 --> 0:11:34,000
Mais, évidemment, si les données sont disponibles,

251
0:11:34.46,000 --> 0:11:36,000
on veut remplacer ça avec quelque chose de plus sophistiqué,

252
0:11:37.53,000 --> 0:11:4,000
comme l'analyse des données, pour en arriver à une meilleure décision.

253
0:11:41.17,000 --> 0:11:43,000
Mais cela ne change pas le concept de base.

254
0:11:43.84,000 --> 0:11:45,000
La boule peut devenir de plus en plus intelligente,

255
0:11:47.03,000 --> 0:11:49,000
mais je pense que c'est toujours à nous de décider

256
0:11:49.89,000 --> 0:11:52,000
si on veut faire quelque chose d'extraordinaire,

257
0:11:52.93,000 --> 0:11:53,000
du côté droit de la courbe.

258
0:11:54.84,000 --> 0:11:58,000
Et je trouve ça très encourageant comme message en fait,

259
0:11:59.37,000 --> 0:12:02,000
que même quand on a toutes ces données devant nous,

260
0:12:03.38,000 --> 0:12:06,000
ça nous rapporte quelque chose de prendre ces décisions,

261
0:12:07.49,000 --> 0:12:09,000
d'être expert dans notre domaine

262
0:12:10.17,000 --> 0:12:11,000
et de prendre des risques.

263
0:12:12.29,000 --> 0:12:14,000
Car à la fin, ce ne sont pas les données,

264
0:12:15.08,000 --> 0:12:18,000
ce sont les risques qui vous amènent du côté droit de la courbe.

265
0:12:19.84,000 --> 0:12:2,000
Merci.

266
0:12:21.06,000 --> 0:12:24,000
(Applaudissements)

