1
0:00:12.844,000 --> 0:00:14,000
When we think about prejudice and bias,

2
0:00:15.222,000 --> 0:00:17,000
we tend to think about stupid and evil people

3
0:00:17.366,000 --> 0:00:19,000
doing stupid and evil things.

4
0:00:19.82,000 --> 0:00:21,000
And this idea is nicely summarized

5
0:00:21.89,000 --> 0:00:23,000
by the British critic William Hazlitt,

6
0:00:24.358,000 --> 0:00:26,000
who wrote, "Prejudice is the child of ignorance."

7
0:00:27.293,000 --> 0:00:29,000
I want to try to convince you here

8
0:00:29.405,000 --> 0:00:3,000
that this is mistaken.

9
0:00:31.04,000 --> 0:00:32,000
I want to try to convince you

10
0:00:32.772,000 --> 0:00:33,000
that prejudice and bias

11
0:00:34.495,000 --> 0:00:37,000
are natural, they're often rational,

12
0:00:37.783,000 --> 0:00:38,000
and they're often even moral,

13
0:00:39.614,000 --> 0:00:41,000
and I think that once we understand this,

14
0:00:41.866,000 --> 0:00:43,000
we're in a better position to make sense of them

15
0:00:44.375,000 --> 0:00:45,000
when they go wrong,

16
0:00:45.432,000 --> 0:00:46,000
when they have horrible consequences,

17
0:00:47.2,000 --> 0:00:49,000
and we're in a better position to know what to do

18
0:00:49.525,000 --> 0:00:5,000
when this happens.

19
0:00:51.207,000 --> 0:00:54,000
So, start with stereotypes. You look at me,

20
0:00:54.234,000 --> 0:00:56,000
you know my name, you know certain facts about me,

21
0:00:56.48,000 --> 0:00:57,000
and you could make certain judgments.

22
0:00:58.309,000 --> 0:01:,000
You could make guesses about my ethnicity,

23
0:01:01.162,000 --> 0:01:04,000
my political affiliation, my religious beliefs.

24
0:01:04.443,000 --> 0:01:06,000
And the thing is, these judgments tend to be accurate.

25
0:01:06.542,000 --> 0:01:08,000
We're very good at this sort of thing.

26
0:01:08.724,000 --> 0:01:09,000
And we're very good at this sort of thing

27
0:01:10.207,000 --> 0:01:12,000
because our ability to stereotype people

28
0:01:12.94,000 --> 0:01:15,000
is not some sort of arbitrary quirk of the mind,

29
0:01:16.195,000 --> 0:01:18,000
but rather it's a specific instance

30
0:01:18.511,000 --> 0:01:19,000
of a more general process,

31
0:01:20.166,000 --> 0:01:21,000
which is that we have experience

32
0:01:21.785,000 --> 0:01:22,000
with things and people in the world

33
0:01:23.326,000 --> 0:01:24,000
that fall into categories,

34
0:01:24.575,000 --> 0:01:26,000
and we can use our experience to make generalizations

35
0:01:27.031,000 --> 0:01:29,000
about novel instances of these categories.

36
0:01:29.39,000 --> 0:01:31,000
So everybody here has a lot of experience

37
0:01:31.757,000 --> 0:01:33,000
with chairs and apples and dogs,

38
0:01:34.01,000 --> 0:01:35,000
and based on this, you could see

39
0:01:35.646,000 --> 0:01:37,000
unfamiliar examples and you could guess,

40
0:01:37.998,000 --> 0:01:38,000
you could sit on the chair,

41
0:01:39.314,000 --> 0:01:41,000
you could eat the apple, the dog will bark.

42
0:01:41.879,000 --> 0:01:42,000
Now we might be wrong.

43
0:01:43.643,000 --> 0:01:44,000
The chair could collapse if you sit on it,

44
0:01:45.443,000 --> 0:01:47,000
the apple might be poison, the dog might not bark,

45
0:01:47.665,000 --> 0:01:49,000
and in fact, this is my dog Tessie, who doesn't bark.

46
0:01:50.535,000 --> 0:01:52,000
But for the most part, we're good at this.

47
0:01:53.294,000 --> 0:01:54,000
For the most part, we make good guesses

48
0:01:55.21,000 --> 0:01:56,000
both in the social domain and the non-social domain,

49
0:01:57.024,000 --> 0:01:58,000
and if we weren't able to do so,

50
0:01:58.973,000 --> 0:02:01,000
if we weren't able to make guesses about new instances that we encounter,

51
0:02:02.189,000 --> 0:02:03,000
we wouldn't survive.

52
0:02:03.64,000 --> 0:02:05,000
And in fact, Hazlitt later on in his wonderful essay

53
0:02:06.509,000 --> 0:02:07,000
concedes this.

54
0:02:07.994,000 --> 0:02:09,000
He writes, "Without the aid of prejudice and custom,

55
0:02:10.536,000 --> 0:02:12,000
I should not be able to find my way my across the room;

56
0:02:12.876,000 --> 0:02:14,000
nor know how to conduct myself in any circumstances,

57
0:02:15.328,000 --> 0:02:19,000
nor what to feel in any relation of life."

58
0:02:19.531,000 --> 0:02:2,000
Or take bias.

59
0:02:21.04,000 --> 0:02:22,000
Now sometimes, we break the world up into

60
0:02:22.748,000 --> 0:02:25,000
us versus them, into in-group versus out-group,

61
0:02:25.749,000 --> 0:02:26,000
and sometimes when we do this,

62
0:02:26.91,000 --> 0:02:27,000
we know we're doing something wrong,

63
0:02:28.467,000 --> 0:02:29,000
and we're kind of ashamed of it.

64
0:02:30.14,000 --> 0:02:31,000
But other times we're proud of it.

65
0:02:31.623,000 --> 0:02:32,000
We openly acknowledge it.

66
0:02:33.436,000 --> 0:02:34,000
And my favorite example of this

67
0:02:34.718,000 --> 0:02:36,000
is a question that came from the audience

68
0:02:37.12,000 --> 0:02:39,000
in a Republican debate prior to the last election.

69
0:02:39.837,000 --> 0:02:41,000
(Video) Anderson Cooper: Gets to your question,

70
0:02:42.129,000 --> 0:02:46,000
the question in the hall, on foreign aid? Yes, ma'am.

71
0:02:46.31,000 --> 0:02:48,000
Woman: The American people are suffering

72
0:02:48.546,000 --> 0:02:5,000
in our country right now.

73
0:02:51.183,000 --> 0:02:54,000
Why do we continue to send foreign aid

74
0:02:54.531,000 --> 0:02:55,000
to other countries

75
0:02:55.847,000 --> 0:02:59,000
when we need all the help we can get for ourselves?

76
0:02:59.95,000 --> 0:03:,000
AC: Governor Perry, what about that?

77
0:03:01.645,000 --> 0:03:02,000
(Applause)

78
0:03:03.012,000 --> 0:03:05,000
Rick Perry: Absolutely, I think it's—

79
0:03:05.35,000 --> 0:03:06,000
Paul Bloom: Each of the people onstage

80
0:03:07.01,000 --> 0:03:08,000
agreed with the premise of her question,

81
0:03:08.981,000 --> 0:03:1,000
which is as Americans, we should care more

82
0:03:11.1,000 --> 0:03:13,000
about Americans than about other people.

83
0:03:13.226,000 --> 0:03:15,000
And in fact, in general, people are often swayed

84
0:03:16.091,000 --> 0:03:19,000
by feelings of solidarity, loyalty, pride, patriotism,

85
0:03:19.599,000 --> 0:03:21,000
towards their country or towards their ethnic group.

86
0:03:22.315,000 --> 0:03:25,000
Regardless of your politics, many people feel proud to be American,

87
0:03:25.4,000 --> 0:03:27,000
and they favor Americans over other countries.

88
0:03:27.462,000 --> 0:03:29,000
Residents of other countries feel the same about their nation,

89
0:03:30.312,000 --> 0:03:32,000
and we feel the same about our ethnicities.

90
0:03:32.798,000 --> 0:03:33,000
Now some of you may reject this.

91
0:03:34.482,000 --> 0:03:35,000
Some of you may be so cosmopolitan

92
0:03:36.213,000 --> 0:03:38,000
that you think that ethnicity and nationality

93
0:03:38.547,000 --> 0:03:4,000
should hold no moral sway.

94
0:03:40.7,000 --> 0:03:42,000
But even you sophisticates accept

95
0:03:43.462,000 --> 0:03:44,000
that there should be some pull

96
0:03:45.296,000 --> 0:03:47,000
towards the in-group in the domain of friends and family,

97
0:03:47.997,000 --> 0:03:48,000
of people you're close to,

98
0:03:49.418,000 --> 0:03:5,000
and so even you make a distinction

99
0:03:50.979,000 --> 0:03:51,000
between us versus them.

100
0:03:52.954,000 --> 0:03:54,000
Now, this distinction is natural enough

101
0:03:55.557,000 --> 0:03:57,000
and often moral enough, but it can go awry,

102
0:03:58.481,000 --> 0:03:59,000
and this was part of the research

103
0:04:00.21,000 --> 0:04:02,000
of the great social psychologist Henri Tajfel.

104
0:04:02.969,000 --> 0:04:04,000
Tajfel was born in Poland in 1919.

105
0:04:05.574,000 --> 0:04:07,000
He left to go to university in France,

106
0:04:07.713,000 --> 0:04:09,000
because as a Jew, he couldn't go to university in Poland,

107
0:04:10.268,000 --> 0:04:12,000
and then he enlisted in the French military

108
0:04:12.778,000 --> 0:04:13,000
in World War II.

109
0:04:14.061,000 --> 0:04:15,000
He was captured and ended up

110
0:04:15.83,000 --> 0:04:16,000
in a prisoner of war camp,

111
0:04:17.361,000 --> 0:04:19,000
and it was a terrifying time for him,

112
0:04:19.628,000 --> 0:04:2,000
because if it was discovered that he was a Jew,

113
0:04:21.316,000 --> 0:04:23,000
he could have been moved to a concentration camp,

114
0:04:23.408,000 --> 0:04:24,000
where he most likely would not have survived.

115
0:04:25.4,000 --> 0:04:27,000
And in fact, when the war ended and he was released,

116
0:04:27.987,000 --> 0:04:29,000
most of his friends and family were dead.

117
0:04:30.492,000 --> 0:04:31,000
He got involved in different pursuits.

118
0:04:32.329,000 --> 0:04:33,000
He helped out the war orphans.

119
0:04:33.86,000 --> 0:04:34,000
But he had a long-lasting interest

120
0:04:35.591,000 --> 0:04:36,000
in the science of prejudice,

121
0:04:37.136,000 --> 0:04:39,000
and so when a prestigious British scholarship

122
0:04:39.796,000 --> 0:04:4,000
on stereotypes opened up, he applied for it,

123
0:04:41.641,000 --> 0:04:42,000
and he won it,

124
0:04:42.998,000 --> 0:04:44,000
and then he began this amazing career.

125
0:04:45.188,000 --> 0:04:47,000
And what started his career is an insight

126
0:04:47.937,000 --> 0:04:48,000
that the way most people were thinking

127
0:04:49.777,000 --> 0:04:51,000
about the Holocaust was wrong.

128
0:04:51.893,000 --> 0:04:53,000
Many people, most people at the time,

129
0:04:54.299,000 --> 0:04:55,000
viewed the Holocaust as sort of representing

130
0:04:56.2,000 --> 0:04:59,000
some tragic flaw on the part of the Germans,

131
0:04:59.204,000 --> 0:05:02,000
some genetic taint, some authoritarian personality.

132
0:05:03.038,000 --> 0:05:05,000
And Tajfel rejected this.

133
0:05:05.096,000 --> 0:05:07,000
Tajfel said what we see in the Holocaust

134
0:05:07.639,000 --> 0:05:09,000
is just an exaggeration

135
0:05:09.95,000 --> 0:05:1,000
of normal psychological processes

136
0:05:11.728,000 --> 0:05:12,000
that exist in every one of us.

137
0:05:13.489,000 --> 0:05:15,000
And to explore this, he did a series of classic studies

138
0:05:16.174,000 --> 0:05:17,000
with British adolescents.

139
0:05:17.918,000 --> 0:05:18,000
And in one of his studies, what he did was he asked

140
0:05:19.467,000 --> 0:05:21,000
the British adolescents all sorts of questions,

141
0:05:22.019,000 --> 0:05:23,000
and then based on their answers, he said,

142
0:05:23.903,000 --> 0:05:25,000
"I've looked at your answers, and based on the answers,

143
0:05:26.26,000 --> 0:05:28,000
I have determined that you are either" —

144
0:05:28.357,000 --> 0:05:29,000
he told half of them —

145
0:05:29.363,000 --> 0:05:31,000
"a Kandinsky lover, you love the work of Kandinsky,

146
0:05:32.32,000 --> 0:05:34,000
or a Klee lover, you love the work of Klee."

147
0:05:35.298,000 --> 0:05:36,000
It was entirely bogus.

148
0:05:37.114,000 --> 0:05:39,000
Their answers had nothing to do with Kandinsky or Klee.

149
0:05:39.404,000 --> 0:05:41,000
They probably hadn't heard of the artists.

150
0:05:42.132,000 --> 0:05:44,000
He just arbitrarily divided them up.

151
0:05:44.872,000 --> 0:05:47,000
But what he found was, these categories mattered,

152
0:05:48.143,000 --> 0:05:5,000
so when he later gave the subjects money,

153
0:05:50.654,000 --> 0:05:51,000
they would prefer to give the money

154
0:05:52.33,000 --> 0:05:53,000
to members of their own group

155
0:05:54.13,000 --> 0:05:55,000
than members of the other group.

156
0:05:55.963,000 --> 0:05:57,000
Worse, they were actually most interested

157
0:05:58.29,000 --> 0:06:,000
in establishing a difference

158
0:06:00.296,000 --> 0:06:02,000
between their group and other groups,

159
0:06:02.862,000 --> 0:06:03,000
so they would give up money for their own group

160
0:06:04.77,000 --> 0:06:09,000
if by doing so they could give the other group even less.

161
0:06:10.018,000 --> 0:06:12,000
This bias seems to show up very early.

162
0:06:12.236,000 --> 0:06:14,000
So my colleague and wife, Karen Wynn, at Yale

163
0:06:14.536,000 --> 0:06:15,000
has done a series of studies with babies

164
0:06:16.147,000 --> 0:06:18,000
where she exposes babies to puppets,

165
0:06:18.979,000 --> 0:06:2,000
and the puppets have certain food preferences.

166
0:06:21.244,000 --> 0:06:23,000
So one of the puppets might like green beans.

167
0:06:23.426,000 --> 0:06:25,000
The other puppet might like graham crackers.

168
0:06:26.001,000 --> 0:06:28,000
They test the babies own food preferences,

169
0:06:28.37,000 --> 0:06:3,000
and babies typically prefer the graham crackers.

170
0:06:31.06,000 --> 0:06:33,000
But the question is, does this matter to babies

171
0:06:33.672,000 --> 0:06:36,000
in how they treat the puppets? And it matters a lot.

172
0:06:36.788,000 --> 0:06:37,000
They tend to prefer the puppet

173
0:06:38.307,000 --> 0:06:41,000
who has the same food tastes that they have,

174
0:06:41.786,000 --> 0:06:43,000
and worse, they actually prefer puppets

175
0:06:44.342,000 --> 0:06:46,000
who punish the puppet with the different food taste.

176
0:06:47.327,000 --> 0:06:49,000
(Laughter)

177
0:06:49.604,000 --> 0:06:52,000
We see this sort of in-group, out-group psychology all the time.

178
0:06:53.236,000 --> 0:06:54,000
We see it in political clashes

179
0:06:54.9,000 --> 0:06:56,000
within groups with different ideologies.

180
0:06:57.314,000 --> 0:07:,000
We see it in its extreme in cases of war,

181
0:07:00.94,000 --> 0:07:03,000
where the out-group isn't merely given less,

182
0:07:04.157,000 --> 0:07:05,000
but dehumanized,

183
0:07:05.745,000 --> 0:07:07,000
as in the Nazi perspective of Jews

184
0:07:07.985,000 --> 0:07:09,000
as vermin or lice,

185
0:07:10.07,000 --> 0:07:14,000
or the American perspective of Japanese as rats.

186
0:07:14.306,000 --> 0:07:16,000
Stereotypes can also go awry.

187
0:07:16.52,000 --> 0:07:18,000
So often they're rational and useful,

188
0:07:18.781,000 --> 0:07:19,000
but sometimes they're irrational,

189
0:07:20.355,000 --> 0:07:21,000
they give the wrong answers,

190
0:07:21.581,000 --> 0:07:22,000
and other times

191
0:07:22.798,000 --> 0:07:24,000
they lead to plainly immoral consequences.

192
0:07:24.973,000 --> 0:07:26,000
And the case that's been most studied

193
0:07:27.781,000 --> 0:07:28,000
is the case of race.

194
0:07:29.448,000 --> 0:07:3,000
There was a fascinating study

195
0:07:30.855,000 --> 0:07:32,000
prior to the 2008 election

196
0:07:32.929,000 --> 0:07:35,000
where social psychologists looked at the extent

197
0:07:35.955,000 --> 0:07:38,000
to which the candidates were associated with America,

198
0:07:39.397,000 --> 0:07:42,000
as in an unconscious association with the American flag.

199
0:07:43.002,000 --> 0:07:44,000
And in one of their studies they compared

200
0:07:44.358,000 --> 0:07:46,000
Obama and McCain, and they found McCain

201
0:07:46.372,000 --> 0:07:49,000
is thought of as more American than Obama,

202
0:07:49.766,000 --> 0:07:51,000
and to some extent, people aren't that surprised by hearing that.

203
0:07:52.339,000 --> 0:07:53,000
McCain is a celebrated war hero,

204
0:07:54.257,000 --> 0:07:55,000
and many people would explicitly say

205
0:07:55.916,000 --> 0:07:57,000
he has more of an American story than Obama.

206
0:07:58.616,000 --> 0:07:59,000
But they also compared Obama

207
0:08:00.553,000 --> 0:08:02,000
to British Prime Minister Tony Blair,

208
0:08:03.069,000 --> 0:08:05,000
and they found that Blair was also thought of

209
0:08:05.33,000 --> 0:08:07,000
as more American than Obama,

210
0:08:07.837,000 --> 0:08:09,000
even though subjects explicitly understood

211
0:08:09.91,000 --> 0:08:11,000
that he's not American at all.

212
0:08:12.9,000 --> 0:08:13,000
But they were responding, of course,

213
0:08:14.324,000 --> 0:08:17,000
to the color of his skin.

214
0:08:17.375,000 --> 0:08:19,000
These stereotypes and biases

215
0:08:19.426,000 --> 0:08:2,000
have real-world consequences,

216
0:08:20.876,000 --> 0:08:22,000
both subtle and very important.

217
0:08:23.748,000 --> 0:08:25,000
In one recent study, researchers

218
0:08:26.41,000 --> 0:08:29,000
put ads on eBay for the sale of baseball cards.

219
0:08:29.679,000 --> 0:08:31,000
Some of them were held by white hands,

220
0:08:32.413,000 --> 0:08:33,000
others by black hands.

221
0:08:33.631,000 --> 0:08:34,000
They were the same baseball cards.

222
0:08:35.21,000 --> 0:08:36,000
The ones held by black hands

223
0:08:36.454,000 --> 0:08:38,000
got substantially smaller bids

224
0:08:38.521,000 --> 0:08:4,000
than the ones held by white hands.

225
0:08:41.005,000 --> 0:08:43,000
In research done at Stanford,

226
0:08:43.367,000 --> 0:08:47,000
psychologists explored the case of people

227
0:08:47.597,000 --> 0:08:5,000
sentenced for the murder of a white person.

228
0:08:51.166,000 --> 0:08:53,000
It turns out, holding everything else constant,

229
0:08:53.97,000 --> 0:08:55,000
you are considerably more likely to be executed

230
0:08:56.34,000 --> 0:08:57,000
if you look like the man on the right

231
0:08:58.117,000 --> 0:08:59,000
than the man on the left,

232
0:09:00.09,000 --> 0:09:02,000
and this is in large part because

233
0:09:02.119,000 --> 0:09:04,000
the man on the right looks more prototypically black,

234
0:09:04.653,000 --> 0:09:06,000
more prototypically African-American,

235
0:09:07.283,000 --> 0:09:09,000
and this apparently influences people's decisions

236
0:09:09.332,000 --> 0:09:1,000
over what to do about him.

237
0:09:11.103,000 --> 0:09:12,000
So now that we know about this,

238
0:09:12.65,000 --> 0:09:13,000
how do we combat it?

239
0:09:14.307,000 --> 0:09:15,000
And there are different avenues.

240
0:09:15.929,000 --> 0:09:16,000
One avenue is to appeal

241
0:09:17.363,000 --> 0:09:19,000
to people's emotional responses,

242
0:09:19.409,000 --> 0:09:21,000
to appeal to people's empathy,

243
0:09:21.542,000 --> 0:09:22,000
and we often do that through stories.

244
0:09:23.415,000 --> 0:09:25,000
So if you are a liberal parent

245
0:09:25.98,000 --> 0:09:26,000
and you want to encourage your children

246
0:09:27.852,000 --> 0:09:29,000
to believe in the merits of nontraditional families,

247
0:09:30.226,000 --> 0:09:32,000
you might give them a book like this. ["Heather Has Two Mommies"]

248
0:09:32.499,000 --> 0:09:33,000
If you are conservative and have a different attitude,

249
0:09:34.225,000 --> 0:09:35,000
you might give them a book like this.

250
0:09:36.156,000 --> 0:09:37,000
(Laughter) ["Help! Mom! There Are Liberals under My Bed!"]

251
0:09:37.905,000 --> 0:09:4,000
But in general, stories can turn

252
0:09:41.241,000 --> 0:09:43,000
anonymous strangers into people who matter,

253
0:09:43.473,000 --> 0:09:45,000
and the idea that we care about people

254
0:09:46.158,000 --> 0:09:47,000
when we focus on them as individuals

255
0:09:47.86,000 --> 0:09:49,000
is an idea which has shown up across history.

256
0:09:50.139,000 --> 0:09:52,000
So Stalin apocryphally said,

257
0:09:52.722,000 --> 0:09:53,000
"A single death is a tragedy,

258
0:09:54.339,000 --> 0:09:56,000
a million deaths is a statistic,"

259
0:09:56.379,000 --> 0:09:57,000
and Mother Teresa said,

260
0:09:57.83,000 --> 0:09:58,000
"If I look at the mass, I will never act.

261
0:09:59.371,000 --> 0:10:01,000
If I look at the one, I will."

262
0:10:01.696,000 --> 0:10:03,000
Psychologists have explored this.

263
0:10:03.766,000 --> 0:10:04,000
For instance, in one study,

264
0:10:05.067,000 --> 0:10:07,000
people were given a list of facts about a crisis,

265
0:10:07.85,000 --> 0:10:11,000
and it was seen how much they would donate

266
0:10:12.106,000 --> 0:10:13,000
to solve this crisis,

267
0:10:13.69,000 --> 0:10:14,000
and another group was given no facts at all

268
0:10:15.527,000 --> 0:10:17,000
but they were told of an individual

269
0:10:17.625,000 --> 0:10:19,000
and given a name and given a face,

270
0:10:20.065,000 --> 0:10:23,000
and it turns out that they gave far more.

271
0:10:23.284,000 --> 0:10:24,000
None of this I think is a secret

272
0:10:25.145,000 --> 0:10:27,000
to the people who are engaged in charity work.

273
0:10:27.256,000 --> 0:10:29,000
People don't tend to deluge people

274
0:10:29.904,000 --> 0:10:3,000
with facts and statistics.

275
0:10:31.227,000 --> 0:10:32,000
Rather, you show them faces,

276
0:10:32.249,000 --> 0:10:33,000
you show them people.

277
0:10:33.985,000 --> 0:10:36,000
It's possible that by extending our sympathies

278
0:10:37.212,000 --> 0:10:38,000
to an individual, they can spread

279
0:10:39.183,000 --> 0:10:41,000
to the group that the individual belongs to.

280
0:10:42.061,000 --> 0:10:44,000
This is Harriet Beecher Stowe.

281
0:10:44.527,000 --> 0:10:46,000
The story, perhaps apocryphal,

282
0:10:46.97,000 --> 0:10:48,000
is that President Lincoln invited her

283
0:10:49.044,000 --> 0:10:5,000
to the White House in the middle of the Civil War

284
0:10:51.042,000 --> 0:10:52,000
and said to her,

285
0:10:52.626,000 --> 0:10:54,000
"So you're the little lady who started this great war."

286
0:10:55.29,000 --> 0:10:56,000
And he was talking about "Uncle Tom's Cabin."

287
0:10:57.175,000 --> 0:10:59,000
"Uncle Tom's Cabin" is not a great book of philosophy

288
0:10:59.706,000 --> 0:11:02,000
or of theology or perhaps not even literature,

289
0:11:02.85,000 --> 0:11:04,000
but it does a great job

290
0:11:05.365,000 --> 0:11:07,000
of getting people to put themselves in the shoes

291
0:11:07.863,000 --> 0:11:09,000
of people they wouldn't otherwise be in the shoes of,

292
0:11:10.196,000 --> 0:11:12,000
put themselves in the shoes of slaves.

293
0:11:12.598,000 --> 0:11:13,000
And that could well have been a catalyst

294
0:11:14.379,000 --> 0:11:15,000
for great social change.

295
0:11:15.983,000 --> 0:11:17,000
More recently, looking at America

296
0:11:18.345,000 --> 0:11:21,000
in the last several decades,

297
0:11:21.414,000 --> 0:11:24,000
there's some reason to believe that shows like "The Cosby Show"

298
0:11:24.563,000 --> 0:11:26,000
radically changed American attitudes towards African-Americans,

299
0:11:27.251,000 --> 0:11:29,000
while shows like "Will and Grace" and "Modern Family"

300
0:11:30.234,000 --> 0:11:31,000
changed American attitudes

301
0:11:31.597,000 --> 0:11:32,000
towards gay men and women.

302
0:11:32.897,000 --> 0:11:34,000
I don't think it's an exaggeration to say

303
0:11:35.352,000 --> 0:11:37,000
that the major catalyst in America for moral change

304
0:11:38.013,000 --> 0:11:4,000
has been a situation comedy.

305
0:11:40.906,000 --> 0:11:41,000
But it's not all emotions,

306
0:11:42.322,000 --> 0:11:43,000
and I want to end by appealing

307
0:11:43.598,000 --> 0:11:45,000
to the power of reason.

308
0:11:45.833,000 --> 0:11:47,000
At some point in his wonderful book

309
0:11:47.989,000 --> 0:11:48,000
"The Better Angels of Our Nature,"

310
0:11:49.212,000 --> 0:11:51,000
Steven Pinker says,

311
0:11:51.228,000 --> 0:11:53,000
the Old Testament says love thy neighbor,

312
0:11:53.81,000 --> 0:11:55,000
and the New Testament says love thy enemy,

313
0:11:56.532,000 --> 0:11:58,000
but I don't love either one of them, not really,

314
0:11:59.218,000 --> 0:12:,000
but I don't want to kill them.

315
0:12:00.885,000 --> 0:12:01,000
I know I have obligations to them,

316
0:12:02.751,000 --> 0:12:05,000
but my moral feelings to them, my moral beliefs

317
0:12:06.221,000 --> 0:12:07,000
about how I should behave towards them,

318
0:12:07.934,000 --> 0:12:09,000
aren't grounded in love.

319
0:12:09.981,000 --> 0:12:1,000
What they're grounded in is the understanding of human rights,

320
0:12:11.92,000 --> 0:12:13,000
a belief that their life is as valuable to them

321
0:12:14.143,000 --> 0:12:16,000
as my life is to me,

322
0:12:16.499,000 --> 0:12:17,000
and to support this, he tells a story

323
0:12:18.431,000 --> 0:12:19,000
by the great philosopher Adam Smith,

324
0:12:20.279,000 --> 0:12:21,000
and I want to tell this story too,

325
0:12:21.965,000 --> 0:12:22,000
though I'm going to modify it a little bit

326
0:12:23.261,000 --> 0:12:24,000
for modern times.

327
0:12:24.939,000 --> 0:12:25,000
So Adam Smith starts by asking you to imagine

328
0:12:26.84,000 --> 0:12:27,000
the death of thousands of people,

329
0:12:28.741,000 --> 0:12:3,000
and imagine that the thousands of people

330
0:12:30.781,000 --> 0:12:32,000
are in a country you are not familiar with.

331
0:12:33.02,000 --> 0:12:36,000
It could be China or India or a country in Africa.

332
0:12:36.574,000 --> 0:12:38,000
And Smith says, how would you respond?

333
0:12:39.058,000 --> 0:12:41,000
And you would say, well that's too bad,

334
0:12:41.365,000 --> 0:12:42,000
and you'd go on to the rest of your life.

335
0:12:43.241,000 --> 0:12:45,000
If you were to open up The New York Times online or something,

336
0:12:45.46,000 --> 0:12:47,000
and discover this, and in fact this happens to us all the time,

337
0:12:48.42,000 --> 0:12:49,000
we go about our lives.

338
0:12:49.941,000 --> 0:12:51,000
But imagine instead, Smith says,

339
0:12:52.135,000 --> 0:12:53,000
you were to learn that tomorrow

340
0:12:53.389,000 --> 0:12:55,000
you were to have your little finger chopped off.

341
0:12:55.928,000 --> 0:12:57,000
Smith says, that would matter a lot.

342
0:12:58.097,000 --> 0:12:59,000
You would not sleep that night

343
0:12:59.508,000 --> 0:13:,000
wondering about that.

344
0:13:00.861,000 --> 0:13:02,000
So this raises the question:

345
0:13:02.88,000 --> 0:13:04,000
Would you sacrifice thousands of lives

346
0:13:05.346,000 --> 0:13:06,000
to save your little finger?

347
0:13:07.315,000 --> 0:13:09,000
Now answer this in the privacy of your own head,

348
0:13:09.633,000 --> 0:13:11,000
but Smith says, absolutely not,

349
0:13:12.552,000 --> 0:13:13,000
what a horrid thought.

350
0:13:14.244,000 --> 0:13:16,000
And so this raises the question,

351
0:13:16.275,000 --> 0:13:17,000
and so, as Smith puts it,

352
0:13:17.649,000 --> 0:13:19,000
"When our passive feelings are almost always

353
0:13:19.867,000 --> 0:13:2,000
so sordid and so selfish,

354
0:13:21.315,000 --> 0:13:22,000
how comes it that our active principles

355
0:13:22.78,000 --> 0:13:24,000
should often be so generous and so noble?"

356
0:13:25.313,000 --> 0:13:27,000
And Smith's answer is, "It is reason,

357
0:13:27.363,000 --> 0:13:28,000
principle, conscience.

358
0:13:29.138,000 --> 0:13:3,000
[This] calls to us,

359
0:13:30.679,000 --> 0:13:33,000
with a voice capable of astonishing the most presumptuous of our passions,

360
0:13:34.104,000 --> 0:13:35,000
that we are but one of the multitude,

361
0:13:35.781,000 --> 0:13:37,000
in no respect better than any other in it."

362
0:13:38.222,000 --> 0:13:4,000
And this last part is what is often described

363
0:13:40.347,000 --> 0:13:43,000
as the principle of impartiality.

364
0:13:43.555,000 --> 0:13:45,000
And this principle of impartiality manifests itself

365
0:13:46.184,000 --> 0:13:47,000
in all of the world's religions,

366
0:13:47.951,000 --> 0:13:49,000
in all of the different versions of the golden rule,

367
0:13:50.209,000 --> 0:13:52,000
and in all of the world's moral philosophies,

368
0:13:52.663,000 --> 0:13:53,000
which differ in many ways

369
0:13:53.97,000 --> 0:13:55,000
but share the presupposition that we should judge morality

370
0:13:56.964,000 --> 0:13:58,000
from sort of an impartial point of view.

371
0:13:59.949,000 --> 0:14:,000
The best articulation of this view

372
0:14:01.771,000 --> 0:14:04,000
is actually, for me, it's not from a theologian or from a philosopher,

373
0:14:04.856,000 --> 0:14:05,000
but from Humphrey Bogart

374
0:14:06.213,000 --> 0:14:07,000
at the end of "Casablanca."

375
0:14:07.76,000 --> 0:14:1,000
So, spoiler alert, he's telling his lover

376
0:14:11.536,000 --> 0:14:12,000
that they have to separate

377
0:14:12.676,000 --> 0:14:13,000
for the more general good,

378
0:14:14.269,000 --> 0:14:15,000
and he says to her, and I won't do the accent,

379
0:14:16.133,000 --> 0:14:17,000
but he says to her, "It doesn't take much to see

380
0:14:17.915,000 --> 0:14:18,000
that the problems of three little people

381
0:14:19.274,000 --> 0:14:22,000
don't amount to a hill of beans in this crazy world."

382
0:14:22.385,000 --> 0:14:25,000
Our reason could cause us to override our passions.

383
0:14:25.665,000 --> 0:14:26,000
Our reason could motivate us

384
0:14:27.381,000 --> 0:14:28,000
to extend our empathy,

385
0:14:28.602,000 --> 0:14:3,000
could motivate us to write a book like "Uncle Tom's Cabin,"

386
0:14:30.929,000 --> 0:14:31,000
or read a book like "Uncle Tom's Cabin,"

387
0:14:32.652,000 --> 0:14:34,000
and our reason can motivate us to create

388
0:14:35.346,000 --> 0:14:36,000
customs and taboos and laws

389
0:14:37.308,000 --> 0:14:38,000
that will constrain us

390
0:14:39.118,000 --> 0:14:4,000
from acting upon our impulses

391
0:14:40.794,000 --> 0:14:41,000
when, as rational beings, we feel

392
0:14:42.383,000 --> 0:14:43,000
we should be constrained.

393
0:14:43.778,000 --> 0:14:45,000
This is what a constitution is.

394
0:14:45.791,000 --> 0:14:47,000
A constitution is something which was set up in the past

395
0:14:48.712,000 --> 0:14:49,000
that applies now in the present,

396
0:14:50.019,000 --> 0:14:5,000
and what it says is,

397
0:14:51.004,000 --> 0:14:53,000
no matter how much we might to reelect

398
0:14:53.231,000 --> 0:14:55,000
a popular president for a third term,

399
0:14:55.834,000 --> 0:14:57,000
no matter how much white Americans might choose

400
0:14:57.929,000 --> 0:15:01,000
to feel that they want to reinstate the institution of slavery, we can't.

401
0:15:01.997,000 --> 0:15:02,000
We have bound ourselves.

402
0:15:03.673,000 --> 0:15:05,000
And we bind ourselves in other ways as well.

403
0:15:06.09,000 --> 0:15:08,000
We know that when it comes to choosing somebody

404
0:15:08.848,000 --> 0:15:1,000
for a job, for an award,

405
0:15:11.799,000 --> 0:15:13,000
we are strongly biased by their race,

406
0:15:14.757,000 --> 0:15:16,000
we are biased by their gender,

407
0:15:17.053,000 --> 0:15:19,000
we are biased by how attractive they are,

408
0:15:19.268,000 --> 0:15:21,000
and sometimes we might say, "Well fine, that's the way it should be."

409
0:15:21.919,000 --> 0:15:23,000
But other times we say, "This is wrong."

410
0:15:24.226,000 --> 0:15:25,000
And so to combat this,

411
0:15:26.115,000 --> 0:15:28,000
we don't just try harder,

412
0:15:28.366,000 --> 0:15:31,000
but rather what we do is we set up situations

413
0:15:31.367,000 --> 0:15:34,000
where these other sources of information can't bias us,

414
0:15:34.406,000 --> 0:15:35,000
which is why many orchestras

415
0:15:35.721,000 --> 0:15:37,000
audition musicians behind screens,

416
0:15:38.366,000 --> 0:15:39,000
so the only information they have

417
0:15:39.61,000 --> 0:15:41,000
is the information they believe should matter.

418
0:15:42.303,000 --> 0:15:44,000
I think prejudice and bias

419
0:15:44.626,000 --> 0:15:47,000
illustrate a fundamental duality of human nature.

420
0:15:47.72,000 --> 0:15:5,000
We have gut feelings, instincts, emotions,

421
0:15:51.496,000 --> 0:15:53,000
and they affect our judgments and our actions

422
0:15:53.657,000 --> 0:15:55,000
for good and for evil,

423
0:15:55.988,000 --> 0:15:58,000
but we are also capable of rational deliberation

424
0:15:59.61,000 --> 0:16:,000
and intelligent planning,

425
0:16:01.045,000 --> 0:16:03,000
and we can use these to, in some cases,

426
0:16:03.862,000 --> 0:16:04,000
accelerate and nourish our emotions,

427
0:16:05.805,000 --> 0:16:07,000
and in other cases staunch them.

428
0:16:08.573,000 --> 0:16:09,000
And it's in this way

429
0:16:09.807,000 --> 0:16:11,000
that reason helps us create a better world.

430
0:16:12.574,000 --> 0:16:14,000
Thank you.

431
0:16:14.918,000 --> 0:16:17,000
(Applause)

