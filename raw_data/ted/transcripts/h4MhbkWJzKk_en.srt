1
0:00:15.402,000 --> 0:00:18,000
So I'm a doctor, but I kind of slipped sideways into research,

2
0:00:18.49,000 --> 0:00:19,000
and now I'm an epidemiologist.

3
0:00:20.212,000 --> 0:00:22,000
And nobody really knows what epidemiology is.

4
0:00:22.38,000 --> 0:00:25,000
Epidemiology is the science of how we know in the real world

5
0:00:25.557,000 --> 0:00:27,000
if something is good for you or bad for you.

6
0:00:27.691,000 --> 0:00:28,000
And it's best understood through example

7
0:00:29.675,000 --> 0:00:33,000
as the science of those crazy, wacky newspaper headlines.

8
0:00:34.35,000 --> 0:00:36,000
And these are just some of the examples.

9
0:00:36.707,000 --> 0:00:37,000
These are from the Daily Mail.

10
0:00:38.181,000 --> 0:00:4,000
Every country in the world has a newspaper like this.

11
0:00:40.724,000 --> 0:00:42,000
It has this bizarre, ongoing philosophical project

12
0:00:43.098,000 --> 0:00:45,000
of dividing all the inanimate objects in the world

13
0:00:45.477,000 --> 0:00:47,000
into the ones that either cause or prevent cancer.

14
0:00:47.854,000 --> 0:00:49,000
Here are some of the things they said cause cancer:

15
0:00:50.386,000 --> 0:00:51,000
divorce, Wi-Fi, toiletries and coffee.

16
0:00:52.391,000 --> 0:00:53,000
Some things they say prevent cancer:

17
0:00:54.179,000 --> 0:00:55,000
crusts, red pepper, licorice and coffee.

18
0:00:56.125,000 --> 0:00:57,000
So you can see there are contradictions.

19
0:00:58.055,000 --> 0:01:,000
Coffee both causes and prevents cancer.

20
0:01:00.079,000 --> 0:01:01,000
As you start to read on, you can see

21
0:01:01.827,000 --> 0:01:03,000
that maybe there's some political valence behind some of this.

22
0:01:04.79,000 --> 0:01:06,000
For women, housework prevents breast cancer,

23
0:01:06.875,000 --> 0:01:09,000
but for men, shopping could make you impotent.

24
0:01:09.944,000 --> 0:01:1,000
(Laughter)

25
0:01:10.977,000 --> 0:01:14,000
So we know that we need to start unpicking the science behind this.

26
0:01:15.505,000 --> 0:01:2,000
And what I hope to show is that unpicking the evidence behind dodgy claims

27
0:01:21.062,000 --> 0:01:24,000
isn't a kind of nasty, carping activity;

28
0:01:24.806,000 --> 0:01:25,000
it's socially useful.

29
0:01:26.191,000 --> 0:01:3,000
But it's also an extremely valuable explanatory tool,

30
0:01:30.773,000 --> 0:01:33,000
because real science is about critically appraising the evidence

31
0:01:33.832,000 --> 0:01:34,000
for somebody else's position.

32
0:01:35.249,000 --> 0:01:36,000
That's what happens in academic journals,

33
0:01:37.232,000 --> 0:01:39,000
it's what happens at academic conferences --

34
0:01:39.32,000 --> 0:01:42,000
the Q&A session after a postdoc presents data is often a bloodbath.

35
0:01:42.653,000 --> 0:01:44,000
And nobody minds that; we actively welcome it.

36
0:01:44.835,000 --> 0:01:47,000
It's like a consenting intellectual S&M activity.

37
0:01:47.897,000 --> 0:01:48,000
(Laughter)

38
0:01:49.076,000 --> 0:01:51,000
So what I'm going to show you is all of the main things,

39
0:01:52.094,000 --> 0:01:55,000
all of the main features of my discipline, evidence-based medicine.

40
0:01:55.308,000 --> 0:01:58,000
And I will talk you through all of these and demonstrate how they work,

41
0:01:59.215,000 --> 0:02:02,000
exclusively using examples of people getting stuff wrong.

42
0:02:02.581,000 --> 0:02:05,000
We'll start with the absolute weakest form of evidence known to man,

43
0:02:06.359,000 --> 0:02:07,000
and that is authority.

44
0:02:08.009,000 --> 0:02:11,000
In science, we don't care how many letters you have after your name --

45
0:02:11.473,000 --> 0:02:14,000
we want to know what your reasons are for believing something.

46
0:02:14.509,000 --> 0:02:16,000
How do you know that something is good for us or bad for us?

47
0:02:17.529,000 --> 0:02:21,000
But we're also unimpressed by authority because it's so easy to contrive.

48
0:02:21.734,000 --> 0:02:23,000
This is somebody called Dr. Gillian McKeith, PhD,

49
0:02:24.14,000 --> 0:02:27,000
or, to give her full medical title, Gillian McKeith.

50
0:02:27.333,000 --> 0:02:29,000
(Laughter)

51
0:02:30.017,000 --> 0:02:32,000
Again, every country has somebody like this.

52
0:02:32.197,000 --> 0:02:33,000
She is our TV diet guru.

53
0:02:33.865,000 --> 0:02:35,000
She has five series of prime-time television,

54
0:02:36.796,000 --> 0:02:38,000
giving out very lavish and exotic health advice.

55
0:02:39.138,000 --> 0:02:42,000
She, it turns out, has a non-accredited correspondence course PhD

56
0:02:43.017,000 --> 0:02:44,000
from somewhere in America.

57
0:02:44.321,000 --> 0:02:46,000
She also boasts that she's a certified professional member

58
0:02:47.11,000 --> 0:02:49,000
of the American Association of Nutritional Consultants,

59
0:02:49.726,000 --> 0:02:51,000
which sounds very glamorous; you get a certificate.

60
0:02:52.149,000 --> 0:02:55,000
This one belongs to my dead cat, Hettie. She was a horrible cat.

61
0:02:55.19,000 --> 0:02:56,000
You go to the website, fill out the form,

62
0:02:57.178,000 --> 0:02:58,000
give them $60, it arrives in the post.

63
0:02:59.023,000 --> 0:03:01,000
That's not the only reason we think this person is an idiot.

64
0:03:01.88,000 --> 0:03:03,000
She also says things like eat lots of dark green leaves,

65
0:03:04.553,000 --> 0:03:06,000
they contain chlorophyll and really oxygenate your blood.

66
0:03:07.434,000 --> 0:03:09,000
And anybody who's done school biology remembers

67
0:03:09.657,000 --> 0:03:12,000
that chlorophyll and chloroplasts only make oxygen in sunlight,

68
0:03:12.893,000 --> 0:03:15,000
and it's quite dark in your bowels after you've eaten spinach.

69
0:03:16.047,000 --> 0:03:18,000
Next, we need proper science, proper evidence.

70
0:03:18.57,000 --> 0:03:2,000
So: "Red wine can help prevent breast cancer."

71
0:03:21.036,000 --> 0:03:23,000
This is a headline from The Daily Telegraph in the UK.

72
0:03:23.623,000 --> 0:03:25,000
"A glass of red wine a day could help prevent breast cancer."

73
0:03:26.565,000 --> 0:03:29,000
So you find this paper, and find that it is a real piece of science.

74
0:03:29.825,000 --> 0:03:31,000
It's a description of the changes in the behavior of one enzyme

75
0:03:32.846,000 --> 0:03:35,000
when you drip a chemical extracted from some red grape skin

76
0:03:36.039,000 --> 0:03:37,000
onto some cancer cells

77
0:03:37.638,000 --> 0:03:4,000
in a dish on a bench in a laboratory somewhere.

78
0:03:40.862,000 --> 0:03:44,000
And that's a really useful thing to describe in a scientific paper.

79
0:03:44.978,000 --> 0:03:47,000
But on the question of your own personal risk of getting breast cancer

80
0:03:48.36,000 --> 0:03:49,000
if you drink red wine,

81
0:03:49.535,000 --> 0:03:5,000
it tells you absolutely bugger all.

82
0:03:51.24,000 --> 0:03:53,000
Actually, it turns out that your risk of breast cancer

83
0:03:53.801,000 --> 0:03:55,000
increases slightly with every amount of alcohol you drink.

84
0:03:56.788,000 --> 0:03:59,000
So what we want are studies in real human people.

85
0:04:00.66,000 --> 0:04:01,000
And here's another example.

86
0:04:02.26,000 --> 0:04:06,000
This is from Britain's "leading" diet nutritionist in the Daily Mirror,

87
0:04:06.445,000 --> 0:04:07,000
our second-biggest selling newspaper.

88
0:04:08.243,000 --> 0:04:1,000
"An Australian study in 2001 found that olive oil,

89
0:04:10.625,000 --> 0:04:12,000
in combination with fruits, vegetables and pulses,

90
0:04:12.991,000 --> 0:04:14,000
offers measurable protection against skin wrinklings,"

91
0:04:15.563,000 --> 0:04:16,000
and give the advice:

92
0:04:16.738,000 --> 0:04:19,000
"If you eat olive oil and vegetables, you'll have fewer wrinkles."

93
0:04:19.892,000 --> 0:04:21,000
They helpfully tell you how to find the paper,

94
0:04:22.074,000 --> 0:04:24,000
and what you find is an observational study.

95
0:04:24.185,000 --> 0:04:26,000
Obviously, nobody has been able to go back to 1930,

96
0:04:27.13,000 --> 0:04:29,000
get all the people born in one maternity unit,

97
0:04:29.647,000 --> 0:04:31,000
and half of them eat lots of fruit and veg and olive oil,

98
0:04:32.367,000 --> 0:04:33,000
half of them eat McDonald's,

99
0:04:33.737,000 --> 0:04:35,000
and then we see how many wrinkles you've got later.

100
0:04:36.164,000 --> 0:04:38,000
You have to take a snapshot of how people are now.

101
0:04:38.601,000 --> 0:04:39,000
And what you find is, of course:

102
0:04:40.189,000 --> 0:04:42,000
people who eat veg and olive oil have fewer wrinkles.

103
0:04:42.714,000 --> 0:04:45,000
But that's because people who eat fruit and veg and olive oil are freaks --

104
0:04:46.479,000 --> 0:04:49,000
they're not normal, they're like you; they come to events like this.

105
0:04:50.327,000 --> 0:04:51,000
(Laughter)

106
0:04:51.41,000 --> 0:04:54,000
They're posh, they're wealthy, less likely to have outdoor jobs,

107
0:04:54.453,000 --> 0:04:55,000
less likely to do manual labor,

108
0:04:55.993,000 --> 0:04:57,000
they have better social support, are less likely to smoke;

109
0:04:58.757,000 --> 0:04:59,000
for a host of fascinating, interlocking

110
0:05:00.655,000 --> 0:05:01,000
social, political and cultural reasons,

111
0:05:02.548,000 --> 0:05:03,000
they're less likely to have wrinkles.

112
0:05:04.344,000 --> 0:05:06,000
That doesn't mean it's the vegetables or olive oil.

113
0:05:06.77,000 --> 0:05:07,000
(Laughter)

114
0:05:08.04,000 --> 0:05:1,000
So ideally, what you want to do is a trial.

115
0:05:10.557,000 --> 0:05:12,000
People think they're familiar with the idea of a trial.

116
0:05:13.161,000 --> 0:05:15,000
Trials are old; the first one was in the Bible, Daniel 1:12.

117
0:05:16.001,000 --> 0:05:19,000
It's straightforward: take a bunch of people, split them in half,

118
0:05:19.1,000 --> 0:05:21,000
treat one group one way, the other group, the other way.

119
0:05:21.75,000 --> 0:05:23,000
A while later, you see what happened to each of them.

120
0:05:24.297,000 --> 0:05:25,000
I'm going to tell you about one trial,

121
0:05:26.155,000 --> 0:05:28,000
which is probably the most well-reported trial

122
0:05:28.345,000 --> 0:05:3,000
in the UK news media over the past decade.

123
0:05:30.374,000 --> 0:05:31,000
This is the trial of fish oil pills.

124
0:05:32.134,000 --> 0:05:35,000
The claim: fish oil pills improve school performance and behavior

125
0:05:35.311,000 --> 0:05:36,000
in mainstream children.

126
0:05:36.486,000 --> 0:05:37,000
They said, "We did a trial.

127
0:05:37.804,000 --> 0:05:39,000
All the previous ones were positive, this one will be too."

128
0:05:40.6,000 --> 0:05:41,000
That should ring alarm bells:

129
0:05:42.006,000 --> 0:05:45,000
if you know the answer to your trial, you shouldn't be doing one.

130
0:05:45.09,000 --> 0:05:46,000
Either you've rigged it by design,

131
0:05:46.742,000 --> 0:05:49,000
or you've got enough data so there's no need to randomize people anymore.

132
0:05:50.203,000 --> 0:05:52,000
So this is what they were going to do in their trial:

133
0:05:52.728,000 --> 0:05:54,000
They were taking 3,000 children,

134
0:05:54.829,000 --> 0:05:57,000
they were going to give them these huge fish oil pills, six of them a day,

135
0:05:58.507,000 --> 0:06:01,000
and then, a year later, measure their school exam performance

136
0:06:01.644,000 --> 0:06:02,000
and compare their performance

137
0:06:03.442,000 --> 0:06:06,000
against what they predicted their exam performance would have been

138
0:06:06.622,000 --> 0:06:08,000
if they hadn't had the pills.

139
0:06:08.722,000 --> 0:06:1,000
Now, can anybody spot a flaw in this design?

140
0:06:11.553,000 --> 0:06:12,000
(Laughter)

141
0:06:12.592,000 --> 0:06:14,000
And no professors of clinical trial methodology

142
0:06:14.859,000 --> 0:06:15,000
are allowed to answer this question.

143
0:06:16.609,000 --> 0:06:18,000
So there's no control group.

144
0:06:18.634,000 --> 0:06:21,000
But that sounds really techie, right? That's a technical term.

145
0:06:21.993,000 --> 0:06:23,000
The kids got the pills, and their performance improved.

146
0:06:24.65,000 --> 0:06:26,000
What else could it possibly be if it wasn't the pills?

147
0:06:28.128,000 --> 0:06:3,000
They got older; we all develop over time.

148
0:06:30.425,000 --> 0:06:32,000
And of course, there's the placebo effect,

149
0:06:32.614,000 --> 0:06:34,000
one of the most fascinating things in the whole of medicine.

150
0:06:35.476,000 --> 0:06:37,000
It's not just taking a pill and performance or pain improving;

151
0:06:38.413,000 --> 0:06:41,000
it's about our beliefs and expectations, the cultural meaning of a treatment.

152
0:06:42.1,000 --> 0:06:45,000
And this has been demonstrated in a whole raft of fascinating studies

153
0:06:45.394,000 --> 0:06:47,000
comparing one kind of placebo against another.

154
0:06:47.635,000 --> 0:06:48,000
So we know, for example,

155
0:06:48.817,000 --> 0:06:5,000
that two sugar pills a day are a more effective treatment

156
0:06:51.554,000 --> 0:06:52,000
for gastric ulcers

157
0:06:52.797,000 --> 0:06:53,000
than one sugar pill.

158
0:06:54.061,000 --> 0:06:55,000
Two sugar pills a day beats one a day.

159
0:06:56.046,000 --> 0:06:58,000
That's an outrageous and ridiculous finding, but it's true.

160
0:06:58.845,000 --> 0:07:01,000
We know from three different studies on three different types of pain

161
0:07:02.166,000 --> 0:07:04,000
that a saltwater injection is a more effective treatment

162
0:07:04.835,000 --> 0:07:06,000
than a sugar pill, a dummy pill with no medicine in it,

163
0:07:07.464,000 --> 0:07:1,000
not because the injection or pills do anything physically to the body,

164
0:07:10.832,000 --> 0:07:13,000
but because an injection feels like a much more dramatic intervention.

165
0:07:14.212,000 --> 0:07:17,000
So we know that our beliefs and expectations can be manipulated,

166
0:07:17.298,000 --> 0:07:21,000
which is why we do trials where we control against a placebo,

167
0:07:21.37,000 --> 0:07:23,000
where one half of the people get the real treatment,

168
0:07:23.932,000 --> 0:07:24,000
and the other half get placebo.

169
0:07:25.633,000 --> 0:07:26,000
But that's not enough.

170
0:07:28.496,000 --> 0:07:29,000
What I've just shown you are examples

171
0:07:30.296,000 --> 0:07:32,000
of the very simple and straightforward ways

172
0:07:32.492,000 --> 0:07:35,000
that journalists and food supplement pill peddlers and naturopaths

173
0:07:35.779,000 --> 0:07:37,000
can distort evidence for their own purposes.

174
0:07:38.26,000 --> 0:07:4,000
What I find really fascinating

175
0:07:40.464,000 --> 0:07:43,000
is that the pharmaceutical industry uses exactly the same kinds

176
0:07:43.645,000 --> 0:07:44,000
of tricks and devices,

177
0:07:45.197,000 --> 0:07:47,000
but slightly more sophisticated versions of them,

178
0:07:47.988,000 --> 0:07:5,000
in order to distort the evidence they give to doctors and patients,

179
0:07:51.19,000 --> 0:07:53,000
and which we use to make vitally important decisions.

180
0:07:53.776,000 --> 0:07:55,000
So firstly, trials against placebo:

181
0:07:56.333,000 --> 0:07:58,000
everybody thinks a trial should be a comparison

182
0:07:58.729,000 --> 0:07:59,000
of your new drug against placebo.

183
0:08:00.348,000 --> 0:08:01,000
But in a lot of situations that's wrong;

184
0:08:02.292,000 --> 0:08:04,000
often, we already have a good treatment currently available.

185
0:08:05.214,000 --> 0:08:07,000
So we don't want to know that your alternative new treatment

186
0:08:08.071,000 --> 0:08:09,000
is better than nothing,

187
0:08:09.246,000 --> 0:08:11,000
but that it's better than the best available treatment we have.

188
0:08:12.238,000 --> 0:08:14,000
And yet, repeatedly, you consistently see people doing trials

189
0:08:15.135,000 --> 0:08:16,000
still against placebo.

190
0:08:16.465,000 --> 0:08:18,000
And you can get licensed to bring your drug to market

191
0:08:18.996,000 --> 0:08:2,000
with only data showing that it's better than nothing,

192
0:08:21.519,000 --> 0:08:24,000
which is useless for a doctor like me trying to make a decision.

193
0:08:24.545,000 --> 0:08:26,000
But that's not the only way you can rig your data.

194
0:08:26.934,000 --> 0:08:27,000
You can also rig your data

195
0:08:28.206,000 --> 0:08:3,000
by making the thing you compare your new drug against

196
0:08:30.723,000 --> 0:08:31,000
really rubbish.

197
0:08:31.904,000 --> 0:08:33,000
You can give the competing drug in too low a dose,

198
0:08:34.397,000 --> 0:08:35,000
so people aren't properly treated.

199
0:08:36.054,000 --> 0:08:38,000
You can give the competing drug in too high a dose,

200
0:08:38.475,000 --> 0:08:39,000
so people get side effects.

201
0:08:39.795,000 --> 0:08:4,000
And this is exactly what happened

202
0:08:41.499,000 --> 0:08:43,000
with antipsychotic medication for schizophrenia.

203
0:08:43.988,000 --> 0:08:46,000
Twenty years ago, a new generation of antipsychotic drugs were brought in;

204
0:08:47.544,000 --> 0:08:49,000
the promise was they would have fewer side effects.

205
0:08:50.125,000 --> 0:08:53,000
So people set about doing trials of the new drugs against the old drugs.

206
0:08:53.603,000 --> 0:08:55,000
But they gave the old drugs in ridiculously high doses:

207
0:08:56.312,000 --> 0:08:57,000
20 milligrams a day of haloperidol.

208
0:08:58.181,000 --> 0:09:01,000
And it's a foregone conclusion if you give a drug at that high a dose,

209
0:09:01.759,000 --> 0:09:04,000
it will have more side effects, and your new drug will look better.

210
0:09:05.063,000 --> 0:09:06,000
Ten years ago, history repeated itself,

211
0:09:07.075,000 --> 0:09:1,000
when risperidone, the first of the new-generation antipsychotic drugs,

212
0:09:10.424,000 --> 0:09:12,000
came off copyright, so anybody could make copies.

213
0:09:12.79,000 --> 0:09:15,000
Everybody wanted to show their drug was better than risperidone,

214
0:09:15.846,000 --> 0:09:17,000
so you see trials comparing new antipsychotic drugs

215
0:09:18.271,000 --> 0:09:2,000
against risperidone at eight milligrams a day.

216
0:09:20.462,000 --> 0:09:22,000
Again, not an insane dose, not an illegal dose,

217
0:09:22.7,000 --> 0:09:23,000
but very much at the high end of normal.

218
0:09:24.642,000 --> 0:09:26,000
So you're bound to make your new drug look better.

219
0:09:27.183,000 --> 0:09:29,000
And so it's no surprise that overall,

220
0:09:29.804,000 --> 0:09:31,000
industry-funded trials are four times more likely

221
0:09:32.597,000 --> 0:09:33,000
to give a positive result

222
0:09:33.95,000 --> 0:09:35,000
than independently sponsored trials.

223
0:09:36.989,000 --> 0:09:38,000
But -- and it's a big but --

224
0:09:39.657,000 --> 0:09:41,000
(Laughter)

225
0:09:42.202,000 --> 0:09:43,000
it turns out,

226
0:09:43.507,000 --> 0:09:46,000
when you look at the methods used by industry-funded trials,

227
0:09:47.172,000 --> 0:09:5,000
that they're actually better than independently sponsored trials.

228
0:09:50.882,000 --> 0:09:52,000
And yet, they always manage to get the result that they want.

229
0:09:53.798,000 --> 0:09:54,000
So how does this work?

230
0:09:54.972,000 --> 0:09:55,000
(Laughter)

231
0:09:56.009,000 --> 0:09:58,000
How can we explain this strange phenomenon?

232
0:09:58.8,000 --> 0:09:59,000
Well, it turns out that what happens

233
0:10:00.622,000 --> 0:10:02,000
is the negative data goes missing in action;

234
0:10:02.879,000 --> 0:10:03,000
it's withheld from doctors and patients.

235
0:10:04.84,000 --> 0:10:06,000
And this is the most important aspect of the whole story.

236
0:10:07.562,000 --> 0:10:09,000
It's at the top of the pyramid of evidence.

237
0:10:09.62,000 --> 0:10:11,000
We need to have all of the data on a particular treatment

238
0:10:12.33,000 --> 0:10:14,000
to know whether or not it really is effective.

239
0:10:14.514,000 --> 0:10:17,000
There are two different ways you can spot whether some data has gone missing.

240
0:10:18.205,000 --> 0:10:2,000
You can use statistics or you can use stories.

241
0:10:20.428,000 --> 0:10:22,000
I prefer statistics, so that's what I'll do first.

242
0:10:22.841,000 --> 0:10:23,000
This is a funnel plot.

243
0:10:24.187,000 --> 0:10:26,000
A funnel plot is a very clever way of spotting

244
0:10:26.402,000 --> 0:10:29,000
if small negative trials have disappeared, have gone missing in action.

245
0:10:29.791,000 --> 0:10:32,000
This is a graph of all of the trials done on a particular treatment.

246
0:10:33.293,000 --> 0:10:35,000
As you go up towards the top of the graph,

247
0:10:35.572,000 --> 0:10:36,000
what you see is each dot is a trial.

248
0:10:37.525,000 --> 0:10:4,000
As you go up, those are bigger trials, so they've got less error;

249
0:10:40.675,000 --> 0:10:43,000
they're less likely to be randomly false positives or negatives.

250
0:10:43.845,000 --> 0:10:44,000
So they all cluster together.

251
0:10:45.261,000 --> 0:10:47,000
The big trials are closer to the true answer.

252
0:10:47.792,000 --> 0:10:49,000
Then as you go further down at the bottom,

253
0:10:49.832,000 --> 0:10:51,000
what you can see is, on this side, spurious false negatives,

254
0:10:52.775,000 --> 0:10:54,000
and over on this side, spurious false positives.

255
0:10:55.045,000 --> 0:10:57,000
If there is publication bias,

256
0:10:57.145,000 --> 0:10:59,000
if small negative trials have gone missing in action,

257
0:10:59.699,000 --> 0:11:,000
you can see it on one of these graphs.

258
0:11:01.538,000 --> 0:11:03,000
So you see here that the small negative trials

259
0:11:03.713,000 --> 0:11:05,000
that should be on the bottom left have disappeared.

260
0:11:06.19,000 --> 0:11:08,000
This is a graph demonstrating the presence of publication bias

261
0:11:09.149,000 --> 0:11:1,000
in studies of publication bias.

262
0:11:11.093,000 --> 0:11:14,000
And I think that's the funniest epidemiology joke you will ever hear.

263
0:11:14.419,000 --> 0:11:15,000
(Laughter)

264
0:11:15.454,000 --> 0:11:17,000
That's how you can prove it statistically.

265
0:11:17.502,000 --> 0:11:18,000
But what about stories?

266
0:11:18.677,000 --> 0:11:19,000
Well, they're heinous, they really are.

267
0:11:20.616,000 --> 0:11:21,000
This is a drug called reboxetine.

268
0:11:22.229,000 --> 0:11:24,000
This is a drug which I, myself, have prescribed to patients.

269
0:11:25.192,000 --> 0:11:26,000
And I'm a very nerdy doctor.

270
0:11:26.552,000 --> 0:11:27,000
I hope I go out of my way

271
0:11:27.888,000 --> 0:11:29,000
to try and read and understand all the literature.

272
0:11:30.271,000 --> 0:11:31,000
I read the trials on this.

273
0:11:31.603,000 --> 0:11:33,000
They were all positive, all well-conducted.

274
0:11:33.894,000 --> 0:11:34,000
I found no flaw.

275
0:11:35.069,000 --> 0:11:38,000
Unfortunately, it turned out, that many of these trials were withheld.

276
0:11:38.674,000 --> 0:11:42,000
In fact, 76 percent of all of the trials that were done on this drug

277
0:11:43.243,000 --> 0:11:44,000
were withheld from doctors and patients.

278
0:11:45.218,000 --> 0:11:46,000
Now if you think about it,

279
0:11:46.495,000 --> 0:11:48,000
if I tossed a coin a hundred times,

280
0:11:48.816,000 --> 0:11:51,000
and I'm allowed to withhold from you the answers half the times,

281
0:11:52.376,000 --> 0:11:56,000
then I can convince you that I have a coin with two heads.

282
0:11:56.489,000 --> 0:11:57,000
If we remove half of the data,

283
0:11:58.426,000 --> 0:12:01,000
we can never know what the true effect size of these medicines is.

284
0:12:02.188,000 --> 0:12:04,000
And this is not an isolated story.

285
0:12:04.283,000 --> 0:12:07,000
Around half of all of the trial data on antidepressants has been withheld,

286
0:12:08.101,000 --> 0:12:09,000
but it goes way beyond that.

287
0:12:09.561,000 --> 0:12:12,000
The Nordic Cochrane Group were trying to get ahold of the data on that

288
0:12:12.931,000 --> 0:12:13,000
to bring it all together.

289
0:12:14.15,000 --> 0:12:17,000
The Cochrane Groups are an international nonprofit collaboration

290
0:12:17.193,000 --> 0:12:18,000
that produce systematic reviews

291
0:12:18.707,000 --> 0:12:2,000
of all of the data that has ever been shown.

292
0:12:20.828,000 --> 0:12:22,000
And they need to have access to all of the trial data.

293
0:12:23.386,000 --> 0:12:25,000
But the companies withheld that data from them.

294
0:12:25.853,000 --> 0:12:27,000
So did the European Medicines Agency --

295
0:12:28.072,000 --> 0:12:29,000
for three years.

296
0:12:29.682,000 --> 0:12:32,000
This is a problem that is currently lacking a solution.

297
0:12:32.738,000 --> 0:12:34,000
And to show how big it goes, this is a drug called Tamiflu,

298
0:12:35.661,000 --> 0:12:36,000
which governments around the world

299
0:12:37.347,000 --> 0:12:39,000
have spent billions and billions of dollars on.

300
0:12:40.214,000 --> 0:12:42,000
And they spend that money on the promise that this is a drug

301
0:12:43.105,000 --> 0:12:45,000
which will reduce the rate of complications with flu.

302
0:12:46.101,000 --> 0:12:47,000
We already have the data

303
0:12:47.276,000 --> 0:12:49,000
showing it reduces the duration of your flu by a few hours.

304
0:12:50.094,000 --> 0:12:52,000
But I don't care about that, governments don't care.

305
0:12:52.572,000 --> 0:12:54,000
I'm sorry if you have the flu, I know it's horrible,

306
0:12:55.05,000 --> 0:12:57,000
but we're not going to spend billions of dollars

307
0:12:57.318,000 --> 0:13:,000
trying to reduce the duration of your flu symptoms by half a day.

308
0:13:00.504,000 --> 0:13:01,000
We prescribe these drugs.

309
0:13:01.853,000 --> 0:13:02,000
We stockpile them for emergencies

310
0:13:03.68,000 --> 0:13:06,000
on the understanding they'll reduce the number of complications,

311
0:13:06.793,000 --> 0:13:07,000
which means pneumonia and death.

312
0:13:08.351,000 --> 0:13:11,000
The infectious diseases Cochrane Group, which are based in Italy,

313
0:13:11.834,000 --> 0:13:14,000
has been trying to get the full data in a usable form

314
0:13:15.035,000 --> 0:13:16,000
out of the drug companies,

315
0:13:16.327,000 --> 0:13:18,000
so they can make a full decision

316
0:13:18.442,000 --> 0:13:2,000
about whether this drug is effective or not,

317
0:13:20.563,000 --> 0:13:22,000
and they've not been able to get that information.

318
0:13:23.553,000 --> 0:13:28,000
This is undoubtedly the single biggest ethical problem

319
0:13:28.783,000 --> 0:13:29,000
facing medicine today.

320
0:13:31.204,000 --> 0:13:36,000
We cannot make decisions in the absence of all of the information.

321
0:13:37.789,000 --> 0:13:39,000
So it's a little bit difficult from there

322
0:13:40.79,000 --> 0:13:43,000
to spin in some kind of positive conclusion.

323
0:13:45.196,000 --> 0:13:46,000
But I would say this:

324
0:13:48.931,000 --> 0:13:5,000
I think that sunlight

325
0:13:51.751,000 --> 0:13:52,000
is the best disinfectant.

326
0:13:54.077,000 --> 0:13:56,000
All of these things are happening in plain sight,

327
0:13:56.836,000 --> 0:14:,000
and they're all protected by a force field of tediousness.

328
0:14:01.631,000 --> 0:14:03,000
And I think, with all of the problems in science,

329
0:14:04.062,000 --> 0:14:05,000
one of the best things that we can do

330
0:14:05.906,000 --> 0:14:07,000
is to lift up the lid, finger around at the mechanics

331
0:14:08.733,000 --> 0:14:09,000
and peer in.

332
0:14:10.036,000 --> 0:14:11,000
Thank you very much.

333
0:14:11.22,000 --> 0:14:14,000
(Applause)

