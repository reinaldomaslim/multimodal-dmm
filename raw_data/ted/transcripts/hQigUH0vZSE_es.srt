1
0:00:,000 --> 0:00:07,000
Traductor: Sebastian Betti Revisor: Lidia Cámara de la Fuente

2
0:00:12.863,000 --> 0:00:16,000
La tecnología del futuro siempre viene con dos cosas: una promesa

3
0:00:17.092,000 --> 0:00:19,000
y consecuencias no deseadas.

4
0:00:19.22,000 --> 0:00:22,000
Hoy quiero explorar esas consecuencias.

5
0:00:23.101,000 --> 0:00:26,000
Pero antes de llegar a cómo puede afectarnos la tecnología del futuro,

6
0:00:26.848,000 --> 0:00:29,000
me gustaría explorar las consecuencias no deseadas

7
0:00:30.621,000 --> 0:00:31,000
de algunas tecnologías recientes,

8
0:00:32.608,000 --> 0:00:33,000
por ejemplo, las redes sociales.

9
0:00:34.885,000 --> 0:00:38,000
Las redes sociales, hace pocos años, eran la tecnología del yo futuro.

10
0:00:39.541,000 --> 0:00:41,000
Ahora son el yo actual.

11
0:00:42.125,000 --> 0:00:44,000
Se suponía que las redes sociales nos unirían

12
0:00:44.976,000 --> 0:00:46,000
en formas inimaginables.

13
0:00:47.443,000 --> 0:00:48,000
Y las predicciones eran correctas.

14
0:00:50.412,000 --> 0:00:52,000
Estas tres chicas hablan unas a otras

15
0:00:53.278,000 --> 0:00:56,000
sin la incomodidad del contacto visual.

16
0:00:56.336,000 --> 0:00:57,000
(Risas)

17
0:00:57.689,000 --> 0:00:59,000
A eso le llamo avance.

18
0:01:01.533,000 --> 0:01:04,000
Se suponía que debíamos sumergirnos en un tsunami de comunicación,

19
0:01:05.065,000 --> 0:01:07,000
como el mundo nunca había visto.

20
0:01:07.929,000 --> 0:01:08,000
Pero ocurrió eso.

21
0:01:09.698,000 --> 0:01:1,000
Y esto.

22
0:01:13.153,000 --> 0:01:16,000
(Canta) Una de estas cosas no es como la otra.

23
0:01:16.221,000 --> 0:01:17,000
(Habla) Ahora, miren esta imagen.

24
0:01:17.942,000 --> 0:01:19,000
Si eligieron al chico con el libro, se equivocan...

25
0:01:20.43,000 --> 0:01:22,000
o, como diría cierto presidente, "¡Incorrecto!"

26
0:01:23.218,000 --> 0:01:24,000
(Risas)

27
0:01:27.206,000 --> 0:01:29,000
Claramente, tres de estos muchachos están leyendo,

28
0:01:29.807,000 --> 0:01:31,000
y un chico, al final, está escuchando música

29
0:01:32.211,000 --> 0:01:33,000
y jugando a "Candy Crush".

30
0:01:33.734,000 --> 0:01:34,000
(Risas)

31
0:01:35.662,000 --> 0:01:36,000
Entonces, ¿estamos más conectados,

32
0:01:37.605,000 --> 0:01:4,000
o solo pasamos más tiempo con nuestros dispositivos?

33
0:01:42.156,000 --> 0:01:45,000
Se suponía que las redes sociales serían como la plaza de la ciudad,

34
0:01:45.585,000 --> 0:01:49,000
donde entraríamos en contacto para debatir ideas desafiantes.

35
0:01:50.348,000 --> 0:01:52,000
Y en cambio tenemos trolls.

36
0:01:53.262,000 --> 0:01:56,000
Este es un tuit real que recibí.

37
0:01:58.22,000 --> 0:02:02,000
"Chuck, nadie quiere oír tus estúpidos y desinformados puntos de vista políticos.

38
0:02:02.398,000 --> 0:02:04,000
Espero que enfermes de lerpa y mueras.

39
0:02:04.743,000 --> 0:02:05,000
Con cariño, papá".

40
0:02:06.175,000 --> 0:02:07,000
(Risas)

41
0:02:08.82,000 --> 0:02:1,000
Lo genial de este tuit si lo miran,

42
0:02:11.473,000 --> 0:02:13,000
como la mayoría de los trolls, no es tan malo,

43
0:02:13.81,000 --> 0:02:16,000
porque me deseó "lerpa" en vez de "lepra",

44
0:02:17.178,000 --> 0:02:19,000
y la "lerpa" no es en absoluto peligrosa.

45
0:02:20.043,000 --> 0:02:21,000
(Risas)

46
0:02:21.648,000 --> 0:02:22,000
(Aplausos)

47
0:02:26.333,000 --> 0:02:3,000
Aparte de los trolls, hay nuevas formas de torturar a los adolescentes...

48
0:02:30.874,000 --> 0:02:31,000
el ciberacoso.

49
0:02:32.848,000 --> 0:02:36,000
Una idea que mi madre de 75 años simplemente no puede entender.

50
0:02:38.441,000 --> 0:02:4,000
"Entonces, ¿lo golpearon?"

51
0:02:40.567,000 --> 0:02:41,000
"No, mamá, no lo golpearon".

52
0:02:42.619,000 --> 0:02:43,000
"¿Le robaron el dinero?"

53
0:02:43.959,000 --> 0:02:44,000
"No, mamá, no le robaron el dinero".

54
0:02:45.849,000 --> 0:02:46,000
"¿Pusieron su cara en el inodoro?"

55
0:02:47.729,000 --> 0:02:48,000
"No, mamá, no..."

56
0:02:48.972,000 --> 0:02:49,000
"Bueno, ¿qué hicieron?"

57
0:02:50.207,000 --> 0:02:51,000
"Lo atacaron en Internet".

58
0:02:52.8,000 --> 0:02:53,000
"¿Lo atacaron en Internet?"

59
0:02:54.345,000 --> 0:02:55,000
(Risas)

60
0:02:55.37,000 --> 0:02:57,000
"Bueno, ¿por qué no apagas Internet?"

61
0:02:57.736,000 --> 0:02:58,000
(Risas)

62
0:02:59.049,000 --> 0:03:01,000
"Toda tu generación es una masa de debiluchos".

63
0:03:01.615,000 --> 0:03:02,000
(Risas)

64
0:03:03.66,000 --> 0:03:04,000
Plantea algo válido.

65
0:03:04.834,000 --> 0:03:05,000
(Risas)

66
0:03:06.197,000 --> 0:03:07,000
Plantea algo válido.

67
0:03:07.38,000 --> 0:03:1,000
Y no voy a entrar en el efecto de las redes sociales sobre las citas.

68
0:03:11.491,000 --> 0:03:13,000
Estuve en Grindr hasta que descubrí que no era una app

69
0:03:14.415,000 --> 0:03:16,000
para sándwiches de tipo molinillo, "grinder".

70
0:03:16.985,000 --> 0:03:17,000
(Risas)

71
0:03:19.908,000 --> 0:03:22,000
Y ni hablar de Tinder,

72
0:03:23.154,000 --> 0:03:26,000
solo decir que si creen que existe algún límite

73
0:03:27.078,000 --> 0:03:3,000
a la cantidad de sexo ocasional que puede haber en el planeta,

74
0:03:30.988,000 --> 0:03:31,000
tristemente, se equivocan.

75
0:03:32.829,000 --> 0:03:33,000
(Risas)

76
0:03:33.854,000 --> 0:03:34,000
Entonces, ¿hacia dónde nos dirigimos?

77
0:03:35.757,000 --> 0:03:37,000
Bueno, pasemos a un tema candente.

78
0:03:38.148,000 --> 0:03:39,000
Autos sin conductor.

79
0:03:39.323,000 --> 0:03:41,000
Algo que vemos desde hace muchos años,

80
0:03:42.019,000 --> 0:03:44,000
solo que sin la asistencia informática.

81
0:03:44.204,000 --> 0:03:46,000
(Risas)

82
0:03:47.352,000 --> 0:03:49,000
(Aplausos)

83
0:03:50.733,000 --> 0:03:53,000
Porque durante años hemos estado mandando mensajes mientras conducimos,

84
0:03:54.737,000 --> 0:03:55,000
maquillándonos,

85
0:03:56.339,000 --> 0:03:59,000
afeitándonos, leyendo, leyendo de verdad,

86
0:03:59.445,000 --> 0:04:,000
ese sería yo.

87
0:04:00.631,000 --> 0:04:01,000
(Risas)

88
0:04:01.668,000 --> 0:04:03,000
Como los autos sin conductor serán compartidos,

89
0:04:04.071,000 --> 0:04:05,000
muchas personas no comprarán autos,

90
0:04:06.031,000 --> 0:04:08,000
eso significa que desaparecerá el organismo de control.

91
0:04:08.83,000 --> 0:04:1,000
El control de vehículos... y sé lo que van a decir.

92
0:04:11.544,000 --> 0:04:13,000
"Lo único que faltaba es que este tipo suba al escenario

93
0:04:14.285,000 --> 0:04:15,000
y hable del organismo de control".

94
0:04:15.98,000 --> 0:04:17,000
Bueno, no sé Uds., pero yo no quiero vivir en un mundo

95
0:04:18.637,000 --> 0:04:19,000
de luces fluorescentes estridentes,

96
0:04:20.623,000 --> 0:04:21,000
de filas infinitas,

97
0:04:22.545,000 --> 0:04:23,000
de terribles formularios a completar,

98
0:04:24.405,000 --> 0:04:27,000
y de burócratas descontentos, sin alma, que me recuerden

99
0:04:28.404,000 --> 0:04:31,000
que soy bastante afortunado de no trabajar aquí.

100
0:04:31.87,000 --> 0:04:32,000
(Risas)

101
0:04:33.49,000 --> 0:04:35,000
Ese es el servicio que brindan.

102
0:04:36.458,000 --> 0:04:37,000
El ente de control:

103
0:04:37.999,000 --> 0:04:39,000
uno va para renovar el registro,

104
0:04:40.084,000 --> 0:04:44,000
y se queda por la satisfacción de saber que tomó buenas decisiones en la vida.

105
0:04:44.359,000 --> 0:04:45,000
(Risas)

106
0:04:49.06,000 --> 0:04:5,000
Nadie será dueño de su auto en el futuro,

107
0:04:51.082,000 --> 0:04:54,000
o sea que los adolescentes no tendrán un lugar para enamorarse.

108
0:04:55.546,000 --> 0:04:56,000
¿Sabes lo que eso significa?

109
0:04:56.943,000 --> 0:04:59,000
Significa que pedirán autos sin chofer para hacer justo eso.

110
0:05:00.602,000 --> 0:05:04,000
No quiero entrar a un vehículo y tener que preguntarme:

111
0:05:04.991,000 --> 0:05:08,000
"¿Por qué este auto huele a torpeza, fracaso y vergüenza?"

112
0:05:09.808,000 --> 0:05:11,000
(Risas)

113
0:05:12.916,000 --> 0:05:15,000
Si quisiera preguntarme eso, iría a mi propia habitación.

114
0:05:15.984,000 --> 0:05:16,000
(Risas)

115
0:05:17.389,000 --> 0:05:19,000
Entonces, ¿qué más esperamos con ansias?

116
0:05:19.423,000 --> 0:05:2,000
Eso es, la inteligencia artificial.

117
0:05:21.271,000 --> 0:05:23,000
La inteligencia artificial, sí.

118
0:05:23.586,000 --> 0:05:26,000
Hubo un tiempo en el que la inteligencia artificial era una broma.

119
0:05:26.799,000 --> 0:05:29,000
Es decir, literalmente, una burla que uno escuchaba en un cóctel

120
0:05:30.455,000 --> 0:05:32,000
cuando alguien sacaba a colación en una conversación:

121
0:05:33.286,000 --> 0:05:34,000
"La inteligencia artificial.

122
0:05:34.796,000 --> 0:05:37,000
La única inteligencia artificial real es nuestro Congreso Estadounidense

123
0:05:38.376,000 --> 0:05:4,000
Ja, ja, ja, ja, ja".

124
0:05:40.428,000 --> 0:05:41,000
Bueno, ya no es divertido.

125
0:05:41.869,000 --> 0:05:43,000
(Risas)

126
0:05:48.108,000 --> 0:05:51,000
Stephen Hawking, Elon Musk y Bill Gates

127
0:05:51.683,000 --> 0:05:54,000
han expresado sus reservas sobre la inteligencia artificial.

128
0:05:55.663,000 --> 0:05:58,000
Es como si Jesús, Moisés y Mahoma juntos, nos dijeran:

129
0:05:59.218,000 --> 0:06:02,000
"Oigan, oigan, aquí hay algo en lo que todos podemos creer".

130
0:06:02.238,000 --> 0:06:02,000
(Risas)

131
0:06:03.078,000 --> 0:06:05,000
Uno querría seguir ese camino, es todo lo que estoy diciendo.

132
0:06:07.31,000 --> 0:06:11,000
Le estamos enseñando a pensar a las máquinas,

133
0:06:11.801,000 --> 0:06:13,000
a entender nuestro comportamiento,

134
0:06:14.049,000 --> 0:06:17,000
a defenderse e incluso a engañar.

135
0:06:18.904,000 --> 0:06:19,000
¿Qué podría fallar?

136
0:06:20.657,000 --> 0:06:21,000
(Risas)

137
0:06:23.568,000 --> 0:06:24,000
Pero algo siempre es seguro:

138
0:06:25.42,000 --> 0:06:28,000
la creación siempre desprecia a su creador.

139
0:06:29.043,000 --> 0:06:3,000
¿Sí?

140
0:06:30.26,000 --> 0:06:32,000
Los Titanes se levantaron contra los dioses;

141
0:06:32.409,000 --> 0:06:33,000
Lucifer contra Jehová.

142
0:06:34.047,000 --> 0:06:37,000
Y cualquiera que tenga un adolescente ha escuchado estas palabras:

143
0:06:37.353,000 --> 0:06:39,000
"¡Te odio y estás arruinando mi vida!

144
0:06:39.41,000 --> 0:06:4,000
¡Te odio!"

145
0:06:42.325,000 --> 0:06:46,000
Ahora imaginen ese sentimiento con una máquina que puede superarnos

146
0:06:46.904,000 --> 0:06:47,000
y está fuertemente armada.

147
0:06:48.771,000 --> 0:06:49,000
(Risas)

148
0:06:51.074,000 --> 0:06:52,000
¿El resultado?

149
0:06:52.976,000 --> 0:06:53,000
Absolutamente.

150
0:06:54.202,000 --> 0:06:55,000
(Risas)

151
0:06:58.973,000 --> 0:07:01,000
Antes de perfeccionar la inteligencia artificial

152
0:07:02.241,000 --> 0:07:04,000
debemos perfeccionar las emociones artificiales.

153
0:07:04.828,000 --> 0:07:07,000
De esa manera, podemos enseñar a los robots o las máquinas

154
0:07:08.727,000 --> 0:07:1,000
cómo amarnos incondicionalmente,

155
0:07:11.232,000 --> 0:07:15,000
para que cuando descubran que el único problema real del planeta

156
0:07:15.781,000 --> 0:07:16,000
somos nosotros,

157
0:07:16.995,000 --> 0:07:17,000
en vez de destruirnos.

158
0:07:18.735,000 --> 0:07:21,000
Lo que, por cierto, es totalmente lógico,

159
0:07:21.863,000 --> 0:07:23,000
pensarán que somos adorables...

160
0:07:24.333,000 --> 0:07:25,000
(Risas)

161
0:07:25.423,000 --> 0:07:26,000
como la caca de bebé.

162
0:07:26.668,000 --> 0:07:27,000
(Risas)

163
0:07:27.695,000 --> 0:07:3,000
"Dios mío, me encanta la forma en que destruyes el planeta.

164
0:07:30.825,000 --> 0:07:32,000
No puedo enojarme contigo, ¡eres tan lindo!

165
0:07:33.621,000 --> 0:07:34,000
¡Eres tan linda!"

166
0:07:34.867,000 --> 0:07:35,000
(Risas)

167
0:07:36.051,000 --> 0:07:41,000
No puedo hablar de esto sin hablar de robótica, ¿sí?

168
0:07:41.9,000 --> 0:07:43,000
¿Recuerdan cuando pensaban que la robótica era genial?

169
0:07:44.775,000 --> 0:07:46,000
Recuerdo que pensaba que la robótica era genial,

170
0:07:47.291,000 --> 0:07:5,000
hasta que descubrí que ocuparía el lugar de todos,

171
0:07:50.325,000 --> 0:07:52,000
del chico del reparto hasta la cirujana cardíaca.

172
0:07:52.765,000 --> 0:07:55,000
La única cosa, sin embargo, muy decepcionante sobre la robótica

173
0:07:55.818,000 --> 0:07:56,000
es el santo grial de la robótica,

174
0:07:57.56,000 --> 0:07:58,000
y ni siquiera ha sucedido.

175
0:07:59.051,000 --> 0:08:01,000
Estoy hablando de la novia robot,

176
0:08:01.264,000 --> 0:08:03,000
el sueño de un geek solitario en un sótano sin ventanas

177
0:08:04.24,000 --> 0:08:07,000
que un día juró: "Me voy a casar con mi creación".

178
0:08:08.738,000 --> 0:08:13,000
Y realmente hay un movimiento en marcha para evitar que esto suceda,

179
0:08:13.789,000 --> 0:08:15,000
por miedo a la explotación.

180
0:08:16.653,000 --> 0:08:18,000
Y yo, por mi parte, estoy en contra de ese movimiento.

181
0:08:20.224,000 --> 0:08:22,000
Creo que deberíamos tener novias robot.

182
0:08:23.596,000 --> 0:08:27,000
Solo creo que deberían venir con un protocolo feminista

183
0:08:27.865,000 --> 0:08:28,000
e inteligencia artificial,

184
0:08:29.768,000 --> 0:08:33,000
para que pueda mirar al tipo y decir: "soy demasiado buena para ti.

185
0:08:33.997,000 --> 0:08:34,000
Me voy".

186
0:08:35.323,000 --> 0:08:36,000
(Risas)

187
0:08:36.912,000 --> 0:08:38,000
(Aplausos)

188
0:08:40.371,000 --> 0:08:41,000
Y finalmente,

189
0:08:42.026,000 --> 0:08:44,000
tengo que hablar sobre bioingeniería,

190
0:08:44.714,000 --> 0:08:47,000
un área promisoria de la ciencia

191
0:08:48.657,000 --> 0:08:51,000
para terminar con la enfermedad incluso antes de que comience,

192
0:08:51.658,000 --> 0:08:55,000
para ayudarnos a vivir más tiempo, vidas más completas y más saludables.

193
0:08:57.218,000 --> 0:09:,000
Y al unir eso con hardware implantable,

194
0:09:00.364,000 --> 0:09:04,000
vemos la próxima encarnación de la evolución humana.

195
0:09:04.815,000 --> 0:09:06,000
Y todo eso suena genial,

196
0:09:07.155,000 --> 0:09:09,000
hasta que descubrimos hacia dónde va realmente.

197
0:09:09.48,000 --> 0:09:1,000
Un lugar:

198
0:09:11.133,000 --> 0:09:12,000
bebes de diseño,

199
0:09:12.837,000 --> 0:09:14,000
donde, sin importar la ubicación en el mundo

200
0:09:15.368,000 --> 0:09:16,000
ni la etnia,

201
0:09:17.177,000 --> 0:09:19,000
los bebés terminarán luciendo así.

202
0:09:19.835,000 --> 0:09:2,000
(Risas)

203
0:09:21.455,000 --> 0:09:23,000
Ese niño está sorprendido

204
0:09:24.061,000 --> 0:09:27,000
porque acaba de enterarse de que sus dos padres son negros.

205
0:09:27.564,000 --> 0:09:29,000
(Risas)

206
0:09:35.569,000 --> 0:09:38,000
¿Pueden imaginarlo en un cóctel en 20 años?

207
0:09:39.429,000 --> 0:09:4,000
"Sí, mis dos padres son negros.

208
0:09:41.066,000 --> 0:09:43,000
Quiero decir, es un poco incómodo a veces,

209
0:09:43.289,000 --> 0:09:45,000
pero deberías ver mi calificación crediticia.

210
0:09:45.676,000 --> 0:09:46,000
Impresionante, muy impresionante".

211
0:09:47.443,000 --> 0:09:47,000
(Risas)

212
0:09:49.353,000 --> 0:09:51,000
Ahora, todo esto parece aterrador,

213
0:09:51.717,000 --> 0:09:53,000
y todos en esta sala saben que no lo es.

214
0:09:54.388,000 --> 0:09:55,000
La tecnología no es aterradora.

215
0:09:56.568,000 --> 0:09:58,000
Nunca lo ha sido y nunca lo será.

216
0:10:00.113,000 --> 0:10:02,000
Nosotros somos aterradores,

217
0:10:02.808,000 --> 0:10:04,000
y también lo que haremos con la tecnología.

218
0:10:05.332,000 --> 0:10:08,000
¿Permitiremos que exponga nuestra humanidad,

219
0:10:09.334,000 --> 0:10:11,000
mostrando nuestro verdadero yo

220
0:10:11.665,000 --> 0:10:14,000
y reforzando el hecho de que somos los guardianes de nuestros hermanos?

221
0:10:16.24,000 --> 0:10:21,000
¿O permitiremos que revele nuestros demonios más profundos y más oscuros?

222
0:10:22.723,000 --> 0:10:27,000
La verdadera pregunta no es si la tecnología es aterradora o no.

223
0:10:28.326,000 --> 0:10:29,000
La verdadera pregunta es:

224
0:10:30.273,000 --> 0:10:31,000
¿Cuán humanos

225
0:10:31.874,000 --> 0:10:32,000
somos?

226
0:10:33.656,000 --> 0:10:34,000
Gracias.

227
0:10:34.831,000 --> 0:10:37,000
(Aplausos)

