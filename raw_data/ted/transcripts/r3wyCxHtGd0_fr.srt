1
0:00:,000 --> 0:00:07,000
Traducteur: jean-Philippe Odekerken Relecteur: Amy Clark

2
0:00:13.16,000 --> 0:00:17,000
Vous savez, je suis frappé de voir à quel point l’un des thèmes implicites de ces conférences de TED

3
0:00:17.16,000 --> 0:00:2,000
est la compassion. Ces démonstrations très émouvantes que nous venons de voir :

4
0:00:21.16,000 --> 0:00:25,000
le virus du SIDA en Afrique, le président Clinton hier soir…

5
0:00:25.16,000 --> 0:00:3,000
Et j’aimerais vous proposer quelques pensées collatérales, si vous voulez bien,

6
0:00:30.16,000 --> 0:00:35,000
sur la compassion et passer d’un plan global à un plan plus personnel

7
0:00:35.16,000 --> 0:00:37,000
(je suis psychologue). Mais rassurez-vous,

8
0:00:37.16,000 --> 0:00:38,000
je ne descendrai pas plus bas que la ceinture.

9
0:00:39.16,000 --> 0:00:43,000
Rires

10
0:00:44.16,000 --> 0:00:46,000
Ils ont fait une étude très importante, il y a quelque temps,

11
0:00:46.16,000 --> 0:00:5,000
au Séminaire de Théologie de Princeton : comment se fait-il, alors que

12
0:00:51.16,000 --> 0:00:54,000
nous avons tous tellement d’occasions d’aider,

13
0:00:54.16,000 --> 0:00:57,000
que parfois nous le faisons et parfois non.

14
0:00:58.16,000 --> 0:01:01,000
On a dit à un groupe d’étudiants en théologie du Séminaire de Princeton

15
0:01:02.16,000 --> 0:01:06,000
qu’ils allaient faire un sermon, comme exercice pratique

16
0:01:06.16,000 --> 0:01:09,000
et on leur a donné à chacun un thème pour leur sermon.

17
0:01:09.16,000 --> 0:01:12,000
La moitié des étudiants a eu comme sujet

18
0:01:12.16,000 --> 0:01:14,000
la parabole du Bon Samaritain

19
0:01:14.16,000 --> 0:01:16,000
l’homme qui s’est arrêté pour aider l’étranger

20
0:01:17.16,000 --> 0:01:19,000
dans le besoin sur le bord de la route.

21
0:01:19.16,000 --> 0:01:22,000
L’autre moitié a eu des sujets choisis au hasard dans la Bible.

22
0:01:22.16,000 --> 0:01:25,000
Ensuite, l’un après l’autre, on leur a dit de se rendre dans un autre bâtiment

23
0:01:26.16,000 --> 0:01:27,000
pour faire leur sermon.

24
0:01:27.16,000 --> 0:01:3,000
En allant d’un bâtiment à l’autre,

25
0:01:30.16,000 --> 0:01:33,000
chacun d’eux est passé près d’un homme plié en deux, qui gémissait

26
0:01:34.16,000 --> 0:01:38,000
et avait visiblement besoin d’aide. Question : « Se sont-ils arrêtés pour l’aider ? »

27
0:01:38.16,000 --> 0:01:39,000
Question plus intéressante :

28
0:01:40.16,000 --> 0:01:43,000
Le fait qu’ils étaient en train de réfléchir à la parabole

29
0:01:43.16,000 --> 0:01:47,000
du Bon Samaritain a-t-il eu un effet quelconque ? Réponse : Non, pas du tout.

30
0:01:48.16,000 --> 0:01:51,000
Au bout du compte, ce qui a décidé qu’ils s’arrêtent ou non

31
0:01:51.16,000 --> 0:01:52,000
pour aider un étranger qui avait besoin d’aide,

32
0:01:52.16,000 --> 0:01:55,000
c’était dans quelle mesure ils se sentaient pressés –

33
0:01:56.16,000 --> 0:02:,000
s’ils se sentaient en retard - ou s’ils étaient plongés dans leurs réflexions

34
0:02:00.16,000 --> 0:02:01,000
sur ce qu’ils allaient raconter.

35
0:02:02.16,000 --> 0:02:04,000
Et c’est ça, je pense, ce qui est vraiment fâcheux dans notre vie :

36
0:02:05.16,000 --> 0:02:09,000
que nous ne saisissons pas toutes les occasions d’aider

37
0:02:09.16,000 --> 0:02:12,000
parce que nous portons notre attention dans la mauvaise direction.

38
0:02:12.16,000 --> 0:02:15,000
Il y a un nouveau domaine en sciences du cerveau : les neurosciences sociales.

39
0:02:16.16,000 --> 0:02:2,000
On y étudie les circuits qui sont activés dans les cerveaux de deux personnes

40
0:02:20.16,000 --> 0:02:22,000
lorsqu’elles ont des contacts l’une avec l’autre.

41
0:02:22.16,000 --> 0:02:26,000
Et la nouvelle compréhension de la compassion qui ressort de ces neurosciences

42
0:02:26.16,000 --> 0:02:3,000
sociales est que la réaction naturelle de notre système (par défaut) est d’aider.

43
0:02:30.16,000 --> 0:02:34,000
C’est-à-dire que, si nous faisons attention à l’autre,

44
0:02:35.16,000 --> 0:02:38,000
automatiquement nous comprenons ce qu’il ressent, nous ressentons ‘avec’ lui.

45
0:02:39.16,000 --> 0:02:41,000
Il y a ces neurones nouvellement identifiés, les neurones miroirs,

46
0:02:41.16,000 --> 0:02:45,000
qui agissent comme une wifi neuronale et mettent en activité dans notre cerveau

47
0:02:45.16,000 --> 0:02:49,000
exactement les mêmes zones que chez l’autre. Nous ressentons ‘avec’, automatiquement.

48
0:02:49.16,000 --> 0:02:53,000
Et si cette personne a besoin de quelque chose, si elle souffre,

49
0:02:54.16,000 --> 0:02:58,000
nous sommes automatiquement préparés à l’aider. En tout cas, c’est ce qu’ils disent.

50
0:02:58.16,000 --> 0:03:01,000
Mais alors, la question est : Pourquoi est-ce que nous ne le faisons pas ?

51
0:03:01.16,000 --> 0:03:03,000
Je pense que ceci montre tout l’éventail

52
0:03:04.16,000 --> 0:03:06,000
des comportements depuis l’auto-absorption complète,

53
0:03:07.16,000 --> 0:03:09,000
au fait de remarquer l’autre, puis à l’empathie et à la compassion.

54
0:03:09.16,000 --> 0:03:13,000
Et c’est tout simple : si nous sommes concentrés sur nous-même,

55
0:03:14.16,000 --> 0:03:17,000
si nous sommes préoccupés, comme nous le sommes si souvent tout au long de la journée,

56
0:03:17.16,000 --> 0:03:2,000
nous ne remarquons pas l’autre pleinement.

57
0:03:20.16,000 --> 0:03:22,000
Et la différence entre l’attention portée sur soi-même et sur l’autre

58
0:03:22.16,000 --> 0:03:23,000
peut être très subtile.

59
0:03:23.16,000 --> 0:03:27,000
Je remplissais ma feuille d’impôts l’autre jour et je suis arrivé à la rubrique

60
0:03:27.16,000 --> 0:03:29,000
où je listais tous les dons que j’avais faits,

61
0:03:30.16,000 --> 0:03:33,000
et j’ai eu une révélation : j’en étais à mon chèque

62
0:03:33.16,000 --> 0:03:36,000
à la Fondation Seva et je me suis surpris à penser

63
0:03:36.16,000 --> 0:03:38,000
« Mince ! mon ami Larry Brilliant serait vraiment content

64
0:03:39.16,000 --> 0:03:4,000
que j’aie donné de l’argent pour Seva ! »

65
0:03:40.16,000 --> 0:03:43,000
Puis j’ai réalisé que, en fait, donner me procurait

66
0:03:43.16,000 --> 0:03:47,000
une satisfaction toute narcissique : j’étais très content de moi.

67
0:03:47.16,000 --> 0:03:52,000
Puis j’ai commencé à penser à ces gens de l’Himalaya

68
0:03:52.16,000 --> 0:03:54,000
dont la cataracte serait soignée et je me suis rendu compte

69
0:03:55.16,000 --> 0:03:58,000
que j’étais passé de cette joie narcissique centrée sur moi

70
0:03:59.16,000 --> 0:04:02,000
à une joie altruiste, je me suis senti bien

71
0:04:02.16,000 --> 0:04:06,000
pour les personnes qui étaient aidées. Je pense que c’est une source de motivation.

72
0:04:06.16,000 --> 0:04:09,000
Mais cette distinction entre être centré sur soi

73
0:04:09.16,000 --> 0:04:1,000
et être centré sur les autres,

74
0:04:10.16,000 --> 0:04:13,000
je nous encourage tous à y prêter attention.

75
0:04:13.16,000 --> 0:04:16,000
C’est ce qui se passe de manière évidente dans le monde du « dating » (les rencontres).

76
0:04:17.16,000 --> 0:04:2,000
J’étais dans un restaurant de sushi il y a quelque temps

77
0:04:20.16,000 --> 0:04:23,000
et j’ai entendu deux femmes parler du frère de l’une d’elle

78
0:04:24.16,000 --> 0:04:27,000
qui fréquentait le monde des célibataires. Et cette femme dit :

79
0:04:27.16,000 --> 0:04:29,000
mon frère a beaucoup de mal à se trouver une partenaire,

80
0:04:29.16,000 --> 0:04:31,000
alors il essaie le ‘speed dating’. » Vous connaissez le ‘speed dating’ ?

81
0:04:31.16,000 --> 0:04:35,000
Des femmes sont assises à des tables et les hommes vont de table en table.

82
0:04:35.16,000 --> 0:04:38,000
Il y a une horloge et une sonnerie : cinq minutes, et bingo,

83
0:04:39.16,000 --> 0:04:41,000
la conversation se termine et la femme peut décider

84
0:04:41.16,000 --> 0:04:45,000
de donner ou non sa carte ou son adresse email à l’homme

85
0:04:45.16,000 --> 0:04:47,000
pour une suite éventuelle. Cette femme dit :

86
0:04:47.16,000 --> 0:04:51,000
« Mon frère n’a jamais eu aucune carte et je sais exactement pourquoi.

87
0:04:51.16,000 --> 0:04:56,000
dès l’instant où il s’assied, il parle de lui, non-stop,

88
0:04:56.16,000 --> 0:04:57,000
et ne pose aucune question à la femme en face de lui. »

89
0:04:58.16,000 --> 0:05:03,000
Je faisais une recherche dans le Sunday Styles

90
0:05:03.16,000 --> 0:05:06,000
du New York Times et je regardais les histoires dans les coulisses des mariages

91
0:05:06.16,000 --> 0:05:09,000
elles sont très intéressantes – et je suis tombé sur le mariage

92
0:05:09.16,000 --> 0:05:12,000
d’Alice Charney Epstein. Elle racontait

93
0:05:12.16,000 --> 0:05:14,000
que lorsqu’elle fréquentait le monde des célibataires,

94
0:05:15.16,000 --> 0:05:17,000
elle faisait un test très simple auquel elle soumettait les gens:

95
0:05:18.16,000 --> 0:05:2,000
à partir du moment où ils étaient ensemble,

96
0:05:20.16,000 --> 0:05:23,000
combien de temps il fallait au type pour lui poser une question

97
0:05:23.16,000 --> 0:05:25,000
contenant le mot « vous / tu » ?

98
0:05:25.16,000 --> 0:05:29,000
Apparemment, Epstein a réussi le test brillamment, d’où l’article…

99
0:05:29.16,000 --> 0:05:3,000
Rires

100
0:05:30.16,000 --> 0:05:32,000
C’est un petit test que

101
0:05:32.16,000 --> 0:05:34,000
je vous encourage tous à faire lors d’une soirée.

102
0:05:34.16,000 --> 0:05:36,000
Ici, à TED il y a de belles occasions !

103
0:05:38.16,000 --> 0:05:41,000
Le « Harvard Business Review » a publié récemment un article intitulé:

104
0:05:41.16,000 --> 0:05:44,000
« Le moment humain » sur comment créer un vrai contact

105
0:05:44.16,000 --> 0:05:47,000
avec quelqu’un au travail. Eh bien,

106
0:05:47.16,000 --> 0:05:5,000
la chose fondamentale à faire, c’est : éteindre son Blackberry,

107
0:05:51.16,000 --> 0:05:54,000
fermer son ordinateur portable, arrêter de rêver

108
0:05:55.16,000 --> 0:05:57,000
et consacrer toute son attention à la personne.

109
0:05:58.16,000 --> 0:06:02,000
Il y a un mot qui a été inventé récemment en anglais

110
0:06:03.16,000 --> 0:06:06,000
pour ce moment où la personne avec qui l’on est sort brusquement son Blackberry

111
0:06:06.16,000 --> 0:06:09,000
ou répond à son portable et où soudain, on n’existe plus.

112
0:06:10.16,000 --> 0:06:14,000
c’est le mot ‘pizzled’, une combinaison de ‘puzzled’ (perplexe) et ‘pissed off’ (avoir les boules).

113
0:06:14.16,000 --> 0:06:17,000
Rires

114
0:06:17.16,000 --> 0:06:23,000
Je crois que c’est bien vu. C’est notre empathie, le fait de nous mettre sur la même longueur d’ondes,

115
0:06:24.16,000 --> 0:06:27,000
qui nous différencie des gens machiavéliques ou des sociopathes.

116
0:06:27.16,000 --> 0:06:32,000
J’ai un beau-frère qui est un expert en horreur et en terreur

117
0:06:32.16,000 --> 0:06:35,000
il a écrit « Dracula annoté » et « L’essentiel de Frankenstein »;

118
0:06:35.16,000 --> 0:06:36,000
c’est un spécialiste de Chaucer,

119
0:06:36.16,000 --> 0:06:38,000
mais il est né en Transylvanie

120
0:06:38.16,000 --> 0:06:4,000
et je pense que ça l’a marqué un petit peu…

121
0:06:40.16,000 --> 0:06:44,000
Bref, à un moment donné, mon beau-frère, Léonard,

122
0:06:44.16,000 --> 0:06:46,000
a décidé d’écrire un livre sur un tueur en série,

123
0:06:46.16,000 --> 0:06:49,000
un homme qui a terrorisé ce quartier même où nous nous trouvons,

124
0:06:50.16,000 --> 0:06:52,000
il y a des années ; on l’appelait « l’étrangleur de Santa Cruz ».

125
0:06:53.16,000 --> 0:06:57,000
Avant d’être arrêté, il avait tué ses grands-parents,

126
0:06:57.16,000 --> 0:07:,000
sa mère et cinq étudiantes de l’université de Santa Cruz.

127
0:07:01.16,000 --> 0:07:03,000
Donc, mon beau-frère va interviewer ce tueur

128
0:07:04.16,000 --> 0:07:06,000
et se rend compte lorsqu’il le rencontre

129
0:07:06.16,000 --> 0:07:07,000
que ce type est absolument terrifiant.

130
0:07:08.16,000 --> 0:07:1,000
D’abord, il mesure presque 2m10,

131
0:07:10.16,000 --> 0:07:13,000
mais ce n’est pas ça le plus terrifiant.

132
0:07:13.16,000 --> 0:07:18,000
Le plus effrayant, c’est qu’il a un QI de 160, un authentique génie.

133
0:07:19.16,000 --> 0:07:23,000
mais il y a zéro corrélation entre l’intelligence (le QI) et l’empathie émotionnelle

134
0:07:23.16,000 --> 0:07:24,000
(ressentir avec l’autre) :

135
0:07:25.16,000 --> 0:07:27,000
elles sont contrôlées par des zones différentes du cerveau.

136
0:07:28.16,000 --> 0:07:3,000
Donc, mon beau-frère finit pas trouver le courage

137
0:07:31.16,000 --> 0:07:33,000
de lui poser LA question pour laquelle il veut vraiment obtenir une réponse,

138
0:07:33.16,000 --> 0:07:36,000
à savoir : « Comment avez-vous pu faire ça ?

139
0:07:36.16,000 --> 0:07:38,000
Vous n’avez ressenti aucune pitié pour vos victimes ? »

140
0:07:38.16,000 --> 0:07:41,000
C’étaient des meurtres très ‘intimes’ : il a étranglé ses victimes.

141
0:07:42.16,000 --> 0:07:44,000
Et l’étrangleur lui répond de manière très détachée :

142
0:07:44.16,000 --> 0:07:49,000
« Oh non, si j’avais senti la douleur, je n’aurais pas pu le faire.

143
0:07:49.16,000 --> 0:07:55,000
Je devais débrancher cette partie de moi. » Je devais débrancher cette partie de moi.

144
0:07:55.16,000 --> 0:08:,000
Je pense que ça, c’est très troublant.

145
0:08:01.16,000 --> 0:08:05,000
et en un sens - j’ai réfléchi à débrancher cette partie de nous.

146
0:08:05.16,000 --> 0:08:07,000
Quand nous portons notre attention sur nous-même dans n’importe quelle activité,

147
0:08:08.16,000 --> 0:08:11,000
nous débranchons cette partie de nous-même s’il y a une autre personne.

148
0:08:12.16,000 --> 0:08:17,000
Prenons : faire les courses. Pensons à ce que pourrait être

149
0:08:17.16,000 --> 0:08:19,000
un consumérisme compatissant.

150
0:08:20.16,000 --> 0:08:22,000
En ce moment même, comme l’a fait remarquer Bill McDonough,

151
0:08:24.16,000 --> 0:08:28,000
les objets que nous achetons et utilisons ont des conséquences cachées.

152
0:08:28.16,000 --> 0:08:31,000
Nous sommes tous sans le savoir les victimes d’une situation à laquelle personne ne comprend rien.

153
0:08:32.16,000 --> 0:08:34,000
Nous ne remarquons pas et ne remarquons pas que nous ne remarquons pas

154
0:08:35.16,000 --> 0:08:41,000
les molécules toxiques qui sortent d’un tapis ou du tissu sur les sièges.

155
0:08:42.16,000 --> 0:08:47,000
Ou, nous ne savons pas si ce tissu ou ce nutriment technologique

156
0:08:47.16,000 --> 0:08:51,000
ou manufacturé peut être réutilisé

157
0:08:51.16,000 --> 0:08:53,000
ou finit simplement à la décharge. En d’autres termes,

158
0:08:53.16,000 --> 0:08:58,000
nous sommes inconscients des conséquences écologiques, de santé publique,

159
0:08:59.16,000 --> 0:09:02,000
de justice sociale et économique qui découlent

160
0:09:02.16,000 --> 0:09:04,000
de ce que nous achetons et utilisons.

161
0:09:06.16,000 --> 0:09:1,000
En un sens, la pièce elle-même est l’éléphant dans la pièce,

162
0:09:10.16,000 --> 0:09:14,000
mais nous ne le voyions pas et nous sommes devenus les victimes

163
0:09:14.16,000 --> 0:09:17,000
d’un système qui détourne notre attention. Réfléchissez-y.

164
0:09:18.16,000 --> 0:09:21,000
Il y a un livre merveilleux qui s’appelle :

165
0:09:22.16,000 --> 0:09:24,000
«Stuff (choses, trucs) : la vie cachée des objets de tous les jours ».

166
0:09:25.16,000 --> 0:09:28,000
Il parle de toute l’histoire qu’il y a derrière un t-shirt,

167
0:09:28.16,000 --> 0:09:31,000
par exemple : où le coton a poussé,

168
0:09:31.16,000 --> 0:09:33,000
les engrais qui ont été utilisés et les conséquences

169
0:09:33.16,000 --> 0:09:37,000
de ces engrais sur le sol. Il précise, par exemple,

170
0:09:37.16,000 --> 0:09:4,000
que le coton est très résistant à la teinture ;

171
0:09:40.16,000 --> 0:09:43,000
environ 60% des teintures partent dans les eaux usées,

172
0:09:43.16,000 --> 0:09:46,000
et les épidémiologistes savent bien que les enfants

173
0:09:46.16,000 --> 0:09:51,000
qui vivent près des usines textiles tendent à être atteints d’un taux élevé de leucémie.

174
0:09:52.16,000 --> 0:09:56,000
Il y a une société, Bennett and Co., qui fournit Polo.com

175
0:09:57.16,000 --> 0:10:02,000
(Victoria’s Secret ®) : parce que leur PDG est conscient de tout cela,

176
0:10:03.16,000 --> 0:10:07,000
ils ont fait une co-entreprise en Chine avec leurs usines de teinture

177
0:10:07.16,000 --> 0:10:09,000
pour s’assurer que les eaux usées

178
0:10:09.16,000 --> 0:10:13,000
soient correctement traitées avant de retourner dans les nappes phréatiques.

179
0:10:13.16,000 --> 0:10:17,000
A l’heure actuelle, nous n’avons pas la possibilité de choisir entre un tee-shirt équitable

180
0:10:18.16,000 --> 0:10:22,000
plutôt que non-équitable. Qu’est-ce que ça nous coûterait d’y arriver ?

181
0:10:25.16,000 --> 0:10:28,000
Eh bien, j’y ai réfléchi. Déjà,

182
0:10:28.16,000 --> 0:10:33,000
il y a une nouvelle technologie d’étiquetage électronique qui permet à n’importe quel magasin

183
0:10:33.16,000 --> 0:10:37,000
de connaître tout l’historique de chaque article en rayon,

184
0:10:38.16,000 --> 0:10:4,000
la traçabilité depuis l’usine. Si on peut remonter

185
0:10:40.16,000 --> 0:10:44,000
jusqu’à l’usine, on peut voir les procédés de fabrication

186
0:10:44.16,000 --> 0:10:48,000
utilisés et si c'est équitable,

187
0:10:48.16,000 --> 0:10:52,000
on peut le labelliser comme tel. Et s’il ne l’est pas tellement,

188
0:10:52.16,000 --> 0:10:56,000
on peut… aujourd’hui, vous pouvez aller dans n’importe quel magasin,

189
0:10:56.16,000 --> 0:10:59,000
placer le scanner de votre Palm sur un code barre

190
0:10:59.16,000 --> 0:11:01,000
qui vous enverra sur un site.

191
0:11:01.16,000 --> 0:11:03,000
Ils ont ça pour les gens qui font des allergies aux cacahuètes.

192
0:11:04.16,000 --> 0:11:06,000
Ce site pourrait vous renseigner sur l’objet.

193
0:11:07.16,000 --> 0:11:08,000
Autrement dit, au moment d’acheter,

194
0:11:08.16,000 --> 0:11:12,000
nous pourrions faire un choix empreint de compassion.

195
0:11:12.16,000 --> 0:11:18,000
On dit dans le monde des sciences de l’information

196
0:11:18.16,000 --> 0:11:21,000
qu’au bout du compte, tout le monde saura tout.

197
0:11:21.16,000 --> 0:11:23,000
Question : est-ce que cela changera quelque chose ?

198
0:11:25.16,000 --> 0:11:28,000
À l’époque où je travaillais pour le New York Times,

199
0:11:29.16,000 --> 0:11:31,000
dans les années 80, j’ai écrit un article

200
0:11:31.16,000 --> 0:11:33,000
sur ce qui était alors un nouveau problème à New York :

201
0:11:33.16,000 --> 0:11:35,000
les sans-abri dans les rues.

202
0:11:35.16,000 --> 0:11:39,000
J’ai passé quelques semaines à travailler avec un groupe de travailleurs sociaux

203
0:11:39.16,000 --> 0:11:42,000
qui s’occupaient des sans-abri. Je me suis rendu compte, en voyant les sans-abri

204
0:11:42.16,000 --> 0:11:47,000
du point de vue des travailleurs sociaux, que presque tous étaient des malades mentaux

205
0:11:47.16,000 --> 0:11:51,000
qui n’avaient nulle part où aller. Ils avaient fait ce diagnostic.Et moi…

206
0:11:52.16,000 --> 0:11:55,000
ça m’a secoué et fait sortir de la transe urbaine,

207
0:11:56.16,000 --> 0:11:59,000
où, quand on voit, quand on passe à côté d’un sans–abri

208
0:11:59.16,000 --> 0:12:02,000
dans la périphérie de notre champ de vision, il reste à la périphérie.

209
0:12:04.16,000 --> 0:12:06,000
Nous ne remarquons pas, donc nous n’agissons pas.

210
0:12:09.16,000 --> 0:12:14,000
Peu après cela, un vendredi, en fin de journée,

211
0:12:14.16,000 --> 0:12:17,000
je descendais dans le métro. C’était l’heure de pointe

212
0:12:17.16,000 --> 0:12:19,000
et des milliers de personnes descendaient les escaliers en flots continus.

213
0:12:19.16,000 --> 0:12:21,000
Tout à coup, en descendant,

214
0:12:21.16,000 --> 0:12:24,000
j’ai remarqué qu’il y avait un homme écroulé sur le côté,

215
0:12:24.16,000 --> 0:12:28,000
torse nu, immobile, et les gens l’enjambaient -

216
0:12:29.16,000 --> 0:12:3,000
des centaines et des centaines de personnes.

217
0:12:31.16,000 --> 0:12:34,000
Parce que mon état de transe urbaine avait été, d’une certaine manière, atténué,

218
0:12:35.16,000 --> 0:12:38,000
je me trouvé en train de m’arrêter pour voir ce qui n’allait pas.

219
0:12:39.16,000 --> 0:12:41,000
Au moment où je me suis arrêté, une demi-douzaine d’autres personnes

220
0:12:42.16,000 --> 0:12:43,000
ont immédiatement entouré ce même type.

221
0:12:44.16,000 --> 0:12:46,000
Nous avons découvert qu’il était hispanique, qu’il ne parlait pas anglais,

222
0:12:46.16,000 --> 0:12:51,000
n’avait pas d’argent, il errait dans la rue depuis des jours, affamé,

223
0:12:51.16,000 --> 0:12:52,000
et s’était évanoui d’inanition.

224
0:12:52.16,000 --> 0:12:54,000
Immédiatement quelqu’un est allé lui chercher du jus d’orange,

225
0:12:54.16,000 --> 0:12:56,000
quelqu’un a apporté un hot-dog, quelqu’un a cherché la police du métro.

226
0:12:57.16,000 --> 0:13:,000
Ce type a été remis sur pied immédiatement.

227
0:13:00.16,000 --> 0:13:04,000
Tout ce qu’il a fallu, c’est tout simplement l’acte de voir.

228
0:13:05.16,000 --> 0:13:06,000
Et donc, je suis optimiste.

229
0:13:06.16,000 --> 0:13:07,000
Merci beaucoup

230
0:13:07.16,000 --> 0:13:09,000
Applaudissements

