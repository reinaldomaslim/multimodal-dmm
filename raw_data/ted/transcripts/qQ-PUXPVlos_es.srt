1
0:00:,000 --> 0:00:07,000
Traductor: Antonia Varo Garrido Revisor: Ciro Gomez

2
0:00:12.944,000 --> 0:00:16,000
En los 80 di mi primera charla en TED,

3
0:00:16.977,000 --> 0:00:2,000
y traje una de las primeras demostraciones públicas

4
0:00:21.263,000 --> 0:00:25,000
de realidad virtual vistas en este escenario.

5
0:00:26.375,000 --> 0:00:28,000
En ese momento, sabíamos

6
0:00:29.286,000 --> 0:00:32,000
que nos enfrentábamos a un futuro que era un arma de doble filo

7
0:00:33.266,000 --> 0:00:38,000
en el que la tecnología que necesitábamos,

8
0:00:38.491,000 --> 0:00:39,000
la tecnología que amábamos,

9
0:00:40.366,000 --> 0:00:42,000
podía ser también nuestra perdición.

10
0:00:43.266,000 --> 0:00:47,000
Sabíamos que si pensábamos en nuestra tecnología

11
0:00:47.381,000 --> 0:00:5,000
como un medio para tener más poder,

12
0:00:50.479,000 --> 0:00:53,000
que si era solo un viaje de poder, al final nos destruiríamos a nosotros mismos.

13
0:00:54.39,000 --> 0:00:55,000
Eso es lo que ocurre

14
0:00:55.595,000 --> 0:00:57,000
cuando están en una lucha de poder y nada más.

15
0:00:59.509,000 --> 0:01:02,000
Así que el idealismo

16
0:01:02.922,000 --> 0:01:06,000
de la cultura digital de entonces

17
0:01:07.755,000 --> 0:01:11,000
era comenzar reconociendo esa posible oscuridad

18
0:01:12.518,000 --> 0:01:15,000
e intentar imaginar una forma de superarla

19
0:01:15.892,000 --> 0:01:17,000
con belleza y creatividad.

20
0:01:19.033,000 --> 0:01:25,000
Solía acabar mis primeras charlas TED con una línea bastante espeluznante:

21
0:01:26.478,000 --> 0:01:29,000
"Tenemos un desafío.

22
0:01:30.368,000 --> 0:01:34,000
Tenemos que crear una cultura tecnológica

23
0:01:34.416,000 --> 0:01:37,000
que sea tan bella, tan significativa,

24
0:01:38.408,000 --> 0:01:4,000
tan profunda, tan infinitamente creativa,

25
0:01:40.973,000 --> 0:01:43,000
provista de un potencial tan infinito

26
0:01:44.013,000 --> 0:01:47,000
que nos aleje de cometer suicidio en masa".

27
0:01:48.519,000 --> 0:01:51,000
Así que hablábamos de la extinción

28
0:01:52.247,000 --> 0:01:55,000
considerándola lo mismo que la necesidad de crear

29
0:01:55.607,000 --> 0:01:58,000
un futuro atractivo, infinitamente creativo.

30
0:01:59.639,000 --> 0:02:04,000
Y todavía creo que la alternativa de la creatividad

31
0:02:05.045,000 --> 0:02:06,000
como alternativa a la muerte

32
0:02:07.043,000 --> 0:02:08,000
es muy real y auténtica,

33
0:02:09.036,000 --> 0:02:1,000
quizás lo más real que haya.

34
0:02:11.87,000 --> 0:02:13,000
En el caso de la realidad virtual...

35
0:02:13.989,000 --> 0:02:15,000
bueno, yo solía hablar de ella

36
0:02:16.295,000 --> 0:02:18,000
como algo parecido

37
0:02:18.954,000 --> 0:02:2,000
a lo que ocurrió cuando la gente descubrió el lenguaje.

38
0:02:21.828,000 --> 0:02:25,000
Con el lenguaje venían nuevas aventuras, nueva profundidad, nuevos significados,

39
0:02:26.447,000 --> 0:02:28,000
nuevas formas de conectar, de coordinar,

40
0:02:28.771,000 --> 0:02:31,000
nuevas formas de imaginar, nuevas formas de educar a los niños,

41
0:02:32.689,000 --> 0:02:36,000
e imaginaba que con la realidad virtual, habíamos conseguido algo nuevo

42
0:02:36.975,000 --> 0:02:37,000
que sería como una conversación,

43
0:02:38.592,000 --> 0:02:41,000
pero también como despertar de un estado de sueño intencional.

44
0:02:41.96,000 --> 0:02:43,000
Lo llamamos comunicación postsimbólica,

45
0:02:44.637,000 --> 0:02:48,000
porque sería como hacer directamente las cosas que experimentan

46
0:02:49.019,000 --> 0:02:52,000
en vez de hacer indirectamente símbolos para referirse a esas cosas.

47
0:02:53.466,000 --> 0:02:57,000
Era una hermosa visión, y todavía creo en ella,

48
0:02:57.828,000 --> 0:03:,000
y aunque tras esa bella visión

49
0:03:01.067,000 --> 0:03:04,000
también estaba el lado oscuro que podría surgir.

50
0:03:04.241,000 --> 0:03:09,000
Supongo que podría mencionar

51
0:03:09.313,000 --> 0:03:12,000
a uno de los primeros científicos informáticos

52
0:03:12.401,000 --> 0:03:14,000
cuyo nombre era Norbert Wiener,

53
0:03:14.56,000 --> 0:03:17,000
que escribió un libro en los años 50, antes incluso de que yo naciera,

54
0:03:18.338,000 --> 0:03:2,000
llamado "El uso humano de los humanos".

55
0:03:21.779,000 --> 0:03:25,000
En el libro, él describía el potencial

56
0:03:25.975,000 --> 0:03:31,000
para crear una computadora que iría recopilando datos de la gente

57
0:03:32.18,000 --> 0:03:35,000
y proporcionando valoraciones a esas personas en tiempo real

58
0:03:35.776,000 --> 0:03:4,000
para ponerlos parcialmente, estadísticamente, en una caja de Skinner,

59
0:03:40.935,000 --> 0:03:42,000
en un sistema conductista.

60
0:03:43.403,000 --> 0:03:45,000
Y tiene esta increíble línea que dice,

61
0:03:45.928,000 --> 0:03:47,000
uno podría imaginar, como un experimento mental,

62
0:03:48.69,000 --> 0:03:5,000
—estoy parafraseando esto no es una cita—

63
0:03:51.175,000 --> 0:03:54,000
uno podría imaginar un sistema informático global

64
0:03:54.279,000 --> 0:03:56,000
en que todos tengan dispositivos todo el tiempo,

65
0:03:57.125,000 --> 0:04:,000
y los dispositivos les va dando valoraciones basadas en lo que hicieron,

66
0:04:00.551,000 --> 0:04:01,000
y toda la población

67
0:04:02.34,000 --> 0:04:05,000
está sujeta a un grado de modificación de conducta.

68
0:04:05.94,000 --> 0:04:08,000
Y tal sociedad estaría demente,

69
0:04:09.51,000 --> 0:04:12,000
no podría sobrevivir, no podría enfrentar sus problemas.

70
0:04:12.631,000 --> 0:04:14,000
Y luego dice, pero esto es solo un experimento mental,

71
0:04:15.276,000 --> 0:04:18,000
y tal futuro es tecnológicamente inviable.

72
0:04:18.72,000 --> 0:04:19,000
(Risas)

73
0:04:19.836,000 --> 0:04:22,000
Y, sin embargo, por supuesto, esto es lo que hemos creado,

74
0:04:22.862,000 --> 0:04:25,000
y es lo que debemos deshacer si queremos sobrevivir.

75
0:04:27.457,000 --> 0:04:28,000
Así que...

76
0:04:28.632,000 --> 0:04:31,000
(Aplausos)

77
0:04:32.631,000 --> 0:04:37,000
Creo que cometimos un error muy particular,

78
0:04:38.632,000 --> 0:04:4,000
y esto sucedió al principio,

79
0:04:40.89,000 --> 0:04:42,000
y si entendemos el error que cometimos,

80
0:04:42.988,000 --> 0:04:43,000
podemos deshacerlo.

81
0:04:44.871,000 --> 0:04:46,000
Esto sucedió en los años 90,

82
0:04:47.454,000 --> 0:04:49,000
y casi cambiando de siglo,

83
0:04:50.22,000 --> 0:04:51,000
y aquí tienen lo que ocurrió.

84
0:04:53.2,000 --> 0:04:54,000
La antigua cultura digital

85
0:04:54.598,000 --> 0:04:58,000
y, de hecho, la cultura digital hasta nuestros días,

86
0:04:59.594,000 --> 0:05:05,000
tenía un sentido de, yo diría, misión socialista izquierdista,

87
0:05:05.927,000 --> 0:05:07,000
que a diferencia de otras cosas que se han hecho,

88
0:05:08.241,000 --> 0:05:09,000
como la invención de los libros,

89
0:05:09.829,000 --> 0:05:12,000
todo en internet debe ser puramente público,

90
0:05:13.006,000 --> 0:05:15,000
debe estar disponible de forma gratuita,

91
0:05:15.355,000 --> 0:05:18,000
porque aunque solo una persona no pueda permitírselo,

92
0:05:18.767,000 --> 0:05:2,000
se crearía esta terrible injusticia.

93
0:05:21.792,000 --> 0:05:23,000
Por supuesto ahora, hay otras formas de lidiar con eso.

94
0:05:24.46,000 --> 0:05:27,000
Si los libros cuestan dinero, pueden tener bibliotecas públicas.

95
0:05:27.5,000 --> 0:05:28,000
Etcétera.

96
0:05:28.548,000 --> 0:05:3,000
Pero estábamos pensando, no, no, no, esta es una excepción.

97
0:05:31.356,000 --> 0:05:35,000
Esto debe ser puro patrimonio público, eso es lo que queremos.

98
0:05:35.969,000 --> 0:05:37,000
Y para que ese espíritu siga vivo.

99
0:05:38.627,000 --> 0:05:41,000
Puedan experimentarlo en diseños como la Wikipedia, por ejemplo,

100
0:05:42.366,000 --> 0:05:43,000
muchos otros.

101
0:05:43.731,000 --> 0:05:44,000
Pero al mismo tiempo,

102
0:05:45.629,000 --> 0:05:47,000
también creímos, con igual fervor,

103
0:05:48.241,000 --> 0:05:51,000
en esta otra cosa que era completamente incompatible,

104
0:05:52.202,000 --> 0:05:55,000
que es que nos encantan nuestros empresarios tecnológicos.

105
0:05:55.853,000 --> 0:05:58,000
Nos encantaba Steve Jobs; amábamos este mito nietzscheano

106
0:05:59.616,000 --> 0:06:02,000
del técnico que podría mellar el universo.

107
0:06:03.108,000 --> 0:06:04,000
¿Correcto?

108
0:06:04.45,000 --> 0:06:09,000
Y ese poder mítico todavía nos domina, también.

109
0:06:10.322,000 --> 0:06:14,000
Entonces tienen estas dos pasiones diferentes,

110
0:06:14.805,000 --> 0:06:15,000
por hacerlo todo gratis

111
0:06:16.766,000 --> 0:06:21,000
y por ese poder casi sobrenatural del emprendedor tecnológico.

112
0:06:21.956,000 --> 0:06:25,000
¿Cómo celebran el espíritu empresarial cuando todo es gratis?

113
0:06:26.332,000 --> 0:06:29,000
Bueno, solo había una solución en ese momento,

114
0:06:29.481,000 --> 0:06:31,000
que era el modelo publicitario.

115
0:06:31.592,000 --> 0:06:35,000
Y así pues, nació Google gratis, con anuncios,

116
0:06:35.619,000 --> 0:06:38,000
nació Facebook gratis, con anuncios.

117
0:06:39.325,000 --> 0:06:42,000
Ahora, al principio, era adorable,

118
0:06:43.214,000 --> 0:06:44,000
como con los primeros Google.

119
0:06:45.198,000 --> 0:06:46,000
(Risas)

120
0:06:46.508,000 --> 0:06:48,000
Realmente eran pocos anuncios.

121
0:06:49.429,000 --> 0:06:51,000
Serían, como, su dentista local o algo así.

122
0:06:51.938,000 --> 0:06:52,000
Pero hay una cosa llamada ley de Moore

123
0:06:53.882,000 --> 0:06:56,000
que hace las computadoras cada vez más eficientes y más baratos.

124
0:06:57.048,000 --> 0:06:58,000
Sus algoritmos mejoran.

125
0:06:58.86,000 --> 0:07:,000
De hecho, tenemos universidades donde la gente los estudian,

126
0:07:01.696,000 --> 0:07:02,000
y los hacen cada vez mejores.

127
0:07:03.202,000 --> 0:07:07,000
Y los clientes y otras entidades que usan estos sistemas

128
0:07:07.678,000 --> 0:07:11,000
se vuelven cada vez más experimentados y cada vez más inteligentes.

129
0:07:11.829,000 --> 0:07:13,000
Y lo que comenzó como publicidad

130
0:07:14.25,000 --> 0:07:16,000
realmente no se puede llamar más publicidad.

131
0:07:16.751,000 --> 0:07:18,000
Se convirtió en modificación de la conducta,

132
0:07:19.687,000 --> 0:07:24,000
lo que a Norbert Wiener le preocupaba que podría ocurrir.

133
0:07:24.784,000 --> 0:07:28,000
Y ya no puedo llamar más a estas cosas redes sociales.

134
0:07:28.848,000 --> 0:07:31,000
Los llamo imperios de modificación de conducta.

135
0:07:32.686,000 --> 0:07:34,000
(Aplausos)

136
0:07:34.945,000 --> 0:07:38,000
Y me niego a vilipendiar a las personas.

137
0:07:39.183,000 --> 0:07:41,000
Tengo amigos queridos en estas compañías,

138
0:07:41.478,000 --> 0:07:45,000
vendí una compañía a Google, aunque creo que es uno de estos imperios.

139
0:07:46.262,000 --> 0:07:51,000
No creo que esto sea cuestión de malas personas que han hecho algo malo.

140
0:07:51.346,000 --> 0:07:55,000
Creo que esto es una cuestión de error globalmente trágico,

141
0:07:55.946,000 --> 0:07:59,000
y asombrosamente ridículo,

142
0:08:00.542,000 --> 0:08:04,000
más que una ola de maldad.

143
0:08:04.695,000 --> 0:08:06,000
Permítanme darles solo otra capa de detalles

144
0:08:07.401,000 --> 0:08:1,000
sobre cómo funciona este particular error.

145
0:08:11.337,000 --> 0:08:13,000
Entonces con el conductismo,

146
0:08:14.068,000 --> 0:08:19,000
le dan a la criatura, ya sea una rata, un perro o una persona,

147
0:08:19.156,000 --> 0:08:21,000
pequeños premios y a veces pequeños castigos

148
0:08:22.02,000 --> 0:08:23,000
como respuesta a lo que hacen.

149
0:08:24.71,000 --> 0:08:29,000
Así, si tienen un animal en una jaula, podrían ser dulces y descargas eléctricas.

150
0:08:30.646,000 --> 0:08:32,000
Pero si tienen un teléfono inteligente,

151
0:08:33.194,000 --> 0:08:39,000
no son esas cosas, son castigos y recompensas simbólicas.

152
0:08:40.144,000 --> 0:08:42,000
Pavlov, uno de los primeros conductistas,

153
0:08:42.611,000 --> 0:08:44,000
demostró el famoso principio.

154
0:08:45.587,000 --> 0:08:48,000
Uds. podrían entrenar a un perro a salivar solo con la campana, solo con el símbolo.

155
0:08:49.572,000 --> 0:08:5,000
Así en las redes sociales,

156
0:08:51.182,000 --> 0:08:56,000
el castigo social y la recompensa social funcionan como castigos y recompensas.

157
0:08:56.286,000 --> 0:08:58,000
Y todos sabemos lo que provocan estas cosas.

158
0:08:58.387,000 --> 0:09:01,000
Consiguen esta emoción: "Oh, mis cosas gustaron y las están repitiendo".

159
0:09:02.066,000 --> 0:09:06,000
O el castigo: "Oh, Dios mío, no gusto, hay alguien más popular, oh Dios mío".

160
0:09:06.373,000 --> 0:09:08,000
Entonces tienen esos dos sentimientos muy comunes,

161
0:09:09.107,000 --> 0:09:12,000
y están repartidos de tal manera que les atrapan en este ciclo.

162
0:09:12.695,000 --> 0:09:16,000
Como se ha reconocido públicamente por muchos de los fundadores del sistema,

163
0:09:16.814,000 --> 0:09:18,000
todos sabían que esto era lo que estaba pasando.

164
0:09:19.871,000 --> 0:09:2,000
Pero la cuestión es esta:

165
0:09:21.514,000 --> 0:09:26,000
tradicionalmente, en el estudio académico de los métodos del conductismo,

166
0:09:26.832,000 --> 0:09:31,000
se han hecho comparaciones de los estímulos positivos y negativos.

167
0:09:32.292,000 --> 0:09:35,000
En este contexto, un contexto comercial, hay un nuevo tipo de diferencia

168
0:09:36.076,000 --> 0:09:39,000
que por un tiempo ha sido un poco evadido por el mundo académico,

169
0:09:39.219,000 --> 0:09:42,000
y esa diferencia es que si bien los estímulos positivos

170
0:09:43.165,000 --> 0:09:46,000
en diferentes circunstancias son más efectivos que los negativos,

171
0:09:46.498,000 --> 0:09:48,000
los negativos son más baratos.

172
0:09:48.626,000 --> 0:09:5,000
Son los estímulos de oferta.

173
0:09:50.706,000 --> 0:09:55,000
Por tanto, lo que quiero decir es que es mucho más fácil

174
0:09:56.433,000 --> 0:09:59,000
perder la confianza que construir confianza.

175
0:09:59.573,000 --> 0:10:02,000
Lleva mucho tiempo construir amor.

176
0:10:02.769,000 --> 0:10:04,000
Lleva poco tiempo arruinar el amor.

177
0:10:05.399,000 --> 0:10:09,000
Ahora los clientes de estos imperios de modificación de conducta

178
0:10:10.011,000 --> 0:10:11,000
están en un bucle muy rápido.

179
0:10:11.448,000 --> 0:10:13,000
Son casi como comerciantes de alta frecuencia.

180
0:10:13.617,000 --> 0:10:14,000
Están recibiendo datos de sus gastos

181
0:10:15.605,000 --> 0:10:18,000
o de cualesquiera que sean sus actividades si no están gastando,

182
0:10:18.657,000 --> 0:10:21,000
y ven lo que funciona, y luego hacen más de eso.

183
0:10:21.695,000 --> 0:10:23,000
Y así están obteniendo esa respuesta rápida,

184
0:10:23.799,000 --> 0:10:26,000
es decir están respondiendo más a las emociones negativas,

185
0:10:26.859,000 --> 0:10:29,000
porque son las que que suben más rápidas, ¿verdad?

186
0:10:30.784,000 --> 0:10:33,000
Y por esto, incluso los jugadores bien intencionados

187
0:10:34.306,000 --> 0:10:37,000
que piensan que lo que están haciendo es anunciar pasta de dientes

188
0:10:37.421,000 --> 0:10:39,000
terminan fomentando la causa de las personas negativas,

189
0:10:40.3,000 --> 0:10:42,000
las emociones negativas, los excéntricos,

190
0:10:42.658,000 --> 0:10:43,000
los paranoicos,

191
0:10:44.126,000 --> 0:10:47,000
los cínicos, los nihilistas.

192
0:10:47.23,000 --> 0:10:5,000
Esos son los que se amplifican con el sistema.

193
0:10:50.747,000 --> 0:10:53,000
Y no pueden pagar a una de estas compañías

194
0:10:54.552,000 --> 0:10:57,000
para hacer que el mundo de pronto sea agradable y mejore la democracia

195
0:10:57.873,000 --> 0:11:,000
tan fácilmente como pueden casi pagar para arruinar esas cosas

196
0:11:01.462,000 --> 0:11:04,000
Y este es el dilema en el que nos hemos metido.

197
0:11:05.856,000 --> 0:11:1,000
La alternativa es hacer retroceder el reloj, con gran dificultad,

198
0:11:11.112,000 --> 0:11:13,000
y rehacer esa decisión.

199
0:11:13.977,000 --> 0:11:17,000
Rehacerlo significaría dos cosas.

200
0:11:18.039,000 --> 0:11:21,000
Significaría primero que muchas personas, esas que podrían pagarlo,

201
0:11:21.991,000 --> 0:11:23,000
de hecho pagarían, por estas cosas.

202
0:11:24.222,000 --> 0:11:28,000
Uds. pagarían por la búsqueda, pagarían por las redes sociales.

203
0:11:28.653,000 --> 0:11:31,000
¿Cómo pagarían? Tal vez con una tarifa de suscripción,

204
0:11:32.138,000 --> 0:11:34,000
tal vez con micropagos mientras las usan.

205
0:11:34.9,000 --> 0:11:35,000
Hay muchas opciones.

206
0:11:36.726,000 --> 0:11:38,000
Si algunos de Uds. rebufan, y están pensando,

207
0:11:39.147,000 --> 0:11:41,000
"Oh Dios mío, yo nunca pagaría por estas cosas.

208
0:11:41.537,000 --> 0:11:43,000
¿Cómo podrían conseguir que alguien pague?

209
0:11:43.656,000 --> 0:11:46,000
Quiero recordarles algo que acaba de ocurrir.

210
0:11:46.919,000 --> 0:11:48,000
En esos mismos momentos

211
0:11:48.997,000 --> 0:11:53,000
que empresas como Google y Facebook estaban formulando su idea libre,

212
0:11:54.728,000 --> 0:11:58,000
mucha cultura cibernética también creía que en el futuro,

213
0:11:59.256,000 --> 0:12:02,000
las televisiones y las películas se crearían de la misma manera,

214
0:12:02.302,000 --> 0:12:03,000
algo así como la Wikipedia.

215
0:12:04.456,000 --> 0:12:09,000
Pero entonces, las empresas como Netflix, Amazon, HBO, dijeron:

216
0:12:09.784,000 --> 0:12:12,000
"En realidad, ya saben, suscríbanse. Le daremos una buena TV".

217
0:12:13.307,000 --> 0:12:14,000
¡Y funcionó!

218
0:12:14.704,000 --> 0:12:17,000
Ahora estamos en este período llamado "el pico televisivo", ¿verdad?

219
0:12:18.604,000 --> 0:12:21,000
Así que, a veces cuando pagan por cosas, estas mejoran.

220
0:12:22.894,000 --> 0:12:24,000
Podemos imaginar un hipotético...

221
0:12:24.919,000 --> 0:12:28,000
(Aplausos)

222
0:12:29.922,000 --> 0:12:32,000
Podemos imaginar un mundo hipotético de "el pico de los medios sociales".

223
0:12:33.585,000 --> 0:12:34,000
¿Cómo seria?

224
0:12:34.759,000 --> 0:12:35,000
Significaría que cuando los usen,

225
0:12:36.364,000 --> 0:12:39,000
Uds. pueden conseguir consejos, médicos acreditados realmente útiles

226
0:12:39.573,000 --> 0:12:4,000
en vez de chiflados.

227
0:12:40.957,000 --> 0:12:43,000
Podría significar que si quieren obtener información objetiva,

228
0:12:44.365,000 --> 0:12:47,000
no hay miles de teorías de conspiración paranoicas y raras.

229
0:12:47.754,000 --> 0:12:5,000
Podemos imaginarnos esta otra maravillosa posibilidad.

230
0:12:52.149,000 --> 0:12:52,000
Ah.

231
0:12:53.183,000 --> 0:12:55,000
Sueño con eso. Creo que es posible.

232
0:12:55.469,000 --> 0:12:57,000
Estoy seguro de que es posible.

233
0:12:57.92,000 --> 0:13:02,000
Y estoy seguro de que las empresas, los Googles y los Facebook,

234
0:13:03.516,000 --> 0:13:05,000
de verdad lo harían mejor en este mundo.

235
0:13:06.076,000 --> 0:13:08,000
No creo que necesitemos castigar a Silicon Valley.

236
0:13:09.012,000 --> 0:13:11,000
Solo tenemos que rehacer la decisión.

237
0:13:12.718,000 --> 0:13:15,000
De las grandes compañías tecnológicas, en realidad son solo dos

238
0:13:15.895,000 --> 0:13:19,000
las que dependen de la modificación de la conducta y el espionaje

239
0:13:19.986,000 --> 0:13:2,000
como plan de negocios.

240
0:13:21.186,000 --> 0:13:22,000
Son Google y Facebook.

241
0:13:22.823,000 --> 0:13:23,000
(Risas)

242
0:13:24.568,000 --> 0:13:26,000
Y los amo chicos. De verdad.

243
0:13:27.391,000 --> 0:13:29,000
Al igual que la gente son fantásticas.

244
0:13:30.187,000 --> 0:13:34,000
Quiero señalar, si puedo, si miran a Google,

245
0:13:34.743,000 --> 0:13:39,000
ellos pueden propagar centros de costos infinitamente con todas estas empresas,

246
0:13:39.785,000 --> 0:13:41,000
pero no pueden propagar centros de beneficios.

247
0:13:42.11,000 --> 0:13:44,000
No pueden diversificarse, porque están enganchados.

248
0:13:44.851,000 --> 0:13:47,000
Están enganchados a este modelo, al igual que sus propios usuarios.

249
0:13:48.013,000 --> 0:13:5,000
Están en la misma trampa que sus usuarios,

250
0:13:50.041,000 --> 0:13:52,000
y no pueden llevar una gran corporación de esa manera.

251
0:13:52.628,000 --> 0:13:55,000
Así que esto es básica y totalmente en beneficio de los accionistas

252
0:13:56.217,000 --> 0:13:58,000
y todos los interesados en estas empresas.

253
0:13:58.791,000 --> 0:14:02,000
Es una solución beneficiosa para todos. Solo tomará algo de tiempo averiguarlo.

254
0:14:03.436,000 --> 0:14:05,000
Un montón de detalles que resolver,

255
0:14:05.96,000 --> 0:14:06,000
totalmente factibles.

256
0:14:07.429,000 --> 0:14:09,000
(Risas)

257
0:14:10.147,000 --> 0:14:14,000
No creo que nuestra especie pueda sobrevivir si no solucionamos esto.

258
0:14:14.221,000 --> 0:14:15,000
No podemos tener una sociedad

259
0:14:16.166,000 --> 0:14:19,000
en la que, si dos personas desean comunicarse,

260
0:14:19.48,000 --> 0:14:22,000
la única forma de hacerlo sea siendo financiada por una tercera persona

261
0:14:22.89,000 --> 0:14:23,000
que desea manipularlas.

262
0:14:24.847,000 --> 0:14:25,000
(Aplausos)

263
0:14:35.182,000 --> 0:14:36,000
(El aplauso termina)

264
0:14:36.797,000 --> 0:14:39,000
Mientras tanto, si las compañías no cambiasen,

265
0:14:39.951,000 --> 0:14:41,000
borren sus cuentas, ¿de acuerdo?

266
0:14:41.984,000 --> 0:14:41,000
(Risas)

267
0:14:42.814,000 --> 0:14:43,000
(Aplausos)

268
0:14:43.977,000 --> 0:14:44,000
Es suficiente por ahora.

269
0:14:45.472,000 --> 0:14:46,000
Muchas gracias.

270
0:14:46.676,000 --> 0:14:52,000
(Aplausos)

