1
0:00:,000 --> 0:00:07,000
Traducteur: assia elaouam Relecteur: Joel Bomane

2
0:00:12.56,000 --> 0:00:13,000
Que vous le vouliez ou pas,

3
0:00:13.945,000 --> 0:00:18,000
transparence radicale et algorithmes de prise de décision arrivent rapidement,

4
0:00:19.316,000 --> 0:00:2,000
et cela va changer votre vie.

5
0:00:21.317,000 --> 0:00:23,000
C'est parce qu'il est facile de prendre des algorithmes,

6
0:00:24.16,000 --> 0:00:25,000
de les intégrer dans des ordinateurs,

7
0:00:26.08,000 --> 0:00:28,000
de recueillir toutes ces données que vous laissez sur vous

8
0:00:29.04,000 --> 0:00:3,000
un peu partout,

9
0:00:30.44,000 --> 0:00:31,000
d'identifier vos préférences,

10
0:00:32.09,000 --> 0:00:34,000
et de faire interagir les ordinateurs avec vous

11
0:00:34.666,000 --> 0:00:37,000
mieux que la plupart des gens.

12
0:00:37.98,000 --> 0:00:38,000
Bien sûr, cela peut paraître effrayant.

13
0:00:39.86,000 --> 0:00:42,000
Je fais ça depuis longtemps et je trouve ça merveilleux.

14
0:00:44.159,000 --> 0:00:46,000
Mon objectif a été d'avoir un travail stimulant,

15
0:00:46.55,000 --> 0:00:49,000
des relations enrichissantes au travail,

16
0:00:49.79,000 --> 0:00:51,000
et je ne pouvais pas y arriver

17
0:00:51.81,000 --> 0:00:55,000
sans une transparence radicale et les algorithmes de prise de décision.

18
0:00:56.68,000 --> 0:00:58,000
Je veux vous expliquer pourquoi,

19
0:00:58.72,000 --> 0:00:59,000
je veux vous montrer comment ça marche.

20
0:01:00.586,000 --> 0:01:03,000
Et je vous préviens que certaines choses que je vais vous montrer

21
0:01:03.686,000 --> 0:01:04,000
sont probablement un peu choquantes.

22
0:01:05.76,000 --> 0:01:08,000
Depuis mon enfance, j'ai une mauvaise mémoire mécanique

23
0:01:10.12,000 --> 0:01:12,000
et je n'aimais pas suivre les instructions,

24
0:01:12.32,000 --> 0:01:14,000
je n'étais pas doué pour ça.

25
0:01:14.76,000 --> 0:01:17,000
Mais plus interessé par le pourquoi et le comment des choses.

26
0:01:18.49,000 --> 0:01:2,000
A l'âge de 12 ans, je détestais l'école,

27
0:01:20.576,000 --> 0:01:22,000
mais je suis tombé amoureux des marchés boursiers.

28
0:01:23.92,000 --> 0:01:24,000
J'étais un caddie à l'époque,

29
0:01:25.6,000 --> 0:01:27,000
je gagnais environ cinq dollars par joueur,

30
0:01:27.686,000 --> 0:01:3,000
et je prenais l'argent gagné ainsi, et je le jouais en Bourse.

31
0:01:31.24,000 --> 0:01:34,000
Car le marché boursier était dans le vent.

32
0:01:34.64,000 --> 0:01:35,000
Et la première société achetée

33
0:01:36.456,000 --> 0:01:38,000
fut une société du nom de Northeast Airlines.

34
0:01:39.36,000 --> 0:01:42,000
Northeast Airlines, la seule société dont j'avais entendu parler

35
0:01:42.506,000 --> 0:01:44,000
qui était à moins de 5 dollars l'action.

36
0:01:45.066,000 --> 0:01:46,000
(Rires)

37
0:01:46.7,000 --> 0:01:48,000
Je me suis dit : « Achète plus d'actions,

38
0:01:49.066,000 --> 0:01:51,000
si elles grimpent, tu gagneras plus d'argent. »

39
0:01:51.256,000 --> 0:01:53,000
Au final, c'était une stratégie stupide, non ?

40
0:01:54.36,000 --> 0:01:55,000
Mais j'ai triplé mes gains,

41
0:01:55.82,000 --> 0:01:57,000
et j'ai triplé mes gains parce que j'ai eu de la chance.

42
0:01:58.56,000 --> 0:02:,000
La compagnie était en train de faire faillite,

43
0:02:00.846,000 --> 0:02:01,000
mais a été rachetée par une autre,

44
0:02:02.486,000 --> 0:02:03,000
et j'ai triplé mes gains.

45
0:02:03.96,000 --> 0:02:04,000
Et j'ai été séduit.

46
0:02:05.72,000 --> 0:02:07,000
Je me suis dit : « Ce jeu est facile ! »

47
0:02:09.2,000 --> 0:02:1,000
Au fil du temps,

48
0:02:10.44,000 --> 0:02:12,000
j'ai appris que ce jeu est tout sauf facile.

49
0:02:12.88,000 --> 0:02:14,000
Afin d'être un vrai investisseur,

50
0:02:15.04,000 --> 0:02:17,000
il faut parier contre l'avis général

51
0:02:17.96,000 --> 0:02:18,000
et avoir raison.

52
0:02:19.216,000 --> 0:02:22,000
Ce n'est pas facile de parier contre la majorité et avoir raison.

53
0:02:22.346,000 --> 0:02:24,000
Il faut parier contre la majorité et avoir raison,

54
0:02:24.766,000 --> 0:02:26,000
car le consensus fait partie intégrante du prix.

55
0:02:28.12,000 --> 0:02:3,000
Et pour être un entrepreneur,

56
0:02:30.6,000 --> 0:02:31,000
un entrepreneur prospère,

57
0:02:32.24,000 --> 0:02:35,000
if faut parier contre le consensus et avoir raison.

58
0:02:37.4,000 --> 0:02:39,000
J'ai dû être à la fois un entrepreneur et un investisseur...

59
0:02:40.36,000 --> 0:02:44,000
Et ce qui vient avec le territoire, ce sont les multiples erreurs pénibles.

60
0:02:45.44,000 --> 0:02:47,000
Donc j'ai eu de nombreuses expériences douloureuses,

61
0:02:48.28,000 --> 0:02:49,000
et au fil du temps,

62
0:02:49.56,000 --> 0:02:51,000
mon attitude face à ces erreurs a commencé à changer.

63
0:02:52.97,000 --> 0:02:54,000
J'ai commencé à les considérer comme des puzzles.

64
0:02:55.356,000 --> 0:02:56,000
Si je pouvais résoudre ces puzzles,

65
0:02:57.24,000 --> 0:02:58,000
j'en ferais des perles.

66
0:02:59.16,000 --> 0:03:,000
Et les puzzles étaient :

67
0:03:00.306,000 --> 0:03:04,000
que faire à l'avenir afin de ne pas reproduire ces douloureuses expériences ?

68
0:03:05.28,000 --> 0:03:07,000
Et ces perles étaient des principes,

69
0:03:07.88,000 --> 0:03:09,000
que j'écrivais afin de m'en souvenir,

70
0:03:10.64,000 --> 0:03:11,000
et qui pourraient m'aider dans le futur.

71
0:03:13,000 --> 0:03:15,000
Et c'est parce que je les avaient écrites avec clarté,

72
0:03:15.72,000 --> 0:03:16,000
j'ai pu alors

73
0:03:17.08,000 --> 0:03:18,000
découvrir dans la foulée

74
0:03:18.68,000 --> 0:03:21,000
que je pouvais intégrer ces principes dans des algorithmes,

75
0:03:23.4,000 --> 0:03:26,000
et ces algorithmes seraient intégrés dans les ordinateurs,

76
0:03:26.88,000 --> 0:03:29,000
et les ordinateurs prendraient des décisions avec moi ;

77
0:03:30.24,000 --> 0:03:33,000
et donc prendre ces décisions parallèlement.

78
0:03:33.4,000 --> 0:03:36,000
Et je pouvais comparer ces décisions avec mes propres décisions,

79
0:03:37.4,000 --> 0:03:39,000
et ces décisions étaient en fait bien meilleures.

80
0:03:40.24,000 --> 0:03:42,000
L'ordinateur pouvait prendre des décisions

81
0:03:43.14,000 --> 0:03:45,000
en traitant bien plus de données,

82
0:03:45.67,000 --> 0:03:46,000
en le faisait bien plus rapidement,

83
0:03:47.726,000 --> 0:03:52,000
et sans l'interférence des émotions.

84
0:03:55.313,000 --> 0:03:58,000
Cela a radicalement amélioré mes prises de décisions.

85
0:04:00.4,000 --> 0:04:05,000
Huit ans après avoir créé Bridgewater,

86
0:04:05.466,000 --> 0:04:06,000
j'ai subi mon plus grand échec,

87
0:04:07.303,000 --> 0:04:08,000
et fait ma plus grande erreur.

88
0:04:09.51,000 --> 0:04:11,000
C'était à la fin des années 70.

89
0:04:11.84,000 --> 0:04:12,000
J'avais 34 ans.

90
0:04:13.84,000 --> 0:04:16,000
Et j'avais calculé que les banques américaines

91
0:04:17.52,000 --> 0:04:19,000
avaient prêté beaucoup trop d'argent aux pays émergents,

92
0:04:20.4,000 --> 0:04:22,000
et que ces pays ne seraient pas en mesure de rembourser.

93
0:04:23.24,000 --> 0:04:25,000
Et que nous aurions la pire crise de la dette

94
0:04:25.96,000 --> 0:04:26,000
depuis la Grande Dépression.

95
0:04:28.2,000 --> 0:04:3,000
Et de plus, une crise économique

96
0:04:30.44,000 --> 0:04:32,000
et un énorme marché baissier.

97
0:04:33.59,000 --> 0:04:35,000
C'était une vision controversée à l'époque.

98
0:04:36.16,000 --> 0:04:38,000
D'aucuns pensaient que cette opinion était un peu folle.

99
0:04:39.48,000 --> 0:04:41,000
Mais en août 1982,

100
0:04:41.72,000 --> 0:04:43,000
le Mexique a été en défaut de paiement,

101
0:04:44.52,000 --> 0:04:46,000
et plusieurs autres pays ont suivi.

102
0:04:46.8,000 --> 0:04:49,000
Et on a eu la plus grande crise de la dette depuis la Grande Dépression.

103
0:04:51.08,000 --> 0:04:53,000
Étant donné que je l'avais prévu,

104
0:04:53.88,000 --> 0:04:55,000
j'avais témoigné devant le Congrès, et « Wall Street Week »

105
0:05:00.326,000 --> 0:05:03,000
Juste pour vous donner une idée, j'ai un clip vidéo,

106
0:05:03.546,000 --> 0:05:05,000
et vous me verrez dedans.

107
0:05:05.827,000 --> 0:05:06,000
(Vidéo) M. le Président, M. Mitchell,

108
0:05:07.7,000 --> 0:05:1,000
c'est un grand honneur et plaisir de me présenter devant vous

109
0:05:11.336,000 --> 0:05:14,000
afin d'examiner ce qui ne va pas avec notre économie.

110
0:05:15.64,000 --> 0:05:16,000
Une l'économie anémique...

111
0:05:17.27,000 --> 0:05:18,000
au bord de l'échec.

112
0:05:19.07,000 --> 0:05:21,000
Il a été fait mention de vous dans un article.

113
0:05:21.366,000 --> 0:05:24,000
Je cite : « Je peux dire cela avec une certitude absolue car

114
0:05:24.46,000 --> 0:05:25,000
je sais comment le marché fonctionne. »

115
0:05:26.33,000 --> 0:05:27,000
Ray Dalio : « En toute certitude,

116
0:05:28.246,000 --> 0:05:3,000
si vous regardez la base de liquidités

117
0:05:30.306,000 --> 0:05:33,000
dans les entreprises et dans le monde,

118
0:05:33.656,000 --> 0:05:38,000
ce niveau est si faible qu'il n'y aura pas de retour à une ère de stagflation. »

119
0:05:38.854,000 --> 0:05:4,000
Là je me dis : « Quel abruti arrogant ! »

120
0:05:42.17,000 --> 0:05:45,000
(Rires)

121
0:05:45.9,000 --> 0:05:47,000
J'étais si arrogant, et j'avais tort.

122
0:05:48.586,000 --> 0:05:5,000
En fait, lors de la crise de la dette,

123
0:05:50.91,000 --> 0:05:54,000
le marché boursier et l'économie étaient en hausse,

124
0:05:54.91,000 --> 0:05:59,000
et j'ai perdu tellement d'argent, le mien et celui de mes clients,

125
0:06:00.08,000 --> 0:06:03,000
que j'ai dû presque fermer boutique,

126
0:06:03.81,000 --> 0:06:05,000
la quasi totalité des employés sont partis.

127
0:06:06.01,000 --> 0:06:07,000
Nous étions comme une grande famille.

128
0:06:07.97,000 --> 0:06:08,000
J'avais le cœur brisé.

129
0:06:09.51,000 --> 0:06:1,000
Et j'ai perdu tellement d'argent

130
0:06:11.36,000 --> 0:06:13,000
que j'ai dû emprunter 4 000 dollars à mon père

131
0:06:14.24,000 --> 0:06:16,000
pour payer les factures de mon foyer.

132
0:06:16.84,000 --> 0:06:19,000
Une des expériences les plus douloureuses de ma vie...

133
0:06:21.24,000 --> 0:06:24,000
qui va, en fait, s'avérer être une bénédiction,

134
0:06:25.04,000 --> 0:06:28,000
parce qu'elle a changé mon attitude envers la prise de décision.

135
0:06:28.36,000 --> 0:06:3,000
Plutôt que de penser : « J'ai raison ! »,

136
0:06:31.33,000 --> 0:06:32,000
j'ai commencé à me demander :

137
0:06:33.2,000 --> 0:06:34,000
« Comment savoir si j'ai raison ? »

138
0:06:36.25,000 --> 0:06:38,000
J'ai gagné l'humilité dont j'avais besoin

139
0:06:38.546,000 --> 0:06:4,000
en vue d'équilibrer mon audace.

140
0:06:42.36,000 --> 0:06:45,000
Cherchant les plus brillants de ceux qui avaient un avis opposé au mien,

141
0:06:46.01,000 --> 0:06:47,000
afin de comprendre leur point de vue,

142
0:06:48.05,000 --> 0:06:5,000
et les pousser à tester le mien.

143
0:06:51.106,000 --> 0:06:54,000
Je voulais créer une méritocratie liée aux idées.

144
0:06:54.447,000 --> 0:06:55,000
A vrai dire,

145
0:06:55.566,000 --> 0:06:58,000
pas une autocratie dans laquelle je dirige et les autres suivent,

146
0:06:59.303,000 --> 0:07:02,000
ni une démocratie où tous les points de vue ont la même valeur,

147
0:07:02.97,000 --> 0:07:07,000
mais une méritocratie liée aux idées, où les meilleures idées l'emportent.

148
0:07:07.99,000 --> 0:07:12,000
Pour cela, Il fallait une franchise radicale,

149
0:07:13.22,000 --> 0:07:14,000
et transparence radicale.

150
0:07:14.56,000 --> 0:07:17,000
Par franchise radicale et transparence radicale,

151
0:07:18.42,000 --> 0:07:2,000
j'entends que nous devons dire ce que nous pensons vraiment,

152
0:07:21.346,000 --> 0:07:22,000
et la nécessité de la transparence.

153
0:07:23.48,000 --> 0:07:26,000
Nous avons donc enregistré presque toutes les conversations,

154
0:07:27.44,000 --> 0:07:28,000
rendues accessibles à tous,

155
0:07:29.06,000 --> 0:07:3,000
on ne pouvait faire autrement,

156
0:07:30.786,000 --> 0:07:33,000
si on voulait garantir une méritocratie liée aux idées.

157
0:07:34.76,000 --> 0:07:37,000
Afin d'avoir une telle méritocratie,

158
0:07:38.48,000 --> 0:07:4,000
on doit laisser tout le monde s'exprimer librement.

159
0:07:41.236,000 --> 0:07:42,000
Comme exemple,

160
0:07:42.636,000 --> 0:07:44,000
voici un email de Jim Haskel,

161
0:07:45,000 --> 0:07:46,000
quelqu'un qui travaille pour moi,

162
0:07:46.736,000 --> 0:07:49,000
et accessible à tous au sein de l'entreprise.

163
0:07:49.966,000 --> 0:07:51,000
« Ray, tu mérites un 07/20

164
0:07:52.36,000 --> 0:07:54,000
pour ta performance lors de la réunion...

165
0:07:54.746,000 --> 0:07:56,000
Yu n'étais pas bien préparé du tout,

166
0:07:56.86,000 --> 0:07:59,000
car il est impossible d'être aussi désorganisé... »

167
0:08:01.52,000 --> 0:08:01,000
Génial ! Non ?

168
0:08:02.42,000 --> 0:08:03,000
(Rires)

169
0:08:04.006,000 --> 0:08:05,000
C'est formidable,

170
0:08:05.237,000 --> 0:08:07,000
parce que, tout d'abord, j'avais besoin d'un tel feedback.

171
0:08:08.166,000 --> 0:08:09,000
J'ai besoin de feedback similaires.

172
0:08:09.886,000 --> 0:08:11,000
Et c'est génial car si je ne laisse pas Jim,

173
0:08:12.156,000 --> 0:08:13,000
et des gens comme Jim,

174
0:08:13.23,000 --> 0:08:14,000
exprimer leur point de vue,

175
0:08:14.656,000 --> 0:08:16,000
notre relation ne saurait être la même.

176
0:08:16.996,000 --> 0:08:18,000
Et si cela n'était pas accessible, en toute transparence,

177
0:08:19.966,000 --> 0:08:21,000
nous n'aurions pas eu une méritocratie des idées.

178
0:08:23.777,000 --> 0:08:26,000
Donc depuis 25 ans, c'est ainsi que nous avons fonctionné.

179
0:08:27.644,000 --> 0:08:3,000
Nous avons fonctionné avec cette transparence radicale,

180
0:08:30.72,000 --> 0:08:32,000
et puis nous avons collecté ces principes,

181
0:08:33.04,000 --> 0:08:35,000
venant dans une large mesure de nos erreurs,

182
0:08:35.12,000 --> 0:08:39,000
et puis nous avons intégré ces principes dans des algorithmes.

183
0:08:39.56,000 --> 0:08:41,000
Et puis ces algorithmes permettent...

184
0:08:42.28,000 --> 0:08:44,000
nous suivons les algorithmes,

185
0:08:44.32,000 --> 0:08:45,000
en parallèle avec nos réflexions.

186
0:08:47.304,000 --> 0:08:5,000
C'est ainsi que nous avons géré nos activités d'investissement,

187
0:08:50.48,000 --> 0:08:52,000
et c'est ainsi que nous traitons la gestion du personnel.

188
0:08:53.24,000 --> 0:08:56,000
Afin de vous donner une idée du processus,

189
0:08:57,000 --> 0:08:59,000
j'aimerais vous emmener à une réunion

190
0:08:59.36,000 --> 0:09:02,000
et vous présenter un outil nommé le « Dot Collector »

191
0:09:02.52,000 --> 0:09:03,000
nous aidant dans ce sens.

192
0:09:07.64,000 --> 0:09:09,000
Une semaine après les élections américaines,

193
0:09:09.84,000 --> 0:09:11,000
notre équipe de recherche a tenu une réunion

194
0:09:11.96,000 --> 0:09:14,000
sur les répercussions de l'élection de Trump sur l'économie américaine.

195
0:09:16,000 --> 0:09:19,000
Bien sûr, il y a eu des opinions divergentes sur la question,

196
0:09:19.076,000 --> 0:09:21,000
et sur la manière d'aborder la discussion.

197
0:09:21.69,000 --> 0:09:23,000
« Dot Collector » recueille ces opinions.

198
0:09:24.644,000 --> 0:09:26,000
Il a une liste avec des dizaines d'attributs,

199
0:09:26.93,000 --> 0:09:3,000
Quand on a une opinion sur une idée émise par l'autre,

200
0:09:31.136,000 --> 0:09:33,000
il est facile de partager une évaluation.

201
0:09:33.996,000 --> 0:09:37,000
On note tout simplement l'attribut, et on donne une note de 1 à 10.

202
0:09:39.52,000 --> 0:09:41,000
Par exemple, au début de la réunion,

203
0:09:41.8,000 --> 0:09:44,000
une chercheuse nommée Jen m'a donné une note de trois...

204
0:09:45.52,000 --> 0:09:47,000
autrement dit, une note médiocre.

205
0:09:47.787,000 --> 0:09:48,000
(Rires)

206
0:09:49.323,000 --> 0:09:53,000
pour manque d'équilibre entre ouverture d'esprit et affirmation de soi.

207
0:09:54,000 --> 0:09:55,000
Au cours de la réunion,

208
0:09:55.646,000 --> 0:09:58,000
voici le résultat des évaluations de Jen.

209
0:09:59.74,000 --> 0:10:01,000
Les autres avaient des opinions divergentes.

210
0:10:01.856,000 --> 0:10:02,000
C'est normal.

211
0:10:03.36,000 --> 0:10:06,000
Nous avons tous des opinions différentes.

212
0:10:06.8,000 --> 0:10:07,000
Et qui sait qui a raison?

213
0:10:09.24,000 --> 0:10:12,000
Alors qu'en est-il de ma performance?

214
0:10:13.6,000 --> 0:10:15,000
Pour certains je m'étais pas mal débrouillé,

215
0:10:15.84,000 --> 0:10:16,000
et pour d'autres, mal...

216
0:10:18.08,000 --> 0:10:19,000
Pour chaque opinion,

217
0:10:19.44,000 --> 0:10:21,000
on peut découvrir la réflexion derrière les notes.

218
0:10:22.52,000 --> 0:10:24,000
Voilà ce que Jen et Larry ont dit.

219
0:10:25.65,000 --> 0:10:27,000
Notez que chacun peut exprimer sa pensée,

220
0:10:28.4,000 --> 0:10:29,000
et son esprit critique,

221
0:10:30.05,000 --> 0:10:32,000
quel que soit le poste dans l'entreprise.

222
0:10:33.12,000 --> 0:10:36,000
Jen, 24 ans, récemment diplômée,

223
0:10:36.24,000 --> 0:10:39,000
peut me dire, au PDG, que j'appréhende mal la situation.

224
0:10:40.48,000 --> 0:10:43,000
Cet outil aide les gens à exprimer leur opinion,

225
0:10:44.28,000 --> 0:10:47,000
et aussi à s'en détacher,

226
0:10:47.4,000 --> 0:10:49,000
et voir les choses avec une autre perspective.

227
0:10:50.64,000 --> 0:10:54,000
Quand Jen et d’autres dirigent leur attention de leur opinion

228
0:10:55.56,000 --> 0:10:57,000
vers une vision plus globale,

229
0:10:58.16,000 --> 0:10:59,000
un changement d'optique en résulte.

230
0:11:00.68,000 --> 0:11:03,000
Chacun réalise que son avis n'est qu’un avis parmi d’autres,

231
0:11:03.84,000 --> 0:11:05,000
et naturellement ils commencent à se demander :

232
0:11:06.4,000 --> 0:11:08,000
« Comment savoir si mon avis est juste ? »

233
0:11:09.48,000 --> 0:11:13,000
C'est comme passer d'une vision en une seule dimension

234
0:11:13.56,000 --> 0:11:15,000
à une vision multidimensionnelle,

235
0:11:15.84,000 --> 0:11:18,000
réorientant une conversation argumentative

236
0:11:19.836,000 --> 0:11:23,000
vers des critères objectifs qui ciblent les meilleurs avis.

237
0:11:24.92,000 --> 0:11:27,000
Derrière le « Dot Collector », il y a un ordinateur qui surveille,

238
0:11:29.12,000 --> 0:11:31,000
qui observe tout ce que ces personnes pensent

239
0:11:31.32,000 --> 0:11:33,000
et qui relie le tout avec leur manière de penser.

240
0:11:33.92,000 --> 0:11:36,000
Et sur cette base, il les conseille en retour.

241
0:11:38.52,000 --> 0:11:41,000
Ensuite, il tire les données de toutes les réunions

242
0:11:41.96,000 --> 0:11:44,000
afin de créer un portrait pointilliste des personnes,

243
0:11:45.2,000 --> 0:11:46,000
et leur façon de penser.

244
0:11:47.16,000 --> 0:11:49,000
Tout ça guidé par des algorithmes.

245
0:11:50.8,000 --> 0:11:53,000
Connaitre les gens permet une meilleure adéquation des compétences et des emplois.

246
0:11:54.96,000 --> 0:11:55,000
Par exemple,

247
0:11:55.96,000 --> 0:11:57,000
un penseur créatif mais peu fiable

248
0:11:58.058,000 --> 0:12:02,000
peut être compatible avec quelqu'un de fiable mais pas créatif.

249
0:12:02.281,000 --> 0:12:05,000
Connaitre les gens permet aussi de décider

250
0:12:05.96,000 --> 0:12:06,000
quelles responsabilités leur confier,

251
0:12:07.92,000 --> 0:12:1,000
et d'évaluer nos décisions en fonction du mérite de ces personnes.

252
0:12:12.04,000 --> 0:12:13,000
En fonction de leur crédibilité.

253
0:12:14.56,000 --> 0:12:15,000
Voici l'exemple d’un vote

254
0:12:16.56,000 --> 0:12:18,000
où la majorité avait une certaine opinion,

255
0:12:20.8,000 --> 0:12:23,000
mais suite à l'évaluation des opinions basée sur le mérite,

256
0:12:24.216,000 --> 0:12:26,000
le résultat a totalement changé.

257
0:12:26.92,000 --> 0:12:28,000
Ce processus nous permet de prendre des décisions

258
0:12:29.24,000 --> 0:12:33,000
basées non sur la démocratie, ou l’autocratie,

259
0:12:33.68,000 --> 0:12:35,000
mais basées sur des algorithmes

260
0:12:35.79,000 --> 0:12:38,000
qui prennent en considération la crédibilité.

261
0:12:41.78,000 --> 0:12:42,000
Oui, on fait vraiment ça.

262
0:12:43.43,000 --> 0:12:46,000
(Rires)

263
0:12:46.56,000 --> 0:12:48,000
Nous le faisons parce que cela élimine

264
0:12:49.44,000 --> 0:12:53,000
ce qui constitue pour moi l'une des plus grandes tragédies de l'humanité,

265
0:12:53.92,000 --> 0:12:55,000
c’est-à-dire que dans notre arrogance,

266
0:12:56.76,000 --> 0:13:,000
naïvement, nous chérissons des opinions erronées,

267
0:13:01.24,000 --> 0:13:02,000
et leur donnons suite,

268
0:13:02.52,000 --> 0:13:05,000
et nous ne les exprimons pas afin de pouvoir les tester.

269
0:13:06,000 --> 0:13:07,000
Et c’est une tragédie.

270
0:13:07.36,000 --> 0:13:12,000
Faire cela, c'est nous élever au-dessus de nos propres opinions,

271
0:13:12.53,000 --> 0:13:15,000
afin de voir enfin le monde au travers des yeux des autres,

272
0:13:15.906,000 --> 0:13:16,000
et de le voir de manière collective.

273
0:13:18.362,000 --> 0:13:22,000
Une prise de décision collective est bien plus efficace qu'une décision individuelle

274
0:13:22.602,000 --> 0:13:23,000
si tout est bien fait.

275
0:13:24.36,000 --> 0:13:26,000
Elle a été la recette secrète de notre succès.

276
0:13:27.002,000 --> 0:13:29,000
Gagnant plus d'argent pour nos clients

277
0:13:29.486,000 --> 0:13:31,000
que les autres fonds d'investissement spéculatif,

278
0:13:32.016,000 --> 0:13:35,000
réalisant des bénéfices 23 années sur les 26 dernières années.

279
0:13:35.88,000 --> 0:13:39,000
Alors quel est le problème avec le fait d'être totalement sincères

280
0:13:40.44,000 --> 0:13:42,000
d'être radicalement transparents entre nous ?

281
0:13:45.4,000 --> 0:13:47,000
On dit qu'il y a un côté affectif difficile à gérer.

282
0:13:48.24,000 --> 0:13:52,000
Les critiques disent que c'est la formule pour un environnement de travail brutal.

283
0:13:53.4,000 --> 0:13:57,000
Les neuroscientifiques disent que c'est lié au pré-câblage de nos cerveaux.

284
0:13:58.11,000 --> 0:14:01,000
Il y a une part de notre cerveau qui veut bien reconnaître nos erreurs

285
0:14:01.52,000 --> 0:14:04,000
et faire face à nos faiblesses afin de nous améliorer la prochaine fois.

286
0:14:06.12,000 --> 0:14:08,000
On me dit que c'est le cortex préfrontal.

287
0:14:08.91,000 --> 0:14:1,000
Ensuite il y a une partie de notre cerveau

288
0:14:10.99,000 --> 0:14:12,000
qui voit tout ça comme des attaques.

289
0:14:13.63,000 --> 0:14:15,000
On me dit que c'est l'amygdale.

290
0:14:16.44,000 --> 0:14:19,000
Autrement dit, à l’intérieur de vous, il y a deux « vous » :

291
0:14:19.52,000 --> 0:14:2,000
il y a un « vous » émotionnel

292
0:14:20.96,000 --> 0:14:21,000
et il y a un « vous » intellectuel,

293
0:14:22.76,000 --> 0:14:23,000
et ils sont souvent en désaccord,

294
0:14:24.56,000 --> 0:14:26,000
et ils travaillent souvent contre vous.

295
0:14:27.16,000 --> 0:14:3,000
Par expérience, nous savons que nous pouvons gagner cette bataille.

296
0:14:30.92,000 --> 0:14:31,000
Nous la gagnons en tant que groupe.

297
0:14:33,000 --> 0:14:34,000
Cela prend environ 18 mois en général

298
0:14:34.926,000 --> 0:14:37,000
pour découvrir que la plupart des gens préfèrent fonctionner ainsi,

299
0:14:38.44,000 --> 0:14:4,000
avec cette transparence radicale,

300
0:14:40.48,000 --> 0:14:43,000
plutôt que de travailler dans un environnement opaque.

301
0:14:43.74,000 --> 0:14:46,000
On ne fait pas de politique, il n'y a pas de brutalité celle...

302
0:14:47.54,000 --> 0:14:49,000
vous savez, tout ce qui est caché, en coulisses...

303
0:14:50.366,000 --> 0:14:53,000
Il y a une méritocratie des idées, et on s'exprime librement.

304
0:14:53.39,000 --> 0:14:54,000
Une expérience magnifique !

305
0:14:54.77,000 --> 0:14:55,000
Résultant en un travail plus efficace,

306
0:14:56.726,000 --> 0:14:58,000
et des relations privilégiées.

307
0:14:59.4,000 --> 0:15:,000
Ce n'est pas le cas pour tous.

308
0:15:01.68,000 --> 0:15:03,000
Pour 25 ou 30% de la population,

309
0:15:04.64,000 --> 0:15:05,000
cela ne fonctionne pas.

310
0:15:06.4,000 --> 0:15:07,000
Et d'ailleurs, quand je dis

311
0:15:07.726,000 --> 0:15:08,000
transparence radicale,

312
0:15:09.33,000 --> 0:15:11,000
je veux pas dire la transparence à propos de tout.

313
0:15:11.84,000 --> 0:15:14,000
Je veux dire, vous n'avez pas à dire à quelqu'un que sa calvitie est visible,

314
0:15:15.68,000 --> 0:15:16,000
ou que son bébé est moche.

315
0:15:17.32,000 --> 0:15:19,000
Donc, ceci s'applique seulement...

316
0:15:19.44,000 --> 0:15:2,000
(Rires)

317
0:15:20.68,000 --> 0:15:22,000
aux choses importantes.

318
0:15:22.88,000 --> 0:15:23,000
Alors...

319
0:15:24.12,000 --> 0:15:27,000
(Rires)

320
0:15:28.38,000 --> 0:15:29,000
Alors quand vous quitterez cette salle,

321
0:15:30.256,000 --> 0:15:34,000
il serait bien de prêter attention à vos conversations.

322
0:15:35.36,000 --> 0:15:38,000
Imaginez si vous saviez ce que l'autre pense vraiment,

323
0:15:39.76,000 --> 0:15:41,000
et imaginez si vous saviez vraiment qui ils sont...

324
0:15:43.84,000 --> 0:15:46,000
Et imaginez s'ils savaient vraiment ce que vous pensez,

325
0:15:47.84,000 --> 0:15:48,000
et qui vous êtes vraiment.

326
0:15:50.16,000 --> 0:15:52,000
Cela clarifierait certainement une foule de choses,

327
0:15:52.76,000 --> 0:15:54,000
et rendrait votre échange beaucoup plus fluide.

328
0:15:55.64,000 --> 0:15:57,000
Je pense que cela améliorerait vos relations.

329
0:15:58.6,000 --> 0:16:01,000
Maintenant imaginez que vous avez accès à des algorithmes

330
0:16:01.92,000 --> 0:16:04,000
qui peuvent vous aider à rassembler toutes ces informations,

331
0:16:05.76,000 --> 0:16:1,000
et même vous aider à prendre des décisions basées sur la méritocratie liée aux idées.

332
0:16:12.64,000 --> 0:16:16,000
Ce genre de transparence radicale arrive à grands pas,

333
0:16:17,000 --> 0:16:18,000
et va avoir un impact sur votre vie.

334
0:16:19.6,000 --> 0:16:21,000
Et à mon avis,

335
0:16:21.68,000 --> 0:16:22,000
ça sera merveilleux.

336
0:16:23.04,000 --> 0:16:25,000
J’espère que cela sera aussi merveilleux pour vous,

337
0:16:25.576,000 --> 0:16:26,000
qu'il le fut pour moi.

338
0:16:27.16,000 --> 0:16:28,000
Merci beaucoup.

339
0:16:28.44,000 --> 0:16:32,000
(Applaudissements)

