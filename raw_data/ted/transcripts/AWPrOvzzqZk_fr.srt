1
0:00:,000 --> 0:00:07,000
Traducteur: Jean-Christophe Houzel Relecteur: Sophie ADAMA

2
0:00:13.354,000 --> 0:00:16,000
La technologie nous a tellement apporté :

3
0:00:16.489,000 --> 0:00:17,000
l'alunissage, Internet,

4
0:00:18.095,000 --> 0:00:21,000
la possibilité de séquencer le génome humain.

5
0:00:21.133,000 --> 0:00:24,000
Mais elle infiltre aussi nos plus grandes peurs

6
0:00:24.857,000 --> 0:00:25,000
et il y a environ 30 ans,

7
0:00:26.713,000 --> 0:00:28,000
le critique Neil Postman a écrit un livre

8
0:00:29.266,000 --> 0:00:31,000
intitulé « Se distraire à en mourir »

9
0:00:31.381,000 --> 0:00:33,000
qui expose celà brillamment.

10
0:00:34.14,000 --> 0:00:35,000
Voici ce qu'il a dit,

11
0:00:35.79,000 --> 0:00:37,000
en comparant les vues dystopiques

12
0:00:38.053,000 --> 0:00:41,000
de George Orwell et d'Aldous Huxley.

13
0:00:41.626,000 --> 0:00:44,000
Il a dit que Orwell avait peur que nous devenions

14
0:00:44.752,000 --> 0:00:46,000
une culture en captivité.

15
0:00:47,000 --> 0:00:5,000
Huxley avait peur que nous devenions une culture banale.

16
0:00:50.752,000 --> 0:00:52,000
Orwell avait peur que la vérité

17
0:00:52.897,000 --> 0:00:53,000
ne nous soit dissimulée,

18
0:00:54.82,000 --> 0:00:56,000
et Huxley craignait que nous nous noyions

19
0:00:57.01,000 --> 0:00:59,000
dans un océan de choses sans importance.

20
0:00:59.703,000 --> 0:01:01,000
En un mot, c'est un choix entre

21
0:01:01.873,000 --> 0:01:03,000
être regardé par Big Brother

22
0:01:04.473,000 --> 0:01:06,000
et regarder Big Brother.

23
0:01:06.969,000 --> 0:01:07,000
(Rires)

24
0:01:08.33,000 --> 0:01:1,000
Mais ça ne doit pas forcément se passer comme ça.

25
0:01:10.634,000 --> 0:01:13,000
Nous ne sommes pas des consommateurs passifs de données et de technologie.

26
0:01:13.97,000 --> 0:01:15,000
Nous façonnons le rôle qu'elles jouent dans nos vies

27
0:01:16.373,000 --> 0:01:18,000
et la façon dont nous leur donnons sens.

28
0:01:18.503,000 --> 0:01:19,000
Mais, pour ce faire,

29
0:01:20.106,000 --> 0:01:23,000
nous devons prêter autant d'attention à notre façon de penser

30
0:01:23.619,000 --> 0:01:25,000
qu'à notre façon de programmer.

31
0:01:25.649,000 --> 0:01:28,000
Nous devons nous poser des questions, des questions difficiles,

32
0:01:28.747,000 --> 0:01:29,000
pour aller au-delà de compter les choses,

33
0:01:30.726,000 --> 0:01:32,000
et commencer à les comprendre.

34
0:01:33.218,000 --> 0:01:35,000
Nous sommes constamment bombardés d'histoires

35
0:01:35.664,000 --> 0:01:37,000
sur la quantité de données dans le monde,

36
0:01:38.14,000 --> 0:01:39,000
mais quand il s'agit de mégadonnées

37
0:01:39.83,000 --> 0:01:41,000
et des défis pour les interpréter,

38
0:01:42.316,000 --> 0:01:44,000
la taille n'est pas tout.

39
0:01:44.404,000 --> 0:01:46,000
Il y a aussi la vitesse à laquelle elles bougent,

40
0:01:47.307,000 --> 0:01:49,000
et la grande variété des types de données.

41
0:01:49.403,000 --> 0:01:51,000
Voici juste quelques exemples :

42
0:01:51.501,000 --> 0:01:52,000
des images,

43
0:01:53.699,000 --> 0:01:55,000
des textes,

44
0:01:57.706,000 --> 0:01:58,000
des vidéos,

45
0:01:59.801,000 --> 0:02:,000
des sons.

46
0:02:01.631,000 --> 0:02:04,000
Ce qui unifie ces différents types de données,

47
0:02:04.673,000 --> 0:02:06,000
c'est qu'elles sont créées par des personnes

48
0:02:06.894,000 --> 0:02:08,000
et qu'elles nécessitent un contexte.

49
0:02:09.669,000 --> 0:02:11,000
Un groupe de scientifiques de données

50
0:02:12.114,000 --> 0:02:14,000
de l'Université d'Illinois à Chicago,

51
0:02:14.419,000 --> 0:02:16,000
dénommé « Collectif Média Santé »

52
0:02:16.863,000 --> 0:02:18,000
qui ont travaillé au Centre de Contrôle des Maladies [CDC]

53
0:02:19.56,000 --> 0:02:2,000
pour mieux comprendre comment

54
0:02:21.065,000 --> 0:02:23,000
les gens discutent à propos d'arrêter de fumer,

55
0:02:23.913,000 --> 0:02:25,000
comment ils parlent des cigarettes électroniques,

56
0:02:26.593,000 --> 0:02:27,000
et sur ce qu'ils peuvent faire ensemble

57
0:02:28.578,000 --> 0:02:29,000
pour les aider à arrêter.

58
0:02:30.312,000 --> 0:02:32,000
Ce qui est intéressant, si on veut comprendre

59
0:02:32.575,000 --> 0:02:34,000
comment les gens parlent de fumer,

60
0:02:34.791,000 --> 0:02:35,000
d'abord, on doit commencer par comprendre

61
0:02:36.692,000 --> 0:02:38,000
ce qu'ils entendent par « fumer ».

62
0:02:39.257,000 --> 0:02:42,000
Sur Twitter, il y a quatre catégories :

63
0:02:43.183,000 --> 0:02:45,000
numéro un : fumer des cigarettes ;

64
0:02:46.18,000 --> 0:02:48,000
numéro deux : fumer de la marijuana ;

65
0:02:48.987,000 --> 0:02:5,000
numéro trois : côtelettes fumées ;

66
0:02:51.63,000 --> 0:02:54,000
et numéro quatre : femmes chaudes et sexy.

67
0:02:55.183,000 --> 0:02:57,000
(Rires)

68
0:02:58.176,000 --> 0:02:59,000
Ensuite, on doit réfléchir sur

69
0:03:00.162,000 --> 0:03:02,000
comment les gens parlent de cigarette électroniques.

70
0:03:02.742,000 --> 0:03:04,000
Il y a tant de façons différentes d'en parler,

71
0:03:04.907,000 --> 0:03:06,000
comme vous pouvez le voir sur la diapositive,

72
0:03:07.366,000 --> 0:03:09,000
c'est une requête bien complexe.

73
0:03:09.976,000 --> 0:03:12,000
Et ceci nous rappelle que

74
0:03:13.01,000 --> 0:03:15,000
le langage a été créé par des personnes,

75
0:03:15.121,000 --> 0:03:17,000
et les personnes sont désordonnées, et nous sommes complexes,

76
0:03:17.971,000 --> 0:03:19,000
et que nous utilisons des métaphores, de l'argot, du jargon

77
0:03:20.718,000 --> 0:03:23,000
et nous faisons ça 24h/24, 7j/7, dans plein, plein de langues,

78
0:03:23.997,000 --> 0:03:26,000
et aussitôt qu'on se décide, on change tout à nouveau.

79
0:03:27.221,000 --> 0:03:32,000
Donc, est-ce que ces annonces du CDC,

80
0:03:32.339,000 --> 0:03:34,000
ces publicités à la télé qui montraient

81
0:03:34.769,000 --> 0:03:36,000
une femme avec un trou dans la gorge,

82
0:03:36.79,000 --> 0:03:37,000
qui étaient très crues et troublantes.

83
0:03:38.694,000 --> 0:03:39,000
ont-elles finalement eu un impact

84
0:03:40.579,000 --> 0:03:42,000
sur la décision des gens d'arrêter de fumer ?

85
0:03:43.25,000 --> 0:03:46,000
Le Collectif Média Santé a respecté les limites de leurs données

86
0:03:46.557,000 --> 0:03:48,000
mais ils ont réussi à conclure que ces annonces

87
0:03:48.902,000 --> 0:03:5,000
- que vous avez probablement vues -

88
0:03:51.874,000 --> 0:03:53,000
ont eu pour effet d'induire les gens

89
0:03:54.465,000 --> 0:03:55,000
à un processus de réfléxion

90
0:03:56.287,000 --> 0:03:59,000
qui peut avoir eu un impact sur leur comportement futur.

91
0:03:59.954,000 --> 0:04:02,000
Ce que j'admire et reconnais de ce projet,

92
0:04:03.845,000 --> 0:04:04,000
en dehors du fait qu'il est basé

93
0:04:05.424,000 --> 0:04:08,000
sur des besoins humains réels

94
0:04:09.391,000 --> 0:04:11,000
est que c'est un exemple fantastique de courage

95
0:04:12.237,000 --> 0:04:15,000
dans un océan de choses sans importance.

96
0:04:16.52,000 --> 0:04:18,000
Ainsi, ce ne sont pas uniquement les mégadonnées

97
0:04:19.515,000 --> 0:04:22,000
qui représentent un défi d'interprétation, car, soyons honnêtes,

98
0:04:22.586,000 --> 0:04:24,000
nous, les humains, nous avons un riche historique

99
0:04:25.18,000 --> 0:04:27,000
de prendre n'importe quelles données, même petites,

100
0:04:27.873,000 --> 0:04:28,000
et de tout gâcher.

101
0:04:29.49,000 --> 0:04:32,000
Il y a plusieurs années, vous vous en rappelez peut être,

102
0:04:33.227,000 --> 0:04:35,000
l'ancien Président Ronald Reagan

103
0:04:35.5,000 --> 0:04:36,000
fut violemment critiqué pour avoir dit que

104
0:04:37.491,000 --> 0:04:4,000
les faits étaient des choses stupides.

105
0:04:40.501,000 --> 0:04:42,000
Soyons honnêtes, ce fut à peine un lapsus.

106
0:04:42.965,000 --> 0:04:45,000
Il voulait citer John Adams, dans sa défense des soldats anglais

107
0:04:45.995,000 --> 0:04:47,000
lors du procès du massacre de Boston,

108
0:04:48.476,000 --> 0:04:51,000
disant que les faits étaient des choses tenaces.

109
0:04:51.626,000 --> 0:04:53,000
Mais je pense qu'il y a un peu de

110
0:04:54.25,000 --> 0:04:57,000
sagesse fortuite dans ce qu'il a dit,

111
0:04:57.668,000 --> 0:04:59,000
car les faits sont tenaces,

112
0:05:00.444,000 --> 0:05:02,000
et, parfois, ils sont aussi stupides.

113
0:05:03.367,000 --> 0:05:05,000
J'aimerai vous raconter une histoire personnelle

114
0:05:05.835,000 --> 0:05:07,000
sur pourquoi cela me tient tant à cœur.

115
0:05:08.803,000 --> 0:05:1,000
J'ai besoin de respirer.

116
0:05:11.24,000 --> 0:05:13,000
Isaac, mon fils, quand il avait deux ans,

117
0:05:13.994,000 --> 0:05:15,000
a été diagnostiqué d'autisme.

118
0:05:16.411,000 --> 0:05:18,000
C'était un petit gars heureux, drôle,

119
0:05:18.572,000 --> 0:05:2,000
aimant, affectueux,

120
0:05:20.607,000 --> 0:05:22,000
mais, les scores des évaluations de son développement

121
0:05:23.509,000 --> 0:05:25,000
qui considèrent des choses comme le nombre de mots --

122
0:05:26.119,000 --> 0:05:29,000
à cette époque là : zéro --

123
0:05:29.236,000 --> 0:05:32,000
de gestes communicatifs, et de contact visuel minimal,

124
0:05:33.176,000 --> 0:05:35,000
plaçaient son développement

125
0:05:35.179,000 --> 0:05:38,000
au niveau de celui d'un bébé de 9 mois.

126
0:05:39.14,000 --> 0:05:41,000
Ces diagnostics étaient effectivement corrects,

127
0:05:42.1,000 --> 0:05:45,000
mais ils ne racontaient pas tout.

128
0:05:45.309,000 --> 0:05:46,000
Environ un an et demi plus tard,

129
0:05:46.99,000 --> 0:05:47,000
quand il avait presque 4 ans,

130
0:05:48.812,000 --> 0:05:5,000
je l'ai trouvé, un beau jour, devant l'ordinateur

131
0:05:51.175,000 --> 0:05:55,000
cherchant sur Google des images de femmes

132
0:05:56.628,000 --> 0:05:58,000
épelées "f-a-m-e-s."

133
0:06:00.154,000 --> 0:06:02,000
Et j'ai fait ce que tout parent obsessif aurait fait :

134
0:06:02.804,000 --> 0:06:04,000
J'ai cliqué immédiatement le bouton « précédent »

135
0:06:05.265,000 --> 0:06:07,000
pour voir quoi d'autre il avait cherché.

136
0:06:08.248,000 --> 0:06:1,000
C'était, dans l'ordre : hommes,

137
0:06:10.419,000 --> 0:06:17,000
école, bus et ordinateur.

138
0:06:17.686,000 --> 0:06:18,000
J'étais stupéfaite,

139
0:06:19.626,000 --> 0:06:21,000
car on ne savait pas qu'il savait épeler,

140
0:06:21.648,000 --> 0:06:23,000
et encore moins lire. Donc je lui ai demandé :

141
0:06:23.744,000 --> 0:06:24,000
« Isaac, comment as-tu fait ça ? »

142
0:06:25.717,000 --> 0:06:27,000
Il m'a regardé très sérieusement et dit :

143
0:06:28.395,000 --> 0:06:31,000
« Écrit dans le cadre. »

144
0:06:31.747,000 --> 0:06:34,000
Il s'apprenait lui-même à communiquer,

145
0:06:35.481,000 --> 0:06:38,000
mais nous cherchions au mauvais endroit,

146
0:06:38.485,000 --> 0:06:4,000
et c'est ce qui se passe quand les évaluations

147
0:06:40.6,000 --> 0:06:42,000
et les analyses donnent plus d'importance à une mesure --

148
0:06:43.176,000 --> 0:06:45,000
dans ce cas, la communication verbale --

149
0:06:45.785,000 --> 0:06:5,000
et en sous-estiment d'autres, comme la résolution créative de problèmes.

150
0:06:51.488,000 --> 0:06:53,000
Communiquer était difficile pour Isaac,

151
0:06:53.795,000 --> 0:06:54,000
et il avait donc trouvé une astuce

152
0:06:55.707,000 --> 0:06:57,000
pour découvrir ce qu'il avait besoin de savoir.

153
0:06:58.434,000 --> 0:07:,000
Quand on y pense, ça semble logique,

154
0:07:00.454,000 --> 0:07:02,000
car formuler une question

155
0:07:02.535,000 --> 0:07:04,000
est un processus vraiment complexe,

156
0:07:05.1,000 --> 0:07:07,000
mais il a réussi à faire un grand pas

157
0:07:07.622,000 --> 0:07:11,000
en tapant un mot dans un cadre de recherche.

158
0:07:11.714,000 --> 0:07:13,000
Et ce court instant

159
0:07:14.65,000 --> 0:07:16,000
a eu un profond impact sur moi

160
0:07:17.486,000 --> 0:07:18,000
et sur notre famille.

161
0:07:18.795,000 --> 0:07:21,000
Car ça nous a aidé à changer nos références

162
0:07:21.936,000 --> 0:07:23,000
sur ce qu'il lui arrivait,

163
0:07:24.144,000 --> 0:07:26,000
à nous préoccuper un peu moins et à apprécier davantage

164
0:07:27.12,000 --> 0:07:29,000
sa débrouillardise.

165
0:07:29.302,000 --> 0:07:31,000
Les faits sont des choses stupides.

166
0:07:32.163,000 --> 0:07:34,000
Et ils sont vulnérables à une mauvaise utilisation,

167
0:07:34.56,000 --> 0:07:35,000
délibérée ou non.

168
0:07:36.213,000 --> 0:07:39,000
J'ai une amie, Emily Willingham, qui est une scientifique.

169
0:07:39.239,000 --> 0:07:41,000
Elle a écrit un article pour Forbes

170
0:07:42.04,000 --> 0:07:43,000
il n'y a pas longtemps, intitulé

171
0:07:44.02,000 --> 0:07:46,000
« Les 10 choses plus bizarres reliées à l'autisme. »

172
0:07:46.37,000 --> 0:07:48,000
Il y en a toute une liste.

173
0:07:48.835,000 --> 0:07:51,000
On blâme Internet pour tout , n'est ce pas ?

174
0:07:52.367,000 --> 0:07:55,000
Et bien entendu, les mères, parce que voilà.

175
0:07:56.124,000 --> 0:07:57,000
Attendez, ça n'est pas tout,

176
0:07:57.711,000 --> 0:08:,000
Il y a toute une liste dans la catégorie « mère »,

177
0:08:01.141,000 --> 0:08:05,000
comme vous voyez, une liste très complète et intéressante.

178
0:08:05.956,000 --> 0:08:07,000
Personnellement. je suis vraiment fan de

179
0:08:08.149,000 --> 0:08:11,000
« tomber enceinte près des autoroutes ».

180
0:08:11.853,000 --> 0:08:12,000
La dernière est intéressante,

181
0:08:13.392,000 --> 0:08:16,000
car le terme « mère réfrigérateur »

182
0:08:16.395,000 --> 0:08:18,000
était en fait l'hypothèse initiale

183
0:08:19,000 --> 0:08:2,000
de la cause de l'autisme,

184
0:08:20.431,000 --> 0:08:22,000
il signifie quelqu'un de froid et sans amour.

185
0:08:23.166,000 --> 0:08:24,000
À ce stade, vous devez penser:

186
0:08:24.728,000 --> 0:08:25,000
« Ok, Susan, on comprend,

187
0:08:26.385,000 --> 0:08:27,000
on peut prendre des données et leur faire dire ce qu'on veut. »

188
0:08:28.167,000 --> 0:08:32,000
Et c'est vrai, c'est absolument vrai,

189
0:08:32.87,000 --> 0:08:36,000
mais, le défi c'est que

190
0:08:38.36,000 --> 0:08:39,000
nous avons cette chance

191
0:08:40.298,000 --> 0:08:42,000
d'essayer de leur donner nous-mêmes un sens car, franchement,

192
0:08:43.212,000 --> 0:08:48,000
les données ne se créent pas leur sens. C'est nous qui le faisons.

193
0:08:48.564,000 --> 0:08:51,000
Donc, en tant qu'hommes d'affaires, et consommateurs

194
0:08:51.82,000 --> 0:08:53,000
en tant que patients, en tant que citoyens

195
0:08:54.359,000 --> 0:08:56,000
nous avons la responsabilité, je pense,

196
0:08:56.755,000 --> 0:08:58,000
de passer plus de temps

197
0:08:58.949,000 --> 0:09:,000
à se concentrer sur nos capacités de pensée critique.

198
0:09:01.819,000 --> 0:09:02,000
Pourquoi ?

199
0:09:02.897,000 --> 0:09:05,000
Parce qu'à ce moment de notre histoire,

200
0:09:06.075,000 --> 0:09:07,000
comme nous l'avons entendu souvent,

201
0:09:07.781,000 --> 0:09:08,000
nous pouvons traiter des milliards d'octets de données,

202
0:09:09.762,000 --> 0:09:11,000
à la vitesse de la lumière,

203
0:09:11.915,000 --> 0:09:14,000
et nous avons le potentiel de prendre de mauvaises décisions

204
0:09:15.43,000 --> 0:09:16,000
bien plus rapidement, efficacement,

205
0:09:17.264,000 --> 0:09:21,000
et avec un impact bien plus grand que par le passé.

206
0:09:22.052,000 --> 0:09:23,000
Super, n'est ce pas ?

207
0:09:23.68,000 --> 0:09:26,000
Donc, ce que nous devons faire, au contraire,

208
0:09:26.71,000 --> 0:09:28,000
c'est consacrer un peu plus de temps

209
0:09:29.04,000 --> 0:09:31,000
sur des choses comme les sciences humaines,

210
0:09:31.786,000 --> 0:09:34,000
la sociologie, les sciences sociales,

211
0:09:35.25,000 --> 0:09:37,000
la rhétorique, la philosophie, l'éthique,

212
0:09:37.558,000 --> 0:09:39,000
car elles nous fournissent le contexte qui est si important

213
0:09:40.414,000 --> 0:09:42,000
pour les mégadonnées, et parce que

214
0:09:42.86,000 --> 0:09:44,000
elles nous aident à devenir de meilleurs penseurs critiques.

215
0:09:45.798,000 --> 0:09:48,000
Car, en fin de compte,

216
0:09:49.615,000 --> 0:09:51,000
si je repère un problème dans une controverse,

217
0:09:52.101,000 --> 0:09:54,000
il importe peu qu'il soit exprimé en mots ou en chiffres.

218
0:09:54.86,000 --> 0:09:56,000
Cela signifie que nous devons nous enseigner

219
0:09:57.579,000 --> 0:10:01,000
à détecter ces biais d'interprétation,

220
0:10:02,000 --> 0:10:03,000
et ces fausses corrélations

221
0:10:03.592,000 --> 0:10:05,000
et à être capables de repérer un recours clairement émotionnel

222
0:10:06.47,000 --> 0:10:07,000
à 30 mètres de distance.

223
0:10:07.622,000 --> 0:10:09,000
Car si un événement se produit après un autre

224
0:10:10.144,000 --> 0:10:13,000
ça ne veut pas forcément dire qu'il s'est produit à cause du premier.

225
0:10:13.486,000 --> 0:10:15,000
Et, si vous me permettez d'oser un instant,

226
0:10:15.835,000 --> 0:10:18,000
les romains appelaient cela « post hoc ergo propter hoc »

227
0:10:19.642,000 --> 0:10:22,000
« à la suite de ceci, donc à cause de cela ».

228
0:10:22.938,000 --> 0:10:25,000
Cela signifie mettre en doute les disciplines telles que la démographie.

229
0:10:26.695,000 --> 0:10:28,000
Pourquoi ? Parce qu'elles sont basées sur des hypothèses

230
0:10:29.505,000 --> 0:10:3,000
sur qui nous sommes,

231
0:10:30.851,000 --> 0:10:32,000
fondées sur notre sexe, notre âge, notre lieu de vie,

232
0:10:33.273,000 --> 0:10:36,000
au contraire des données sur ce que nous pensons et faisons vraiment.

233
0:10:36.461,000 --> 0:10:37,000
Et, puisque nous avons ces données,

234
0:10:38.124,000 --> 0:10:41,000
nous devons la traiter avec un contrôle approprié de confidentialité

235
0:10:41.263,000 --> 0:10:44,000
et avec le consentement du consommateur,

236
0:10:44.839,000 --> 0:10:46,000
et au-delà de ça, nous devons être clairs

237
0:10:47.832,000 --> 0:10:49,000
quant à nos hypothèses,

238
0:10:49.935,000 --> 0:10:51,000
aux méthodes que nous utilisons,

239
0:10:52.531,000 --> 0:10:54,000
et à notre confiance dans les résultats.

240
0:10:55.335,000 --> 0:10:57,000
Comme disait mon prof d'algèbre au lycée :

241
0:10:57.809,000 --> 0:10:58,000
« Montre tes calculs,

242
0:10:59.34,000 --> 0:11:02,000
car si je ne sais pas quelles étapes tu as suivies,

243
0:11:02.631,000 --> 0:11:04,000
je ne sais pas les étapes tu n'as pas suivies,

244
0:11:04.752,000 --> 0:11:06,000
et, si je ne sais pas les questions que tu t'es posées,

245
0:11:07.26,000 --> 0:11:1,000
je ne sais pas quelles questions tu n'as pas posées. »

246
0:11:10.407,000 --> 0:11:11,000
Ce qui signifie, vraiment,

247
0:11:11.93,000 --> 0:11:13,000
nous poser la plus difficile des questions :

248
0:11:13.939,000 --> 0:11:15,000
Est ce que les données nous montrent vraiment ceci

249
0:11:16.909,000 --> 0:11:18,000
ou est-ce que les résultats nous font nous sentir

250
0:11:19.22,000 --> 0:11:22,000
plus performants et plus à l'aise ?

251
0:11:23.098,000 --> 0:11:25,000
Donc, à la fin du projet,

252
0:11:25.682,000 --> 0:11:26,000
le Collectif Média Santé a réussi

253
0:11:27.381,000 --> 0:11:3,000
à trouver que 87% des tweets

254
0:11:30.789,000 --> 0:11:32,000
sur ces annonces anti-tabac très dérangeantes

255
0:11:33.553,000 --> 0:11:35,000
exprimaient la peur.

256
0:11:36.661,000 --> 0:11:38,000
Mais ont-ils conclu qu'elles avaient

257
0:11:38.827,000 --> 0:11:41,000
vraiment fait les gens arrêter de fumer?

258
0:11:41.988,000 --> 0:11:43,000
Non. C'est de la science, pas de la magie.

259
0:11:44.53,000 --> 0:11:47,000
Donc, si nous sommes sur le point de dévoiler

260
0:11:47.72,000 --> 0:11:49,000
le pouvoir des données

261
0:11:50.382,000 --> 0:11:53,000
nous n'avons pas à suivre aveuglément

262
0:11:54.03,000 --> 0:11:57,000
Orwell dans sa vision d'un futur totalitaire,

263
0:11:57.466,000 --> 0:12:,000
ni Huxley et sa vision d'un futur banal,

264
0:12:00.583,000 --> 0:12:03,000
ni quelque horrible mixture des deux.

265
0:12:03.603,000 --> 0:12:05,000
Ce que nous devons faire,

266
0:12:05.982,000 --> 0:12:07,000
c'est respecter la pensée critique

267
0:12:08.7,000 --> 0:12:1,000
et s'inspirer d'exemples

268
0:12:10.729,000 --> 0:12:12,000
comme le Collectif Média Santé,

269
0:12:13.339,000 --> 0:12:15,000
comme ils disent dans les films de superhéros

270
0:12:15.667,000 --> 0:12:16,000
« Utilisons nos pouvoirs pour le bien ».

271
0:12:17.489,000 --> 0:12:18,000
Merci.

272
0:12:18.77,000 --> 0:12:21,000
(Applaudissements)

