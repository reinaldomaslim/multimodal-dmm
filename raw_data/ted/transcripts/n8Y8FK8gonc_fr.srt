1
0:00:,000 --> 0:00:07,000
Traducteur: Elisabeth Buffard Relecteur: Amélie Gourdon

2
0:00:16.26,000 --> 0:00:19,000
J'ai passé beaucoup de temps à l'hôpital.

3
0:00:19.26,000 --> 0:00:22,000
Et quelques années après en être sorti, j'y suis retourné,

4
0:00:22.26,000 --> 0:00:25,000
et le chef du service des brûlés était très excité de me voir.

5
0:00:25.26,000 --> 0:00:28,000
Il a dit : "Dan, j'ai un nouveau traitement fantastique pour vous."

6
0:00:28.26,000 --> 0:00:3,000
J'étais très emballé. Je l'ai accompagné jusqu'à son bureau.

7
0:00:30.26,000 --> 0:00:33,000
Et il m'a expliqué que, quand je me rase,

8
0:00:33.26,000 --> 0:00:36,000
j'ai des petits points noirs sur le côté gauche de mon visage là où il y a des poils,

9
0:00:36.26,000 --> 0:00:38,000
mais sur le côté droit de mon visage,

10
0:00:38.26,000 --> 0:00:4,000
j'ai été gravement brûlé donc je n'ai pas de poils,

11
0:00:40.26,000 --> 0:00:42,000
et cela crée une dissymétrie.

12
0:00:42.26,000 --> 0:00:44,000
Et quelle brillante idée a-t-il eue ?

13
0:00:44.26,000 --> 0:00:46,000
Il allait tatouer de petits points noirs

14
0:00:46.26,000 --> 0:00:49,000
sur le côté droit de mon visage

15
0:00:49.26,000 --> 0:00:51,000
pour me donner un aspect symétrique.

16
0:00:51.26,000 --> 0:00:54,000
Ça avait l'air intéressant. Il m'a demandé d'aller me raser.

17
0:00:54.26,000 --> 0:00:56,000
Je dois vous dire que c'était une étrange façon de se raser,

18
0:00:56.26,000 --> 0:00:58,000
parce que j'y réfléchissais

19
0:00:58.26,000 --> 0:01:,000
et je me suis rendu compte que la façon dont je me rasais à ce moment-là

20
0:01:00.26,000 --> 0:01:02,000
serait la même pour le reste de ma vie,

21
0:01:02.26,000 --> 0:01:04,000
parce que je devais conserver la même largeur.

22
0:01:04.26,000 --> 0:01:06,000
Quand je suis rentré dans son bureau,

23
0:01:06.26,000 --> 0:01:08,000
je n'étais pas très sûr.

24
0:01:08.26,000 --> 0:01:1,000
J'ai dit : "Je peux voir des preuves de cette technique ?"

25
0:01:10.26,000 --> 0:01:12,000
Alors il m'a montré des images

26
0:01:12.26,000 --> 0:01:14,000
de petites joues avec des petits points noirs,

27
0:01:14.26,000 --> 0:01:16,000
ça ne m'en disait pas long.

28
0:01:16.26,000 --> 0:01:18,000
J'ai dit : "Qu'est-ce qui se passe quand je vieillis et que mes poils blanchissent ?

29
0:01:18.26,000 --> 0:01:2,000
Que va-t-il se passer ?"

30
0:01:20.26,000 --> 0:01:22,000
"Oh, ne vous inquiétez pas pour ça", a-t-il dit.

31
0:01:22.26,000 --> 0:01:25,000
"Nous avons des lasers ; nous pouvons les blanchir."

32
0:01:25.26,000 --> 0:01:27,000
Mais j'étais encore inquiet,

33
0:01:27.26,000 --> 0:01:3,000
alors j'ai dit : "Vous savez quoi, je ne vais pas le faire."

34
0:01:30.26,000 --> 0:01:34,000
Et alors j'ai subi une tentative de culpabilisation comme rarement.

35
0:01:34.26,000 --> 0:01:37,000
Et c'est un juif qui vous le dit, alors ça veut dire beaucoup.

36
0:01:37.26,000 --> 0:01:39,000
(Rires)

37
0:01:39.26,000 --> 0:01:42,000
Et il a dit : " Dan, qu'est-ce qui ne va pas ?

38
0:01:42.26,000 --> 0:01:44,000
Ça te plait d'avoir l'air dissymétrique ?

39
0:01:44.26,000 --> 0:01:49,000
Est-ce que ça te procure une sorte de plaisir tordu ?

40
0:01:49.26,000 --> 0:01:51,000
Est-ce que les femmes ont pitié de toi

41
0:01:51.26,000 --> 0:01:54,000
et couchent avec toi plus souvent ?"

42
0:01:54.26,000 --> 0:01:57,000
Rien de tout ça ne s'est passé.

43
0:01:58.26,000 --> 0:02:,000
Et ça m'a beaucoup surpris,

44
0:02:00.26,000 --> 0:02:02,000
parce que j'ai suivi de nombreux traitements,

45
0:02:02.26,000 --> 0:02:04,000
il y a eu beaucoup de traitements que j'ai refusé de suivre,

46
0:02:04.26,000 --> 0:02:06,000
et on ne m'a jamais autant essayé de me faire culpabiliser.

47
0:02:06.26,000 --> 0:02:08,000
Mais j'ai décidé de ne pas suivre ce traitement.

48
0:02:08.26,000 --> 0:02:1,000
Et je suis allé trouver son adjoint et je lui ai demandé : "Qu'est-ce qui se passe ?

49
0:02:10.26,000 --> 0:02:12,000
D'où vient cette tentative de culpabilisation ?"

50
0:02:12.26,000 --> 0:02:16,000
Et il a expliqué qu'ils avaient déjà appliqué cette procédure sur deux patients,

51
0:02:16.26,000 --> 0:02:19,000
et il leur fallait un troisième patient pour l'article qu'ils étaient en train d'écrire.

52
0:02:19.26,000 --> 0:02:21,000
(Rires)

53
0:02:21.26,000 --> 0:02:23,000
Maintenant vous pensez probablement que ce type est un con.

54
0:02:23.26,000 --> 0:02:25,000
Bien, il en a l'air.

55
0:02:25.26,000 --> 0:02:28,000
Mais laissez-moi vous donner une perspective différente de la même histoire.

56
0:02:28.26,000 --> 0:02:31,000
Il y a quelques années, je faisais moi-même des expériences au laboratoire.

57
0:02:31.26,000 --> 0:02:33,000
Et quand nous faisons des expériences,

58
0:02:33.26,000 --> 0:02:36,000
en général nous espérons qu'un groupe se comportera différemment de l'autre.

59
0:02:36.26,000 --> 0:02:39,000
Nous avions donc un groupe dont j'espérais que les performances seraient très élevées,

60
0:02:39.26,000 --> 0:02:42,000
un autre groupe dont je pensais qu'elles seraient très faibles.

61
0:02:42.26,000 --> 0:02:44,000
Et quand j'ai eu les résultats, c'est ce que nous avons obtenu

62
0:02:44.26,000 --> 0:02:47,000
(j'étais très content), excepté une personne.

63
0:02:47.26,000 --> 0:02:49,000
Il y avait une personne dans le groupe

64
0:02:49.26,000 --> 0:02:51,000
qui était supposé avoir de très hautes performances,

65
0:02:51.26,000 --> 0:02:53,000
qui en fait en avait de très mauvaises.

66
0:02:53.26,000 --> 0:02:55,000
E il faisait baisser la moyenne,

67
0:02:55.26,000 --> 0:02:58,000
et détruisait la significativité statistique de mon test.

68
0:02:59.26,000 --> 0:03:01,000
Alors j'ai soigneusement examiné ce type.

69
0:03:01.26,000 --> 0:03:04,000
Il avait 20 et quelques années de plus que tous les autres dans l'échantillon.

70
0:03:04.26,000 --> 0:03:06,000
Et je me suis souvenu que le vieux poivrot

71
0:03:06.26,000 --> 0:03:08,000
était venu un jour au labo

72
0:03:08.26,000 --> 0:03:1,000
en voulant gagner de l'argent facilement

73
0:03:10.26,000 --> 0:03:12,000
et c'était ce type.

74
0:03:12.26,000 --> 0:03:14,000
J'ai pensé : "Fantastique ! Virons-le.

75
0:03:14.26,000 --> 0:03:17,000
Qui inclurait un poivrot dans un échantillon ?"

76
0:03:17.26,000 --> 0:03:19,000
Mais deux ou trois jours plus tard,

77
0:03:19.26,000 --> 0:03:21,000
mes étudiants et moi y avons réfléchi

78
0:03:21.26,000 --> 0:03:24,000
et nous avons dit : "Que se serait-il passé si ce poivrot n'était pas dans cette condition ?

79
0:03:24.26,000 --> 0:03:26,000
Que se serait-il passé s'il avait été dans l'autre groupe ?

80
0:03:26.26,000 --> 0:03:28,000
L'aurions-nous viré alors ?"

81
0:03:28.26,000 --> 0:03:3,000
Nous n'aurions probablement pas examiné du tout les données,

82
0:03:30.26,000 --> 0:03:32,000
et si nous les avions regardées,

83
0:03:32.26,000 --> 0:03:35,000
nous aurions probablement dit : "Fantastique ! Quel type intelligent qui a des performances si basses",

84
0:03:35.26,000 --> 0:03:37,000
parce qu'il aurait fait baisser la moyenne du groupe

85
0:03:37.26,000 --> 0:03:4,000
en nous donnant des résultats statistiques encore plus forts.

86
0:03:41.26,000 --> 0:03:44,000
Alors nous avons décidé de ne pas virer ce type et de refaire l'expérience.

87
0:03:44.26,000 --> 0:03:47,000
Mais vous savez, ces histoires,

88
0:03:47.26,000 --> 0:03:5,000
et beaucoup d'autres expériences que j'ai faites sur les conflits d'intérêts,

89
0:03:50.26,000 --> 0:03:52,000
mettent en évidence en gros

90
0:03:52.26,000 --> 0:03:54,000
deux points selon moi.

91
0:03:54.26,000 --> 0:03:57,000
Le premier point est que dans la vie nous rencontrons beaucoup de gens

92
0:03:57.26,000 --> 0:04:,000
qui, d'une manière ou d'une autre,

93
0:04:00.26,000 --> 0:04:02,000
essayent de nous tatouer le visage.

94
0:04:02.26,000 --> 0:04:05,000
Ils ont simplement des motivations qui les amènent à être aveuglés par la réalité

95
0:04:05.26,000 --> 0:04:08,000
et nous donnent des conseils qui manquent intrinsèquement d'objectivité.

96
0:04:08.26,000 --> 0:04:1,000
Et je suis sûr que c'est une chose que nous reconnaissons tous,

97
0:04:10.26,000 --> 0:04:12,000
et nous voyons que ça arrive.

98
0:04:12.26,000 --> 0:04:14,000
Nous ne le reconnaissons peut-être pas à tous les coups,

99
0:04:14.26,000 --> 0:04:16,000
mais nous comprenons que ça arrive.

100
0:04:16.26,000 --> 0:04:18,000
Le plus difficile, bien sûr, c'est de reconnaître

101
0:04:18.26,000 --> 0:04:2,000
que parfois, nous aussi,

102
0:04:20.26,000 --> 0:04:22,000
nous sommes aveuglés par nos propres motivations.

103
0:04:22.26,000 --> 0:04:25,000
Et c'est une leçon vraiment bien plus difficile à prendre en compte.

104
0:04:25.26,000 --> 0:04:29,000
Parce que nous ne voyons pas comment les conflits d'intérêt opèrent sur nous.

105
0:04:29.26,000 --> 0:04:31,000
Quand je faisais ces expériences,

106
0:04:31.26,000 --> 0:04:33,000
pour moi, j'aidais la science.

107
0:04:33.26,000 --> 0:04:35,000
J'éliminais les données

108
0:04:35.26,000 --> 0:04:37,000
pour révéler le vrai modèle des données.

109
0:04:37.26,000 --> 0:04:39,000
Je ne faisais rien de mal.

110
0:04:39.26,000 --> 0:04:41,000
Pour moi, j'étais en fait un chevalier

111
0:04:41.26,000 --> 0:04:43,000
qui essayait de faire avancer la science.

112
0:04:43.26,000 --> 0:04:45,000
Mais ce n'était pas le cas.

113
0:04:45.26,000 --> 0:04:48,000
En fait, j'interférais avec le processus avec beaucoup de bonnes intentions.

114
0:04:48.26,000 --> 0:04:5,000
Et je pense que le vrai problème est de trouver

115
0:04:50.26,000 --> 0:04:52,000
quels sont les cas dans nos vies

116
0:04:52.26,000 --> 0:04:54,000
où les conflits d'intérêts opèrent sur nous,

117
0:04:54.26,000 --> 0:04:57,000
et d'essayer de ne pas nous fier à notre propre intuition pour le résoudre,

118
0:04:57.26,000 --> 0:04:59,000
mais d'essayer de faire des choses

119
0:04:59.26,000 --> 0:05:01,000
qui nous empêchent d'être en proie avec ces comportements,

120
0:05:01.26,000 --> 0:05:04,000
parce que nous pouvons créer beaucoup de circonstances indésirables.

121
0:05:05.26,000 --> 0:05:07,000
Je veux vraiment vous laisser sur une pensée positive.

122
0:05:07.26,000 --> 0:05:09,000
Je veux dire, tout ça est très déprimant,

123
0:05:09.26,000 --> 0:05:12,000
les gens ont des conflits d'intérêt, nous ne le voyons pas et ainsi de suite.

124
0:05:12.26,000 --> 0:05:14,000
La perspective positive, je pense, de tout ça

125
0:05:14.26,000 --> 0:05:17,000
est que, si nous comprenons vraiment où nous commettons une erreur,

126
0:05:17.26,000 --> 0:05:19,000
si nous comprenons les mécanismes profonds

127
0:05:19.26,000 --> 0:05:21,000
de pourquoi et où nous échouons,

128
0:05:21.26,000 --> 0:05:23,000
nous pouvons vraiment espérer réparer les choses.

129
0:05:23.26,000 --> 0:05:25,000
Et je pense que l'espoir est là. Merci beaucoup.

130
0:05:25.26,000 --> 0:05:29,000
(Applaudissements)

