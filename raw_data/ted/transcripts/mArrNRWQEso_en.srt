1
0:00:13.381,000 --> 0:00:16,000
Charlie Rose: So Larry sent me an email

2
0:00:17.007,000 --> 0:00:18,000
and he basically said,

3
0:00:18.994,000 --> 0:00:21,000
we've got to make sure that we don't seem like we're

4
0:00:22.723,000 --> 0:00:26,000
a couple of middle-aged boring men.

5
0:00:27.214,000 --> 0:00:3,000
I said, I'm flattered by that --

6
0:00:30.256,000 --> 0:00:32,000
(Laughter) —

7
0:00:32.628,000 --> 0:00:35,000
because I'm a bit older,

8
0:00:36.143,000 --> 0:00:4,000
and he has a bit more net worth than I do.

9
0:00:40.294,000 --> 0:00:42,000
Larry Page: Well, thank you.

10
0:00:42.893,000 --> 0:00:44,000
CR: So we'll have a conversation about

11
0:00:45.873,000 --> 0:00:47,000
the Internet, and we'll have a conversation Google,

12
0:00:48.571,000 --> 0:00:49,000
and we'll have a conversation about search

13
0:00:50.005,000 --> 0:00:51,000
and privacy,

14
0:00:51.372,000 --> 0:00:52,000
and also about your philosophy

15
0:00:52.927,000 --> 0:00:54,000
and a sense of how you've connected the dots

16
0:00:55.383,000 --> 0:00:57,000
and how this journey that began

17
0:00:57.474,000 --> 0:00:58,000
some time ago

18
0:00:58.758,000 --> 0:00:59,000
has such interesting prospects.

19
0:01:00.653,000 --> 0:01:02,000
Mainly we want to talk about the future.

20
0:01:03.249,000 --> 0:01:04,000
So my first question: Where is Google

21
0:01:04.838,000 --> 0:01:06,000
and where is it going?

22
0:01:06.884,000 --> 0:01:07,000
LP: Well, this is something we think about a lot,

23
0:01:08.343,000 --> 0:01:11,000
and our mission we defined a long time ago

24
0:01:11.918,000 --> 0:01:13,000
is to organize the world's information

25
0:01:14.181,000 --> 0:01:17,000
and make it universally accessible and useful.

26
0:01:17.619,000 --> 0:01:19,000
And people always say,

27
0:01:19.661,000 --> 0:01:21,000
is that really what you guys are still doing?

28
0:01:21.876,000 --> 0:01:23,000
And I always kind of think about that myself,

29
0:01:23.994,000 --> 0:01:25,000
and I'm not quite sure.

30
0:01:26.19,000 --> 0:01:3,000
But actually, when I think about search,

31
0:01:30.197,000 --> 0:01:32,000
it's such a deep thing for all of us,

32
0:01:32.813,000 --> 0:01:34,000
to really understand what you want,

33
0:01:35.056,000 --> 0:01:37,000
to understand the world's information,

34
0:01:37.424,000 --> 0:01:4,000
and we're still very much in the early stages of that,

35
0:01:40.956,000 --> 0:01:41,000
which is totally crazy.

36
0:01:42.769,000 --> 0:01:44,000
We've been at it for 15 years already,

37
0:01:45.287,000 --> 0:01:48,000
but it's not at all done.

38
0:01:48.862,000 --> 0:01:5,000
CR: When it's done, how will it be?

39
0:01:51.538,000 --> 0:01:53,000
LP: Well, I guess,

40
0:01:54.255,000 --> 0:01:56,000
in thinking about where we're going --

41
0:01:56.655,000 --> 0:01:58,000
you know, why is it not done? --

42
0:01:58.942,000 --> 0:02:,000
a lot of it is just computing's kind of a mess.

43
0:02:01.378,000 --> 0:02:02,000
You know, your computer doesn't know where you are,

44
0:02:03.181,000 --> 0:02:05,000
it doesn't know what you're doing,

45
0:02:05.216,000 --> 0:02:06,000
it doesn't know what you know,

46
0:02:06.898,000 --> 0:02:08,000
and a lot we've been trying to do recently

47
0:02:09.474,000 --> 0:02:12,000
is just make your devices work,

48
0:02:12.769,000 --> 0:02:14,000
make them understand your context.

49
0:02:15.11,000 --> 0:02:17,000
Google Now, you know, knows where you are,

50
0:02:17.113,000 --> 0:02:19,000
knows what you may need.

51
0:02:19.295,000 --> 0:02:23,000
So really having computing work and understand you

52
0:02:23.403,000 --> 0:02:25,000
and understand that information,

53
0:02:25.459,000 --> 0:02:27,000
we really haven't done that yet.

54
0:02:27.769,000 --> 0:02:28,000
It's still very, very clunky.

55
0:02:29.318,000 --> 0:02:31,000
CR: Tell me, when you look at what Google is doing,

56
0:02:31.684,000 --> 0:02:33,000
where does Deep Mind fit?

57
0:02:34.653,000 --> 0:02:35,000
LP: Yeah, so Deep Mind is a company

58
0:02:36.237,000 --> 0:02:38,000
we just acquired recently.

59
0:02:38.768,000 --> 0:02:41,000
It's in the U.K.

60
0:02:41.85,000 --> 0:02:43,000
First, let me tell you the way we got there,

61
0:02:44.504,000 --> 0:02:46,000
which was looking at search

62
0:02:46.732,000 --> 0:02:47,000
and really understanding,

63
0:02:48.355,000 --> 0:02:5,000
trying to understand everything,

64
0:02:50.588,000 --> 0:02:51,000
and also make the computers not clunky

65
0:02:52.193,000 --> 0:02:54,000
and really understand you --

66
0:02:54.394,000 --> 0:02:56,000
like, voice was really important.

67
0:02:56.506,000 --> 0:02:58,000
So what's the state of the art on speech recognition?

68
0:02:59.367,000 --> 0:03:,000
It's not very good.

69
0:03:01.027,000 --> 0:03:03,000
It doesn't really understand you.

70
0:03:03.093,000 --> 0:03:05,000
So we started doing machine learning research

71
0:03:05.096,000 --> 0:03:06,000
to improve that.

72
0:03:06.633,000 --> 0:03:07,000
That helped a lot.

73
0:03:08.336,000 --> 0:03:1,000
And we started just looking at things like YouTube.

74
0:03:10.703,000 --> 0:03:11,000
Can we understand YouTube?

75
0:03:12.671,000 --> 0:03:14,000
But we actually ran machine learning on YouTube

76
0:03:15.357,000 --> 0:03:19,000
and it discovered cats, just by itself.

77
0:03:19.442,000 --> 0:03:21,000
Now, that's an important concept.

78
0:03:21.533,000 --> 0:03:23,000
And we realized there's really something here.

79
0:03:24.524,000 --> 0:03:26,000
If we can learn what cats are,

80
0:03:26.641,000 --> 0:03:28,000
that must be really important.

81
0:03:28.716,000 --> 0:03:3,000
So I think Deep Mind,

82
0:03:31.345,000 --> 0:03:33,000
what's really amazing about Deep Mind

83
0:03:33.709,000 --> 0:03:35,000
is that it can actually --

84
0:03:35.713,000 --> 0:03:38,000
they're learning things in this unsupervised way.

85
0:03:39.27,000 --> 0:03:41,000
They started with video games,

86
0:03:41.837,000 --> 0:03:43,000
and really just, maybe I can show the video,

87
0:03:44.33,000 --> 0:03:46,000
just playing video games,

88
0:03:46.534,000 --> 0:03:48,000
and learning how to do that automatically.

89
0:03:48.549,000 --> 0:03:49,000
CR: Take a look at the video games

90
0:03:50.401,000 --> 0:03:52,000
and how machines are coming to be able

91
0:03:52.811,000 --> 0:03:54,000
to do some remarkable things.

92
0:03:55.267,000 --> 0:03:56,000
LP: The amazing thing about this

93
0:03:56.596,000 --> 0:03:57,000
is this is, I mean, obviously,

94
0:03:58.276,000 --> 0:03:59,000
these are old games,

95
0:03:59.75,000 --> 0:04:03,000
but the system just sees what you see, the pixels,

96
0:04:04.548,000 --> 0:04:06,000
and it has the controls and it has the score,

97
0:04:06.979,000 --> 0:04:08,000
and it's learned to play all of these games,

98
0:04:09.19,000 --> 0:04:1,000
same program.

99
0:04:10.769,000 --> 0:04:12,000
It's learned to play all of these games

100
0:04:12.806,000 --> 0:04:13,000
with superhuman performance.

101
0:04:14.592,000 --> 0:04:15,000
We've not been able to do things like this

102
0:04:16.447,000 --> 0:04:17,000
with computers before.

103
0:04:17.965,000 --> 0:04:19,000
And maybe I'll just narrate this one quickly.

104
0:04:20.26,000 --> 0:04:22,000
This is boxing, and it figures out it can

105
0:04:23.065,000 --> 0:04:25,000
sort of pin the opponent down.

106
0:04:25.699,000 --> 0:04:26,000
The computer's on the left,

107
0:04:27.438,000 --> 0:04:3,000
and it's just racking up points.

108
0:04:30.523,000 --> 0:04:32,000
So imagine if this kind

109
0:04:32.609,000 --> 0:04:34,000
of intelligence were thrown at your schedule,

110
0:04:34.736,000 --> 0:04:38,000
or your information needs, or things like that.

111
0:04:39.373,000 --> 0:04:41,000
We're really just at the beginning of that,

112
0:04:41.991,000 --> 0:04:43,000
and that's what I'm really excited about.

113
0:04:44.356,000 --> 0:04:46,000
CR: When you look at all that's taken place

114
0:04:46.826,000 --> 0:04:48,000
with Deep Mind and the boxing,

115
0:04:49.41,000 --> 0:04:51,000
also a part of where we're going

116
0:04:51.75,000 --> 0:04:53,000
is artificial intelligence.

117
0:04:54.639,000 --> 0:04:56,000
Where are we, when you look at that?

118
0:04:57.438,000 --> 0:04:58,000
LP: Well, I think for me,

119
0:04:59.223,000 --> 0:05:,000
this is kind of one of the most exciting things

120
0:05:00.726,000 --> 0:05:01,000
I've seen in a long time.

121
0:05:02.638,000 --> 0:05:04,000
The guy who started this company, Demis,

122
0:05:05.051,000 --> 0:05:07,000
has a neuroscience and a computer science background.

123
0:05:07.829,000 --> 0:05:08,000
He went back to school

124
0:05:09.459,000 --> 0:05:12,000
to get his Ph.D. to study the brain.

125
0:05:12.585,000 --> 0:05:14,000
And so I think we're seeing a lot of exciting work

126
0:05:15.205,000 --> 0:05:18,000
going on that sort of crosses computer science

127
0:05:18.286,000 --> 0:05:19,000
and neuroscience

128
0:05:20.036,000 --> 0:05:22,000
in terms of really understanding

129
0:05:22.361,000 --> 0:05:24,000
what it takes to make something smart

130
0:05:24.815,000 --> 0:05:25,000
and do really interesting things.

131
0:05:26.53,000 --> 0:05:28,000
CR: But where's the level of it now?

132
0:05:28.668,000 --> 0:05:3,000
And how fast do you think we are moving?

133
0:05:31.374,000 --> 0:05:34,000
LP: Well, this is the state of the art right now,

134
0:05:34.643,000 --> 0:05:36,000
understanding cats on YouTube

135
0:05:36.774,000 --> 0:05:37,000
and things like that,

136
0:05:38.057,000 --> 0:05:4,000
improving voice recognition.

137
0:05:40.204,000 --> 0:05:42,000
We used a lot of machine learning

138
0:05:42.622,000 --> 0:05:44,000
to improve things incrementally,

139
0:05:45.101,000 --> 0:05:48,000
but I think for me, this example's really exciting,

140
0:05:48.495,000 --> 0:05:5,000
because it's one program

141
0:05:50.738,000 --> 0:05:52,000
that can do a lot of different things.

142
0:05:52.782,000 --> 0:05:53,000
CR: I don't know if we can do this,

143
0:05:53.92,000 --> 0:05:54,000
but we've got the image of the cat.

144
0:05:55.105,000 --> 0:05:56,000
It would be wonderful to see this.

145
0:05:56.859,000 --> 0:05:58,000
This is how machines looked at cats

146
0:05:59.368,000 --> 0:06:,000
and what they came up with.

147
0:06:00.483,000 --> 0:06:01,000
Can we see that image?

148
0:06:01.538,000 --> 0:06:03,000
LP: Yeah. CR: There it is. Can you see the cat?

149
0:06:03.94,000 --> 0:06:05,000
Designed by machines, seen by machines.

150
0:06:05.967,000 --> 0:06:06,000
LP: That's right.

151
0:06:07.077,000 --> 0:06:09,000
So this is learned from just watching YouTube.

152
0:06:09.684,000 --> 0:06:1,000
And there's no training,

153
0:06:11.551,000 --> 0:06:12,000
no notion of a cat,

154
0:06:12.935,000 --> 0:06:14,000
but this concept of a cat

155
0:06:15.496,000 --> 0:06:17,000
is something important that you would understand,

156
0:06:18.304,000 --> 0:06:2,000
and now that the machines can kind of understand.

157
0:06:20.827,000 --> 0:06:21,000
Maybe just finishing

158
0:06:21.999,000 --> 0:06:23,000
also on the search part,

159
0:06:24.221,000 --> 0:06:26,000
it started with search, really understanding

160
0:06:27.007,000 --> 0:06:29,000
people's context and their information.

161
0:06:29.571,000 --> 0:06:3,000
I did have a video

162
0:06:31.431,000 --> 0:06:33,000
I wanted to show quickly on that

163
0:06:33.441,000 --> 0:06:34,000
that we actually found.

164
0:06:35.088,000 --> 0:06:4,000
(Video) ["Soy, Kenya"]

165
0:06:40.58,000 --> 0:06:41,000
Zack Matere: Not long ago,

166
0:06:42.452,000 --> 0:06:44,000
I planted a crop of potatoes.

167
0:06:45.038,000 --> 0:06:48,000
Then suddenly they started dying one after the other.

168
0:06:48.438,000 --> 0:06:5,000
I checked out the books and they didn't tell me much.

169
0:06:51.188,000 --> 0:06:52,000
So, I went and I did a search.

170
0:06:53.134,000 --> 0:06:56,000
["Zack Matere, Farmer"]

171
0:06:57.609,000 --> 0:07:,000
Potato diseases.

172
0:07:00.756,000 --> 0:07:01,000
One of the websites told me

173
0:07:02.484,000 --> 0:07:03,000
that ants could be the problem.

174
0:07:04.386,000 --> 0:07:06,000
It said, sprinkle wood ash over the plants.

175
0:07:06.657,000 --> 0:07:08,000
Then after a few days the ants disappeared.

176
0:07:08.941,000 --> 0:07:1,000
I got excited about the Internet.

177
0:07:11.535,000 --> 0:07:12,000
I have this friend

178
0:07:13.2,000 --> 0:07:16,000
who really would like to expand his business.

179
0:07:16.818,000 --> 0:07:19,000
So I went with him to the cyber cafe

180
0:07:20.013,000 --> 0:07:22,000
and we checked out several sites.

181
0:07:22.554,000 --> 0:07:24,000
When I met him next, he was going to put a windmill

182
0:07:25.095,000 --> 0:07:27,000
at the local school.

183
0:07:27.789,000 --> 0:07:28,000
I felt proud because

184
0:07:29.393,000 --> 0:07:31,000
something that wasn't there before

185
0:07:31.421,000 --> 0:07:32,000
was suddenly there.

186
0:07:33.308,000 --> 0:07:35,000
I realized that not everybody

187
0:07:35.998,000 --> 0:07:36,000
can be able to access

188
0:07:37.532,000 --> 0:07:38,000
what I was able to access.

189
0:07:39.018,000 --> 0:07:4,000
I thought that I need to have an Internet

190
0:07:40.856,000 --> 0:07:41,000
that my grandmother can use.

191
0:07:42.657,000 --> 0:07:44,000
So I thought about a notice board.

192
0:07:45.114,000 --> 0:07:46,000
A simple wooden notice board.

193
0:07:47.03,000 --> 0:07:49,000
When I get information on my phone,

194
0:07:49.345,000 --> 0:07:51,000
I'm able to post the information

195
0:07:51.582,000 --> 0:07:52,000
on the notice board.

196
0:07:53.304,000 --> 0:07:55,000
So it's basically like a computer.

197
0:07:56.162,000 --> 0:07:59,000
I use the Internet to help people.

198
0:08:00.051,000 --> 0:08:03,000
I think I am searching for

199
0:08:03.461,000 --> 0:08:04,000
a better life

200
0:08:05.002,000 --> 0:08:09,000
for me and my neighbors.

201
0:08:09.116,000 --> 0:08:12,000
So many people have access to information,

202
0:08:13.1,000 --> 0:08:15,000
but there's no follow-up to that.

203
0:08:15.681,000 --> 0:08:17,000
I think the follow-up to that is our knowledge.

204
0:08:18.189,000 --> 0:08:19,000
When people have the knowledge,

205
0:08:19.795,000 --> 0:08:2,000
they can find solutions

206
0:08:21.425,000 --> 0:08:22,000
without having to helped out.

207
0:08:23.44,000 --> 0:08:25,000
Information is powerful,

208
0:08:25.561,000 --> 0:08:29,000
but it is how we use it that will define us.

209
0:08:30.163,000 --> 0:08:34,000
(Applause)

210
0:08:34.544,000 --> 0:08:36,000
LP: Now, the amazing thing about that video,

211
0:08:37.09,000 --> 0:08:38,000
actually, was we just read about it in the news,

212
0:08:38.556,000 --> 0:08:4,000
and we found this gentlemen,

213
0:08:41.061,000 --> 0:08:43,000
and made that little clip.

214
0:08:43.376,000 --> 0:08:44,000
CR: When I talk to people about you,

215
0:08:44.767,000 --> 0:08:46,000
they say to me, people who know you well, say,

216
0:08:47.372,000 --> 0:08:48,000
Larry wants to change the world,

217
0:08:49.263,000 --> 0:08:53,000
and he believes technology can show the way.

218
0:08:53.375,000 --> 0:08:54,000
And that means access to the Internet.

219
0:08:55.233,000 --> 0:08:56,000
It has to do with languages.

220
0:08:56.964,000 --> 0:08:58,000
It also means how people can get access

221
0:08:59.793,000 --> 0:09:01,000
and do things that will affect their community,

222
0:09:02.499,000 --> 0:09:04,000
and this is an example.

223
0:09:04.992,000 --> 0:09:07,000
LP: Yeah, that's right, and I think for me,

224
0:09:08.568,000 --> 0:09:1,000
I have been focusing on access more,

225
0:09:10.95,000 --> 0:09:12,000
if we're talking about the future.

226
0:09:13.148,000 --> 0:09:15,000
We recently released this Loon Project

227
0:09:15.822,000 --> 0:09:17,000
which is using balloons to do it.

228
0:09:18.122,000 --> 0:09:19,000
It sounds totally crazy.

229
0:09:19.782,000 --> 0:09:21,000
We can show the video here.

230
0:09:22.321,000 --> 0:09:23,000
Actually, two out of three people in the world

231
0:09:23.801,000 --> 0:09:25,000
don't have good Internet access now.

232
0:09:26.187,000 --> 0:09:28,000
We actually think this can really help people

233
0:09:29.093,000 --> 0:09:31,000
sort of cost-efficiently.

234
0:09:31.15,000 --> 0:09:34,000
CR: It's a balloon. LP: Yeah, get access to the Internet.

235
0:09:34.521,000 --> 0:09:36,000
CR: And why does this balloon give you access

236
0:09:36.664,000 --> 0:09:37,000
to the Internet?

237
0:09:37.877,000 --> 0:09:38,000
Because there was some interesting things

238
0:09:39.092,000 --> 0:09:4,000
you had to do to figure out how

239
0:09:40.926,000 --> 0:09:42,000
to make balloons possible,

240
0:09:43.057,000 --> 0:09:44,000
they didn't have to be tethered.

241
0:09:44.806,000 --> 0:09:46,000
LP: Yeah, and this is a good example of innovation.

242
0:09:46.887,000 --> 0:09:48,000
Like, we've been thinking about this idea

243
0:09:49.431,000 --> 0:09:5,000
for five years or more

244
0:09:51.203,000 --> 0:09:52,000
before we started working on it,

245
0:09:52.804,000 --> 0:09:53,000
but it was just really,

246
0:09:54.123,000 --> 0:09:57,000
how do we get access points up high, cheaply?

247
0:09:57.643,000 --> 0:09:58,000
You normally have to use satellites

248
0:09:59.435,000 --> 0:10:01,000
and it takes a long time to launch them.

249
0:10:02.374,000 --> 0:10:04,000
But you saw there how easy it is to launch a balloon

250
0:10:04.868,000 --> 0:10:05,000
and get it up,

251
0:10:06.387,000 --> 0:10:08,000
and actually again, it's the power of the Internet,

252
0:10:08.388,000 --> 0:10:09,000
I did a search on it,

253
0:10:10.168,000 --> 0:10:12,000
and I found, 30, 40 years ago,

254
0:10:12.472,000 --> 0:10:13,000
someone had put up a balloon

255
0:10:14.361,000 --> 0:10:16,000
and it had gone around the Earth multiple times.

256
0:10:17.166,000 --> 0:10:19,000
And I thought, why can't we do that today?

257
0:10:20.001,000 --> 0:10:22,000
And that's how this project got going.

258
0:10:22.368,000 --> 0:10:24,000
CR: But are you at the mercy of the wind?

259
0:10:24.698,000 --> 0:10:26,000
LP: Yeah, but it turns out,

260
0:10:26.82,000 --> 0:10:27,000
we did some weather simulations

261
0:10:28.313,000 --> 0:10:3,000
which probably hadn't really been done before,

262
0:10:30.86,000 --> 0:10:32,000
and if you control the altitude of the balloons,

263
0:10:32.97,000 --> 0:10:34,000
which you can do by pumping air into them

264
0:10:35.251,000 --> 0:10:36,000
and other ways,

265
0:10:37.073,000 --> 0:10:39,000
you can actually control roughly where they go,

266
0:10:40.002,000 --> 0:10:42,000
and so I think we can build a worldwide mesh

267
0:10:42.207,000 --> 0:10:45,000
of these balloons that can cover the whole planet.

268
0:10:45.546,000 --> 0:10:47,000
CR: Before I talk about the future and transportation,

269
0:10:47.788,000 --> 0:10:48,000
where you've been a nerd for a while,

270
0:10:49.683,000 --> 0:10:51,000
and this fascination you have with transportation

271
0:10:52.107,000 --> 0:10:54,000
and automated cars and bicycles,

272
0:10:54.17,000 --> 0:10:55,000
let me talk a bit about what's been the subject here

273
0:10:55.907,000 --> 0:10:57,000
earlier with Edward Snowden.

274
0:10:58.35,000 --> 0:11:01,000
It is security and privacy.

275
0:11:01.456,000 --> 0:11:03,000
You have to have been thinking about that.

276
0:11:03.796,000 --> 0:11:04,000
LP: Yeah, absolutely.

277
0:11:05.15,000 --> 0:11:07,000
I saw the picture of Sergey with Edward Snowden yesterday.

278
0:11:07.993,000 --> 0:11:09,000
Some of you may have seen it.

279
0:11:10.863,000 --> 0:11:13,000
But I think, for me, I guess,

280
0:11:14.034,000 --> 0:11:17,000
privacy and security are a really important thing.

281
0:11:17.696,000 --> 0:11:19,000
We think about it in terms of both things,

282
0:11:19.941,000 --> 0:11:21,000
and I think you can't have privacy without security,

283
0:11:22.844,000 --> 0:11:24,000
so let me just talk about security first,

284
0:11:25.215,000 --> 0:11:27,000
because you asked about Snowden and all of that,

285
0:11:27.811,000 --> 0:11:29,000
and then I'll say a little bit about privacy.

286
0:11:30.252,000 --> 0:11:33,000
I think for me, it's tremendously disappointing

287
0:11:34.052,000 --> 0:11:35,000
that the government

288
0:11:35.491,000 --> 0:11:37,000
secretly did all this stuff and didn't tell us.

289
0:11:37.821,000 --> 0:11:4,000
I don't think we can have a democracy

290
0:11:41.124,000 --> 0:11:44,000
if we're having to protect you and our users

291
0:11:44.554,000 --> 0:11:45,000
from the government

292
0:11:46.25,000 --> 0:11:48,000
for stuff that we've never had a conversation about.

293
0:11:49.053,000 --> 0:11:5,000
And I don't mean we have to know

294
0:11:50.949,000 --> 0:11:51,000
what the particular terrorist attack is they're worried

295
0:11:52.644,000 --> 0:11:53,000
about protecting us from,

296
0:11:54.406,000 --> 0:11:55,000
but we do need to know

297
0:11:56.204,000 --> 0:11:58,000
what the parameters of it is,

298
0:11:58.614,000 --> 0:12:,000
what kind of surveillance the government's

299
0:12:00.658,000 --> 0:12:02,000
going to do and how and why,

300
0:12:02.826,000 --> 0:12:04,000
and I think we haven't had that conversation.

301
0:12:05.103,000 --> 0:12:07,000
So I think the government's actually done

302
0:12:07.67,000 --> 0:12:09,000
itself a tremendous disservice

303
0:12:09.838,000 --> 0:12:11,000
by doing all that in secret.

304
0:12:11.999,000 --> 0:12:12,000
CR: Never coming to Google

305
0:12:13.614,000 --> 0:12:14,000
to ask for anything.

306
0:12:15.139,000 --> 0:12:17,000
LP: Not Google, but the public.

307
0:12:17.169,000 --> 0:12:2,000
I think we need to have a debate about that,

308
0:12:20.942,000 --> 0:12:22,000
or we can't have a functioning democracy.

309
0:12:23.441,000 --> 0:12:24,000
It's just not possible.

310
0:12:24.847,000 --> 0:12:26,000
So I'm sad that Google's

311
0:12:27.091,000 --> 0:12:29,000
in the position of protecting you and our users

312
0:12:29.707,000 --> 0:12:3,000
from the government

313
0:12:31.241,000 --> 0:12:33,000
doing secret thing that nobody knows about.

314
0:12:33.485,000 --> 0:12:34,000
It doesn't make any sense.

315
0:12:35.232,000 --> 0:12:37,000
CR: Yeah. And then there's a privacy side of it.

316
0:12:38.222,000 --> 0:12:4,000
LP: Yes. The privacy side,

317
0:12:40.649,000 --> 0:12:41,000
I think it's -- the world is changing.

318
0:12:42.618,000 --> 0:12:45,000
You carry a phone. It knows where you are.

319
0:12:46.523,000 --> 0:12:49,000
There's so much more information about you,

320
0:12:49.608,000 --> 0:12:51,000
and that's an important thing,

321
0:12:52.454,000 --> 0:12:54,000
and it makes sense why people are asking

322
0:12:54.726,000 --> 0:12:56,000
difficult questions.

323
0:12:56.762,000 --> 0:12:59,000
We spend a lot of time thinking about this

324
0:13:00.129,000 --> 0:13:02,000
and what the issues are.

325
0:13:02.84,000 --> 0:13:03,000
I'm a little bit --

326
0:13:04.569,000 --> 0:13:05,000
I think the main thing that we need to do

327
0:13:05.829,000 --> 0:13:07,000
is just provide people choice,

328
0:13:08.191,000 --> 0:13:1,000
show them what data's being collected --

329
0:13:10.703,000 --> 0:13:14,000
search history, location data.

330
0:13:15.454,000 --> 0:13:17,000
We're excited about incognito mode in Chrome,

331
0:13:18.226,000 --> 0:13:2,000
and doing that in more ways,

332
0:13:20.475,000 --> 0:13:21,000
just giving people more choice

333
0:13:21.871,000 --> 0:13:24,000
and more awareness of what's going on.

334
0:13:25.164,000 --> 0:13:27,000
I also think it's very easy.

335
0:13:27.557,000 --> 0:13:28,000
What I'm worried is that we throw out

336
0:13:28.834,000 --> 0:13:3,000
the baby with the bathwater.

337
0:13:30.924,000 --> 0:13:32,000
And I look at, on your show, actually,

338
0:13:33.838,000 --> 0:13:34,000
I kind of lost my voice,

339
0:13:35.557,000 --> 0:13:36,000
and I haven't gotten it back.

340
0:13:36.888,000 --> 0:13:37,000
I'm hoping that by talking to you

341
0:13:38.532,000 --> 0:13:39,000
I'm going to get it back.

342
0:13:40.185,000 --> 0:13:41,000
CR: If I could do anything, I would do that.

343
0:13:41.917,000 --> 0:13:43,000
LP: All right. So get out your voodoo doll

344
0:13:44.097,000 --> 0:13:46,000
and whatever you need to do.

345
0:13:46.516,000 --> 0:13:48,000
But I think, you know what, I look at that,

346
0:13:48.844,000 --> 0:13:49,000
I made that public,

347
0:13:50.674,000 --> 0:13:51,000
and I got all this information.

348
0:13:51.891,000 --> 0:13:53,000
We got a survey done on medical conditions

349
0:13:54.62,000 --> 0:13:57,000
with people who have similar issues,

350
0:13:57.991,000 --> 0:14:01,000
and I look at medical records, and I say,

351
0:14:02.732,000 --> 0:14:03,000
wouldn't it be amazing

352
0:14:04.137,000 --> 0:14:06,000
if everyone's medical records were available

353
0:14:06.187,000 --> 0:14:07,000
anonymously

354
0:14:07.87,000 --> 0:14:09,000
to research doctors?

355
0:14:10.506,000 --> 0:14:13,000
And when someone accesses your medical record,

356
0:14:13.547,000 --> 0:14:14,000
a research doctor,

357
0:14:15.156,000 --> 0:14:17,000
they could see, you could see which doctor

358
0:14:17.79,000 --> 0:14:18,000
accessed it and why,

359
0:14:19.65,000 --> 0:14:2,000
and you could maybe learn about

360
0:14:21.23,000 --> 0:14:22,000
what conditions you have.

361
0:14:22.86,000 --> 0:14:23,000
I think if we just did that,

362
0:14:24.362,000 --> 0:14:26,000
we'd save 100,000 lives this year.

363
0:14:26.527,000 --> 0:14:28,000
CR: Absolutely. Let me go — (Applause)

364
0:14:29.475,000 --> 0:14:31,000
LP: So I guess I'm just very worried that

365
0:14:32.237,000 --> 0:14:33,000
with Internet privacy,

366
0:14:34.043,000 --> 0:14:36,000
we're doing the same thing we're doing with medical records,

367
0:14:36.347,000 --> 0:14:38,000
is we're throwing out the baby with the bathwater,

368
0:14:38.876,000 --> 0:14:39,000
and we're not really thinking

369
0:14:40.704,000 --> 0:14:42,000
about the tremendous good that can come

370
0:14:42.914,000 --> 0:14:44,000
from people sharing information

371
0:14:45.105,000 --> 0:14:47,000
with the right people in the right ways.

372
0:14:47.682,000 --> 0:14:49,000
CR: And the necessary condition

373
0:14:49.919,000 --> 0:14:5,000
that people have to have confidence

374
0:14:51.621,000 --> 0:14:53,000
that their information will not be abused.

375
0:14:54.076,000 --> 0:14:55,000
LP: Yeah, and I had this problem with my voice stuff.

376
0:14:55.853,000 --> 0:14:56,000
I was scared to share it.

377
0:14:57.361,000 --> 0:14:58,000
Sergey encouraged me to do that,

378
0:14:59.251,000 --> 0:15:,000
and it was a great thing to do.

379
0:15:01.078,000 --> 0:15:02,000
CR: And the response has been overwhelming.

380
0:15:02.812,000 --> 0:15:03,000
LP: Yeah, and people are super positive.

381
0:15:04.472,000 --> 0:15:06,000
We got thousands and thousands of people

382
0:15:07.305,000 --> 0:15:08,000
with similar conditions,

383
0:15:08.593,000 --> 0:15:11,000
which there's no data on today.

384
0:15:11.621,000 --> 0:15:12,000
So it was a really good thing.

385
0:15:12.977,000 --> 0:15:15,000
CR: So talking about the future, what is it about you

386
0:15:15.996,000 --> 0:15:18,000
and transportation systems?

387
0:15:19.754,000 --> 0:15:21,000
LP: Yeah. I guess I was just frustrated

388
0:15:21.931,000 --> 0:15:23,000
with this when I was at college in Michigan.

389
0:15:24.47,000 --> 0:15:25,000
I had to get on the bus and take it

390
0:15:25.92,000 --> 0:15:26,000
and wait for it.

391
0:15:27.562,000 --> 0:15:29,000
And it was cold and snowing.

392
0:15:29.741,000 --> 0:15:31,000
I did some research on how much it cost,

393
0:15:32.396,000 --> 0:15:38,000
and I just became a bit obsessed with transportation systems.

394
0:15:38.821,000 --> 0:15:4,000
CR: And that began the idea of an automated car.

395
0:15:41.191,000 --> 0:15:42,000
LP: Yeah, about 18 years ago I learned about

396
0:15:42.885,000 --> 0:15:45,000
people working on automated cars,

397
0:15:46.067,000 --> 0:15:47,000
and I became fascinated by that,

398
0:15:47.69,000 --> 0:15:49,000
and it takes a while to get these projects going,

399
0:15:50.467,000 --> 0:15:55,000
but I'm super excited about the possibilities of that

400
0:15:55.564,000 --> 0:15:56,000
improving the world.

401
0:15:57.232,000 --> 0:16:01,000
There's 20 million people or more injured per year.

402
0:16:01.758,000 --> 0:16:02,000
It's the leading cause of death

403
0:16:03.744,000 --> 0:16:05,000
for people under 34 in the U.S.

404
0:16:05.874,000 --> 0:16:06,000
CR: So you're talking about saving lives.

405
0:16:07.425,000 --> 0:16:09,000
LP: Yeah, and also saving space

406
0:16:09.78,000 --> 0:16:12,000
and making life better.

407
0:16:13.695,000 --> 0:16:17,000
Los Angeles is half parking lots and roads,

408
0:16:17.94,000 --> 0:16:18,000
half of the area,

409
0:16:19.673,000 --> 0:16:21,000
and most cities are not far behind, actually.

410
0:16:22.5,000 --> 0:16:23,000
It's just crazy

411
0:16:24.064,000 --> 0:16:25,000
that that's what we use our space for.

412
0:16:25.657,000 --> 0:16:27,000
CR: And how soon will we be there?

413
0:16:28,000 --> 0:16:29,000
LP: I think we can be there very, very soon.

414
0:16:29.926,000 --> 0:16:32,000
We've driven well over 100,000 miles

415
0:16:33.427,000 --> 0:16:37,000
now totally automated.

416
0:16:37.52,000 --> 0:16:4,000
I'm super excited about getting that out quickly.

417
0:16:41.172,000 --> 0:16:43,000
CR: But it's not only you're talking about automated cars.

418
0:16:43.577,000 --> 0:16:45,000
You also have this idea for bicycles.

419
0:16:45.963,000 --> 0:16:47,000
LP: Well at Google, we got this idea

420
0:16:48.209,000 --> 0:16:51,000
that we should just provide free bikes to everyone,

421
0:16:51.66,000 --> 0:16:53,000
and that's been amazing, most of the trips.

422
0:16:54.428,000 --> 0:16:55,000
You see bikes going everywhere,

423
0:16:56.014,000 --> 0:16:57,000
and the bikes wear out.

424
0:16:57.58,000 --> 0:16:58,000
They're getting used 24 hours a day.

425
0:16:59.034,000 --> 0:17:01,000
CR: But you want to put them above the street, too.

426
0:17:01.194,000 --> 0:17:02,000
LP: Well I said, how do we get people

427
0:17:02.769,000 --> 0:17:03,000
using bikes more?

428
0:17:04.296,000 --> 0:17:05,000
CR: We may have a video here.

429
0:17:05.921,000 --> 0:17:06,000
LP: Yeah, let's show the video.

430
0:17:07.199,000 --> 0:17:1,000
I just got excited about this.

431
0:17:10.291,000 --> 0:17:14,000
(Music)

432
0:17:16.213,000 --> 0:17:18,000
So this is actually how you might separate

433
0:17:18.638,000 --> 0:17:21,000
bikes from cars with minimal cost.

434
0:17:26.711,000 --> 0:17:27,000
Anyway, it looks totally crazy,

435
0:17:28.466,000 --> 0:17:3,000
but I was actually thinking about our campus,

436
0:17:30.793,000 --> 0:17:32,000
working with the Zippies and stuff,

437
0:17:32.853,000 --> 0:17:34,000
and just trying to get a lot more bike usage,

438
0:17:35.151,000 --> 0:17:36,000
and I was thinking about,

439
0:17:36.699,000 --> 0:17:38,000
how do you cost-effectively separate

440
0:17:39.53,000 --> 0:17:4,000
the bikes from traffic?

441
0:17:40.944,000 --> 0:17:41,000
And I went and searched,

442
0:17:42.094,000 --> 0:17:43,000
and this is what I found.

443
0:17:43.465,000 --> 0:17:44,000
And we're not actually working on this,

444
0:17:45.31,000 --> 0:17:46,000
that particular thing,

445
0:17:46.602,000 --> 0:17:48,000
but it gets your imagination going.

446
0:17:48.656,000 --> 0:17:49,000
CR: Let me close with this.

447
0:17:50.42,000 --> 0:17:52,000
Give me a sense of the philosophy of your own mind.

448
0:17:52.765,000 --> 0:17:54,000
You have this idea of [Google X].

449
0:17:55.253,000 --> 0:17:57,000
You don't simply want

450
0:17:58.249,000 --> 0:18:03,000
to go in some small, measurable arena of progress.

451
0:18:03.845,000 --> 0:18:04,000
LP: Yeah, I think

452
0:18:05.558,000 --> 0:18:07,000
many of the things we just talked about are like that,

453
0:18:07.689,000 --> 0:18:09,000
where they're really --

454
0:18:10.641,000 --> 0:18:13,000
I almost use the economic concept of additionality,

455
0:18:14.271,000 --> 0:18:16,000
which means that you're doing something

456
0:18:16.461,000 --> 0:18:18,000
that wouldn't happen unless you were actually doing it.

457
0:18:19.409,000 --> 0:18:22,000
And I think the more you can do things like that,

458
0:18:22.549,000 --> 0:18:24,000
the bigger impact you have,

459
0:18:24.62,000 --> 0:18:26,000
and that's about doing things

460
0:18:27.61,000 --> 0:18:3,000
that people might not think are possible.

461
0:18:31.217,000 --> 0:18:32,000
And I've been amazed,

462
0:18:33.046,000 --> 0:18:35,000
the more I learn about technology,

463
0:18:35.275,000 --> 0:18:37,000
the more I realize I don't know,

464
0:18:37.471,000 --> 0:18:4,000
and that's because this technological horizon,

465
0:18:40.808,000 --> 0:18:42,000
the thing that you can see to do next,

466
0:18:43.705,000 --> 0:18:44,000
the more you learn about technology,

467
0:18:45.545,000 --> 0:18:47,000
the more you learn what's possible.

468
0:18:48.147,000 --> 0:18:5,000
You learn that the balloons are possible

469
0:18:50.393,000 --> 0:18:52,000
because there's some material that will work for them.

470
0:18:52.73,000 --> 0:18:54,000
CR: What's interesting about you too, though, for me,

471
0:18:55.109,000 --> 0:18:56,000
is that, we have lots of people

472
0:18:56.82,000 --> 0:18:58,000
who are thinking about the future,

473
0:18:58.962,000 --> 0:19:01,000
and they are going and looking and they're coming back,

474
0:19:02.23,000 --> 0:19:04,000
but we never see the implementation.

475
0:19:04.357,000 --> 0:19:05,000
I think of somebody you knew

476
0:19:05.962,000 --> 0:19:07,000
and read about, Tesla.

477
0:19:08.869,000 --> 0:19:11,000
The principle of that for you is what?

478
0:19:12.673,000 --> 0:19:13,000
LP: Well, I think invention is not enough.

479
0:19:14.458,000 --> 0:19:15,000
If you invent something,

480
0:19:15.679,000 --> 0:19:18,000
Tesla invented electric power that we use,

481
0:19:18.874,000 --> 0:19:2,000
but he struggled to get it out to people.

482
0:19:21.535,000 --> 0:19:22,000
That had to be done by other people.

483
0:19:23.219,000 --> 0:19:24,000
It took a long time.

484
0:19:24.845,000 --> 0:19:27,000
And I think if we can actually combine both things,

485
0:19:28.712,000 --> 0:19:31,000
where we have an innovation and invention focus,

486
0:19:32.243,000 --> 0:19:34,000
plus the ability to really -- a company

487
0:19:35.215,000 --> 0:19:36,000
that can really commercialize things

488
0:19:37.213,000 --> 0:19:38,000
and get them to people

489
0:19:38.843,000 --> 0:19:4,000
in a way that's positive for the world

490
0:19:40.918,000 --> 0:19:42,000
and to give people hope.

491
0:19:42.974,000 --> 0:19:44,000
You know, I'm amazed with the Loon Project

492
0:19:45.748,000 --> 0:19:47,000
just how excited people were about that,

493
0:19:48.534,000 --> 0:19:49,000
because it gave them hope

494
0:19:50.348,000 --> 0:19:51,000
for the two thirds of the world

495
0:19:51.969,000 --> 0:19:53,000
that doesn't have Internet right now that's any good.

496
0:19:54.695,000 --> 0:19:56,000
CR: Which is a second thing about corporations.

497
0:19:56.817,000 --> 0:19:58,000
You are one of those people who believe

498
0:19:59.293,000 --> 0:20:01,000
that corporations are an agent of change

499
0:20:01.61,000 --> 0:20:02,000
if they are run well.

500
0:20:03.081,000 --> 0:20:04,000
LP: Yeah. I'm really dismayed

501
0:20:04.902,000 --> 0:20:07,000
most people think companies are basically evil.

502
0:20:08.196,000 --> 0:20:09,000
They get a bad rap.

503
0:20:09.962,000 --> 0:20:11,000
And I think that's somewhat correct.

504
0:20:12.203,000 --> 0:20:14,000
Companies are doing the same incremental thing

505
0:20:15.073,000 --> 0:20:16,000
that they did 50 years ago

506
0:20:16.836,000 --> 0:20:17,000
or 20 years ago.

507
0:20:18.467,000 --> 0:20:19,000
That's not really what we need.

508
0:20:19.837,000 --> 0:20:21,000
We need, especially in technology,

509
0:20:22.055,000 --> 0:20:24,000
we need revolutionary change,

510
0:20:24.172,000 --> 0:20:25,000
not incremental change.

511
0:20:25.585,000 --> 0:20:26,000
CR: You once said, actually,

512
0:20:26.754,000 --> 0:20:27,000
as I think I've got this about right,

513
0:20:28.572,000 --> 0:20:29,000
that you might consider,

514
0:20:30.217,000 --> 0:20:31,000
rather than giving your money,

515
0:20:31.97,000 --> 0:20:34,000
if you were leaving it to some cause,

516
0:20:35.29,000 --> 0:20:37,000
just simply giving it to Elon Musk,

517
0:20:37.296,000 --> 0:20:38,000
because you had confidence

518
0:20:38.459,000 --> 0:20:39,000
that he would change the future,

519
0:20:40.301,000 --> 0:20:41,000
and that you would therefore —

520
0:20:42.078,000 --> 0:20:43,000
LP: Yeah, if you want to go Mars,

521
0:20:43.662,000 --> 0:20:44,000
he wants to go to Mars,

522
0:20:45.383,000 --> 0:20:46,000
to back up humanity,

523
0:20:47.354,000 --> 0:20:48,000
that's a worthy goal, but it's a company,

524
0:20:49.026,000 --> 0:20:51,000
and it's philanthropical.

525
0:20:51.581,000 --> 0:20:53,000
So I think we aim to do kind of similar things.

526
0:20:54.533,000 --> 0:20:56,000
And I think, you ask, we have a lot of employees

527
0:20:57.52,000 --> 0:21:,000
at Google who have become pretty wealthy.

528
0:21:00.835,000 --> 0:21:02,000
People make a lot of money in technology.

529
0:21:03.355,000 --> 0:21:05,000
A lot of people in the room are pretty wealthy.

530
0:21:05.511,000 --> 0:21:07,000
You're working because you want to change the world.

531
0:21:07.825,000 --> 0:21:08,000
You want to make it better.

532
0:21:09.587,000 --> 0:21:12,000
Why isn't the company that you work for

533
0:21:13.032,000 --> 0:21:14,000
worthy not just of your time

534
0:21:14.975,000 --> 0:21:16,000
but your money as well?

535
0:21:17.126,000 --> 0:21:18,000
I mean, but we don't have a concept of that.

536
0:21:18.848,000 --> 0:21:2,000
That's not how we think about companies,

537
0:21:21.152,000 --> 0:21:22,000
and I think it's sad,

538
0:21:22.619,000 --> 0:21:25,000
because companies are most of our effort.

539
0:21:26.386,000 --> 0:21:28,000
They're where most of people's time is,

540
0:21:28.901,000 --> 0:21:29,000
where a lot of the money is,

541
0:21:30.755,000 --> 0:21:32,000
and so I think I'd like for us to help out

542
0:21:33.107,000 --> 0:21:34,000
more than we are.

543
0:21:34.233,000 --> 0:21:35,000
CR: When I close conversations with lots of people,

544
0:21:35.954,000 --> 0:21:36,000
I always ask this question:

545
0:21:37.733,000 --> 0:21:38,000
What state of mind,

546
0:21:39.248,000 --> 0:21:4,000
what quality of mind is it

547
0:21:41.057,000 --> 0:21:42,000
that has served you best?

548
0:21:42.824,000 --> 0:21:44,000
People like Rupert Murdoch have said curiosity,

549
0:21:45.345,000 --> 0:21:47,000
and other people in the media have said that.

550
0:21:47.973,000 --> 0:21:5,000
Bill Gates and Warren Buffett have said focus.

551
0:21:50.997,000 --> 0:21:51,000
What quality of mind,

552
0:21:52.424,000 --> 0:21:53,000
as I leave this audience,

553
0:21:53.798,000 --> 0:21:56,000
has enabled you to think about the future

554
0:21:57.328,000 --> 0:21:58,000
and at the same time

555
0:21:58.975,000 --> 0:22:,000
change the present?

556
0:22:01.18,000 --> 0:22:02,000
LP: You know, I think the most important thing --

557
0:22:02.85,000 --> 0:22:03,000
I looked at lots of companies

558
0:22:04.462,000 --> 0:22:07,000
and why I thought they don't succeed over time.

559
0:22:07.765,000 --> 0:22:09,000
We've had a more rapid turnover of companies.

560
0:22:10.598,000 --> 0:22:12,000
And I said, what did they fundamentally do wrong?

561
0:22:13.367,000 --> 0:22:15,000
What did those companies all do wrong?

562
0:22:15.534,000 --> 0:22:18,000
And usually it's just that they missed the future.

563
0:22:18.806,000 --> 0:22:2,000
And so I think, for me,

564
0:22:21.25,000 --> 0:22:23,000
I just try to focus on that and say,

565
0:22:23.674,000 --> 0:22:25,000
what is that future really going to be

566
0:22:25.858,000 --> 0:22:26,000
and how do we create it,

567
0:22:27.645,000 --> 0:22:31,000
and how do we cause our organization,

568
0:22:32.312,000 --> 0:22:34,000
to really focus on that

569
0:22:34.752,000 --> 0:22:37,000
and drive that at a really high rate?

570
0:22:38.077,000 --> 0:22:39,000
And so that's been curiosity,

571
0:22:39.437,000 --> 0:22:4,000
it's been looking at things

572
0:22:41.17,000 --> 0:22:42,000
people might not think about,

573
0:22:42.888,000 --> 0:22:45,000
working on things that no one else is working on,

574
0:22:45.993,000 --> 0:22:48,000
because that's where the additionality really is,

575
0:22:49.299,000 --> 0:22:5,000
and be willing to do that,

576
0:22:50.85,000 --> 0:22:51,000
to take that risk.

577
0:22:52.232,000 --> 0:22:53,000
Look at Android.

578
0:22:53.297,000 --> 0:22:55,000
I felt guilty about working on Android

579
0:22:56.082,000 --> 0:22:57,000
when it was starting.

580
0:22:57.398,000 --> 0:22:58,000
It was a little startup we bought.

581
0:22:59.356,000 --> 0:23:01,000
It wasn't really what we were really working on.

582
0:23:02.026,000 --> 0:23:04,000
And I felt guilty about spending time on that.

583
0:23:04.521,000 --> 0:23:05,000
That was stupid.

584
0:23:05.975,000 --> 0:23:06,000
That was the future, right?

585
0:23:07.026,000 --> 0:23:09,000
That was a good thing to be working on.

586
0:23:09.311,000 --> 0:23:1,000
CR: It is great to see you here.

587
0:23:10.728,000 --> 0:23:11,000
It's great to hear from you,

588
0:23:12.188,000 --> 0:23:14,000
and a pleasure to sit at this table with you.

589
0:23:14.485,000 --> 0:23:14,000
Thanks, Larry.

590
0:23:15.413,000 --> 0:23:17,000
LP: Thank you.

591
0:23:17.516,000 --> 0:23:2,000
(Applause)

592
0:23:21.448,000 --> 0:23:24,000
CR: Larry Page.

