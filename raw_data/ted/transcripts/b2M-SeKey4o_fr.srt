1
0:00:,000 --> 0:00:07,000
Traducteur: Margaux Cervatius Relecteur: Meryl Ducray

2
0:00:12.495,000 --> 0:00:14,000
Dans deux semaines, ça fera neuf ans

3
0:00:15.27,000 --> 0:00:19,000
depuis ma première apparition sur le plateau sacré de « Jeopardy ».

4
0:00:19.37,000 --> 0:00:2,000
Neuf ans, c'est long.

5
0:00:21.22,000 --> 0:00:22,000
Et étant donné l'âge moyen des gens qui regardent « Jeopardy »,

6
0:00:23.138,000 --> 0:00:24,000
je pense que ça veut dire

7
0:00:24.43,000 --> 0:00:27,000
que la plupart des gens qui m'ont vu dans l'émission sont maintenant décédés.

8
0:00:27.621,000 --> 0:00:29,000
(Rires)

9
0:00:29.804,000 --> 0:00:3,000
Mais pas tous, un petit nombre est encore en vie.

10
0:00:31.243,000 --> 0:00:33,000
Parfois on me reconnait dans un magasin ou autre.

11
0:00:33.756,000 --> 0:00:35,000
Et dans ce cas, on me voit comme Monsieur-je-sais-tout.

12
0:00:36.458,000 --> 0:00:38,000
Je pense que je ne peux plus rien y faire, c'est trop tard.

13
0:00:38.912,000 --> 0:00:4,000
Pour le meilleur ou pour le pire, je serai désormais

14
0:00:41.103,000 --> 0:00:44,000
le type qui sait un tas de choses bizarres.

15
0:00:44.337,000 --> 0:00:46,000
Mais je ne m'en plains pas.

16
0:00:46.625,000 --> 0:00:48,000
J'ai l'impression que ça a toujours été ma destinée,

17
0:00:49.038,000 --> 0:00:52,000
même si pendant longtemps j'en avais honte.

18
0:00:52.505,000 --> 0:00:54,000
Dès l'adolescence, vous vous rendez compte que

19
0:00:55.271,000 --> 0:00:58,000
connaître le 2ème prénom de Capitaine Kirk ne séduit pas les filles.

20
0:00:58.459,000 --> 0:00:59,000
(Rires)

21
0:00:59.624,000 --> 0:01:03,000
Et donc, j'ai longtemps caché que j'étais un monsieur je-sais-tout

22
0:01:03.855,000 --> 0:01:06,000
Mais en y regardant de plus près, c'était déjà là avant.

23
0:01:07.079,000 --> 0:01:1,000
J'étais le genre de gamin qui agace ses parents

24
0:01:10.208,000 --> 0:01:12,000
avec la super anecdote qu'il vient de lire sur

25
0:01:13.14,000 --> 0:01:14,000
la comète de Halley ou les calmars géants

26
0:01:14.841,000 --> 0:01:17,000
ou la taille de la plus grosse tarte à la citrouille ou n'importe quoi d'autre.

27
0:01:18.77,000 --> 0:01:21,000
J'ai maintenant un fils de 10 ans qui est pareil.

28
0:01:21.987,000 --> 0:01:25,000
Et je comprends combien c'est agaçant donc le karma existe.

29
0:01:26.088,000 --> 0:01:27,000
(Rires)

30
0:01:27.588,000 --> 0:01:29,000
Et j'adorais les jeux télévisés, j'en étais fasciné.

31
0:01:30.421,000 --> 0:01:33,000
Je me rappelle m'être mis à pleurer le premier jour en maternelle, en 1979,

32
0:01:33.827,000 --> 0:01:35,000
parce que je réalisais que même si j'étais super content d'aller à l'école,

33
0:01:36.352,000 --> 0:01:39,000
j'allais louper « Hollywood Squares » et « Family Feud ».

34
0:01:39.685,000 --> 0:01:43,000
J'allais louper mes émissions.

35
0:01:43.912,000 --> 0:01:44,000
Et plus tard, au milieu des années 1980,

36
0:01:45.602,000 --> 0:01:46,000
quand « Jeopardy » a recommencé à être diffusé,

37
0:01:47.213,000 --> 0:01:51,000
je me rappelle revenir en courant de l'école pour regarder l'émission.

38
0:01:51.286,000 --> 0:01:56,000
C'était mon émission préférée, avant même qu'elle ne finance ma maison.

39
0:01:56.788,000 --> 0:01:58,000
J'ai vécu à l'étranger, en Corée du Sud, où mon père travaillait

40
0:01:59.202,000 --> 0:02:01,000
et il n'y avait qu'une seule chaine télé en anglais :

41
0:02:01.619,000 --> 0:02:02,000
Armed Forces TV.

42
0:02:02.869,000 --> 0:02:04,000
Si vous ne parliez pas coréen, voilà ce que vous regardiez.

43
0:02:05.035,000 --> 0:02:08,000
Alors avec mes amis, nous nous dépêchions de rentrer pour regarder « Jeopardy ».

44
0:02:08.351,000 --> 0:02:11,000
J'ai toujours été obsédé par la culture générale.

45
0:02:11.352,000 --> 0:02:16,000
Je me souviens, dans les années 80, quand le Trivial Pursuit était à la mode,

46
0:02:16.535,000 --> 0:02:18,000
je me débrouillais bien face à mes parents.

47
0:02:19.369,000 --> 0:02:21,000
Il y a une certaine fierté lorsque vous savez un truc

48
0:02:21.417,000 --> 0:02:24,000
que Maman et Papa ignorent.

49
0:02:24.662,000 --> 0:02:27,000
Vous savez un truc sur les Beatles que Papa ne connait pas.

50
0:02:28.218,000 --> 0:02:3,000
Et vous pensez : « Ha ha, la connaissance, c'est le pouvoir --

51
0:02:31.202,000 --> 0:02:38,000
si le bon élément est utilisé au bon moment. »

52
0:02:38.386,000 --> 0:02:39,000
Jamais un conseiller d'orientation n'a pensé

53
0:02:40.202,000 --> 0:02:42,000
que je pouvais faire carrière avec ça,

54
0:02:42.586,000 --> 0:02:44,000
avoir un diplôme en culture générale

55
0:02:45.035,000 --> 0:02:48,000
ou être un ancien candidat de jeux télévisé professionnel.

56
0:02:48.452,000 --> 0:02:5,000
Et donc j'ai abandonné trop tôt.

57
0:02:50.852,000 --> 0:02:51,000
Je n'ai pas cherché à comprendre quoi faire de ce talent.

58
0:02:52.286,000 --> 0:02:54,000
J'ai étudié l'informatique car c'était la mode

59
0:02:54.751,000 --> 0:02:55,000
et je suis devenu programmeur en informatique --

60
0:02:56.612,000 --> 0:02:57,000
pas spécialement bon ni heureux

61
0:02:58.411,000 --> 0:03:03,000
lorsque je suis passé à « Jeopardy » pour la première fois en 2004.

62
0:03:03.42,000 --> 0:03:04,000
Mais c'était mon travail.

63
0:03:04.745,000 --> 0:03:06,000
Et mon expérience dans l'informatique est encore plus ironique

64
0:03:07.585,000 --> 0:03:11,000
que quelques années plus tard, vers 2009,

65
0:03:11.801,000 --> 0:03:13,000
Jeopardy m'a rappelé pour me dire

66
0:03:14.339,000 --> 0:03:16,000
« Ce n'est que le début, mais IBM nous a annoncé

67
0:03:16.662,000 --> 0:03:21,000
qu'ils veulent fabriquer un super ordinateur pour te battre au jeu.

68
0:03:21.746,000 --> 0:03:22,000
Es-tu partant ? »

69
0:03:23.244,000 --> 0:03:24,000
Je n'en avais jamais entendu parler avant.

70
0:03:24.834,000 --> 0:03:26,000
Et bien entendu j'ai accepté, pour différentes raisons.

71
0:03:27.502,000 --> 0:03:29,000
D'abord, car j'adore jouer à « Jeopardy ».

72
0:03:29.754,000 --> 0:03:32,000
C'est amusant. La chose la plus amusante à faire habillé.

73
0:03:33.426,000 --> 0:03:35,000
(Rires)

74
0:03:35.43,000 --> 0:03:36,000
Et je le ferais même gratuitement.

75
0:03:36.835,000 --> 0:03:37,000
Je ne pense pas qu'ils ne le savent pas, heureusement,

76
0:03:38.568,000 --> 0:03:41,000
mais j'y retournerais, même pour des bons de réductions pour Arby's.

77
0:03:41.786,000 --> 0:03:43,000
J'adore « Jeopardy », ça a toujours été comme ça.

78
0:03:43.918,000 --> 0:03:47,000
Et deuxièmement, parce que je suis un geek et cela semblait être l'avenir.

79
0:03:48.152,000 --> 0:03:49,000
J'ai toujours imaginé que, dans le futur,

80
0:03:50.018,000 --> 0:03:53,000
des personnes joueraient contre des ordinateurs dans les jeux télévisés,

81
0:03:53.07,000 --> 0:03:54,000
et désormais je pouvais y prendre part.

82
0:03:54.618,000 --> 0:03:55,000
Je n'allais pas refuser cela.

83
0:03:55.702,000 --> 0:03:56,000
La troisième raison pour laquelle j'ai accepté,

84
0:03:56.835,000 --> 0:03:58,000
c'est parce que j'étais sûr de gagner.

85
0:03:59.435,000 --> 0:04:01,000
J'avais pris des cours en intelligence artificielle.

86
0:04:01.571,000 --> 0:04:05,000
Je savais qu'aucun ordinateur ne pouvait faire ce dont vous avez besoin pour gagner à « Jeopardy ».

87
0:04:05.901,000 --> 0:04:08,000
Les gens ne se rendent pas compte de la difficulté pour coder ce genre de programme

88
0:04:09.101,000 --> 0:04:12,000
qui peut lire un indice de « Jeopardy » dans une langue naturelle comme l'anglais

89
0:04:12.661,000 --> 0:04:15,000
et comprendre les doubles sens, les jeux de mots, les pièges

90
0:04:16.286,000 --> 0:04:18,000
et donc déchiffrer le sens de l'indice.

91
0:04:18.853,000 --> 0:04:22,000
Ce qu'un gamin de 3 ou 4 ans peut faire

92
0:04:23.494,000 --> 0:04:25,000
se révèle très difficile pour un ordinateur.

93
0:04:25.719,000 --> 0:04:28,000
J'ai pensé, ça va être un jeu d'enfant.

94
0:04:28.828,000 --> 0:04:32,000
Oui, j'accepte de venir détruire l'ordinateur et défendre mon espèce.

95
0:04:33.752,000 --> 0:04:34,000
(Rires)

96
0:04:35.603,000 --> 0:04:36,000
Mais au fil des ans,

97
0:04:37.203,000 --> 0:04:4,000
alors que IBM commençait à mettre de l'argent, de la main d'oeuvre et de la technologie là-dedans,

98
0:04:40.994,000 --> 0:04:42,000
j'ai commencé à avoir ponctuellement des nouvelles d'eux,

99
0:04:43.085,000 --> 0:04:44,000
et j'ai commencé à devenir un peu inquiet.

100
0:04:44.87,000 --> 0:04:5,000
Je me souviens d'un article de journal sur les logiciels de réponse aux questions.

101
0:04:50.953,000 --> 0:04:53,000
Il y avait dedans un diagramme de dispersion sur les performances à « Jeopardy »,

102
0:04:54.87,000 --> 0:04:57,000
des milliers de points représentaient les grands champions de « Jeopardy »

103
0:04:58.521,000 --> 0:05:,000
avec une courbe de leur performance en nombre de --

104
0:05:00.803,000 --> 0:05:04,000
j'allais dire réponses aux questions,

105
0:05:04.869,000 --> 0:05:05,000
mais c'est plutôt de questions répondues --

106
0:05:06.828,000 --> 0:05:08,000
par rapport à l'exactitude de ces réponses.

107
0:05:09.219,000 --> 0:05:12,000
Donc il y a un certain niveau de performance que l'ordinateur doit atteindre.

108
0:05:12.578,000 --> 0:05:13,000
Au début, l'ordinateur était très faible.

109
0:05:14.369,000 --> 0:05:17,000
Aucun logiciel ne pouvait faire concurrence dans ce domaine.

110
0:05:17.736,000 --> 0:05:19,000
Mais ensuite la courbe commence à grimper.

111
0:05:19.92,000 --> 0:05:21,000
Et elle s'approche dangereusement du « nuage des gagnants ».

112
0:05:22.403,000 --> 0:05:23,000
En haut à droite du diagramme, j'ai remarqué

113
0:05:24.077,000 --> 0:05:3,000
des points plus foncés, d'une couleur différente.

114
0:05:30.202,000 --> 0:05:31,000
Je me suis demandé, qu'est-ce que c'est?

115
0:05:31.77,000 --> 0:05:34,000
« Les points noirs en haut à droite représentent les 74 victoires du champion de Jeopardy Ken Jennings »

116
0:05:35.662,000 --> 0:05:37,000
J'ai vu cette courbe venir vers moi.

117
0:05:37.854,000 --> 0:05:38,000
Et j'ai compris que ça ressemble à ça

118
0:05:38.954,000 --> 0:05:4,000
lorsque le futur vient pour toi.

119
0:05:40.994,000 --> 0:05:41,000
(Rires)

120
0:05:42.937,000 --> 0:05:44,000
Ce n'est pas le viseur de Terminator.

121
0:05:45.119,000 --> 0:05:49,000
C'est une simple ligne qui se rapproche petit à petit de ce que tu sais faire,

122
0:05:49.286,000 --> 0:05:52,000
la seule chose qui te distingue des autres, la chose où tu es le meilleur.

123
0:05:52.421,000 --> 0:05:56,000
Et quand le jeu arriva finallement un an plus tard,

124
0:05:57.173,000 --> 0:05:59,000
il était très différent de mon expérience passée à « Jeopardy ».

125
0:06:00.036,000 --> 0:06:02,000
On ne jouait pas à Los Angeles, sur le plateau habituel de « Jeopardy ».

126
0:06:02.537,000 --> 0:06:04,000
Watson ne se déplace pas.

127
0:06:04.803,000 --> 0:06:05,000
Watson, en fait, est énorme.

128
0:06:05.903,000 --> 0:06:09,000
Des milliers de processeurs, un téraoctet de mémoire,

129
0:06:10.436,000 --> 0:06:11,000
soit mille milliards d'octets.

130
0:06:11.854,000 --> 0:06:13,000
Nous sommes entrés dans la salle climatisée du serveur.

131
0:06:14.287,000 --> 0:06:17,000
Le seul adversaire de « Jeopardy » dont j'ai pu voir l'intérieur.

132
0:06:17.912,000 --> 0:06:2,000
Et donc Watson ne se déplace pas.

133
0:06:21.236,000 --> 0:06:25,000
C'est à vous de venir, de faire le pélerinage.

134
0:06:25.27,000 --> 0:06:27,000
Donc l'autre joueur humain et moi sommes arrivés

135
0:06:27.327,000 --> 0:06:3,000
dans ce laboratoire de recherche secret d'IBM

136
0:06:30.535,000 --> 0:06:32,000
au milieu des forêts enneigées du Comté de Westchester

137
0:06:33.083,000 --> 0:06:34,000
pour affronter l'ordinateur.

138
0:06:34.665,000 --> 0:06:36,000
Nous avons réalisé tout de suite que

139
0:06:36.715,000 --> 0:06:38,000
l'ordinateur avait le gros avantage d'être à domicile.

140
0:06:39.614,000 --> 0:06:41,000
Il y avait un gros logo Watson au milieu du plateau.

141
0:06:41.965,000 --> 0:06:43,000
Comme si vous jouiez contre les Chicago Bulls

142
0:06:44.632,000 --> 0:06:46,000
et il y a leur truc en plein milieu du terrain.

143
0:06:46.932,000 --> 0:06:49,000
Le public était rempli de programmeurs et dirigeants d'IBM

144
0:06:50.168,000 --> 0:06:51,000
venus soutenir leur petit bijou

145
0:06:52.065,000 --> 0:06:54,000
pour lequel ils ont dépensé des millions de dollars,

146
0:06:54.431,000 --> 0:06:56,000
espérant contre toute attente que les humains allaient rater leur coup.

147
0:06:57.369,000 --> 0:06:58,000
Ils portaient des pancartes « Allez Watson ! »

148
0:06:59.166,000 --> 0:07:03,000
et applaudissaient comme des mères-poules leur petit protégé à chaque fois qu'il devinait juste.

149
0:07:03.814,000 --> 0:07:08,000
Je crois même que certains avaient peint « W-A-T-S-O-N » sur leur ventre.

150
0:07:09.681,000 --> 0:07:14,000
Imaginez des programmateurs en informatique avec les lettres « W-A-T-S-O-N » sur leur ventre,

151
0:07:15.085,000 --> 0:07:16,000
ce n'est pas très plaisant à voir.

152
0:07:16.752,000 --> 0:07:19,000
Mais ils avaient raison. Ils avaient tout à fait raison.

153
0:07:19.799,000 --> 0:07:21,000
Je ne veux pas gâcher la surprise si vous avez encore l'émission sur votre magnétoscope,

154
0:07:22.215,000 --> 0:07:25,000
mais Watson l'a largement emporté.

155
0:07:25.382,000 --> 0:07:27,000
Je me souviens, j'étais debout derrière le podium

156
0:07:28.249,000 --> 0:07:3,000
et j'entendais ce petit bruit de clic.

157
0:07:31.014,000 --> 0:07:34,000
Ils avaient fabriqué un pouce robotique pour appuyer sur le buzzer.

158
0:07:34.383,000 --> 0:07:38,000
Et vous entendiez ce petit clic, clic, clic.

159
0:07:38.498,000 --> 0:07:4,000
Et je me suis dit, c'est fini.

160
0:07:41.251,000 --> 0:07:42,000
Je me sentais obsolète.

161
0:07:42.848,000 --> 0:07:45,000
Je me sentais comme un ouvrier de Détroit dans les années 80

162
0:07:45.899,000 --> 0:07:47,000
qui regardait un robot faire son travail sur la chaîne d'assemblage.

163
0:07:48.75,000 --> 0:07:53,000
Je pensais que participant de jeux télé était maintenant le premier métier qui était devenu désué

164
0:07:53.841,000 --> 0:07:56,000
sous le nouveau régime des ordinateurs pensant.

165
0:07:57.62,000 --> 0:07:58,000
Et ce n'était pas le dernier.

166
0:07:59.577,000 --> 0:08:01,000
Si vous regardez les informations, vous verrez parfois

167
0:08:02.219,000 --> 0:08:03,000
je vois cela tout le temps --

168
0:08:03.911,000 --> 0:08:07,000
que dans les pharmacies, il y a désormais une machine pour remplir les ordonnances médicales

169
0:08:08.669,000 --> 0:08:1,000
à la place des pharmaciens humains.

170
0:08:11.078,000 --> 0:08:13,000
Et beaucoup de cabinets d'avocats se débarrassent des assistants juridiques

171
0:08:13.269,000 --> 0:08:17,000
car il y a des logiciels qui peuvent résumer les dossiers et décisions.

172
0:08:17.661,000 --> 0:08:19,000
Plus besoin d'assistants humains pour cela de nos jours.

173
0:08:20.169,000 --> 0:08:23,000
J'ai lu un article sur un programme dans lequel

174
0:08:23.302,000 --> 0:08:24,000
on entre les résultats d'un match de baseball ou de football.

175
0:08:25.086,000 --> 0:08:27,000
et qui crée alors un article comme si un humain

176
0:08:27.662,000 --> 0:08:28,000
avait regardé et commenté le match.

177
0:08:29.087,000 --> 0:08:32,000
Bien sûr, ces nouvelles technologies ne sont pas aussi intelligentes ou créatives

178
0:08:33.086,000 --> 0:08:34,000
que les humains qu'elles remplacent,

179
0:08:34.521,000 --> 0:08:37,000
mais elles sont plus rapides, et plus que tout, beaucoup, beaucoup moins chères.

180
0:08:38.338,000 --> 0:08:43,000
Je me demande donc quelles répercussions économiques cela aura.

181
0:08:43.355,000 --> 0:08:46,000
Certains économistes disent que, grâce à ces technologies,

182
0:08:46.701,000 --> 0:08:48,000
nous entrerons dans un nouvel âge d'or de loisirs :

183
0:08:48.826,000 --> 0:08:5,000
nous aurons le temps de faire ce que nous aimons vraiment

184
0:08:51.119,000 --> 0:08:57,000
car toutes les tâches pénibles seront accomplies par Watson et ses frères numériques.

185
0:08:58.091,000 --> 0:08:59,000
A contrario, d'autres affirment

186
0:08:59.805,000 --> 0:09:01,000
qu'une partie de la classe moyenne voit

187
0:09:02.021,000 --> 0:09:07,000
la nouvelle technologie lui enlever ce qu'elle sait faire

188
0:09:07.055,000 --> 0:09:08,000
et que c'est en fait une menace

189
0:09:08.619,000 --> 0:09:09,000
qui devrait être davantage prise au sérieux.

190
0:09:10.124,000 --> 0:09:11,000
Je ne suis pas un économiste.

191
0:09:11.973,000 --> 0:09:14,000
Tout ce que je sais c'est ce que l'on ressent quand on se retrouve sans travail.

192
0:09:15.245,000 --> 0:09:18,000
C'était super démoralisant. C'était horrible.

193
0:09:18.305,000 --> 0:09:2,000
C'était la seule chose à laquelle j'étais bon

194
0:09:20.536,000 --> 0:09:24,000
et tout ce qu'il a fallu c'est qu'IBM mette des dizaines de millions de dollars, ses brillants cerveaux

195
0:09:24.689,000 --> 0:09:26,000
et des milliers de processeurs travaillant en parallèle

196
0:09:27.222,000 --> 0:09:29,000
pour pouvoir faire la même chose.

197
0:09:29.306,000 --> 0:09:32,000
Ils ont réussi à être meilleurs et plus rapides à la télé

198
0:09:32.537,000 --> 0:09:34,000
et « Désolé, Ken. Nous n'avons plus besoin de toi. »

199
0:09:35.272,000 --> 0:09:38,000
Et je me suis demandé ce que ça veut dire

200
0:09:39.005,000 --> 0:09:4,000
si l'on commence à pouvoir externaliser

201
0:09:40.744,000 --> 0:09:43,000
pas seulement des fonctions cérébrales secondaires.

202
0:09:44.369,000 --> 0:09:46,000
Vous vous souvenez sûrement de l'époque

203
0:09:46.844,000 --> 0:09:48,000
où l'on devait connaitre les numéros de téléphone, ceux de nos amis.

204
0:09:49.671,000 --> 0:09:5,000
Et puis une machine capable de le faire est arrivée

205
0:09:51.662,000 --> 0:09:53,000
et maintenant nous n'avons plus à nous souvenir des numéros.

206
0:09:54.055,000 --> 0:09:55,000
J'ai lu qu'il est prouvé que l'hippocampe,

207
0:09:55.938,000 --> 0:09:59,000
le partie du cerveau chargée de la navigation spatiale,

208
0:10:00.382,000 --> 0:10:01,000
rétrécit et s'atrophie chez les personnes

209
0:10:02.036,000 --> 0:10:04,000
qui utilisent un GPS

210
0:10:04.638,000 --> 0:10:06,000
car elles n'utilisent plus leur sens de l'orientation.

211
0:10:07.202,000 --> 0:10:09,000
Elles ne font qu'obéir à la petite voix sur le tableau de bord.

212
0:10:09.536,000 --> 0:10:11,000
Résultat, la partie du cerveau censée faire ce genre de chose

213
0:10:12.14,000 --> 0:10:13,000
perd alors en taille et en efficacité.

214
0:10:13.953,000 --> 0:10:16,000
Et donc que se passe-t-il quand les ordinateurs sont meilleurs que nous

215
0:10:17.744,000 --> 0:10:2,000
pour savoir et se rappeler des choses ?

216
0:10:21.244,000 --> 0:10:25,000
Notre cerveau entier va-t-il commencer à rétrécir et s'atrophier comme ça ?

217
0:10:25.32,000 --> 0:10:28,000
Notre culture va-t-elle accorder moins d'importance à la connaissance?

218
0:10:29.087,000 --> 0:10:32,000
J'ai toujours cru à l'importance de nos connaissances,

219
0:10:32.959,000 --> 0:10:39,000
et donc cette hypothèse me terrifie.

220
0:10:40.183,000 --> 0:10:44,000
Plus j'y pensais, plus je réalisais que c'était toujours important.

221
0:10:45.16,000 --> 0:10:47,000
Nos connaissances sont toujours importantes.

222
0:10:47.369,000 --> 0:10:5,000
J'en suis venu à me dire que ceux d'entre nous

223
0:10:50.371,000 --> 0:10:53,000
qui ont ces infos dans leur têtes ont deux avantages

224
0:10:54.042,000 --> 0:10:58,000
sur ceux qui disent « Ah ouais, attends, je cherche sur Google. »

225
0:10:58.868,000 --> 0:11:,000
Il y a un avantage de volume et un avantage de temps.

226
0:11:01.536,000 --> 0:11:02,000
Tout d'abord, l'avantage du volume

227
0:11:03.092,000 --> 0:11:05,000
est lié à la complexité du monde actuel.

228
0:11:05.724,000 --> 0:11:06,000
Il y a tellement d'informations autour de nous.

229
0:11:07.141,000 --> 0:11:08,000
Cela était possible uniquement

230
0:11:08.425,000 --> 0:11:1,000
au temps de la Renaissance.

231
0:11:10.591,000 --> 0:11:11,000
Désormais, il est difficile d'avoir des connaissances correctes

232
0:11:11.857,000 --> 0:11:14,000
dans tous les domaines de l'activité humaine.

233
0:11:14.941,000 --> 0:11:15,000
Il y en a trop.

234
0:11:16.545,000 --> 0:11:18,000
Il parait que l'étendue de l'information humaine,

235
0:11:19.042,000 --> 0:11:21,000
la somme totale d'informations,

236
0:11:21.091,000 --> 0:11:23,000
est multipliée par 2 tous les 18 mois environ.

237
0:11:23.627,000 --> 0:11:26,000
Cela veut dire qu'entre aujourd'hui et fin 2014,

238
0:11:27.209,000 --> 0:11:3,000
on aura généré autant d'informations, en terme de gigaoctets,

239
0:11:30.676,000 --> 0:11:34,000
que ce qu'a généré toute l'humanité durant tous les millénaires passés.

240
0:11:34.756,000 --> 0:11:36,000
Tout ça est multiplié par 2 tous les 18 mois.

241
0:11:36.827,000 --> 0:11:39,000
C'est effrayant car pour prendre des décisions importantes,

242
0:11:40.186,000 --> 0:11:43,000
nous avons besoin de connaitre plein de choses différentes.

243
0:11:43.462,000 --> 0:11:48,000
Des décisions comme où aller à l'université ? Quelles études choisir ?

244
0:11:48.494,000 --> 0:11:49,000
Pour qui voter ?

245
0:11:49.928,000 --> 0:11:5,000
Dois-je accepter ce travail ou celui-là ?

246
0:11:51.694,000 --> 0:11:54,000
Ces décisions nécessitent des jugements corrects

247
0:11:55.328,000 --> 0:11:57,000
sur différents types de faits.

248
0:11:57.448,000 --> 0:11:58,000
Si nous avons ces éléments dans nos têtes,

249
0:11:59.185,000 --> 0:12:01,000
nous pourrons prendre des décisions réfléchies.

250
0:12:01.885,000 --> 0:12:03,000
Mais, au contraire, si nous devons les rechercher toutes,

251
0:12:04.552,000 --> 0:12:05,000
nous pourrions avoir des problèmes.

252
0:12:06.412,000 --> 0:12:07,000
D'après un sondage de National Geographic,

253
0:12:08.35,000 --> 0:12:1,000
près de 80% des électeurs

254
0:12:10.67,000 --> 0:12:14,000
qui votent aux élections présidentielles américaines sur des sujets comme la politique étrangère

255
0:12:14.685,000 --> 0:12:16,000
sont incapables de situer l'Irak ou l'Afghanistan sur une carte.

256
0:12:17.652,000 --> 0:12:19,000
Si vous ne pouvez pas faire ce premier pas,

257
0:12:20.218,000 --> 0:12:23,000
allez-vous vraiment vous renseigner sur les milliers de choses

258
0:12:23.253,000 --> 0:12:25,000
nécessaires pour comprendre la politique étrangère américaine ?

259
0:12:26.219,000 --> 0:12:27,000
Très probablement pas.

260
0:12:27.484,000 --> 0:12:28,000
A un moment, vous allez juste dire

261
0:12:28.801,000 --> 0:12:29,000
« Vous savez quoi ? Y'a trop de choses à savoir. J'abandonne. »

262
0:12:30.668,000 --> 0:12:31,000
et vous prendrez une décision moins informée.

263
0:12:32.468,000 --> 0:12:35,000
L'autre avantage concerne le temps dont vous disposez

264
0:12:35.952,000 --> 0:12:36,000
si vous avez toutes ces choses en tête.

265
0:12:37.886,000 --> 0:12:4,000
Je me rappellerai toujours l'histoire de cette petite fille prénommée Tilly Smith.

266
0:12:41.302,000 --> 0:12:43,000
Elle avait 10 ans et venait du Surrey, en Angleterre.

267
0:12:43.985,000 --> 0:12:46,000
Il y a quelques années, elle était en vacances avec ses parents à Phuket, en Thailande.

268
0:12:47.318,000 --> 0:12:48,000
Un matin, elle court vers eux sur la plage

269
0:12:48.968,000 --> 0:12:5,000
et en disant « Maman, Papa, il faut partir de la plage »

270
0:12:51.553,000 --> 0:12:53,000
Ils répondent : « Mais pourquoi ? On vient juste d'arriver. »

271
0:12:54.1,000 --> 0:12:57,000
Elle rétorque : « Dans le cours de géographie de M. Kearney, le mois dernier,

272
0:12:57.2,000 --> 0:12:59,000
on a appris que lorsque la marée se retire soudainement

273
0:13:00.135,000 --> 0:13:01,000
et que les vagues bouillonnent au loin,

274
0:13:01.827,000 --> 0:13:05,000
c'est le signe d'un tsunami et on doit quitter la plage. »

275
0:13:06.025,000 --> 0:13:08,000
Comment réagiriez-vous si votre fille de 10 ans vient vous dire ça ?

276
0:13:08.22,000 --> 0:13:09,000
Ses parents ont réfléchi,

277
0:13:09.564,000 --> 0:13:11,000
et, à leur crédit, ont finalement décidé de la croire.

278
0:13:11.698,000 --> 0:13:13,000
Ils ont informé le maitre nageur et ont regagné leur hotel.

279
0:13:13.713,000 --> 0:13:16,000
Le maitre nageur a évacué plus de 100 personnes de la plage,

280
0:13:17.597,000 --> 0:13:19,000
heureusement car c'était le 26 décembre 2004,

281
0:13:20.502,000 --> 0:13:21,000
le jour du tsunami qui a tué des milliers de personnes

282
0:13:22.097,000 --> 0:13:25,000
en Asie du Sud-Est et autour de l'océan Indien.

283
0:13:26.063,000 --> 0:13:28,000
Mais pas sur cette plage, pas à Mai Khao Beach,

284
0:13:28.537,000 --> 0:13:33,000
car cette petite fille s'était souvenue du cours de géographie du mois précédent.

285
0:13:33.751,000 --> 0:13:35,000
J'aime cette histoire car elle montre

286
0:13:35.848,000 --> 0:13:38,000
le pouvoir d'une information connue et utilisée au bon endroit et au bon moment.

287
0:13:39.463,000 --> 0:13:43,000
Des infos comme celle-ci sont utiles

288
0:13:43.735,000 --> 0:13:45,000
mais cela se voit plus facilement dans les jeux télé que dans la réalité.

289
0:13:46.48,000 --> 0:13:48,000
Dans ce cas, il s'agit de la réalité.

290
0:13:48.583,000 --> 0:13:49,000
Cela se produit tous les jours dans la vie réelle.

291
0:13:50.202,000 --> 0:13:52,000
Ce n'est pas toujours un tsunami, c'est souvent une évènement social.

292
0:13:52.416,000 --> 0:13:56,000
Une réunion, un entretien d'embauche ou un premier rendez-vous.

293
0:13:57.129,000 --> 0:13:58,000
Il est plus facile d'échanger lorsque

294
0:13:58.803,000 --> 0:14:01,000
deux personnes réalisent qu'elles partagent certaines connaissances.

295
0:14:02.183,000 --> 0:14:04,000
Vous me dites d'où vous venez et je réponds « ah oui ».

296
0:14:04.734,000 --> 0:14:05,000
ou votre université ou votre travail,

297
0:14:06.367,000 --> 0:14:07,000
et je sais assez de choses à ce sujet

298
0:14:08.284,000 --> 0:14:09,000
pour continuer la conversation.

299
0:14:09.833,000 --> 0:14:1,000
Les gens aiment cette connexion partagée qui se crée

300
0:14:11.702,000 --> 0:14:13,000
lorsque quelqu'un sait quelque chose sur vous.

301
0:14:13.994,000 --> 0:14:17,000
Comme s'ils avaient pris le temps de vous connaitre avant même de vous rencontrer.

302
0:14:18.004,000 --> 0:14:19,000
C'est souvent l'avantage du temps.

303
0:14:19.416,000 --> 0:14:2,000
C'est moins efficace si vous répondez « Attends,

304
0:14:20.901,000 --> 0:14:25,000
tu es de Fargo, Dakota du Nord. Laisse moi regarder.

305
0:14:26.465,000 --> 0:14:27,000
Ah, Roger Maris vient de Fargo. »

306
0:14:28.367,000 --> 0:14:31,000
Cela ne marche pas, c'est même agaçant.

307
0:14:31.4,000 --> 0:14:33,000
(Rires)

308
0:14:33.847,000 --> 0:14:38,000
Samuel Parr, théologien et penseur britannique du XVIIIe siècle,

309
0:14:39.549,000 --> 0:14:45,000
ami du Dr. Johnson, a dit : « C'est toujours mieux de savoir une chose que de ne pas la savoir. »

310
0:14:45.917,000 --> 0:14:49,000
Et si j'ai une devise dans ma vie, c'est bien celle-là.

311
0:14:50.45,000 --> 0:14:55,000
J'ai toujours pensé que nos connaissances -- que la connaissance est un bien absolu,

312
0:14:55.983,000 --> 0:14:57,000
que les choses apprises et conservées dans nos têtes

313
0:14:58.783,000 --> 0:15:,000
font ce que nous sommes,

314
0:15:00.801,000 --> 0:15:02,000
en tant qu'individu et espèce.

315
0:15:03.318,000 --> 0:15:07,000
Je ne sais pas si je veux vivre dans un monde où la connaissance est désuète.

316
0:15:07.415,000 --> 0:15:1,000
Je ne veux pas vivre dans un monde où la culture générale

317
0:15:10.751,000 --> 0:15:11,000
a été remplacée par ces bulles spécialisées

318
0:15:12.661,000 --> 0:15:15,000
et où personne ne connait les liens

319
0:15:16.167,000 --> 0:15:18,000
qui liaient nos civilisations ensemble.

320
0:15:18.683,000 --> 0:15:19,000
Je ne veux pas être le dernier Monsieur-je-sais-tout

321
0:15:20.617,000 --> 0:15:21,000
assis sur une montagne quelque part,

322
0:15:22.035,000 --> 0:15:26,000
se récitant les capitales des états et les titres des épisodes des Simpsons

323
0:15:26.4,000 --> 0:15:29,000
et les paroles des chansons d'ABBA.

324
0:15:30.066,000 --> 0:15:34,000
Je pense que notre civilisation fonctionne lorsque nous partageons un vaste patrimoine culturel

325
0:15:34.549,000 --> 0:15:37,000
que nous connaissons sans avoir à utiliser nos appareils,

326
0:15:37.735,000 --> 0:15:39,000
nos moteurs de recherche et nos smartphones.

327
0:15:40.34,000 --> 0:15:44,000
Dans les films, lorsque des ordinateurs comme Watson commencent à réfléchir,

328
0:15:44.967,000 --> 0:15:46,000
ça ne finit pas toujours bien.

329
0:15:47.55,000 --> 0:15:5,000
Ces films ne sont jamais de belles utopies.

330
0:15:51.348,000 --> 0:15:56,000
C'est toujours un terminator ou un matrix ou un astronaute aspiré dans l'espace dans « 2001 ».

331
0:15:57.083,000 --> 0:16:,000
Les choses tournent toujours mal.

332
0:16:00.318,000 --> 0:16:01,000
Et je pense que nous avons atteint le moment

333
0:16:02.25,000 --> 0:16:06,000
où nous devons choisir dans quel type de futur nous voulons vivre.

334
0:16:06.333,000 --> 0:16:07,000
C'est une question de leadership,

335
0:16:07.85,000 --> 0:16:1,000
car il faut décider de qui dirigera le futur.

336
0:16:11.517,000 --> 0:16:17,000
D'un côté, on peut choisir un nouvel âge d'or où

337
0:16:17.7,000 --> 0:16:2,000
les informations seront plus disponibles que jamais

338
0:16:21.002,000 --> 0:16:22,000
à travers l'histoire de l'humanité,

339
0:16:22.663,000 --> 0:16:24,000
où nous aurons toutes les réponses à nos questions à portée de main.

340
0:16:25.034,000 --> 0:16:26,000
De l'autre, la possibilité

341
0:16:26.577,000 --> 0:16:28,000
de vivre dans une dystopie lugubre

342
0:16:29.35,000 --> 0:16:31,000
où les machines auront pris le dessus,

343
0:16:31.369,000 --> 0:16:34,000
où nous aurons décidé que ce que nous savons n'est pas important

344
0:16:34.418,000 --> 0:16:36,000
que les connaissances n'ont pas grande valeur car tout est dans le « cloud »

345
0:16:37.033,000 --> 0:16:43,000
et qu'il n'y a aucun intérêt à s'embêter à apprendre quelque chose de nouveau.

346
0:16:43.144,000 --> 0:16:46,000
Voilà les deux possibilités que nous avons. Je sais dans quel futur je préfère vivre.

347
0:16:46.933,000 --> 0:16:48,000
Et nous pouvons tous faire ce choix.

348
0:16:49.166,000 --> 0:16:52,000
Nous faisons ce choix en étant des personnes curieuses et intéressées d'apprendre,

349
0:16:52.501,000 --> 0:16:55,000
qui ne se contentent pas de dire « Dès que la sonnerie retentit, le cours est fini

350
0:16:55.637,000 --> 0:16:56,000
je n'ai plus besoin d'apprendre »

351
0:16:56.96,000 --> 0:16:59,000
ou « J'ai enfin eu mon diplôme. J'en ai fini d'apprendre pour toute une vie.

352
0:17:00.037,000 --> 0:17:02,000
Plus besoin d'apprendre de choses nouvelles."

353
0:17:02.396,000 --> 0:17:05,000
Non, chaque jour, nous devrions nous efforcer d'apprendre quelque chose de nouveau.

354
0:17:05.703,000 --> 0:17:09,000
Nous devrions avoir cette curiosité insatiable pour le monde qui nous entoure.

355
0:17:09.895,000 --> 0:17:11,000
Voilà d'où viennent les candidats de « Jeopardy ».

356
0:17:12.62,000 --> 0:17:15,000
Ces je-sais-tout ne sont pas des savants à la Rainman

357
0:17:15.701,000 --> 0:17:17,000
apprenant l'annuaire chez eux.

358
0:17:17.803,000 --> 0:17:18,000
J'en ai rencontré beaucoup.

359
0:17:19.119,000 --> 0:17:2,000
Pour la plupart, ce sont des personnes normales

360
0:17:20.669,000 --> 0:17:24,000
qui sont intéressées par le monde autour d'elles, curieuses de tout,

361
0:17:24.767,000 --> 0:17:27,000
assoiffées de connaissances dans n'importe quel domaine.

362
0:17:28.086,000 --> 0:17:3,000
Nous pouvons vivre dans un de ces deux mondes.

363
0:17:30.619,000 --> 0:17:33,000
Nous pouvons vivre dans un monde où nos cerveaux, nos connaissances,

364
0:17:33.92,000 --> 0:17:34,000
continuent de faire de nous des êtres spéciaux ou alors dans un monde

365
0:17:35.75,000 --> 0:17:41,000
où nous avons délégué tout ça à ces diaboliques super-ordinateurs du futur comme Watson.

366
0:17:42.12,000 --> 0:17:44,000
Mesdames et messieurs, le choix vous appartient.

367
0:17:44.768,000 --> 0:17:46,000
Merci beaucoup.

