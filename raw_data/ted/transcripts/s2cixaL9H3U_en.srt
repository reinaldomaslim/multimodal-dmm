1
0:00:,000 --> 0:00:07,000
Translator: Joseph Geni Reviewer: Krystian Aparta

2
0:00:13.515,000 --> 0:00:16,000
So a friend of mine was riding in a taxi to the airport the other day,

3
0:00:17.245,000 --> 0:00:19,000
and on the way, she was chatting with the taxi driver,

4
0:00:19.979,000 --> 0:00:21,000
and he said to her, with total sincerity,

5
0:00:22.432,000 --> 0:00:25,000
"I can tell you are a really good person."

6
0:00:25.742,000 --> 0:00:26,000
And when she told me this story later,

7
0:00:27.583,000 --> 0:00:3,000
she said she couldn't believe how good it made her feel,

8
0:00:30.782,000 --> 0:00:32,000
that it meant a lot to her.

9
0:00:32.865,000 --> 0:00:35,000
Now that may seem like a strong reaction from my friend

10
0:00:35.915,000 --> 0:00:37,000
to the words of a total stranger,

11
0:00:38.143,000 --> 0:00:39,000
but she's not alone.

12
0:00:39.785,000 --> 0:00:4,000
I'm a social scientist.

13
0:00:41.174,000 --> 0:00:43,000
I study the psychology of good people,

14
0:00:43.851,000 --> 0:00:47,000
and research in my field says many of us care deeply

15
0:00:48.165,000 --> 0:00:53,000
about feeling like a good person and being seen as a good person.

16
0:00:53.467,000 --> 0:00:57,000
Now, your definition of "good person" and your definition of "good person"

17
0:00:58.324,000 --> 0:01:,000
and maybe the taxi driver's definition of "good person" --

18
0:01:01.088,000 --> 0:01:02,000
we may not all have the same definition,

19
0:01:03.095,000 --> 0:01:05,000
but within whatever our definition is,

20
0:01:05.944,000 --> 0:01:07,000
that moral identity is important to many of us.

21
0:01:09.154,000 --> 0:01:14,000
Now, if somebody challenges it, like they question us for a joke we tell,

22
0:01:14.399,000 --> 0:01:16,000
or maybe we say our workforce is homogenous,

23
0:01:17.106,000 --> 0:01:19,000
or a slippery business expense,

24
0:01:20.109,000 --> 0:01:23,000
we go into red-zone defensiveness a lot of the time.

25
0:01:23.331,000 --> 0:01:26,000
I mean, sometimes we call out

26
0:01:26.446,000 --> 0:01:29,000
all the ways in which we help people from marginalized groups,

27
0:01:30.139,000 --> 0:01:31,000
or we donate to charity,

28
0:01:31.931,000 --> 0:01:35,000
or the hours we volunteer to nonprofits.

29
0:01:35.994,000 --> 0:01:38,000
We work to protect that good person identity.

30
0:01:39.709,000 --> 0:01:4,000
It's important to many of us.

31
0:01:42.517,000 --> 0:01:43,000
But what if I told you this?

32
0:01:44.399,000 --> 0:01:48,000
What if I told you that our attachment to being good people

33
0:01:49.137,000 --> 0:01:51,000
is getting in the way of us being better people?

34
0:01:52.225,000 --> 0:01:58,000
What if I told you that our definition of "good person" is so narrow,

35
0:01:58.575,000 --> 0:02:,000
it's scientifically impossible to meet?

36
0:02:01.806,000 --> 0:02:04,000
And what if I told you the path to being better people

37
0:02:05.107,000 --> 0:02:07,000
just begins with letting go of being a good person?

38
0:02:08.876,000 --> 0:02:1,000
Now, let me tell you a little bit about the research

39
0:02:11.54,000 --> 0:02:12,000
about how the human mind works

40
0:02:13.036,000 --> 0:02:14,000
to explain.

41
0:02:14.54,000 --> 0:02:18,000
The brain relies on shortcuts to do a lot of its work.

42
0:02:18.672,000 --> 0:02:19,000
That means a lot of the time,

43
0:02:20.321,000 --> 0:02:23,000
your mental processes are taking place outside of your awareness,

44
0:02:23.673,000 --> 0:02:27,000
like in low-battery, low-power mode in the back of your mind.

45
0:02:29.088,000 --> 0:02:32,000
That's, in fact, the premise of bounded rationality.

46
0:02:32.573,000 --> 0:02:35,000
Bounded rationality is the Nobel Prize-winning idea

47
0:02:36.038,000 --> 0:02:38,000
that the human mind has limited storage resources,

48
0:02:38.904,000 --> 0:02:4,000
limited processing power,

49
0:02:41.024,000 --> 0:02:45,000
and as a result, it relies on shortcuts to do a lot of its work.

50
0:02:45.571,000 --> 0:02:46,000
So for example,

51
0:02:47.833,000 --> 0:02:49,000
some scientists estimate that in any given moment ...

52
0:02:51.27,000 --> 0:02:53,000
Better, better click, right? There we go.

53
0:02:53.374,000 --> 0:02:54,000
(Laughter)

54
0:02:54.405,000 --> 0:02:55,000
At any given moment,

55
0:02:55.673,000 --> 0:02:58,000
11 million pieces of information are coming into your mind.

56
0:03:00.054,000 --> 0:03:01,000
Eleven million.

57
0:03:01.694,000 --> 0:03:03,000
And only 40 of them are being processed consciously.

58
0:03:05.051,000 --> 0:03:07,000
So 11 million, 40.

59
0:03:08.14,000 --> 0:03:09,000
I mean, has this ever happened to you?

60
0:03:10.048,000 --> 0:03:12,000
Have you ever had a really busy day at work,

61
0:03:12.426,000 --> 0:03:13,000
and you drive home,

62
0:03:14.179,000 --> 0:03:16,000
and when you get in the door,

63
0:03:16.421,000 --> 0:03:19,000
you realize you don't even remember the drive home,

64
0:03:19.693,000 --> 0:03:21,000
like whether you had green lights or red lights.

65
0:03:22.22,000 --> 0:03:24,000
You don't even remember. You were on autopilot.

66
0:03:24.974,000 --> 0:03:27,000
Or have you ever opened the fridge,

67
0:03:28.285,000 --> 0:03:3,000
looked for the butter,

68
0:03:30.381,000 --> 0:03:32,000
swore there is no butter,

69
0:03:33.349,000 --> 0:03:36,000
and then realized the butter was right in front of you the whole time?

70
0:03:36.99,000 --> 0:03:39,000
These are the kinds of "whoops" moments that make us giggle,

71
0:03:40.535,000 --> 0:03:42,000
and this is what happens in a brain

72
0:03:42.57,000 --> 0:03:45,000
that can handle 11 million pieces of information coming in

73
0:03:46.168,000 --> 0:03:48,000
with only 40 being processed consciously.

74
0:03:48.769,000 --> 0:03:51,000
That's the bounded part of bounded rationality.

75
0:03:55.352,000 --> 0:03:57,000
This work on bounded rationality

76
0:03:57.853,000 --> 0:04:01,000
is what's inspired work I've done with my collaborators

77
0:04:02.043,000 --> 0:04:04,000
Max Bazerman and Mahzarin Banaji,

78
0:04:04.702,000 --> 0:04:06,000
on what we call bounded ethicality.

79
0:04:07.702,000 --> 0:04:1,000
So it's the same premise as bounded rationality,

80
0:04:10.798,000 --> 0:04:15,000
that we have a human mind that is bounded in some sort of way

81
0:04:16.423,000 --> 0:04:18,000
and relying on shortcuts,

82
0:04:18.529,000 --> 0:04:21,000
and that those shortcuts can sometimes lead us astray.

83
0:04:22.886,000 --> 0:04:23,000
With bounded rationality,

84
0:04:24.435,000 --> 0:04:27,000
perhaps it affects the cereal we buy in the grocery store,

85
0:04:28.145,000 --> 0:04:31,000
or the product we launch in the boardroom.

86
0:04:31.836,000 --> 0:04:33,000
With bounded ethicality, the human mind,

87
0:04:34.543,000 --> 0:04:36,000
the same human mind,

88
0:04:36.646,000 --> 0:04:37,000
is making decisions,

89
0:04:38.162,000 --> 0:04:4,000
and here, it's about who to hire next,

90
0:04:40.972,000 --> 0:04:41,000
or what joke to tell

91
0:04:42.646,000 --> 0:04:44,000
or that slippery business decision.

92
0:04:46.157,000 --> 0:04:5,000
So let me give you an example of bounded ethicality at work.

93
0:04:50.784,000 --> 0:04:52,000
Unconscious bias is one place

94
0:04:53.594,000 --> 0:04:56,000
where we see the effects of bounded ethicality.

95
0:04:57.127,000 --> 0:05:01,000
So unconscious bias refers to associations we have in our mind,

96
0:05:01.537,000 --> 0:05:05,000
the shortcuts your brain is using to organize information,

97
0:05:05.851,000 --> 0:05:07,000
very likely outside of your awareness,

98
0:05:08.139,000 --> 0:05:11,000
not necessarily lining up with your conscious beliefs.

99
0:05:12.503,000 --> 0:05:14,000
Researchers Nosek, Banaji and Greenwald

100
0:05:15.051,000 --> 0:05:17,000
have looked at data from millions of people,

101
0:05:17.806,000 --> 0:05:19,000
and what they've found is, for example,

102
0:05:20.587,000 --> 0:05:23,000
most white Americans can more quickly and easily

103
0:05:24.104,000 --> 0:05:28,000
associate white people and good things

104
0:05:28.397,000 --> 0:05:3,000
than black people and good things,

105
0:05:31.65,000 --> 0:05:36,000
and most men and women can more quickly and easily associate

106
0:05:37.288,000 --> 0:05:41,000
men and science than women and science.

107
0:05:42.137,000 --> 0:05:46,000
And these associations don't necessarily line up

108
0:05:46.448,000 --> 0:05:47,000
with what people consciously think.

109
0:05:48.347,000 --> 0:05:51,000
They may have very egalitarian views, in fact.

110
0:05:52.206,000 --> 0:05:56,000
So sometimes, that 11 million and that 40 just don't line up.

111
0:05:57.402,000 --> 0:05:58,000
And here's another example:

112
0:05:59.393,000 --> 0:06:,000
conflicts of interest.

113
0:06:01.372,000 --> 0:06:04,000
So we tend to underestimate how much a small gift --

114
0:06:05.206,000 --> 0:06:08,000
imagine a ballpoint pen or dinner --

115
0:06:08.873,000 --> 0:06:12,000
how much that small gift can affect our decision making.

116
0:06:13.852,000 --> 0:06:17,000
We don't realize that our mind is unconsciously lining up evidence

117
0:06:18.202,000 --> 0:06:21,000
to support the point of view of the gift-giver,

118
0:06:21.757,000 --> 0:06:25,000
no matter how hard we're consciously trying to be objective and professional.

119
0:06:27.689,000 --> 0:06:28,000
We also see bounded ethicality --

120
0:06:29.432,000 --> 0:06:32,000
despite our attachment to being good people,

121
0:06:32.833,000 --> 0:06:34,000
we still make mistakes,

122
0:06:34.938,000 --> 0:06:38,000
and we make mistakes that sometimes hurt other people,

123
0:06:38.973,000 --> 0:06:4,000
that sometimes promote injustice,

124
0:06:41.467,000 --> 0:06:43,000
despite our best attempts,

125
0:06:43.516,000 --> 0:06:47,000
and we explain away our mistakes rather than learning from them.

126
0:06:48.81,000 --> 0:06:5,000
Like, for example,

127
0:06:51.287,000 --> 0:06:54,000
when I got an email from a female student in my class

128
0:06:55.112,000 --> 0:06:57,000
saying that a reading I had assigned,

129
0:06:57.684,000 --> 0:06:59,000
a reading I had been assigning for years,

130
0:07:00.462,000 --> 0:07:01,000
was sexist.

131
0:07:02.738,000 --> 0:07:07,000
Or when I confused two students in my class

132
0:07:08.35,000 --> 0:07:09,000
of the same race --

133
0:07:09.731,000 --> 0:07:11,000
look nothing alike --

134
0:07:12.025,000 --> 0:07:14,000
when I confused them for each other

135
0:07:14.208,000 --> 0:07:16,000
more than once, in front of everybody.

136
0:07:17.885,000 --> 0:07:21,000
These kinds of mistakes send us, send me,

137
0:07:22.232,000 --> 0:07:24,000
into red-zone defensiveness.

138
0:07:25.091,000 --> 0:07:29,000
They leave us fighting for that good person identity.

139
0:07:30.189,000 --> 0:07:34,000
But the latest work that I've been doing on bounded ethicality with Mary Kern

140
0:07:34.553,000 --> 0:07:37,000
says that we're not only prone to mistakes --

141
0:07:38.149,000 --> 0:07:43,000
that tendency towards mistakes depends on how close we are to that red zone.

142
0:07:43.412,000 --> 0:07:47,000
So most of the time, nobody's challenging our good person identity,

143
0:07:47.635,000 --> 0:07:49,000
and so we're not thinking too much

144
0:07:49.818,000 --> 0:07:51,000
about the ethical implications of our decisions,

145
0:07:52.175,000 --> 0:07:55,000
and our model shows that we're then spiraling

146
0:07:56.078,000 --> 0:08:,000
towards less and less ethical behavior most of the time.

147
0:08:00.841,000 --> 0:08:02,000
On the other hand, somebody might challenge our identity,

148
0:08:03.713,000 --> 0:08:06,000
or, upon reflection, we may be challenging it ourselves.

149
0:08:07.236,000 --> 0:08:11,000
So the ethical implications of our decisions become really salient,

150
0:08:11.384,000 --> 0:08:16,000
and in those cases, we spiral towards more and more good person behavior,

151
0:08:17.145,000 --> 0:08:18,000
or, to be more precise,

152
0:08:19.01,000 --> 0:08:23,000
towards more and more behavior that makes us feel like a good person,

153
0:08:23.572,000 --> 0:08:25,000
which isn't always the same, of course.

154
0:08:27.413,000 --> 0:08:3,000
The idea with bounded ethicality

155
0:08:31.08,000 --> 0:08:35,000
is that we are perhaps overestimating

156
0:08:35.306,000 --> 0:08:4,000
the importance our inner compass is playing in our ethical decisions.

157
0:08:40.498,000 --> 0:08:44,000
We perhaps are overestimating how much our self-interest

158
0:08:45.007,000 --> 0:08:48,000
is driving our decisions,

159
0:08:48.403,000 --> 0:08:53,000
and perhaps we don't realize how much our self-view as a good person

160
0:08:54.142,000 --> 0:08:56,000
is affecting our behavior,

161
0:08:56.69,000 --> 0:09:01,000
that in fact, we're working so hard to protect that good person identity,

162
0:09:02.199,000 --> 0:09:04,000
to keep out of that red zone,

163
0:09:04.517,000 --> 0:09:09,000
that we're not actually giving ourselves space to learn from our mistakes

164
0:09:09.895,000 --> 0:09:11,000
and actually be better people.

165
0:09:13.998,000 --> 0:09:16,000
It's perhaps because we expect it to be easy.

166
0:09:17.063,000 --> 0:09:21,000
We have this definition of good person that's either-or.

167
0:09:21.177,000 --> 0:09:24,000
Either you are a good person or you're not.

168
0:09:24.24,000 --> 0:09:26,000
Either you have integrity or you don't.

169
0:09:26.884,000 --> 0:09:3,000
Either you are a racist or a sexist or a homophobe or you're not.

170
0:09:31.54,000 --> 0:09:34,000
And in this either-or definition, there's no room to grow.

171
0:09:36.444,000 --> 0:09:37,000
And by the way,

172
0:09:37.619,000 --> 0:09:39,000
this is not what we do in most parts of our lives.

173
0:09:40.627,000 --> 0:09:42,000
Life, if you needed to learn accounting,

174
0:09:43.126,000 --> 0:09:44,000
you would take an accounting class,

175
0:09:44.843,000 --> 0:09:46,000
or if you become a parent,

176
0:09:47.161,000 --> 0:09:5,000
we pick up a book and we read about it.

177
0:09:50.692,000 --> 0:09:52,000
We talk to experts,

178
0:09:53.343,000 --> 0:09:54,000
we learn from our mistakes,

179
0:09:54.821,000 --> 0:09:55,000
we update our knowledge,

180
0:09:56.344,000 --> 0:09:57,000
we just keep getting better.

181
0:09:58.835,000 --> 0:09:59,000
But when it comes to being a good person,

182
0:10:00.815,000 --> 0:10:02,000
we think it's something we're just supposed to know,

183
0:10:03.331,000 --> 0:10:04,000
we're just supposed to do,

184
0:10:04.618,000 --> 0:10:07,000
without the benefit of effort or growth.

185
0:10:07.95,000 --> 0:10:08,000
So what I've been thinking about

186
0:10:09.814,000 --> 0:10:13,000
is what if we were to just forget about being good people,

187
0:10:13.99,000 --> 0:10:14,000
just let it go,

188
0:10:15.779,000 --> 0:10:18,000
and instead, set a higher standard,

189
0:10:18.899,000 --> 0:10:21,000
a higher standard of being a good-ish person?

190
0:10:24.891,000 --> 0:10:28,000
A good-ish person absolutely still makes mistakes.

191
0:10:29.138,000 --> 0:10:32,000
As a good-ish person, I'm making them all the time.

192
0:10:32.881,000 --> 0:10:36,000
But as a good-ish person, I'm trying to learn from them, own them.

193
0:10:37.279,000 --> 0:10:4,000
I expect them and I go after them.

194
0:10:40.862,000 --> 0:10:42,000
I understand there are costs to these mistakes.

195
0:10:43.49,000 --> 0:10:47,000
When it comes to issues like ethics and bias and diversity and inclusion,

196
0:10:47.582,000 --> 0:10:5,000
there are real costs to real people,

197
0:10:50.748,000 --> 0:10:51,000
and I accept that.

198
0:10:54.602,000 --> 0:10:55,000
As a good-ish person, in fact,

199
0:10:56.507,000 --> 0:10:58,000
I become better at noticing my own mistakes.

200
0:10:59.214,000 --> 0:11:01,000
I don't wait for people to point them out.

201
0:11:01.538,000 --> 0:11:03,000
I practice finding them,

202
0:11:03.704,000 --> 0:11:04,000
and as a result ...

203
0:11:05.911,000 --> 0:11:08,000
Sure, sometimes it can be embarrassing,

204
0:11:09.552,000 --> 0:11:1,000
it can be uncomfortable.

205
0:11:11.438,000 --> 0:11:14,000
We put ourselves in a vulnerable place, sometimes.

206
0:11:15.968,000 --> 0:11:17,000
But through all that vulnerability,

207
0:11:18.143,000 --> 0:11:22,000
just like in everything else we've tried to ever get better at,

208
0:11:22.507,000 --> 0:11:23,000
we see progress.

209
0:11:23.833,000 --> 0:11:24,000
We see growth.

210
0:11:25.008,000 --> 0:11:27,000
We allow ourselves to get better.

211
0:11:29.016,000 --> 0:11:32,000
Why wouldn't we give ourselves that?

212
0:11:32.944,000 --> 0:11:36,000
In every other part of our lives, we give ourselves room to grow --

213
0:11:37.495,000 --> 0:11:39,000
except in this one, where it matters most.

214
0:11:41.256,000 --> 0:11:42,000
Thank you.

215
0:11:42.431,000 --> 0:11:46,000
(Applause)

