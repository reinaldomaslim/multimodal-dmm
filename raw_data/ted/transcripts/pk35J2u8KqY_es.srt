1
0:00:,000 --> 0:00:07,000
Traductor: Gabriela Ahearn Revisor: Sebastian Betti

2
0:00:12.772,000 --> 0:00:13,000
En la antigua Grecia,

3
0:00:15.279,000 --> 0:00:18,000
cuando alguien, desde esclavos a soldados, poetas y políticos,

4
0:00:19.17,000 --> 0:00:22,000
necesitaba tomar una gran decisión sobre las preguntas más importantes,

5
0:00:22.707,000 --> 0:00:23,000
como, "¿Debería casarme?"

6
0:00:24.619,000 --> 0:00:26,000
o "¿Deberíamos iniciar este viaje?"

7
0:00:26.638,000 --> 0:00:28,000
"¿Debería el ejército avanzar a este territorio?"

8
0:00:29.059,000 --> 0:00:31,000
todos consultaban el oráculo.

9
0:00:33.065,000 --> 0:00:34,000
Así funcionaba:

10
0:00:34.44,000 --> 0:00:36,000
traías una pregunta y te arrodillabas,

11
0:00:37.052,000 --> 0:00:38,000
y luego ella entraba en un trance.

12
0:00:38.806,000 --> 0:00:39,000
Llevaba un par de días,

13
0:00:40.708,000 --> 0:00:41,000
y eventualmente salía del trance,

14
0:00:42.626,000 --> 0:00:45,000
dando sus predicciones como respuesta.

15
0:00:46.742,000 --> 0:00:49,000
Desde los oráculos de huesos de la antigua China

16
0:00:49.768,000 --> 0:00:51,000
a la antigua Grecia, a los calendarios mayas,

17
0:00:51.874,000 --> 0:00:53,000
la gente ha buscado la profecía

18
0:00:54.231,000 --> 0:00:56,000
para enterarse de qué va a suceder.

19
0:00:58.273,000 --> 0:01:01,000
Y eso se debe a que todos queremos tomar la decisión correcta.

20
0:01:01.543,000 --> 0:01:02,000
No nos queremos perder de algo.

21
0:01:03.433,000 --> 0:01:04,000
El futuro da miedo,

22
0:01:05.411,000 --> 0:01:08,000
es mucho mejor saber que podemos decidir

23
0:01:08.612,000 --> 0:01:09,000
con alguna garantía del resultado.

24
0:01:10.55,000 --> 0:01:12,000
Bueno, tenemos un nuevo oráculo,

25
0:01:12.795,000 --> 0:01:14,000
y su nombre es big data.

26
0:01:14.806,000 --> 0:01:18,000
o le llamamos "Watson" o "aprendizaje profundo" o "red neural".

27
0:01:19.008,000 --> 0:01:23,000
Y estas son las preguntas que hacemos a nuestro oráculo ahora,

28
0:01:23.341,000 --> 0:01:26,000
"¿Cuál es la forma más eficiente de enviar estos teléfonos

29
0:01:27.189,000 --> 0:01:28,000
de China a Suecia?"

30
0:01:28.912,000 --> 0:01:3,000
O, "¿Cuál es la probabilidad

31
0:01:31.429,000 --> 0:01:34,000
de que mi hijo nazca con un problema genético?"

32
0:01:34.859,000 --> 0:01:38,000
O, "¿Qué volumen de ventas podemos proyectar para este producto?"

33
0:01:39.777,000 --> 0:01:43,000
Tengo una perra. Se llama Elle, y odia la lluvia.

34
0:01:44.122,000 --> 0:01:47,000
He tratado todo para re-entrenarla.

35
0:01:47.691,000 --> 0:01:49,000
Pero como he fallado con esto,

36
0:01:50.544,000 --> 0:01:52,000
le consulto a un oráculo que se llama Cielos Oscuros,

37
0:01:53.53,000 --> 0:01:54,000
cada vez que salimos a caminar,

38
0:01:55.331,000 --> 0:01:57,000
para tener predicciones precisas para los próximos diez minutos.

39
0:01:58.302,000 --> 0:02:01,000
(Risas)

40
0:02:01.304,000 --> 0:02:03,000
Ella es tan dulce.

41
0:02:03.535,000 --> 0:02:08,000
Por estas razones, nuestra industria de oráculos es de USD 122 000 millones.

42
0:02:09.072,000 --> 0:02:12,000
A pesar del tamaño de esta industria,

43
0:02:13.011,000 --> 0:02:16,000
los dividendos son sorprendentemente bajos.

44
0:02:16.024,000 --> 0:02:18,000
Invertir en big data es muy fácil,

45
0:02:18.794,000 --> 0:02:2,000
pero usar macrodatos es difícil.

46
0:02:21.769,000 --> 0:02:24,000
Más del 73 % de los proyectos de big data no son rentables,

47
0:02:25.761,000 --> 0:02:27,000
hay ejecutivos que dicen:

48
0:02:28.291,000 --> 0:02:29,000
"Se repite el problema.

49
0:02:30.151,000 --> 0:02:32,000
Invertimos en algún sistema de big data,

50
0:02:32.496,000 --> 0:02:34,000
y nuestros empleados no toman mejores decisiones.

51
0:02:35.337,000 --> 0:02:38,000
Y definitivamente no generan ideas innovadoras".

52
0:02:38.427,000 --> 0:02:41,000
Esto me parece muy interesante,

53
0:02:42.031,000 --> 0:02:44,000
porque soy etnógrafa de tecnología.

54
0:02:44.565,000 --> 0:02:46,000
Estudio y aconsejo a empresas

55
0:02:47.22,000 --> 0:02:49,000
en las tendencias de uso de tecnología.

56
0:02:49.569,000 --> 0:02:51,000
Una de las áreas que me interesan es el análisis de datos.

57
0:02:52.295,000 --> 0:02:56,000
¿Por qué no estamos tomando mejores decisiones,

58
0:02:56.718,000 --> 0:02:59,000
especialmente compañías que tienen todos los recursos

59
0:02:59.8,000 --> 0:03:01,000
para invertir en estos sistemas de big data?

60
0:03:02.302,000 --> 0:03:04,000
¿Por qué no les está facilitando nuevas estrategias?

61
0:03:05.748,000 --> 0:03:07,000
Soy testigo,

62
0:03:08.374,000 --> 0:03:12,000
en 2009, empecé un puesto de investigadora en Nokia.

63
0:03:13.246,000 --> 0:03:14,000
En esa época, Nokia era

64
0:03:14.82,000 --> 0:03:16,000
una de las empresas más grandes del mundo,

65
0:03:17.309,000 --> 0:03:2,000
dominaba los mercados emergentes como China, México e India...

66
0:03:20.784,000 --> 0:03:22,000
todos sitios que yo había investigado bastante

67
0:03:23.559,000 --> 0:03:25,000
la forma de uso de tecnología de perfiles de bajos ingresos.

68
0:03:25.813,000 --> 0:03:27,000
Pasé mucho tiempo en China,

69
0:03:28.521,000 --> 0:03:3,000
familiarizándome con la economía informal.

70
0:03:31.279,000 --> 0:03:33,000
Trabajé como vendedora ambulante

71
0:03:33.766,000 --> 0:03:34,000
vendiendo comida a obreros.

72
0:03:35.72,000 --> 0:03:37,000
Hice trabajo de campo,

73
0:03:38.005,000 --> 0:03:4,000
pasé días y noches en cibercafés,

74
0:03:40.319,000 --> 0:03:42,000
parando con la juventud china, para entender

75
0:03:42.392,000 --> 0:03:44,000
cómo estaban usando los videojuegos y móviles.

76
0:03:44.736,000 --> 0:03:48,000
Y cómo los usaban en la migración del campo a las ciudades.

77
0:03:50.311,000 --> 0:03:53,000
Con toda esta evidencia cualitativa que estaba coleccionando,

78
0:03:54.07,000 --> 0:03:56,000
noté claramente

79
0:03:57.013,000 --> 0:04:02,000
que iba a haber un gran cambio entre los pobres de China.

80
0:04:03.047,000 --> 0:04:06,000
A pesar de estar rodeados de publicidad para productos de lujo,

81
0:04:06.816,000 --> 0:04:09,000
como inodoros sofisticados -- ¿quién no quiere uno? --

82
0:04:10.663,000 --> 0:04:12,000
y departamentos y autos,

83
0:04:13.161,000 --> 0:04:15,000
en nuestras conversaciones,

84
0:04:15.681,000 --> 0:04:19,000
me di cuenta de que los anuncios que realmente les interesaban

85
0:04:19.769,000 --> 0:04:21,000
eran los anuncios para iPhones,

86
0:04:22.141,000 --> 0:04:25,000
que les prometía acceso a esta vida de alta tecnología.

87
0:04:25.163,000 --> 0:04:28,000
Incluso cuando viví con ellos en barriadas como esta,

88
0:04:28.611,000 --> 0:04:31,000
veía gente invirtiendo más de la mitad de su sueldo mensual

89
0:04:31.814,000 --> 0:04:32,000
para comprar un celular,

90
0:04:33.344,000 --> 0:04:35,000
y cada vez más, eran "shanzhai",

91
0:04:35.525,000 --> 0:04:38,000
que son imitaciones baratas de iPhones y otras marcas.

92
0:04:39.524,000 --> 0:04:41,000
Son bastante usables,

93
0:04:42.536,000 --> 0:04:43,000
funcionan.

94
0:04:44.262,000 --> 0:04:49,000
Y después de años de vivir con inmigrantes y trabajar con ellos,

95
0:04:50.124,000 --> 0:04:53,000
y básicamente hacer todo lo que ellos hacían,

96
0:04:53.824,000 --> 0:04:56,000
empecé a unir los datos...

97
0:04:57.184,000 --> 0:05:,000
desde las cosas que parecen al azar como yo vendiendo comida,

98
0:05:01.064,000 --> 0:05:02,000
a las cosas más obvias,

99
0:05:02.688,000 --> 0:05:04,000
como calcular cuánto gastan en las cuentas de móviles.

100
0:05:05.317,000 --> 0:05:07,000
Así pude ver una figura más clara, más completa,

101
0:05:07.75,000 --> 0:05:08,000
de lo que estaba pasando.

102
0:05:09.522,000 --> 0:05:1,000
Ahí me di cuenta

103
0:05:11.245,000 --> 0:05:15,000
de que hasta los más pobres de China iban a querer un teléfono inteligente,

104
0:05:15.324,000 --> 0:05:19,000
y que harían casi cualquier cosa por conseguir uno.

105
0:05:20.182,000 --> 0:05:22,000
Acuérdense,

106
0:05:23.112,000 --> 0:05:26,000
los iPhones acababan de salir, era el 2009,

107
0:05:26.74,000 --> 0:05:27,000
o sea, hace ocho años,

108
0:05:28.707,000 --> 0:05:3,000
y los Androids se parecían más a los iPhones.

109
0:05:31.269,000 --> 0:05:33,000
Y mucha gente inteligente y realista dijo:

110
0:05:33.558,000 --> 0:05:35,000
"Esos teléfonos inteligentes son una moda pasajera.

111
0:05:36.151,000 --> 0:05:38,000
¿Quién quiere estar cargando esas cosas pesadas

112
0:05:39.073,000 --> 0:05:42,000
que se les gastan las baterías y que se rompen cada vez que se te caen?"

113
0:05:44.751,000 --> 0:05:46,000
Pero yo tenía bastantes datos,

114
0:05:46.866,000 --> 0:05:48,000
y confiaba en mis ideas,

115
0:05:49.027,000 --> 0:05:51,000
así que estaba muy entusiasmada en compartirlas con Nokia.

116
0:05:52.949,000 --> 0:05:54,000
Pero en Nokia no estaban convencidos,

117
0:05:55.316,000 --> 0:05:57,000
porque no era big data.

118
0:05:58.731,000 --> 0:06:,000
Dijeron: "Tenemos millones de datos,

119
0:06:01.322,000 --> 0:06:05,000
no hay ninguna indicación de que alguien quiera comprar teléfonos inteligentes,

120
0:06:05.77,000 --> 0:06:09,000
y tu lista de 100 datos, aún siendo diversa, es muy débil

121
0:06:10.066,000 --> 0:06:12,000
para tomarla en serio".

122
0:06:12.067,000 --> 0:06:14,000
Yo les dije: "Nokia, tienen razón,

123
0:06:14.166,000 --> 0:06:15,000
por supuesto que no ven esto,

124
0:06:15.661,000 --> 0:06:18,000
porque Uds. mandan encuestas suponiendo que la gente no sabe

125
0:06:19.023,000 --> 0:06:21,000
qué es un teléfono inteligente,

126
0:06:21.076,000 --> 0:06:23,000
así que claro que no van a obtener ningún resultado

127
0:06:23.541,000 --> 0:06:25,000
sobre demanda de teléfonos inteligentes.

128
0:06:25.582,000 --> 0:06:27,000
Sus encuestas, sus métodos han sido diseñados

129
0:06:27.747,000 --> 0:06:29,000
para optimizar el modelo empresarial existente,

130
0:06:30.091,000 --> 0:06:32,000
y yo estoy mirando las dinámicas humanas emergentes,

131
0:06:32.659,000 --> 0:06:33,000
que no han pasado todavía.

132
0:06:34.362,000 --> 0:06:36,000
Mirando fuera de las dinámicas del mercado

133
0:06:36.573,000 --> 0:06:38,000
para poder estar en la vanguardia".

134
0:06:38.775,000 --> 0:06:4,000
¿Saben que le pasó a Nokia?

135
0:06:40.919,000 --> 0:06:43,000
La empresa se cayó por un barranco.

136
0:06:44.292,000 --> 0:06:48,000
Ese es el costo de ignorar algo.

137
0:06:48.407,000 --> 0:06:5,000
Fue increíble.

138
0:06:51.296,000 --> 0:06:53,000
Pero Nokia no está sola.

139
0:06:53.834,000 --> 0:06:56,000
Veo organizaciones que desechan datos todo el tiempo

140
0:06:57.006,000 --> 0:06:59,000
porque no vienen de un modelo cuantitativo

141
0:06:59.285,000 --> 0:07:01,000
o no son compatibles con uno cuantitativo.

142
0:07:01.465,000 --> 0:07:04,000
Pero no se debe a los grandes volúmenes de datos.

143
0:07:04.67,000 --> 0:07:08,000
Es la manera en que los usamos; nosotros somos los responsables.

144
0:07:09.694,000 --> 0:07:1,000
La reputación exitosa de big data

145
0:07:11.647,000 --> 0:07:14,000
se debe a cuantificaciones en ambientes bastante específicos,

146
0:07:15.563,000 --> 0:07:19,000
como redes eléctricas, logística de distribución, o códigos genéticos,

147
0:07:20.463,000 --> 0:07:24,000
cuando el análisis cuantitativo es de sistemas contenidos.

148
0:07:24.49,000 --> 0:07:27,000
Pero no todos los sistemas son contenidos tan organizadamente.

149
0:07:28.03,000 --> 0:07:3,000
Cuando uno cuantifica sistemas más dinámicos,

150
0:07:30.958,000 --> 0:07:33,000
especialmente sistemas que conciernen a seres humanos,

151
0:07:34.374,000 --> 0:07:36,000
hay fuerzas complejas e impredecibles,

152
0:07:37.317,000 --> 0:07:4,000
cosas que no sabemos modelar tan bien.

153
0:07:40.48,000 --> 0:07:43,000
Y una vez que uno predice algo sobre la conducta humana,

154
0:07:43.712,000 --> 0:07:45,000
emergen nuevos factores,

155
0:07:45.994,000 --> 0:07:47,000
porque las condiciones cambian constantemente.

156
0:07:48.295,000 --> 0:07:5,000
Por eso es un ciclo interminable.

157
0:07:50.301,000 --> 0:07:52,000
Uno cree que sabe algo y aparece algo nuevo.

158
0:07:53.124,000 --> 0:07:56,000
Por eso es que confiar solo en big data,

159
0:07:56.968,000 --> 0:07:58,000
incrementa la posibilidad de no ver algo,

160
0:07:59.959,000 --> 0:08:02,000
y a la vez nos da la ilusión de saberlo todo.

161
0:08:03.828,000 --> 0:08:07,000
Lo que hace difícil de ver esta contradicción,

162
0:08:08.295,000 --> 0:08:11,000
y hasta de comprenderla,

163
0:08:11.331,000 --> 0:08:13,000
es algo que se llama predisposición cuantitativa

164
0:08:14.033,000 --> 0:08:18,000
que significa que inconscientemente valoramos más lo que podemos medir

165
0:08:18.6,000 --> 0:08:2,000
que lo que no es medible.

166
0:08:20.932,000 --> 0:08:23,000
Y muy a menudo tenemos esta experiencia en el trabajo.

167
0:08:24.241,000 --> 0:08:26,000
Quizás tenemos colegas que son así,

168
0:08:27.175,000 --> 0:08:29,000
o quizás la empresa es así,

169
0:08:29.531,000 --> 0:08:31,000
donde la gente tiene una fijación con un número,

170
0:08:32.329,000 --> 0:08:33,000
y no ve nada más,

171
0:08:33.87,000 --> 0:08:37,000
aún si tienen las pruebas en la punta de la nariz.

172
0:08:38.462,000 --> 0:08:41,000
Y este es un mensaje muy atractivo,

173
0:08:42.342,000 --> 0:08:44,000
porque no hay nada malo en cuantificar;

174
0:08:44.81,000 --> 0:08:46,000
realmente da mucha satisfacción.

175
0:08:47.074,000 --> 0:08:5,000
Me causa bienestar ver una hoja de cálculo Excel,

176
0:08:50.866,000 --> 0:08:51,000
hasta las más simples.

177
0:08:52.306,000 --> 0:08:52,000
(Risas)

178
0:08:53.052,000 --> 0:08:53,000
Es así:

179
0:08:54.017,000 --> 0:08:57,000
"¡Sí, la formula funciona! Todo está bien. Todo está bajo control".

180
0:08:58.719,000 --> 0:09:,000
Pero el problema es

181
0:09:00.772,000 --> 0:09:02,000
que la cuantificación es adictiva.

182
0:09:03.712,000 --> 0:09:04,000
Y cuando nos olvidamos de eso

183
0:09:05.352,000 --> 0:09:07,000
y no tenemos un sistema de control,

184
0:09:08.03,000 --> 0:09:1,000
podemos muy fácilmente desechar datos

185
0:09:10.844,000 --> 0:09:12,000
que no se pueden expresar numéricamente.

186
0:09:13.334,000 --> 0:09:15,000
Es muy fácil caer en la idea milagrosa,

187
0:09:15.727,000 --> 0:09:18,000
como si existiera una solución simple.

188
0:09:19.083,000 --> 0:09:23,000
Este es un momento peligroso para cualquier organización,

189
0:09:23.559,000 --> 0:09:25,000
en muchos casos, el futuro que predecimos

190
0:09:25.836,000 --> 0:09:27,000
no está en el pajar,

191
0:09:28.386,000 --> 0:09:3,000
es un tornado que se nos viene encima

192
0:09:30.811,000 --> 0:09:31,000
afuera del granero.

193
0:09:34.695,000 --> 0:09:36,000
No hay peor riesgo

194
0:09:36.81,000 --> 0:09:38,000
que no ver lo desconocido.

195
0:09:39.027,000 --> 0:09:41,000
Puede causar malas decisiones.

196
0:09:41.064,000 --> 0:09:43,000
Puede causar que no veas algo importante.

197
0:09:43.376,000 --> 0:09:46,000
Pero no es necesario que vayamos por ese camino.

198
0:09:47.129,000 --> 0:09:5,000
Resulta que el oráculo de la antigua Grecia

199
0:09:50.731,000 --> 0:09:54,000
tiene la llave secreta para enseñarnos el camino hacia adelante.

200
0:09:55.117,000 --> 0:09:58,000
Estudios geológicos recientes han demostrado

201
0:09:58.342,000 --> 0:10:01,000
que el Templo de Apolo, donde estaba el oráculo más famoso,

202
0:10:02.22,000 --> 0:10:04,000
fue construido sobre dos fallas sísmicas;

203
0:10:04.993,000 --> 0:10:06,000
y estas fallas emiten gases petroquímicos

204
0:10:07.935,000 --> 0:10:09,000
que están bajo la corteza terrestre,

205
0:10:10.104,000 --> 0:10:13,000
y que el oráculo estaba literalmente sentado sobre estas fallas,

206
0:10:13.486,000 --> 0:10:16,000
inhalando cantidades inmensas de gas etileno, por estas grietas.

207
0:10:16.849,000 --> 0:10:16,000
(Risas)

208
0:10:17.841,000 --> 0:10:17,000
Es verdad.

209
0:10:18.769,000 --> 0:10:19,000
(Risas)

210
0:10:19.891,000 --> 0:10:22,000
Todo es verdad, eso es lo que la hacía balbucear, alucinar,

211
0:10:23.887,000 --> 0:10:24,000
y entrar en trance.

212
0:10:25.697,000 --> 0:10:26,000
¡Volar como una cometa!

213
0:10:27.591,000 --> 0:10:28,000
(Risas)

214
0:10:28.591,000 --> 0:10:3,000
(Aplausos)

215
0:10:31.294,000 --> 0:10:33,000
Entonces cómo...

216
0:10:33.537,000 --> 0:10:36,000
¿Cómo recibió alguien buenos consejos

217
0:10:36.748,000 --> 0:10:37,000
de ella en ese estado?

218
0:10:39.315,000 --> 0:10:41,000
Bueno, ¿ven la gente que rodeaba al oráculo?

219
0:10:41.439,000 --> 0:10:43,000
Toda esa gente que la está sujetando

220
0:10:43.766,000 --> 0:10:44,000
porque está un poquito mareada.

221
0:10:45.565,000 --> 0:10:47,000
Y ¿pueden ver al hombre que está a su izquierda,

222
0:10:48.064,000 --> 0:10:49,000
con un cuaderno anaranjado?

223
0:10:49.899,000 --> 0:10:5,000
Todos esos eran guías del templo,

224
0:10:51.895,000 --> 0:10:54,000
y trabajaban mano a mano con el oráculo.

225
0:10:55.618,000 --> 0:10:57,000
Cuando las personas entraban y se arrodillaban,

226
0:10:58.031,000 --> 0:11:,000
los guías se ponían a trabajar,

227
0:11:00.395,000 --> 0:11:02,000
después que la persona preguntaba,

228
0:11:02.682,000 --> 0:11:03,000
observaban su estado emocional,

229
0:11:04.351,000 --> 0:11:05,000
le hacían más preguntas,

230
0:11:05.809,000 --> 0:11:09,000
como: "¿Por qué quieres saber esta profecía? ¿Quién eres?

231
0:11:09.847,000 --> 0:11:11,000
¿Qué vas a hacer con esta información?"

232
0:11:11.992,000 --> 0:11:14,000
Y después los guías usaban esta información, más etnográfica,

233
0:11:15.283,000 --> 0:11:17,000
esta información más cualitativa,

234
0:11:17.569,000 --> 0:11:19,000
e interpretaban los balbuceos del oráculo.

235
0:11:20.782,000 --> 0:11:22,000
Así que el oráculo no estaba solo,

236
0:11:23.522,000 --> 0:11:25,000
y tampoco deberían estarlo los sistemas de big data.

237
0:11:26.3,000 --> 0:11:27,000
Ahora, aclaremos,

238
0:11:27.323,000 --> 0:11:3,000
no estoy diciendo que los sistemas de big data estén inhalando gas

239
0:11:31.306,000 --> 0:11:32,000
o haciendo malas predicciones.

240
0:11:33.254,000 --> 0:11:34,000
Al contrario,

241
0:11:34.327,000 --> 0:11:36,000
estoy diciendo que

242
0:11:36.841,000 --> 0:11:39,000
de la misma forma que el oráculo necesitaba los guías de templo,

243
0:11:40.351,000 --> 0:11:42,000
nuestros sistemas de big data también los necesitan.

244
0:11:43.152,000 --> 0:11:46,000
Necesitan etnógrafos e investigadores

245
0:11:47.059,000 --> 0:11:5,000
que puedan colectar lo que yo llamo "datos densos".

246
0:11:50.085,000 --> 0:11:53,000
Estos preciosos datos humanos,

247
0:11:53.137,000 --> 0:11:57,000
como historias, emociones, interacciones que no se pueden cuantificar.

248
0:11:57.52,000 --> 0:11:59,000
Es el tipo de datos que colecté para Nokia,

249
0:11:59.534,000 --> 0:12:01,000
que se obtienen con pocas muestras,

250
0:12:02.482,000 --> 0:12:05,000
pero traen información trascendente.

251
0:12:06.013,000 --> 0:12:09,000
Y lo que hace esto tan denso y sustancioso,

252
0:12:09.799,000 --> 0:12:13,000
es la experiencia de entender la narrativa humana.

253
0:12:14.509,000 --> 0:12:18,000
Y eso es lo que ayuda a ver lo que hace falta en nuestros modelos.

254
0:12:18.743,000 --> 0:12:21,000
Los "datos densos" arraigan nuestras preguntas de negocios en preguntas humanas

255
0:12:22.708,000 --> 0:12:26,000
y por eso integrando big data y "datos densos"

256
0:12:26.812,000 --> 0:12:27,000
formamos una figura más completa.

257
0:12:28.759,000 --> 0:12:3,000
Los grandes volúmenes de datos nos ofrecen ideas en escala,

258
0:12:31.524,000 --> 0:12:33,000
sostienen lo mejor de la inteligencia artificial

259
0:12:34.007,000 --> 0:12:37,000
mientras que los "datos densos" nos ayudan a rescatar el contexto perdido

260
0:12:37.493,000 --> 0:12:39,000
que viene del uso de big data

261
0:12:39.519,000 --> 0:12:41,000
y le saca provecho a lo mejor de la inteligencia humana.

262
0:12:42.267,000 --> 0:12:45,000
Y cuando se integra ambas cosas, la cosa se pone divertida,

263
0:12:45.417,000 --> 0:12:47,000
porque uno ya no trabaja solo con datos

264
0:12:47.656,000 --> 0:12:48,000
que ha recolectado.

265
0:12:48.77,000 --> 0:12:5,000
También trabaja con datos que nunca ha recolectado.

266
0:12:51.479,000 --> 0:12:53,000
Puede hacer preguntas como ¿por qué?

267
0:12:53.927,000 --> 0:12:54,000
¿Por qué está pasando esto?

268
0:12:55.484,000 --> 0:12:56,000
Ahora, cuando Netflix hizo esto,

269
0:12:57.327,000 --> 0:13:,000
desencadenó una nueva manera de transformar su negocio.

270
0:13:01.501,000 --> 0:13:04,000
Netflix es conocido por su excelente algoritmo de recomendaciones,

271
0:13:05.235,000 --> 0:13:09,000
y tenía un premio de USD 1 millón para cualquiera que lo pudiera mejorar.

272
0:13:09.823,000 --> 0:13:11,000
Y hubo ganadores.

273
0:13:11.859,000 --> 0:13:15,000
Pero Netflix descubrió que las mejoras eran solo graduales.

274
0:13:16.659,000 --> 0:13:18,000
Para realmente enterarse de lo que pasaba,

275
0:13:19.238,000 --> 0:13:22,000
contrataron a un etnógrafo, Grant McCracken,

276
0:13:22.772,000 --> 0:13:24,000
para compilar inferencias de "datos densos".

277
0:13:25.124,000 --> 0:13:28,000
Y Grant descubrió algo que no vieron inicialmente

278
0:13:28.555,000 --> 0:13:3,000
en los datos cuantitativos.

279
0:13:30.638,000 --> 0:13:33,000
Descubrió que a la gente le encanta mirar de una sentada.

280
0:13:33.782,000 --> 0:13:35,000
Tanto es así que las personas ni se sentían culpables.

281
0:13:35.799,000 --> 0:13:35,000
Disfrutaban.

282
0:13:36.7,000 --> 0:13:37,000
(Risas)

283
0:13:38.266,000 --> 0:13:4,000
Así que Netflix dijo: "Ah, esto es nuevo".

284
0:13:40.66,000 --> 0:13:42,000
Incluyeron al equipo de análisis de datos,

285
0:13:43.099,000 --> 0:13:45,000
y lograron incluir estos hallazgos de los datos densos

286
0:13:45.768,000 --> 0:13:47,000
con los datos cuantitativos.

287
0:13:47.785,000 --> 0:13:5,000
Y una vez que lo verificaron y validaron,

288
0:13:51.031,000 --> 0:13:56,000
Netflix decidió hacer algo muy simple pero con mucho impacto.

289
0:13:56.283,000 --> 0:14:02,000
Dijeron: "En vez de ofrecer series de diferentes géneros

290
0:14:02.847,000 --> 0:14:06,000
o más variedad de series a usuarios similares,

291
0:14:06.894,000 --> 0:14:08,000
vamos a ofrecer más de la misma serie.

292
0:14:09.639,000 --> 0:14:11,000
Les vamos a facilitar ver series de una sentada.

293
0:14:11.936,000 --> 0:14:12,000
Y no pararon allí.

294
0:14:13.065,000 --> 0:14:15,000
Hicieron todo esto

295
0:14:15.253,000 --> 0:14:17,000
para rediseñar la experiencia completa de los espectadores,

296
0:14:18.147,000 --> 0:14:2,000
para fomentar los atracones de series.

297
0:14:20.162,000 --> 0:14:23,000
Por eso es que la gente y los amigos se desaparecen por fines de semanas,

298
0:14:23.493,000 --> 0:14:25,000
están mirando shows como Dueño de nadie.

299
0:14:25.854,000 --> 0:14:29,000
Al integrar big data con "datos densos", no solo mejoraron su negocio,

300
0:14:30.037,000 --> 0:14:32,000
sino que transformaron la manera de consumo de la audiencia.

301
0:14:33.03,000 --> 0:14:37,000
Ahora proyectan duplicar el valor de sus acciones en los próximos años.

302
0:14:37.576,000 --> 0:14:4,000
Pero esto no solo se trata de cómo consumimos programación,

303
0:14:41.341,000 --> 0:14:43,000
o vendemos más teléfonos inteligentes.

304
0:14:44.108,000 --> 0:14:48,000
Para algunos, la integración de ideas de "datos densos" a los algoritmos

305
0:14:48.53,000 --> 0:14:5,000
puede significar algo de vida o muerte,

306
0:14:50.814,000 --> 0:14:52,000
especialmente para los marginados.

307
0:14:53.506,000 --> 0:14:56,000
En todo el país, las comisarías están usando big data

308
0:14:57.297,000 --> 0:14:59,000
para predecir dónde patrullar;

309
0:14:59.407,000 --> 0:15:02,000
para determinar las fianzas y las sentencias

310
0:15:02.539,000 --> 0:15:05,000
en maneras que refuerzan prejuicios existentes.

311
0:15:05.582,000 --> 0:15:09,000
El algoritmo "Skynet" de la Agencia Nacional de Seguridad

312
0:15:09.757,000 --> 0:15:12,000
quizá haya contribuido a miles de muertes de civiles

313
0:15:13.051,000 --> 0:15:17,000
en Pakistán por malinterpretar metadatos de aparatos móviles.

314
0:15:19.273,000 --> 0:15:21,000
Mientras más automatizadas nuestras vidas,

315
0:15:21.854,000 --> 0:15:24,000
desde automóviles hasta seguro médico o empleo,

316
0:15:25.077,000 --> 0:15:27,000
es probable que a todos

317
0:15:28.011,000 --> 0:15:31,000
nos afecte la parcialidad hacia la cuantificación.

318
0:15:32.783,000 --> 0:15:34,000
Las buenas noticias son que hemos progresado mucho

319
0:15:35.671,000 --> 0:15:37,000
desde que aspirábamos gases para hacer predicciones.

320
0:15:38.172,000 --> 0:15:4,000
Tenemos mejores herramientas, o sea que usémoslas mejor.

321
0:15:40.806,000 --> 0:15:42,000
Integremos big data con los "datos densos",

322
0:15:43.31,000 --> 0:15:45,000
Unamos a los guías del templo con los oráculos,

323
0:15:45.791,000 --> 0:15:48,000
y ya sea que lo hagamos en empresas u organizaciones sin fines de lucro

324
0:15:49.299,000 --> 0:15:51,000
en gobiernos o en el software,

325
0:15:51.561,000 --> 0:15:52,000
todo es importante,

326
0:15:53.3,000 --> 0:15:57,000
porque significa que colectivamente estamos comprometidos

327
0:15:57.338,000 --> 0:15:58,000
a crear mejores datos,

328
0:15:59.074,000 --> 0:16:,000
algoritmos, resultados,

329
0:16:00.462,000 --> 0:16:02,000
y a tomar mejores decisiones.

330
0:16:02.562,000 --> 0:16:05,000
Así evitaremos perdernos algo.

331
0:16:06.206,000 --> 0:16:1,000
(Aplausos)

