1
0:00:15.285,000 --> 0:00:19,000
Okay, now I don't want to alarm anybody in this room,

2
0:00:20.26,000 --> 0:00:23,000
but it's just come to my attention that the person to your right is a liar.

3
0:00:24.26,000 --> 0:00:25,000
(Laughter)

4
0:00:26.26,000 --> 0:00:28,000
Also, the person to your left is a liar.

5
0:00:29.26,000 --> 0:00:31,000
Also the person sitting in your very seats is a liar.

6
0:00:32.26,000 --> 0:00:33,000
We're all liars.

7
0:00:34.26,000 --> 0:00:35,000
What I'm going to do today

8
0:00:36.26,000 --> 0:00:39,000
is I'm going to show you what the research says about why we're all liars,

9
0:00:39.86,000 --> 0:00:4,000
how you can become a liespotter

10
0:00:41.46,000 --> 0:00:43,000
and why you might want to go the extra mile

11
0:00:44.26,000 --> 0:00:46,000
and go from liespotting to truth seeking,

12
0:00:47.26,000 --> 0:00:48,000
and ultimately to trust building.

13
0:00:49.26,000 --> 0:00:51,000
Now, speaking of trust,

14
0:00:52.26,000 --> 0:00:54,000
ever since I wrote this book, "Liespotting,"

15
0:00:55.26,000 --> 0:00:57,000
no one wants to meet me in person anymore, no, no, no, no, no.

16
0:00:58.26,000 --> 0:01:,000
They say, "It's okay, we'll email you."

17
0:01:01.26,000 --> 0:01:02,000
(Laughter)

18
0:01:03.26,000 --> 0:01:06,000
I can't even get a coffee date at Starbucks.

19
0:01:07.26,000 --> 0:01:08,000
My husband's like, "Honey, deception?

20
0:01:09.26,000 --> 0:01:12,000
Maybe you could have focused on cooking. How about French cooking?"

21
0:01:12.475,000 --> 0:01:14,000
So before I get started, what I'm going to do

22
0:01:14.642,000 --> 0:01:16,000
is I'm going to clarify my goal for you,

23
0:01:17.26,000 --> 0:01:18,000
which is not to teach a game of Gotcha.

24
0:01:19.26,000 --> 0:01:2,000
Liespotters aren't those nitpicky kids,

25
0:01:21.26,000 --> 0:01:24,000
those kids in the back of the room that are shouting, "Gotcha! Gotcha!

26
0:01:24.618,000 --> 0:01:26,000
Your eyebrow twitched. You flared your nostril.

27
0:01:27.26,000 --> 0:01:29,000
I watch that TV show 'Lie To Me.' I know you're lying."

28
0:01:30.26,000 --> 0:01:31,000
No, liespotters are armed

29
0:01:32.26,000 --> 0:01:34,000
with scientific knowledge of how to spot deception.

30
0:01:35.26,000 --> 0:01:36,000
They use it to get to the truth,

31
0:01:37.26,000 --> 0:01:39,000
and they do what mature leaders do everyday;

32
0:01:39.38,000 --> 0:01:41,000
they have difficult conversations with difficult people,

33
0:01:42.26,000 --> 0:01:43,000
sometimes during very difficult times.

34
0:01:44.26,000 --> 0:01:47,000
And they start up that path by accepting a core proposition,

35
0:01:48.26,000 --> 0:01:49,000
and that proposition is the following:

36
0:01:50.26,000 --> 0:01:52,000
Lying is a cooperative act.

37
0:01:54.037,000 --> 0:01:57,000
Think about it, a lie has no power whatsoever by its mere utterance.

38
0:01:57.26,000 --> 0:01:58,000
Its power emerges

39
0:01:59.26,000 --> 0:02:01,000
when someone else agrees to believe the lie.

40
0:02:01.38,000 --> 0:02:02,000
So I know it may sound like tough love,

41
0:02:03.38,000 --> 0:02:06,000
but look, if at some point you got lied to,

42
0:02:07.26,000 --> 0:02:08,000
it's because you agreed to get lied to.

43
0:02:09.26,000 --> 0:02:11,000
Truth number one about lying: Lying's a cooperative act.

44
0:02:12.26,000 --> 0:02:13,000
Now not all lies are harmful.

45
0:02:14.26,000 --> 0:02:16,000
Sometimes we're willing participants in deception

46
0:02:17.26,000 --> 0:02:19,000
for the sake of social dignity,

47
0:02:20.26,000 --> 0:02:22,000
maybe to keep a secret that should be kept secret, secret.

48
0:02:23.26,000 --> 0:02:24,000
We say, "Nice song."

49
0:02:25.26,000 --> 0:02:27,000
"Honey, you don't look fat in that, no."

50
0:02:28.26,000 --> 0:02:29,000
Or we say, favorite of the digiratti,

51
0:02:30.26,000 --> 0:02:32,000
"You know, I just fished that email out of my Spam folder.

52
0:02:33.26,000 --> 0:02:35,000
So sorry."

53
0:02:36.26,000 --> 0:02:39,000
But there are times when we are unwilling participants in deception.

54
0:02:39.523,000 --> 0:02:41,000
And that can have dramatic costs for us.

55
0:02:42.26,000 --> 0:02:44,000
Last year saw 997 billion dollars

56
0:02:45.26,000 --> 0:02:48,000
in corporate fraud alone in the United States.

57
0:02:49.593,000 --> 0:02:51,000
That's an eyelash under a trillion dollars.

58
0:02:51.632,000 --> 0:02:52,000
That's seven percent of revenues.

59
0:02:53.26,000 --> 0:02:54,000
Deception can cost billions.

60
0:02:55.26,000 --> 0:02:57,000
Think Enron, Madoff, the mortgage crisis.

61
0:02:58.26,000 --> 0:03:,000
Or in the case of double agents and traitors,

62
0:03:01.26,000 --> 0:03:02,000
like Robert Hanssen or Aldrich Ames,

63
0:03:03.26,000 --> 0:03:04,000
lies can betray our country,

64
0:03:05.26,000 --> 0:03:08,000
they can compromise our security, they can undermine democracy,

65
0:03:08.284,000 --> 0:03:1,000
they can cause the deaths of those that defend us.

66
0:03:11.26,000 --> 0:03:13,000
Deception is actually serious business.

67
0:03:14.26,000 --> 0:03:17,000
This con man, Henry Oberlander, he was such an effective con man,

68
0:03:18.26,000 --> 0:03:19,000
British authorities say

69
0:03:20.26,000 --> 0:03:23,000
he could have undermined the entire banking system of the Western world.

70
0:03:23.76,000 --> 0:03:26,000
And you can't find this guy on Google; you can't find him anywhere.

71
0:03:26.96,000 --> 0:03:28,000
He was interviewed once, and he said the following.

72
0:03:29.46,000 --> 0:03:3,000
He said, "Look, I've got one rule."

73
0:03:31.16,000 --> 0:03:33,000
And this was Henry's rule, he said,

74
0:03:33.26,000 --> 0:03:35,000
"Look, everyone is willing to give you something.

75
0:03:35.66,000 --> 0:03:38,000
They're ready to give you something for whatever it is they're hungry for."

76
0:03:39.256,000 --> 0:03:4,000
And that's the crux of it.

77
0:03:40.66,000 --> 0:03:42,000
If you don't want to be deceived, you have to know,

78
0:03:43.113,000 --> 0:03:44,000
what is it that you're hungry for?

79
0:03:44.813,000 --> 0:03:46,000
And we all kind of hate to admit it.

80
0:03:47.26,000 --> 0:03:49,000
We wish we were better husbands, better wives,

81
0:03:50.26,000 --> 0:03:53,000
smarter, more powerful, taller, richer --

82
0:03:54.26,000 --> 0:03:55,000
the list goes on.

83
0:03:56.26,000 --> 0:03:57,000
Lying is an attempt to bridge that gap,

84
0:03:58.26,000 --> 0:03:59,000
to connect our wishes and our fantasies

85
0:04:00.26,000 --> 0:04:02,000
about who we wish we were, how we wish we could be,

86
0:04:03.26,000 --> 0:04:05,000
with what we're really like.

87
0:04:06.26,000 --> 0:04:09,000
And boy are we willing to fill in those gaps in our lives with lies.

88
0:04:09.523,000 --> 0:04:11,000
On a given day, studies show that you may be lied to

89
0:04:12.26,000 --> 0:04:13,000
anywhere from 10 to 200 times.

90
0:04:14.26,000 --> 0:04:16,000
Now granted, many of those are white lies.

91
0:04:17.26,000 --> 0:04:18,000
But in another study,

92
0:04:19.26,000 --> 0:04:2,000
it showed that strangers lied three times

93
0:04:21.26,000 --> 0:04:23,000
within the first 10 minutes of meeting each other.

94
0:04:23.665,000 --> 0:04:24,000
(Laughter)

95
0:04:25.26,000 --> 0:04:27,000
Now when we first hear this data, we recoil.

96
0:04:28.26,000 --> 0:04:29,000
We can't believe how prevalent lying is.

97
0:04:30.26,000 --> 0:04:31,000
We're essentially against lying.

98
0:04:32.26,000 --> 0:04:35,000
But if you look more closely, the plot actually thickens.

99
0:04:36.26,000 --> 0:04:38,000
We lie more to strangers than we lie to coworkers.

100
0:04:39.26,000 --> 0:04:42,000
Extroverts lie more than introverts.

101
0:04:43.26,000 --> 0:04:47,000
Men lie eight times more about themselves than they do other people.

102
0:04:48.26,000 --> 0:04:5,000
Women lie more to protect other people.

103
0:04:51.26,000 --> 0:04:53,000
If you're an average married couple,

104
0:04:54.26,000 --> 0:04:57,000
you're going to lie to your spouse in one out of every 10 interactions.

105
0:04:58.26,000 --> 0:04:59,000
Now, you may think that's bad.

106
0:05:00.26,000 --> 0:05:02,000
If you're unmarried, that number drops to three.

107
0:05:02.57,000 --> 0:05:03,000
Lying's complex.

108
0:05:04.26,000 --> 0:05:07,000
It's woven into the fabric of our daily and our business lives.

109
0:05:07.284,000 --> 0:05:08,000
We're deeply ambivalent about the truth.

110
0:05:09.26,000 --> 0:05:1,000
We parse it out on an as-needed basis,

111
0:05:11.26,000 --> 0:05:12,000
sometimes for very good reasons,

112
0:05:13.26,000 --> 0:05:16,000
other times just because we don't understand the gaps in our lives.

113
0:05:16.475,000 --> 0:05:17,000
That's truth number two about lying.

114
0:05:18.26,000 --> 0:05:19,000
We're against lying,

115
0:05:20.26,000 --> 0:05:21,000
but we're covertly for it

116
0:05:22.26,000 --> 0:05:26,000
in ways that our society has sanctioned for centuries and centuries and centuries.

117
0:05:26.284,000 --> 0:05:27,000
It's as old as breathing.

118
0:05:28.26,000 --> 0:05:3,000
It's part of our culture, it's part of our history.

119
0:05:30.713,000 --> 0:05:35,000
Think Dante, Shakespeare, the Bible, News of the World.

120
0:05:36.26,000 --> 0:05:37,000
(Laughter)

121
0:05:38.26,000 --> 0:05:4,000
Lying has evolutionary value to us as a species.

122
0:05:40.57,000 --> 0:05:43,000
Researchers have long known that the more intelligent the species,

123
0:05:44.26,000 --> 0:05:45,000
the larger the neocortex,

124
0:05:46.26,000 --> 0:05:47,000
the more likely it is to be deceptive.

125
0:05:48.26,000 --> 0:05:49,000
Now you might remember Koko.

126
0:05:50.26,000 --> 0:05:53,000
Does anybody remember Koko the gorilla who was taught sign language?

127
0:05:53.523,000 --> 0:05:55,000
Koko was taught to communicate via sign language.

128
0:05:56.26,000 --> 0:05:57,000
Here's Koko with her kitten.

129
0:05:58.26,000 --> 0:06:,000
It's her cute little, fluffy pet kitten.

130
0:06:01.26,000 --> 0:06:04,000
Koko once blamed her pet kitten for ripping a sink out of the wall.

131
0:06:05.26,000 --> 0:06:06,000
(Laughter)

132
0:06:07.26,000 --> 0:06:09,000
We're hardwired to become leaders of the pack.

133
0:06:09.475,000 --> 0:06:1,000
It's starts really, really early.

134
0:06:11.26,000 --> 0:06:12,000
How early?

135
0:06:13.26,000 --> 0:06:14,000
Well babies will fake a cry,

136
0:06:15.26,000 --> 0:06:16,000
pause, wait to see who's coming

137
0:06:17.26,000 --> 0:06:18,000
and then go right back to crying.

138
0:06:19.26,000 --> 0:06:2,000
One-year-olds learn concealment.

139
0:06:21.26,000 --> 0:06:22,000
(Laughter)

140
0:06:23.26,000 --> 0:06:24,000
Two-year-olds bluff.

141
0:06:25.26,000 --> 0:06:26,000
Five-year-olds lie outright.

142
0:06:27.26,000 --> 0:06:28,000
They manipulate via flattery.

143
0:06:29.26,000 --> 0:06:31,000
Nine-year-olds, masters of the cover-up.

144
0:06:32.26,000 --> 0:06:33,000
By the time you enter college,

145
0:06:34.26,000 --> 0:06:37,000
you're going to lie to your mom in one out of every five interactions.

146
0:06:37.66,000 --> 0:06:39,000
By the time we enter this work world and we're breadwinners,

147
0:06:40.56,000 --> 0:06:43,000
we enter a world that is just cluttered with Spam, fake digital friends,

148
0:06:44.26,000 --> 0:06:45,000
partisan media,

149
0:06:46.26,000 --> 0:06:47,000
ingenious identity thieves,

150
0:06:48.26,000 --> 0:06:49,000
world-class Ponzi schemers,

151
0:06:50.26,000 --> 0:06:51,000
a deception epidemic --

152
0:06:52.26,000 --> 0:06:56,000
in short, what one author calls a post-truth society.

153
0:06:57.261,000 --> 0:07:,000
It's been very confusing for a long time now.

154
0:07:03.925,000 --> 0:07:04,000
What do you do?

155
0:07:05.26,000 --> 0:07:08,000
Well, there are steps we can take to navigate our way through the morass.

156
0:07:09.26,000 --> 0:07:11,000
Trained liespotters get to the truth 90 percent of the time.

157
0:07:12.26,000 --> 0:07:14,000
The rest of us, we're only 54 percent accurate.

158
0:07:15.26,000 --> 0:07:16,000
Why is it so easy to learn?

159
0:07:17.26,000 --> 0:07:19,000
There are good liars and bad liars.

160
0:07:19.499,000 --> 0:07:2,000
There are no real original liars.

161
0:07:21.16,000 --> 0:07:23,000
We all make the same mistakes. We all use the same techniques.

162
0:07:24.16,000 --> 0:07:27,000
So what I'm going to do is I'm going to show you two patterns of deception.

163
0:07:27.813,000 --> 0:07:29,000
And then we're going to look at the hot spots

164
0:07:30.036,000 --> 0:07:31,000
and see if we can find them ourselves.

165
0:07:31.913,000 --> 0:07:32,000
We're going to start with speech.

166
0:07:33.56,000 --> 0:07:35,000
(Video) Bill Clinton: I want you to listen to me.

167
0:07:35.918,000 --> 0:07:36,000
I'm going to say this again.

168
0:07:37.36,000 --> 0:07:43,000
I did not have sexual relations with that woman, Miss Lewinsky.

169
0:07:44.26,000 --> 0:07:47,000
I never told anybody to lie, not a single time, never.

170
0:07:48.26,000 --> 0:07:5,000
And these allegations are false.

171
0:07:51.26,000 --> 0:07:53,000
And I need to go back to work for the American people.

172
0:07:53.856,000 --> 0:07:54,000
Thank you.

173
0:07:55.856,000 --> 0:07:56,000
(Applause)

174
0:07:58.26,000 --> 0:08:,000
Pamela Meyer: Okay, what were the telltale signs?

175
0:08:01.26,000 --> 0:08:04,000
Well first we heard what's known as a non-contracted denial.

176
0:08:05.26,000 --> 0:08:08,000
Studies show that people who are overdetermined in their denial

177
0:08:08.284,000 --> 0:08:1,000
will resort to formal rather than informal language.

178
0:08:11.26,000 --> 0:08:13,000
We also heard distancing language: "that woman."

179
0:08:14.26,000 --> 0:08:16,000
We know that liars will unconsciously distance themselves

180
0:08:16.999,000 --> 0:08:17,000
from their subject,

181
0:08:18.26,000 --> 0:08:2,000
using language as their tool.

182
0:08:21.26,000 --> 0:08:24,000
Now if Bill Clinton had said, "Well, to tell you the truth ..."

183
0:08:24.332,000 --> 0:08:26,000
or Richard Nixon's favorite, "In all candor ..."

184
0:08:26.647,000 --> 0:08:27,000
he would have been a dead giveaway

185
0:08:28.36,000 --> 0:08:29,000
for any liespotter that knows

186
0:08:30.26,000 --> 0:08:33,000
that qualifying language, as it's called, qualifying language like that,

187
0:08:33.713,000 --> 0:08:34,000
further discredits the subject.

188
0:08:35.26,000 --> 0:08:37,000
Now if he had repeated the question in its entirety,

189
0:08:38.26,000 --> 0:08:41,000
or if he had peppered his account with a little too much detail --

190
0:08:42.26,000 --> 0:08:44,000
and we're all really glad he didn't do that --

191
0:08:44.475,000 --> 0:08:46,000
he would have further discredited himself.

192
0:08:46.499,000 --> 0:08:47,000
Freud had it right.

193
0:08:48.26,000 --> 0:08:5,000
Freud said, look, there's much more to it than speech:

194
0:08:51.26,000 --> 0:08:53,000
"No mortal can keep a secret.

195
0:08:54.26,000 --> 0:08:56,000
If his lips are silent, he chatters with his fingertips."

196
0:08:57.26,000 --> 0:08:59,000
And we all do it no matter how powerful you are.

197
0:09:00.26,000 --> 0:09:01,000
We all chatter with our fingertips.

198
0:09:02.26,000 --> 0:09:04,000
I'm going to show you Dominique Strauss-Kahn with Obama

199
0:09:05.26,000 --> 0:09:07,000
who's chattering with his fingertips.

200
0:09:08.26,000 --> 0:09:1,000
(Laughter)

201
0:09:11.26,000 --> 0:09:16,000
Now this brings us to our next pattern, which is body language.

202
0:09:17.26,000 --> 0:09:19,000
With body language, here's what you've got to do.

203
0:09:20.26,000 --> 0:09:22,000
You've really got to just throw your assumptions out the door.

204
0:09:23.26,000 --> 0:09:25,000
Let the science temper your knowledge a little bit.

205
0:09:25.713,000 --> 0:09:27,000
Because we think liars fidget all the time.

206
0:09:28.26,000 --> 0:09:31,000
Well guess what, they're known to freeze their upper bodies when they're lying.

207
0:09:32.046,000 --> 0:09:34,000
We think liars won't look you in the eyes.

208
0:09:34.26,000 --> 0:09:36,000
Well guess what, they look you in the eyes a little too much

209
0:09:37.16,000 --> 0:09:38,000
just to compensate for that myth.

210
0:09:38.76,000 --> 0:09:41,000
We think warmth and smiles convey honesty, sincerity.

211
0:09:42.26,000 --> 0:09:45,000
But a trained liespotter can spot a fake smile a mile away.

212
0:09:46.26,000 --> 0:09:49,000
Can you all spot the fake smile here?

213
0:09:50.26,000 --> 0:09:54,000
You can consciously contract the muscles in your cheeks.

214
0:09:55.26,000 --> 0:09:57,000
But the real smile's in the eyes, the crow's feet of the eyes.

215
0:09:58.26,000 --> 0:09:59,000
They cannot be consciously contracted,

216
0:10:00.26,000 --> 0:10:01,000
especially if you overdid the Botox.

217
0:10:02.26,000 --> 0:10:04,000
Don't overdo the Botox; nobody will think you're honest.

218
0:10:05.26,000 --> 0:10:06,000
Now we're going to look at the hot spots.

219
0:10:07.26,000 --> 0:10:09,000
Can you tell what's happening in a conversation?

220
0:10:09.57,000 --> 0:10:11,000
Can you start to find the hot spots

221
0:10:12.26,000 --> 0:10:13,000
to see the discrepancies

222
0:10:14.26,000 --> 0:10:16,000
between someone's words and someone's actions?

223
0:10:16.475,000 --> 0:10:17,000
Now, I know it seems really obvious,

224
0:10:18.26,000 --> 0:10:22,000
but when you're having a conversation with someone you suspect of deception,

225
0:10:23.26,000 --> 0:10:26,000
attitude is by far the most overlooked but telling of indicators.

226
0:10:26.36,000 --> 0:10:28,000
An honest person is going to be cooperative.

227
0:10:28.58,000 --> 0:10:3,000
They're going to show they're on your side.

228
0:10:30.652,000 --> 0:10:31,000
They're going to be enthusiastic.

229
0:10:32.26,000 --> 0:10:35,000
They're going to be willing and helpful to getting you to the truth.

230
0:10:35.56,000 --> 0:10:37,000
They're going to be willing to brainstorm, name suspects,

231
0:10:38.36,000 --> 0:10:39,000
provide details.

232
0:10:39.66,000 --> 0:10:4,000
They're going to say,

233
0:10:41.26,000 --> 0:10:44,000
"Hey, maybe it was those guys in payroll that forged those checks."

234
0:10:44.46,000 --> 0:10:47,000
They're going to be infuriated if they sense they're wrongly accused

235
0:10:47.76,000 --> 0:10:5,000
throughout the entire course of the interview, not just in flashes;

236
0:10:50.96,000 --> 0:10:53,000
they'll be infuriated throughout the entire course of the interview.

237
0:10:54.223,000 --> 0:10:55,000
And if you ask someone honest

238
0:10:55.66,000 --> 0:10:57,000
what should happen to whomever did forge those checks,

239
0:10:58.26,000 --> 0:10:59,000
an honest person is much more likely

240
0:11:00.06,000 --> 0:11:03,000
to recommend strict rather than lenient punishment.

241
0:11:03.26,000 --> 0:11:05,000
Now let's say you're having that exact same conversation

242
0:11:05.951,000 --> 0:11:06,000
with someone deceptive.

243
0:11:07.26,000 --> 0:11:08,000
That person may be withdrawn,

244
0:11:09.26,000 --> 0:11:1,000
look down, lower their voice,

245
0:11:11.26,000 --> 0:11:12,000
pause, be kind of herky-jerky.

246
0:11:13.26,000 --> 0:11:15,000
Ask a deceptive person to tell their story,

247
0:11:15.332,000 --> 0:11:17,000
they're going to pepper it with way too much detail

248
0:11:18.26,000 --> 0:11:2,000
in all kinds of irrelevant places.

249
0:11:21.26,000 --> 0:11:24,000
And then they're going to tell their story in strict chronological order.

250
0:11:24.76,000 --> 0:11:25,000
And what a trained interrogator does

251
0:11:26.56,000 --> 0:11:29,000
is they come in and in very subtle ways over the course of several hours,

252
0:11:30.26,000 --> 0:11:32,000
they will ask that person to tell that story backwards,

253
0:11:33.26,000 --> 0:11:34,000
and then they'll watch them squirm,

254
0:11:35.26,000 --> 0:11:38,000
and track which questions produce the highest volume of deceptive tells.

255
0:11:38.713,000 --> 0:11:4,000
Why do they do that? Well, we all do the same thing.

256
0:11:41.26,000 --> 0:11:42,000
We rehearse our words,

257
0:11:43.26,000 --> 0:11:44,000
but we rarely rehearse our gestures.

258
0:11:45.26,000 --> 0:11:46,000
We say "yes," we shake our heads "no."

259
0:11:47.26,000 --> 0:11:5,000
We tell very convincing stories, we slightly shrug our shoulders.

260
0:11:50.38,000 --> 0:11:51,000
We commit terrible crimes,

261
0:11:52.26,000 --> 0:11:54,000
and we smile at the delight in getting away with it.

262
0:11:55.26,000 --> 0:11:57,000
Now, that smile is known in the trade as "duping delight."

263
0:11:58.26,000 --> 0:12:,000
And we're going to see that in several videos moving forward,

264
0:12:01.26,000 --> 0:12:04,000
but we're going to start -- for those of you who don't know him,

265
0:12:04.36,000 --> 0:12:06,000
this is presidential candidate John Edwards

266
0:12:06.46,000 --> 0:12:08,000
who shocked America by fathering a child out of wedlock.

267
0:12:09.26,000 --> 0:12:11,000
We're going to see him talk about getting a paternity test.

268
0:12:12.26,000 --> 0:12:16,000
See now if you can spot him saying, "yes" while shaking his head "no,"

269
0:12:16.284,000 --> 0:12:17,000
slightly shrugging his shoulders.

270
0:12:18.26,000 --> 0:12:2,000
(Video) John Edwards: I'd be happy to participate in one.

271
0:12:20.96,000 --> 0:12:22,000
I know that it's not possible that this child could be mine,

272
0:12:23.86,000 --> 0:12:24,000
because of the timing of events.

273
0:12:25.46,000 --> 0:12:26,000
So I know it's not possible.

274
0:12:27.26,000 --> 0:12:3,000
Happy to take a paternity test, and would love to see it happen.

275
0:12:31.26,000 --> 0:12:34,000
Interviewer: Are you going to do that soon? Is there somebody --

276
0:12:34.332,000 --> 0:12:36,000
JE: Well, I'm only one side. I'm only one side of the test.

277
0:12:37.26,000 --> 0:12:39,000
But I'm happy to participate in one.

278
0:12:41.055,000 --> 0:12:43,000
PM: Okay, those head shakes are much easier to spot

279
0:12:43.513,000 --> 0:12:44,000
once you know to look for them.

280
0:12:45.06,000 --> 0:12:48,000
There are going to be times when someone makes one expression

281
0:12:49.06,000 --> 0:12:52,000
while masking another that just kind of leaks through in a flash.

282
0:12:52.26,000 --> 0:12:53,000
Murderers are known to leak sadness.

283
0:12:54.26,000 --> 0:12:56,000
Your new joint venture partner might shake your hand,

284
0:12:56.86,000 --> 0:13:,000
celebrate, go out to dinner with you and then leak an expression of anger.

285
0:13:01.26,000 --> 0:13:04,000
And we're not all going to become facial expression experts overnight here,

286
0:13:04.86,000 --> 0:13:06,000
but there's one I can teach you that's very dangerous

287
0:13:07.362,000 --> 0:13:08,000
and it's easy to learn,

288
0:13:08.599,000 --> 0:13:09,000
and that's the expression of contempt.

289
0:13:10.46,000 --> 0:13:13,000
Now with anger, you've got two people on an even playing field.

290
0:13:13.484,000 --> 0:13:15,000
It's still somewhat of a healthy relationship.

291
0:13:15.699,000 --> 0:13:18,000
But when anger turns to contempt, you've been dismissed.

292
0:13:19.26,000 --> 0:13:2,000
It's associated with moral superiority.

293
0:13:21.26,000 --> 0:13:23,000
And for that reason, it's very, very hard to recover from.

294
0:13:24.26,000 --> 0:13:25,000
Here's what it looks like.

295
0:13:26.26,000 --> 0:13:29,000
It's marked by one lip corner pulled up and in.

296
0:13:30.26,000 --> 0:13:32,000
It's the only asymmetrical expression.

297
0:13:33.26,000 --> 0:13:36,000
And in the presence of contempt, whether or not deception follows --

298
0:13:37.26,000 --> 0:13:38,000
and it doesn't always follow --

299
0:13:39.26,000 --> 0:13:41,000
look the other way, go the other direction,

300
0:13:41.332,000 --> 0:13:42,000
reconsider the deal,

301
0:13:43.26,000 --> 0:13:46,000
say, "No thank you. I'm not coming up for just one more nightcap. Thank you."

302
0:13:47.26,000 --> 0:13:5,000
Science has surfaced many, many more indicators.

303
0:13:51.26,000 --> 0:13:52,000
We know, for example,

304
0:13:53.26,000 --> 0:13:55,000
we know liars will shift their blink rate,

305
0:13:55.284,000 --> 0:13:56,000
point their feet towards an exit.

306
0:13:57.26,000 --> 0:13:58,000
They will take barrier objects

307
0:13:59.26,000 --> 0:14:02,000
and put them between themselves and the person that is interviewing them.

308
0:14:02.713,000 --> 0:14:03,000
They'll alter their vocal tone,

309
0:14:04.26,000 --> 0:14:06,000
often making their vocal tone much lower.

310
0:14:07.26,000 --> 0:14:08,000
Now here's the deal.

311
0:14:09.26,000 --> 0:14:11,000
These behaviors are just behaviors.

312
0:14:12.26,000 --> 0:14:13,000
They're not proof of deception.

313
0:14:14.26,000 --> 0:14:15,000
They're red flags.

314
0:14:16.26,000 --> 0:14:17,000
We're human beings.

315
0:14:18.26,000 --> 0:14:21,000
We make deceptive flailing gestures all over the place all day long.

316
0:14:21.56,000 --> 0:14:23,000
They don't mean anything in and of themselves.

317
0:14:23.775,000 --> 0:14:25,000
But when you see clusters of them, that's your signal.

318
0:14:26.36,000 --> 0:14:28,000
Look, listen, probe, ask some hard questions,

319
0:14:29.26,000 --> 0:14:31,000
get out of that very comfortable mode of knowing,

320
0:14:32.26,000 --> 0:14:34,000
walk into curiosity mode, ask more questions,

321
0:14:35.26,000 --> 0:14:38,000
have a little dignity, treat the person you're talking to with rapport.

322
0:14:38.66,000 --> 0:14:41,000
Don't try to be like those folks on "Law & Order" and those other TV shows

323
0:14:42.26,000 --> 0:14:44,000
that pummel their subjects into submission.

324
0:14:44.332,000 --> 0:14:46,000
Don't be too aggressive, it doesn't work.

325
0:14:47.379,000 --> 0:14:5,000
Now, we've talked a little bit about how to talk to someone who's lying

326
0:14:50.76,000 --> 0:14:51,000
and how to spot a lie.

327
0:14:52.26,000 --> 0:14:55,000
And as I promised, we're now going to look at what the truth looks like.

328
0:14:55.76,000 --> 0:14:56,000
But I'm going to show you two videos,

329
0:14:57.56,000 --> 0:14:59,000
two mothers -- one is lying, one is telling the truth.

330
0:15:00.26,000 --> 0:15:04,000
And these were surfaced by researcher David Matsumoto in California.

331
0:15:04.38,000 --> 0:15:07,000
And I think they're an excellent example of what the truth looks like.

332
0:15:08.26,000 --> 0:15:09,000
This mother, Diane Downs,

333
0:15:10.26,000 --> 0:15:11,000
shot her kids at close range,

334
0:15:12.26,000 --> 0:15:15,000
drove them to the hospital while they bled all over the car,

335
0:15:16.26,000 --> 0:15:17,000
claimed a scraggy-haired stranger did it.

336
0:15:18.26,000 --> 0:15:19,000
And you'll see when you see the video,

337
0:15:20.26,000 --> 0:15:22,000
she can't even pretend to be an agonizing mother.

338
0:15:22.618,000 --> 0:15:25,000
What you want to look for here is an incredible discrepancy

339
0:15:26.26,000 --> 0:15:29,000
between horrific events that she describes and her very, very cool demeanor.

340
0:15:30.26,000 --> 0:15:33,000
And if you look closely, you'll see duping delight throughout this video.

341
0:15:33.76,000 --> 0:15:35,000
(Video) Diane Downs: At night when I close my eyes,

342
0:15:36.26,000 --> 0:15:39,000
I can see Christie reaching her hand out to me while I'm driving,

343
0:15:39.38,000 --> 0:15:41,000
and the blood just kept coming out of her mouth.

344
0:15:41.66,000 --> 0:15:43,000
And that -- maybe it'll fade too with time --

345
0:15:43.827,000 --> 0:15:44,000
but I don't think so.

346
0:15:45.26,000 --> 0:15:48,000
That bothers me the most.

347
0:15:55.26,000 --> 0:15:56,000
PM: Now I'm going to show you a video

348
0:15:57.26,000 --> 0:15:59,000
of an actual grieving mother, Erin Runnion,

349
0:15:59.332,000 --> 0:16:02,000
confronting her daughter's murderer and torturer in court.

350
0:16:03.26,000 --> 0:16:05,000
Here you're going to see no false emotion,

351
0:16:05.284,000 --> 0:16:07,000
just the authentic expression of a mother's agony.

352
0:16:08.26,000 --> 0:16:1,000
(Video) Erin Runnion: I wrote this statement

353
0:16:10.375,000 --> 0:16:12,000
on the third anniversary of the night you took my baby,

354
0:16:13.06,000 --> 0:16:14,000
and you hurt her,

355
0:16:14.36,000 --> 0:16:15,000
and you crushed her,

356
0:16:16.26,000 --> 0:16:19,000
you terrified her until her heart stopped.

357
0:16:20.26,000 --> 0:16:22,000
And she fought, and I know she fought you.

358
0:16:23.26,000 --> 0:16:26,000
But I know she looked at you with those amazing brown eyes,

359
0:16:27.26,000 --> 0:16:29,000
and you still wanted to kill her.

360
0:16:30.26,000 --> 0:16:31,000
And I don't understand it,

361
0:16:32.26,000 --> 0:16:33,000
and I never will.

362
0:16:35.91,000 --> 0:16:38,000
PM: Okay, there's no doubting the veracity of those emotions.

363
0:16:39.26,000 --> 0:16:41,000
Now the technology around what the truth looks like

364
0:16:42.26,000 --> 0:16:44,000
is progressing on, the science of it.

365
0:16:45.26,000 --> 0:16:46,000
We know, for example,

366
0:16:47.26,000 --> 0:16:5,000
that we now have specialized eye trackers and infrared brain scans,

367
0:16:50.427,000 --> 0:16:52,000
MRI's that can decode the signals that our bodies send out

368
0:16:53.26,000 --> 0:16:54,000
when we're trying to be deceptive.

369
0:16:55.26,000 --> 0:16:57,000
And these technologies are going to be marketed to all of us

370
0:16:58.26,000 --> 0:16:59,000
as panaceas for deceit,

371
0:17:00.26,000 --> 0:17:02,000
and they will prove incredibly useful some day.

372
0:17:03.26,000 --> 0:17:05,000
But you've got to ask yourself in the meantime:

373
0:17:05.523,000 --> 0:17:07,000
Who do you want on your side of the meeting,

374
0:17:07.643,000 --> 0:17:09,000
someone who's trained in getting to the truth

375
0:17:10.26,000 --> 0:17:13,000
or some guy who's going to drag a 400-pound electroencephalogram

376
0:17:13.36,000 --> 0:17:14,000
through the door?

377
0:17:14.66,000 --> 0:17:17,000
Liespotters rely on human tools.

378
0:17:18.26,000 --> 0:17:19,000
They know, as someone once said,

379
0:17:20.26,000 --> 0:17:21,000
"Character's who you are in the dark."

380
0:17:22.26,000 --> 0:17:25,000
And what's kind of interesting is that today, we have so little darkness.

381
0:17:26.26,000 --> 0:17:28,000
Our world is lit up 24 hours a day.

382
0:17:29.26,000 --> 0:17:32,000
It's transparent with blogs and social networks

383
0:17:33.26,000 --> 0:17:35,000
broadcasting the buzz of a whole new generation of people

384
0:17:35.96,000 --> 0:17:37,000
that have made a choice to live their lives in public.

385
0:17:38.56,000 --> 0:17:41,000
It's a much more noisy world.

386
0:17:42.26,000 --> 0:17:45,000
So one challenge we have is to remember,

387
0:17:46.26,000 --> 0:17:48,000
oversharing, that's not honesty.

388
0:17:49.26,000 --> 0:17:52,000
Our manic tweeting and texting can blind us

389
0:17:53.26,000 --> 0:17:56,000
to the fact that the subtleties of human decency -- character integrity --

390
0:17:56.86,000 --> 0:17:59,000
that's still what matters, that's always what's going to matter.

391
0:17:59.932,000 --> 0:18:,000
So in this much noisier world,

392
0:18:01.46,000 --> 0:18:02,000
it might make sense for us

393
0:18:03.26,000 --> 0:18:07,000
to be just a little bit more explicit about our moral code.

394
0:18:08.26,000 --> 0:18:1,000
When you combine the science of recognizing deception

395
0:18:10.86,000 --> 0:18:11,000
with the art of looking, listening,

396
0:18:12.56,000 --> 0:18:14,000
you exempt yourself from collaborating in a lie.

397
0:18:15.26,000 --> 0:18:18,000
You start up that path of being just a little bit more explicit,

398
0:18:19.26,000 --> 0:18:21,000
because you signal to everyone around you,

399
0:18:21.284,000 --> 0:18:25,000
you say, "Hey, my world, our world, it's going to be an honest one.

400
0:18:26.26,000 --> 0:18:28,000
My world is going to be one where truth is strengthened

401
0:18:28.904,000 --> 0:18:3,000
and falsehood is recognized and marginalized."

402
0:18:31.26,000 --> 0:18:32,000
And when you do that,

403
0:18:33.26,000 --> 0:18:35,000
the ground around you starts to shift just a little bit.

404
0:18:36.26,000 --> 0:18:38,000
And that's the truth. Thank you.

405
0:18:39.26,000 --> 0:18:44,000
(Applause)

