1
0:00:13.16,000 --> 0:00:19,000
I'm here to enlist you

2
0:00:19.16,000 --> 0:00:27,000
in helping reshape the story about how humans and other critters get things done.

3
0:00:27.16,000 --> 0:00:32,000
Here is the old story -- we've already heard a little bit about it:

4
0:00:32.16,000 --> 0:00:39,000
biology is war in which only the fiercest survive;

5
0:00:39.16,000 --> 0:00:47,000
businesses and nations succeed only by defeating,

6
0:00:47.16,000 --> 0:00:53,000
destroying and dominating competition;

7
0:00:53.16,000 --> 0:01:,000
politics is about your side winning at all costs.

8
0:01:00.16,000 --> 0:01:08,000
But I think we can see the very beginnings of a new story beginning to emerge.

9
0:01:08.16,000 --> 0:01:15,000
It's a narrative spread across a number of different disciplines,

10
0:01:15.16,000 --> 0:01:23,000
in which cooperation, collective action and complex interdependencies

11
0:01:23.16,000 --> 0:01:26,000
play a more important role.

12
0:01:26.16,000 --> 0:01:35,000
And the central, but not all-important, role of competition and survival of the fittest

13
0:01:35.16,000 --> 0:01:39,000
shrinks just a little bit to make room.

14
0:01:39.16,000 --> 0:01:46,000
I started thinking about the relationship between communication, media

15
0:01:46.16,000 --> 0:01:51,000
and collective action when I wrote "Smart Mobs,"

16
0:01:51.16,000 --> 0:01:56,000
and I found that when I finished the book, I kept thinking about it.

17
0:01:56.16,000 --> 0:02:02,000
In fact, if you look back, human communication media

18
0:02:02.16,000 --> 0:02:09,000
and the ways in which we organize socially have been co-evolving for quite a long time.

19
0:02:09.16,000 --> 0:02:13,000
Humans have lived for much, much longer

20
0:02:13.16,000 --> 0:02:2,000
than the approximately 10,000 years of settled agricultural civilization

21
0:02:20.16,000 --> 0:02:28,000
in small family groups. Nomadic hunters bring down rabbits, gathering food.

22
0:02:28.16,000 --> 0:02:33,000
The form of wealth in those days was enough food to stay alive.

23
0:02:33.16,000 --> 0:02:4,000
But at some point, they banded together to hunt bigger game.

24
0:02:40.16,000 --> 0:02:43,000
And we don't know exactly how they did this,

25
0:02:43.16,000 --> 0:02:48,000
although they must have solved some collective action problems;

26
0:02:48.16,000 --> 0:02:52,000
it only makes sense that you can't hunt mastodons

27
0:02:52.16,000 --> 0:02:55,000
while you're fighting with the other groups.

28
0:02:55.16,000 --> 0:02:57,000
And again, we have no way of knowing,

29
0:02:57.16,000 --> 0:03:02,000
but it's clear that a new form of wealth must have emerged.

30
0:03:02.16,000 --> 0:03:07,000
More protein than a hunter's family could eat before it rotted.

31
0:03:07.16,000 --> 0:03:09,000
So that raised a social question

32
0:03:09.16,000 --> 0:03:12,000
that I believe must have driven new social forms.

33
0:03:12.16,000 --> 0:03:17,000
Did the people who ate that mastodon meat owe something

34
0:03:17.16,000 --> 0:03:19,000
to the hunters and their families?

35
0:03:19.16,000 --> 0:03:23,000
And if so, how did they make arrangements?

36
0:03:23.16,000 --> 0:03:26,000
Again, we can't know, but we can be pretty sure that some form of

37
0:03:26.16,000 --> 0:03:31,000
symbolic communication must have been involved.

38
0:03:31.16,000 --> 0:03:36,000
Of course, with agriculture came the first big civilizations,

39
0:03:36.16,000 --> 0:03:41,000
the first cities built of mud and brick, the first empires.

40
0:03:41.16,000 --> 0:03:45,000
And it was the administers of these empires

41
0:03:45.16,000 --> 0:03:51,000
who began hiring people to keep track of the wheat and sheep and wine that was owed

42
0:03:51.16,000 --> 0:03:53,000
and the taxes that was owed on them

43
0:03:53.16,000 --> 0:03:57,000
by making marks; marks on clay in that time.

44
0:03:57.16,000 --> 0:04:02,000
Not too much longer after that, the alphabet was invented.

45
0:04:02.16,000 --> 0:04:08,000
And this powerful tool was really reserved, for thousands of years,

46
0:04:08.16,000 --> 0:04:18,000
for the elite administrators (Laughter) who kept track of accounts for the empires.

47
0:04:18.16,000 --> 0:04:23,000
And then another communication technology enabled new media:

48
0:04:23.16,000 --> 0:04:28,000
the printing press came along, and within decades,

49
0:04:28.16,000 --> 0:04:3,000
millions of people became literate.

50
0:04:30.16,000 --> 0:04:34,000
And from literate populations,

51
0:04:34.16,000 --> 0:04:38,000
new forms of collective action emerged in the spheres of knowledge,

52
0:04:38.16,000 --> 0:04:42,000
religion and politics.

53
0:04:42.16,000 --> 0:04:47,000
We saw scientific revolutions, the Protestant Reformation,

54
0:04:47.16,000 --> 0:04:53,000
constitutional democracies possible where they had not been possible before.

55
0:04:53.16,000 --> 0:04:55,000
Not created by the printing press,

56
0:04:55.16,000 --> 0:05:,000
but enabled by the collective action that emerges from literacy.

57
0:05:00.16,000 --> 0:05:04,000
And again, new forms of wealth emerged.

58
0:05:04.16,000 --> 0:05:09,000
Now, commerce is ancient. Markets are as old as the crossroads.

59
0:05:09.16,000 --> 0:05:13,000
But capitalism, as we know it, is only a few hundred years old,

60
0:05:13.16,000 --> 0:05:18,000
enabled by cooperative arrangements and technologies,

61
0:05:18.16,000 --> 0:05:21,000
such as the joint-stock ownership company,

62
0:05:21.16,000 --> 0:05:26,000
shared liability insurance, double-entry bookkeeping.

63
0:05:26.16,000 --> 0:05:31,000
Now of course, the enabling technologies are based on the Internet,

64
0:05:31.16,000 --> 0:05:38,000
and in the many-to-many era, every desktop is now a printing press,

65
0:05:38.16,000 --> 0:05:44,000
a broadcasting station, a community or a marketplace.

66
0:05:44.16,000 --> 0:05:47,000
Evolution is speeding up.

67
0:05:47.16,000 --> 0:05:53,000
More recently, that power is untethering and leaping off the desktops,

68
0:05:53.16,000 --> 0:05:59,000
and very, very quickly, we're going to see a significant proportion, if not the majority of

69
0:05:59.16,000 --> 0:06:07,000
the human race, walking around holding, carrying or wearing supercomputers

70
0:06:07.16,000 --> 0:06:1,000
linked at speeds greater

71
0:06:10.16,000 --> 0:06:14,000
than what we consider to be broadband today.

72
0:06:14.16,000 --> 0:06:17,000
Now, when I started looking into collective action,

73
0:06:17.16,000 --> 0:06:23,000
the considerable literature on it is based on what sociologists call "social dilemmas."

74
0:06:23.16,000 --> 0:06:26,000
And there are a couple of mythic narratives of social dilemmas.

75
0:06:26.16,000 --> 0:06:29,000
I'm going to talk briefly about two of them:

76
0:06:29.16,000 --> 0:06:32,000
the prisoner's dilemma and the tragedy of the commons.

77
0:06:32.16,000 --> 0:06:34,000
Now, when I talked about this with Kevin Kelly,

78
0:06:34.16,000 --> 0:06:38,000
he assured me that everybody in this audience pretty much knows the details

79
0:06:38.16,000 --> 0:06:4,000
of the prisoner's dilemma,

80
0:06:40.16,000 --> 0:06:43,000
so I'm just going to go over that very, very quickly.

81
0:06:43.16,000 --> 0:06:5,000
If you have more questions about it, ask Kevin Kelly later. (Laughter)

82
0:06:50.16,000 --> 0:06:53,000
The prisoner's dilemma is actually a story that's overlaid

83
0:06:53.16,000 --> 0:06:57,000
on a mathematical matrix that came out of the game theory

84
0:06:57.16,000 --> 0:07:01,000
in the early years of thinking about nuclear war:

85
0:07:01.16,000 --> 0:07:03,000
two players who couldn't trust each other.

86
0:07:03.16,000 --> 0:07:06,000
Let me just say that every unsecured transaction

87
0:07:06.16,000 --> 0:07:09,000
is a good example of a prisoner's dilemma.

88
0:07:09.16,000 --> 0:07:12,000
Person with the goods, person with the money,

89
0:07:12.16,000 --> 0:07:16,000
because they can't trust each other, are not going to exchange.

90
0:07:16.16,000 --> 0:07:19,000
Neither one wants to be the first one

91
0:07:19.16,000 --> 0:07:21,000
or they're going to get the sucker's payoff,

92
0:07:21.16,000 --> 0:07:25,000
but both lose, of course, because they don't get what they want.

93
0:07:25.16,000 --> 0:07:29,000
If they could only agree, if they could only turn a prisoner's dilemma into

94
0:07:29.16,000 --> 0:07:35,000
a different payoff matrix called an assurance game, they could proceed.

95
0:07:35.16,000 --> 0:07:39,000
Twenty years ago, Robert Axelrod used the prisoner's dilemma

96
0:07:39.16,000 --> 0:07:44,000
as a probe of the biological question:

97
0:07:44.16,000 --> 0:07:49,000
if we are here because our ancestors were such fierce competitors,

98
0:07:49.16,000 --> 0:07:51,000
how does cooperation exist at all?

99
0:07:51.16,000 --> 0:07:53,000
He started a computer tournament for

100
0:07:53.16,000 --> 0:07:58,000
people to submit prisoner's dilemma strategies and discovered,

101
0:07:58.16,000 --> 0:08:02,000
much to his surprise, that a very, very simple strategy won --

102
0:08:02.16,000 --> 0:08:06,000
it won the first tournament, and even after everyone knew it won,

103
0:08:06.16,000 --> 0:08:13,000
it won the second tournament -- that's known as tit for tat.

104
0:08:13.16,000 --> 0:08:19,000
Another economic game that may not be as well known as the prisoner's dilemma

105
0:08:19.16,000 --> 0:08:21,000
is the ultimatum game,

106
0:08:21.16,000 --> 0:08:23,000
and it's also a very interesting probe of

107
0:08:23.16,000 --> 0:08:29,000
our assumptions about the way people make economic transactions.

108
0:08:29.16,000 --> 0:08:32,000
Here's how the game is played: there are two players;

109
0:08:32.16,000 --> 0:08:34,000
they've never played the game before,

110
0:08:34.16,000 --> 0:08:37,000
they will not play the game again, they don't know each other,

111
0:08:37.16,000 --> 0:08:4,000
and they are, in fact, in separate rooms.

112
0:08:40.16,000 --> 0:08:42,000
First player is offered a hundred dollars

113
0:08:42.16,000 --> 0:08:48,000
and is asked to propose a split: 50/50, 90/10,

114
0:08:48.16,000 --> 0:08:55,000
whatever that player wants to propose. The second player either accepts the split --

115
0:08:55.16,000 --> 0:08:58,000
both players are paid and the game is over --

116
0:08:58.16,000 --> 0:09:04,000
or rejects the split -- neither player is paid and the game is over.

117
0:09:04.16,000 --> 0:09:08,000
Now, the fundamental basis of neoclassical economics

118
0:09:08.16,000 --> 0:09:12,000
would tell you it's irrational to reject a dollar

119
0:09:12.16,000 --> 0:09:17,000
because someone you don't know in another room is going to get 99.

120
0:09:17.16,000 --> 0:09:23,000
Yet in thousands of trials with American and European and Japanese students,

121
0:09:23.16,000 --> 0:09:29,000
a significant percentage would reject any offer that's not close to 50/50.

122
0:09:29.16,000 --> 0:09:34,000
And although they were screened and didn't know about the game

123
0:09:34.16,000 --> 0:09:36,000
and had never played the game before,

124
0:09:36.16,000 --> 0:09:39,000
proposers seemed to innately know this

125
0:09:39.16,000 --> 0:09:45,000
because the average proposal was surprisingly close to 50/50.

126
0:09:45.16,000 --> 0:09:47,000
Now, the interesting part comes in more recently

127
0:09:47.16,000 --> 0:09:51,000
when anthropologists began taking this game to other cultures

128
0:09:51.16,000 --> 0:09:54,000
and discovered, to their surprise,

129
0:09:54.16,000 --> 0:09:58,000
that slash-and-burn agriculturalists in the Amazon

130
0:09:58.16,000 --> 0:10:03,000
or nomadic pastoralists in Central Asia or a dozen different cultures --

131
0:10:03.16,000 --> 0:10:08,000
each had radically different ideas of what is fair.

132
0:10:08.16,000 --> 0:10:14,000
Which suggests that instead of there being an innate sense of fairness,

133
0:10:14.16,000 --> 0:10:17,000
that somehow the basis of our economic

134
0:10:17.16,000 --> 0:10:23,000
transactions can be influenced by our social institutions,

135
0:10:23.16,000 --> 0:10:25,000
whether we know that or not.

136
0:10:25.16,000 --> 0:10:3,000
The other major narrative of social dilemmas is the tragedy of the commons.

137
0:10:30.16,000 --> 0:10:36,000
Garrett Hardin used it to talk about overpopulation in the late 1960s.

138
0:10:36.16,000 --> 0:10:42,000
He used the example of a common grazing area in which each person

139
0:10:42.16,000 --> 0:10:45,000
by simply maximizing their own flock

140
0:10:45.16,000 --> 0:10:48,000
led to overgrazing and the depletion of the resource.

141
0:10:48.16,000 --> 0:10:5,000
He had the rather gloomy conclusion that

142
0:10:50.16,000 --> 0:10:55,000
humans will inevitably despoil any common pool resource

143
0:10:55.16,000 --> 0:11:01,000
in which people cannot be restrained from using it.

144
0:11:01.16,000 --> 0:11:04,000
Now, Elinor Ostrom, a political scientist, in

145
0:11:04.16,000 --> 0:11:09,000
1990 asked the interesting question that any good scientist should ask,

146
0:11:09.16,000 --> 0:11:14,000
which is: is it really true that humans will always despoil commons?

147
0:11:14.16,000 --> 0:11:18,000
So she went out and looked at what data she could find.

148
0:11:18.16,000 --> 0:11:22,000
She looked at thousands of cases of humans sharing watersheds,

149
0:11:22.16,000 --> 0:11:29,000
forestry resources, fisheries, and discovered that yes, in case after case,

150
0:11:29.16,000 --> 0:11:33,000
humans destroyed the commons that they depended on.

151
0:11:33.16,000 --> 0:11:4,000
But she also found many instances in which people escaped the prisoner's dilemma;

152
0:11:40.16,000 --> 0:11:46,000
in fact, the tragedy of the commons is a multiplayer prisoner's dilemma.

153
0:11:46.16,000 --> 0:11:51,000
And she said that people are only prisoners if they consider themselves to be.

154
0:11:51.16,000 --> 0:11:55,000
They escape by creating institutions for collective action.

155
0:11:55.16,000 --> 0:11:59,000
And she discovered, I think most interestingly,

156
0:11:59.16,000 --> 0:12:02,000
that among those institutions that worked,

157
0:12:02.16,000 --> 0:12:04,000
there were a number of common design

158
0:12:04.16,000 --> 0:12:07,000
principles, and those principles seem to be

159
0:12:07.16,000 --> 0:12:11,000
missing from those institutions that don't work.

160
0:12:11.16,000 --> 0:12:13,000
I'm moving very quickly over a number of

161
0:12:13.16,000 --> 0:12:16,000
disciplines. In biology, the notions of symbiosis,

162
0:12:16.16,000 --> 0:12:22,000
group selection, evolutionary psychology are contested, to be sure.

163
0:12:22.16,000 --> 0:12:27,000
But there is really no longer any major debate over the fact that

164
0:12:27.16,000 --> 0:12:33,000
cooperative arrangements have moved from a peripheral role to a central role

165
0:12:33.16,000 --> 0:12:39,000
in biology, from the level of the cell to the level of the ecology.

166
0:12:39.16,000 --> 0:12:44,000
And again, our notions of individuals as economic beings

167
0:12:44.16,000 --> 0:12:46,000
have been overturned.

168
0:12:46.16,000 --> 0:12:51,000
Rational self-interest is not always the dominating factor.

169
0:12:51.16,000 --> 0:12:59,000
In fact, people will act to punish cheaters, even at a cost to themselves.

170
0:12:59.16,000 --> 0:13:01,000
And most recently, neurophysiological measures

171
0:13:01.16,000 --> 0:13:07,000
have shown that people who punish cheaters in economic games

172
0:13:07.16,000 --> 0:13:11,000
show activity in the reward centers of their brain.

173
0:13:11.16,000 --> 0:13:18,000
Which led one scientist to declare that altruistic punishment

174
0:13:18.16,000 --> 0:13:22,000
may be the glue that holds societies together.

175
0:13:22.16,000 --> 0:13:27,000
Now, I've been talking about how new forms of communication and new media

176
0:13:27.16,000 --> 0:13:31,000
in the past have helped create new economic forms.

177
0:13:31.16,000 --> 0:13:36,000
Commerce is ancient. Markets are very old. Capitalism is fairly recent;

178
0:13:36.16,000 --> 0:13:4,000
socialism emerged as a reaction to that.

179
0:13:40.16,000 --> 0:13:46,000
And yet we see very little talk about how the next form may be emerging.

180
0:13:46.16,000 --> 0:13:51,000
Jim Surowiecki briefly mentioned Yochai Benkler's paper about open source,

181
0:13:51.16,000 --> 0:13:55,000
pointing to a new form of production: peer-to-peer production.

182
0:13:55.16,000 --> 0:14:01,000
I simply want you to keep in mind that if in the past, new forms of cooperation

183
0:14:01.16,000 --> 0:14:05,000
enabled by new technologies create new forms of wealth,

184
0:14:05.16,000 --> 0:14:09,000
we may be moving into yet another economic form

185
0:14:09.16,000 --> 0:14:13,000
that is significantly different from previous ones.

186
0:14:13.16,000 --> 0:14:19,000
Very briefly, let's look at some businesses. IBM, as you know, HP, Sun --

187
0:14:19.16,000 --> 0:14:25,000
some of the most fierce competitors in the IT world are open sourcing

188
0:14:25.16,000 --> 0:14:32,000
their software, are providing portfolios of patents for the commons.

189
0:14:32.16,000 --> 0:14:37,000
Eli Lilly -- in, again, the fiercely competitive pharmaceutical world --

190
0:14:37.16,000 --> 0:14:43,000
has created a market for solutions for pharmaceutical problems.

191
0:14:43.16,000 --> 0:14:48,000
Toyota, instead of treating its suppliers as a marketplace,

192
0:14:48.16,000 --> 0:14:52,000
treats them as a network and trains them to produce better,

193
0:14:52.16,000 --> 0:14:57,000
even though they are also training them to produce better for their competitors.

194
0:14:57.16,000 --> 0:15:01,000
Now none of these companies are doing this out of altruism;

195
0:15:01.16,000 --> 0:15:03,000
they're doing it because they're learning that

196
0:15:03.16,000 --> 0:15:09,000
a certain kind of sharing is in their self-interest.

197
0:15:09.16,000 --> 0:15:16,000
Open source production has shown us that world-class software, like Linux and Mozilla,

198
0:15:16.16,000 --> 0:15:22,000
can be created with neither the bureaucratic structure of the firm

199
0:15:22.16,000 --> 0:15:28,000
nor the incentives of the marketplace as we've known them.

200
0:15:28.16,000 --> 0:15:34,000
Google enriches itself by enriching thousands of bloggers through AdSense.

201
0:15:34.16,000 --> 0:15:38,000
Amazon has opened its Application Programming Interface

202
0:15:38.16,000 --> 0:15:43,000
to 60,000 developers, countless Amazon shops.

203
0:15:43.16,000 --> 0:15:49,000
They're enriching others, not out of altruism but as a way of enriching themselves.

204
0:15:49.16,000 --> 0:15:54,000
eBay solved the prisoner's dilemma and created a market

205
0:15:54.16,000 --> 0:15:58,000
where none would have existed by creating a feedback mechanism

206
0:15:58.16,000 --> 0:16:03,000
that turns a prisoner's dilemma game into an assurance game.

207
0:16:03.16,000 --> 0:16:08,000
Instead of, "Neither of us can trust each other, so we have to make suboptimal moves,"

208
0:16:08.16,000 --> 0:16:14,000
it's, "You prove to me that you are trustworthy and I will cooperate."

209
0:16:14.16,000 --> 0:16:2,000
Wikipedia has used thousands of volunteers to create a free encyclopedia

210
0:16:20.16,000 --> 0:16:27,000
with a million and a half articles in 200 languages in just a couple of years.

211
0:16:27.16,000 --> 0:16:34,000
We've seen that ThinkCycle has enabled NGOs in developing countries

212
0:16:34.16,000 --> 0:16:4,000
to put up problems to be solved by design students around the world,

213
0:16:40.16,000 --> 0:16:43,000
including something that's being used for tsunami relief right now:

214
0:16:43.16,000 --> 0:16:45,000
it's a mechanism for rehydrating

215
0:16:45.16,000 --> 0:16:48,000
cholera victims that's so simple to use it,

216
0:16:48.16,000 --> 0:16:51,000
illiterates can be trained to use it.

217
0:16:51.16,000 --> 0:16:55,000
BitTorrent turns every downloader into an uploader,

218
0:16:55.16,000 --> 0:17:,000
making the system more efficient the more it is used.

219
0:17:00.16,000 --> 0:17:03,000
Millions of people have contributed their desktop computers

220
0:17:03.16,000 --> 0:17:08,000
when they're not using them to link together through the Internet

221
0:17:08.16,000 --> 0:17:1,000
into supercomputing collectives

222
0:17:10.16,000 --> 0:17:14,000
that help solve the protein folding problem for medical researchers --

223
0:17:14.16,000 --> 0:17:17,000
that's Folding@home at Stanford --

224
0:17:17.16,000 --> 0:17:22,000
to crack codes, to search for life in outer space.

225
0:17:22.16,000 --> 0:17:24,000
I don't think we know enough yet.

226
0:17:24.16,000 --> 0:17:28,000
I don't think we've even begun to discover what the basic principles are,

227
0:17:28.16,000 --> 0:17:31,000
but I think we can begin to think about them.

228
0:17:31.16,000 --> 0:17:34,000
And I don't have enough time to talk about all of them,

229
0:17:34.16,000 --> 0:17:36,000
but think about self-interest.

230
0:17:36.16,000 --> 0:17:39,000
This is all about self-interest that adds up to more.

231
0:17:39.16,000 --> 0:17:44,000
In El Salvador, both sides that withdrew from their civil war

232
0:17:44.16,000 --> 0:17:48,000
took moves that had been proven to mirror a prisoner's dilemma strategy.

233
0:17:48.16,000 --> 0:17:54,000
In the U.S., in the Philippines, in Kenya, around the world,

234
0:17:54.16,000 --> 0:17:57,000
citizens have self-organized political protests and

235
0:17:57.16,000 --> 0:18:03,000
get out the vote campaigns using mobile devices and SMS.

236
0:18:03.16,000 --> 0:18:06,000
Is an Apollo Project of cooperation possible?

237
0:18:06.16,000 --> 0:18:1,000
A transdisciplinary study of cooperation?

238
0:18:10.16,000 --> 0:18:14,000
I believe that the payoff would be very big.

239
0:18:14.16,000 --> 0:18:18,000
I think we need to begin developing maps of this territory

240
0:18:18.16,000 --> 0:18:2,000
so that we can talk about it across disciplines.

241
0:18:20.16,000 --> 0:18:24,000
And I am not saying that understanding cooperation

242
0:18:24.16,000 --> 0:18:28,000
is going to cause us to be better people --

243
0:18:28.16,000 --> 0:18:31,000
and sometimes people cooperate to do bad things --

244
0:18:31.16,000 --> 0:18:34,000
but I will remind you that a few hundred years ago,

245
0:18:34.16,000 --> 0:18:38,000
people saw their loved ones die from diseases they thought

246
0:18:38.16,000 --> 0:18:43,000
were caused by sin or foreigners or evil spirits.

247
0:18:43.16,000 --> 0:18:47,000
Descartes said we need an entire new way of thinking.

248
0:18:47.16,000 --> 0:18:5,000
When the scientific method provided that new way of thinking

249
0:18:50.16,000 --> 0:18:54,000
and biology showed that microorganisms caused disease,

250
0:18:54.16,000 --> 0:18:57,000
suffering was alleviated.

251
0:18:57.16,000 --> 0:19:,000
What forms of suffering could be alleviated,

252
0:19:00.16,000 --> 0:19:02,000
what forms of wealth could be created

253
0:19:02.16,000 --> 0:19:05,000
if we knew a little bit more about cooperation?

254
0:19:05.16,000 --> 0:19:09,000
I don't think that this transdisciplinary discourse

255
0:19:09.16,000 --> 0:19:11,000
is automatically going to happen;

256
0:19:11.16,000 --> 0:19:14,000
it's going to require effort.

257
0:19:14.16,000 --> 0:19:2,000
So I enlist you to help me get the cooperation project started.

258
0:19:20.16,000 --> 0:19:22,000
Thank you.

259
0:19:22.16,000 --> 0:19:25,000
(Applause)

