1
0:00:,000 --> 0:00:07,000
Traducteur: Meryl Ducray Relecteur: Beatriz V L

2
0:00:12.771,000 --> 0:00:15,000
Quelle est la tarte préférée des Américains ?

3
0:00:16.431,000 --> 0:00:19,000
Public : La tarte à la pomme ! K. Cukier : En effet !

4
0:00:20.231,000 --> 0:00:21,000
Comment le sait-on ?

5
0:00:21.694,000 --> 0:00:23,000
Grâce aux données.

6
0:00:24.719,000 --> 0:00:25,000
Les ventes de supermarchés.

7
0:00:26.378,000 --> 0:00:29,000
Parmi les ventes en supermarché de tartes surgelées de 30 cm,

8
0:00:30.363,000 --> 0:00:32,000
la tarte à la pomme était n°1, haut la main.

9
0:00:32.948,000 --> 0:00:35,000
La majorité des ventes se fait sur les tartes à la pomme.

10
0:00:38.953,000 --> 0:00:4,000
Puis les supermarchés se sont mis à vendre

11
0:00:41.253,000 --> 0:00:43,000
des tartes plus petites, de 11 cm.

12
0:00:43.8,000 --> 0:00:47,000
Et d'un coup, la pomme a chuté à la 4ème ou 5ème place

13
0:00:48.039,000 --> 0:00:5,000
Pourquoi ? Que s'est-il passé ?

14
0:00:51.005,000 --> 0:00:52,000
Réfléchissez !

15
0:00:53.71,000 --> 0:00:56,000
Quand vous achetez une grande tarte,

16
0:00:57.679,000 --> 0:00:59,000
il faut que toute la famille soit d'accord,

17
0:00:59.948,000 --> 0:01:02,000
Or la pomme est le deuxième choix de tous.

18
0:01:03.504,000 --> 0:01:04,000
(Rires)

19
0:01:05.497,000 --> 0:01:09,000
Mais si vous achetez une petite tartelette,

20
0:01:09.511,000 --> 0:01:12,000
vous pouvez acheter celle que vous préférez.

21
0:01:13.126,000 --> 0:01:15,000
Vous pouvez avoir votre premier choix.

22
0:01:16.854,000 --> 0:01:18,000
Vous avez plus de données.

23
0:01:18.931,000 --> 0:01:2,000
On découvre quelque chose qui nous aurait échappé

24
0:01:21.236,000 --> 0:01:23,000
avec moins de données.

25
0:01:25.29,000 --> 0:01:29,000
Mais plus de données ne nous donnent pas seulement plus d'informations,

26
0:01:29.989,000 --> 0:01:31,000
plus d'informations sur la même chose.

27
0:01:32.259,000 --> 0:01:35,000
Plus de données nous permettent de voir de nouvelles choses,

28
0:01:35.503,000 --> 0:01:38,000
d'y voir plus clair,

29
0:01:38.628,000 --> 0:01:4,000
de voir sous un nouvel angle.

30
0:01:42.399,000 --> 0:01:45,000
Dans ce cas, ça nous a permis de savoir

31
0:01:45.424,000 --> 0:01:47,000
quelle tarte les Américains préfèrent :

32
0:01:48.303,000 --> 0:01:49,000
ce n'est pas la pomme.

33
0:01:50.87,000 --> 0:01:53,000
Vous avez déjà probablement entendu le terme « Big Data ».

34
0:01:54.423,000 --> 0:01:57,000
En fait, vous en avez probablement plein les oreilles des Big Data.

35
0:01:58.26,000 --> 0:02:01,000
C'est vrai qu'il y a beaucoup de bruit autour de ça

36
0:02:01.552,000 --> 0:02:03,000
et c'est bien regrettable,

37
0:02:03.936,000 --> 0:02:05,000
parce c'est un outil extrêmement important

38
0:02:06.707,000 --> 0:02:09,000
qui va faire progresser notre société.

39
0:02:10.673,000 --> 0:02:13,000
Jusqu'ici, on n'utilisait que de petites quantités de données,

40
0:02:14.076,000 --> 0:02:15,000
on cherchait à les interpréter

41
0:02:15.748,000 --> 0:02:16,000
afin de comprendre le monde.

42
0:02:17.405,000 --> 0:02:19,000
On a à présent infiniment plus de données,

43
0:02:19.49,000 --> 0:02:22,000
plus de données que jamais auparavant.

44
0:02:22.614,000 --> 0:02:24,000
Et quand on a une telle quantité de données,

45
0:02:25.188,000 --> 0:02:26,000
on peut accomplir des choses

46
0:02:26.774,000 --> 0:02:29,000
inimaginables avec de petites quantités.

47
0:02:29.815,000 --> 0:02:31,000
Les Big Data sont à la fois nouvelles et importantes.

48
0:02:32.535,000 --> 0:02:33,000
Si on y réfléchit,

49
0:02:34.028,000 --> 0:02:38,000
le seul moyen qu'on aura pour faire face aux enjeux mondiaux :

50
0:02:38.49,000 --> 0:02:39,000
nourrir l'humanité,

51
0:02:39.774,000 --> 0:02:41,000
l'approvisionner en médicaments,

52
0:02:42.059,000 --> 0:02:44,000
en énergie, en électricité,

53
0:02:44.637,000 --> 0:02:47,000
et éviter d'être rôti par le réchauffement climatique,

54
0:02:47.943,000 --> 0:02:5,000
ce sera grâce à une utilisation efficace des données.

55
0:02:51.94,000 --> 0:02:55,000
Qu'y a-t-il de nouveau dans les Big Data ? Pourquoi tout le monde en parle ?

56
0:02:56.348,000 --> 0:02:58,000
Pour y répondre, il faut se rappeler

57
0:02:58.729,000 --> 0:03:01,000
à quoi ressemblait physiquement une information dans le passé.

58
0:03:04.345,000 --> 0:03:06,000
En 1908, sur l'île de Crète,

59
0:03:07.058,000 --> 0:03:11,000
des archéologues ont découvert un disque en argile.

60
0:03:11.825,000 --> 0:03:15,000
Ils l'ont daté de 2 000 ans av. J-C., soit vieux de 4 000 ans.

61
0:03:16.064,000 --> 0:03:19,000
Il y a des inscriptions mais personne n'arrive à les déchiffrer.

62
0:03:19.065,000 --> 0:03:2,000
Le mystère reste entier. Mais c'est à cela

63
0:03:21.028,000 --> 0:03:24,000
que ressemblait l'information il y a 4 000 ans.

64
0:03:24.956,000 --> 0:03:26,000
C'est ainsi que la société stockait

65
0:03:27.762,000 --> 0:03:3,000
et transmettait l'information.

66
0:03:31.417,000 --> 0:03:35,000
La société n'a pas tant évolué que ça.

67
0:03:35.639,000 --> 0:03:38,000
On stocke toujours l'information sur des disques,

68
0:03:38.738,000 --> 0:03:42,000
mais en quantité plus grande, infiniment plus grande.

69
0:03:43.313,000 --> 0:03:45,000
Les informations sont plus faciles à chercher,

70
0:03:45.558,000 --> 0:03:47,000
plus faciles à copier, à partager,

71
0:03:47.899,000 --> 0:03:49,000
plus faciles à traiter.

72
0:03:49.989,000 --> 0:03:51,000
On peut aussi réutiliser ces informations

73
0:03:52.449,000 --> 0:03:54,000
à des fins auxquelles on n'avait pas du tout pensé

74
0:03:54.893,000 --> 0:03:56,000
au moment où on les a collectées.

75
0:03:57.48,000 --> 0:03:59,000
On peut dire que les données sont passées

76
0:03:59.95,000 --> 0:04:02,000
d'un stock à un flux,

77
0:04:03.625,000 --> 0:04:06,000
de statique et immobile,

78
0:04:07.539,000 --> 0:04:1,000
à fluide et dynamique.

79
0:04:10.848,000 --> 0:04:13,000
On peut dire que l'information est devenue liquide.

80
0:04:15.616,000 --> 0:04:17,000
Ce disque découvert en Crète

81
0:04:18.537,000 --> 0:04:21,000
et vieux de 4 000 ans, il est lourd,

82
0:04:22.111,000 --> 0:04:24,000
il ne contient pas beaucoup d'information,

83
0:04:24.28,000 --> 0:04:27,000
et cette information n'est pas modifiable.

84
0:04:27.441,000 --> 0:04:29,000
En revanche,

85
0:04:29.574,000 --> 0:04:3,000
tous les fichiers

86
0:04:31.311,000 --> 0:04:35,000
qu'Edward Snowden a pris à la NSA aux États-Unis

87
0:04:35.929,000 --> 0:04:37,000
tiennent sur une clé USB

88
0:04:38.413,000 --> 0:04:4,000
pas plus grande qu'une pièce de 50 centimes,

89
0:04:41.153,000 --> 0:04:44,000
et ils peuvent être partagés à la vitesse de la lumière.

90
0:04:46.486,000 --> 0:04:49,000
Plus de données. Plus.

91
0:04:50.883,000 --> 0:04:53,000
Une raison pour laquelle nous avons tant de données aujourd'hui,

92
0:04:54.176,000 --> 0:04:55,000
c'est qu'on étudie des choses

93
0:04:55.697,000 --> 0:04:57,000
sur lesquelles on a toujours collecté de l'information.

94
0:04:58.319,000 --> 0:05:,000
Une autre raison, c'est qu'on utilise

95
0:05:00.657,000 --> 0:05:02,000
des choses qui ont toujours été informationnelles

96
0:05:03.4,000 --> 0:05:05,000
et qui n'ont jamais été transformées en données

97
0:05:06.057,000 --> 0:05:08,000
et nous les mettons maintenant en données.

98
0:05:08.338,000 --> 0:05:11,000
Prenez l'exemple des données de localisation.

99
0:05:11.861,000 --> 0:05:12,000
Pensez par exemple à Martin Luther.

100
0:05:13.832,000 --> 0:05:17,000
Si on avait voulu savoir au 16ème siècle où Martin Luther se trouvait,

101
0:05:17.867,000 --> 0:05:19,000
on aurait dû le suivre tout le temps,

102
0:05:20.065,000 --> 0:05:23,000
sans doute avec une plume et un encrier pour noter ses différentes positions.

103
0:05:23.931,000 --> 0:05:25,000
Regardez à quoi ça ressemble aujourd'hui !

104
0:05:25.945,000 --> 0:05:26,000
Vous savez que quelque part,

105
0:05:27.855,000 --> 0:05:3,000
probablement dans la base de données de votre opérateur,

106
0:05:30.997,000 --> 0:05:32,000
il y a un tableau ou une entrée dans une base de données

107
0:05:33.969,000 --> 0:05:36,000
qui enregistre les informations sur votre localisation, à chaque instant.

108
0:05:37.863,000 --> 0:05:38,000
Si vous avez un téléphone portable,

109
0:05:39.695,000 --> 0:05:41,000
que ce dernier soit muni d'un GPS ou non,

110
0:05:42.003,000 --> 0:05:44,000
il stocke vos informations.

111
0:05:44.617,000 --> 0:05:47,000
C'est ainsi que la localisation a été mise en données.

112
0:05:48.683,000 --> 0:05:52,000
Prenons maintenant l'exemple de votre posture,

113
0:05:52.817,000 --> 0:05:54,000
la manière dont vous êtes tous assis en ce moment

114
0:05:55.188,000 --> 0:05:57,000
votre manière de vous asseoir à vous,

115
0:05:57.353,000 --> 0:05:58,000
votre posture à vous, la vôtre.

116
0:05:59.2,000 --> 0:06:,000
Elles sont toutes différentes

117
0:06:00.609,000 --> 0:06:03,000
en fonction de la longueur de vos jambes et des contours de votre dos

118
0:06:04.031,000 --> 0:06:06,000
Et si je posais, disons, 100 capteurs

119
0:06:06.275,000 --> 0:06:07,000
sur chacun de vos sièges,

120
0:06:07.831,000 --> 0:06:1,000
je pourrais créer un index unique qui vous serait propre,

121
0:06:11.456,000 --> 0:06:14,000
comme une empreinte unique, autre qu'une empreinte digitale.

122
0:06:15.941,000 --> 0:06:17,000
Mais à quoi ça pourrait bien servir ?

123
0:06:18.808,000 --> 0:06:2,000
Des chercheurs à Tokyo utilisent ça

124
0:06:21.151,000 --> 0:06:24,000
comme un possible système antivol dans les voitures.

125
0:06:25.537,000 --> 0:06:28,000
Si un voleur s'assied derrière le volant et tente de démarrer,

126
0:06:29.451,000 --> 0:06:31,000
la voiture reconnaît qu'un conducteur non-approuvé

127
0:06:32.06,000 --> 0:06:34,000
est derrière le volant et stoppe simplement le moteur,

128
0:06:34.502,000 --> 0:06:36,000
sauf si vous entrez un mot de passe

129
0:06:37.395,000 --> 0:06:4,000
qui dit que vous avez l'autorisation de conduire la voiture.

130
0:06:43.183,000 --> 0:06:45,000
Imaginons que chaque voiture en Europe

131
0:06:45.471,000 --> 0:06:46,000
soit munie de cette technologie.

132
0:06:47.203,000 --> 0:06:49,000
Quelles perspectives cela nous ouvre-t-il ?

133
0:06:50.155,000 --> 0:06:52,000
En rassemblant ces données,

134
0:06:52.248,000 --> 0:06:54,000
on pourrait peut-être identifier

135
0:06:54.641,000 --> 0:06:57,000
des signes révélateurs qui prédisent au mieux

136
0:06:58.143,000 --> 0:07:,000
qu'un accident va se produire

137
0:07:01.124,000 --> 0:07:04,000
dans les 5 prochaines secondes.

138
0:07:04.957,000 --> 0:07:06,000
C'est ainsi qu'on sera parvenu à mettre en données

139
0:07:07.345,000 --> 0:07:08,000
la fatigue du conducteur.

140
0:07:09.252,000 --> 0:07:1,000
Un nouveau service serait que,

141
0:07:10.782,000 --> 0:07:14,000
quand la voiture sent qu'une personne s'affale dans cette position,

142
0:07:15.492,000 --> 0:07:16,000
elle comprend automatiquement

143
0:07:16.934,000 --> 0:07:19,000
et réagit en faisant vibrer le volant, en klaxonnant à l'intérieur

144
0:07:20.357,000 --> 0:07:24,000
comme pour dire : « Debout, concentre-toi sur la route ! »

145
0:07:24.679,000 --> 0:07:26,000
C'est le genre de choses qui deviennent possibles

146
0:07:27.032,000 --> 0:07:29,000
quand on met en données certains aspects du quotidien.

147
0:07:29.678,000 --> 0:07:32,000
Que valent alors donc les Big Data ?

148
0:07:33.041,000 --> 0:07:35,000
Pensez-y !

149
0:07:35.091,000 --> 0:07:37,000
On a plus d'information.

150
0:07:37.353,000 --> 0:07:4,000
On peut faire des nouvelles choses qui étaient impossibles auparavant.

151
0:07:40.773,000 --> 0:07:43,000
Une des applications les plus impressionnantes des Big Data

152
0:07:44.578,000 --> 0:07:46,000
concerne le domaine de l'apprentissage automatique.

153
0:07:47.517,000 --> 0:07:5,000
Il s'agit d'une branche de l'intelligence artificielle,

154
0:07:50.947,000 --> 0:07:53,000
elle-même branche de l'informatique.

155
0:07:54.045,000 --> 0:07:55,000
L'idée générale c'est que,

156
0:07:55.336,000 --> 0:07:57,000
plutôt que de dire à l'ordinateur ce qu'il a à faire,

157
0:07:57.814,000 --> 0:07:59,000
on va juste donner plein d'informations à l'ordinateur

158
0:08:00.507,000 --> 0:08:02,000
et lui dire de se débrouiller avec.

159
0:08:03.18,000 --> 0:08:05,000
Pour vous aider à comprendre,

160
0:08:05.2,000 --> 0:08:08,000
retournons aux origines de l'apprentissage automatique.

161
0:08:08.839,000 --> 0:08:12,000
En 1950, un informaticien de chez IBM, Arthur Samuel,

162
0:08:13.134,000 --> 0:08:14,000
était amateur du jeu de Dames.

163
0:08:14.875,000 --> 0:08:18,000
Il a donc créé un programme informatique afin de jouer contre l'ordinateur.

164
0:08:19.095,000 --> 0:08:21,000
Il a joué. Il a gagné.

165
0:08:21.759,000 --> 0:08:23,000
Il a joué. Il a gagné.

166
0:08:24.048,000 --> 0:08:26,000
Il a joué. Il a gagné,

167
0:08:26.877,000 --> 0:08:3,000
parce que l'ordinateur ne connaissait rien d'autre que les coups légaux.

168
0:08:30.884,000 --> 0:08:32,000
Arthur Samuel en savait plus.

169
0:08:33.103,000 --> 0:08:37,000
Arthur Samuel avait des notions de stratégie.

170
0:08:37.653,000 --> 0:08:4,000
Il a alors écrit un sous-programme à côté. Il opérait en arrière-plan

171
0:08:41.419,000 --> 0:08:43,000
et tout ce qu'il faisait, c'est qu'après chacun des coups,

172
0:08:44.188,000 --> 0:08:47,000
il comptait les probabilités de chacune des configurations du damier

173
0:08:47.388,000 --> 0:08:51,000
de mener à la victoire ou à la défaite.

174
0:08:51.799,000 --> 0:08:54,000
Il joue contre l'ordinateur. Il gagne.

175
0:08:55.014,000 --> 0:08:57,000
Il joue contre l'ordinateur. Il gagne.

176
0:08:57.505,000 --> 0:09:,000
Il joue contre l'ordinateur. Il gagne.

177
0:09:01.15,000 --> 0:09:05,000
Puis Arthur Samuel a laissé l'ordinateur jouer contre lui-même.

178
0:09:05.962,000 --> 0:09:07,000
Plus il joue contre lui-même, plus il collecte de données.

179
0:09:08.961,000 --> 0:09:09,000
Plus il collecte de données,

180
0:09:10.312,000 --> 0:09:13,000
plus il augmente la précision de ses prédictions.

181
0:09:13.471,000 --> 0:09:15,000
Et quand Samuel a rejoué contre l'ordinateur,

182
0:09:15.91,000 --> 0:09:17,000
il joue et il perd.

183
0:09:17.946,000 --> 0:09:19,000
Il joue et il perd.

184
0:09:20.098,000 --> 0:09:21,000
Il joue et il perd.

185
0:09:22.045,000 --> 0:09:24,000
C'est ainsi qu'Arthur Samuel a créé une machine

186
0:09:24.583,000 --> 0:09:3,000
capable de le surpasser dans une discipline qu'il lui a enseignée.

187
0:09:30.749,000 --> 0:09:34,000
Et cette idée d'apprentissage automatique est partout autour de nous.

188
0:09:37.34,000 --> 0:09:4,000
Comment croyez-vous que des voitures roulent toutes seules ?

189
0:09:40.713,000 --> 0:09:42,000
Notre société est-elle meilleure

190
0:09:42.77,000 --> 0:09:46,000
depuis que le code de la route a été traduit dans un logiciel ? Non.

191
0:09:46.82,000 --> 0:09:47,000
Le stockage est-il moins cher ? Non.

192
0:09:48.555,000 --> 0:09:51,000
Les algorithmes plus rapides ? Non. Les processeurs plus puissants ? Non.

193
0:09:52.41,000 --> 0:09:55,000
Toutes ces choses sont importantes, mais pas décisives.

194
0:09:55.484,000 --> 0:09:57,000
C'est parce que nous avons changé la nature du problème.

195
0:09:58.352,000 --> 0:10:03,000
Avant, on essayait d'expliquer clairement et ouvertement à l'ordinateur

196
0:10:03.46,000 --> 0:10:04,000
comment il devait conduire.

197
0:10:04.76,000 --> 0:10:05,000
Aujourd'hui, on lui dit :

198
0:10:05.949,000 --> 0:10:07,000
« Voici tout plein de données sur le véhicule,

199
0:10:08.135,000 --> 0:10:09,000
débrouille-toi !

200
0:10:09.407,000 --> 0:10:12,000
Débrouille-toi à comprendre que ceci est un feu de signalisation

201
0:10:12.476,000 --> 0:10:13,000
que le feu est rouge et non vert,

202
0:10:14.052,000 --> 0:10:18,000
que cela veut dire que tu dois t'arrêter, et non pas continuer. »

203
0:10:18.461,000 --> 0:10:21,000
L'apprentissage automatique est à la base de nombreux outils en ligne :

204
0:10:22.027,000 --> 0:10:23,000
les moteurs de recherche,

205
0:10:23.844,000 --> 0:10:26,000
l'algorithme de personnalisation d'Amazon,

206
0:10:27.71,000 --> 0:10:29,000
la traduction par ordinateur,

207
0:10:30.063,000 --> 0:10:33,000
ou encore la reconnaissance vocale.

208
0:10:34.303,000 --> 0:10:36,000
Les chercheurs se sont récemment penchés

209
0:10:37.176,000 --> 0:10:4,000
sur la question des biopsies,

210
0:10:40.281,000 --> 0:10:42,000
des biopsies de cellules cancéreuses.

211
0:10:42.944,000 --> 0:10:44,000
Ils ont demandé à des ordinateurs

212
0:10:45.341,000 --> 0:10:47,000
d'analyser les données et le taux de survie

213
0:10:47.835,000 --> 0:10:53,000
pour déterminer quelles cellules sont réellement cancéreuses.

214
0:10:54.66,000 --> 0:10:56,000
Sans surprise, en fournissant assez de données

215
0:10:56.89,000 --> 0:10:58,000
à l'algorithme d'apprentissage automatique,

216
0:10:58.933,000 --> 0:10:59,000
l'ordinateur était capable d'identifier

217
0:11:00.786,000 --> 0:11:02,000
les 12 signes caractéristiques qui prédisent au mieux

218
0:11:03.354,000 --> 0:11:06,000
que cette biopsie de cellules tumorales mammaires

219
0:11:06.601,000 --> 0:11:08,000
sont en effet cancéreuses.

220
0:11:09.325,000 --> 0:11:1,000
Le truc,

221
0:11:11.255,000 --> 0:11:14,000
c'est que les médecins n'en connaissaient que 9.

222
0:11:14.963,000 --> 0:11:17,000
Trois des signes ont été identifiés par l'ordinateur

223
0:11:18.012,000 --> 0:11:23,000
sans que quelqu'un n'ait besoin de faire de recherche dessus.

224
0:11:26.248,000 --> 0:11:3,000
Mais il y a aussi une face sombre des Big Data.

225
0:11:30.868,000 --> 0:11:31,000
Cela va améliorer nos vies,

226
0:11:32.428,000 --> 0:11:35,000
mais il y a aussi des problèmes dont il faut être conscient.

227
0:11:35.648,000 --> 0:11:4,000
Le premier, c'est l'idée que l'on puisse être puni à cause de prédictions,

228
0:11:41.048,000 --> 0:11:47,000
que la police utilise les Big Data un peu comme dans « Minority Report ».

229
0:11:47.272,000 --> 0:11:51,000
On appelle ça la prévision policière ou la criminologie algorithmique.

230
0:11:51.955,000 --> 0:11:53,000
L'idée est que, si on prend beaucoup de données

231
0:11:54.105,000 --> 0:11:56,000
par exemple où des crimes ont été commis,

232
0:11:56.122,000 --> 0:11:58,000
on sait où envoyer les patrouilles.

233
0:11:58.719,000 --> 0:12:,000
C'est logique. Mais le problème,

234
0:12:00.815,000 --> 0:12:04,000
c'est qu'on ne s'arrêtera pas aux données de localisation,

235
0:12:05.582,000 --> 0:12:07,000
on va aller jusqu'au niveau de l'individu.

236
0:12:08.328,000 --> 0:12:12,000
Pourquoi ne pas utiliser les données fournies par vos bulletins scolaires ?

237
0:12:12.744,000 --> 0:12:13,000
Peut-être devrions-nous utiliser le fait

238
0:12:14.669,000 --> 0:12:16,000
que les gens ont un emploi ou non, leur solvabilité,

239
0:12:17.14,000 --> 0:12:2,000
leur comportement sur Internet, s'ils sont debout tard dans la nuit.

240
0:12:20.329,000 --> 0:12:21,000
Leur FitBit, quand c'est possible,

241
0:12:21.962,000 --> 0:12:25,000
pour identifier les réactions biochimiques qui produisent des pensées agressives.

242
0:12:27.156,000 --> 0:12:28,000
On peut avoir des algorithmes

243
0:12:28.537,000 --> 0:12:31,000
qui pourraient prédire ce que nous sommes sur le point de faire,

244
0:12:31.6,000 --> 0:12:34,000
nous pourrions être tenus responsables de ce que l'on n'a pas encore fait.

245
0:12:35.169,000 --> 0:12:39,000
La vie privée était le défi principal lorsqu'on avait peu de données.

246
0:12:39.825,000 --> 0:12:4,000
Avec les Big Data,

247
0:12:41.44,000 --> 0:12:46,000
le défi sera de préserver le libre-arbitre,

248
0:12:46.594,000 --> 0:12:49,000
les choix moraux, le consentement

249
0:12:50.055,000 --> 0:12:52,000
et la capacité d'agir de l'homme.

250
0:12:54.647,000 --> 0:12:56,000
Et il y a un autre problème :

251
0:12:57.142,000 --> 0:13:,000
les Big Data vont nous voler notre travail.

252
0:13:00.406,000 --> 0:13:03,000
A l'aide des algorithmes, elles vont entrer en concurrence

253
0:13:04.318,000 --> 0:13:06,000
avec les cols blancs, avec les travailleurs intellectuels

254
0:13:07.047,000 --> 0:13:08,000
du 21ème siècle,

255
0:13:08.543,000 --> 0:13:12,000
de la même manière que l'automatisation des lignes de montage

256
0:13:13.301,000 --> 0:13:15,000
a concurrencé le travail des cols bleus, au 20ème siècle.

257
0:13:16.292,000 --> 0:13:19,000
Imaginez un technicien de laboratoire qui examine à l'aide d'un microscope

258
0:13:19.77,000 --> 0:13:23,000
la biopsie d'une tumeur pour déterminer si elle est cancéreuse.

259
0:13:24.047,000 --> 0:13:26,000
Cette personne a fait des études.

260
0:13:26.094,000 --> 0:13:27,000
Cette personne est propriétaire.

261
0:13:27.626,000 --> 0:13:28,000
Il ou elle vote.

262
0:13:29.25,000 --> 0:13:32,000
Il ou elle est acteur à part entière de notre société.

263
0:13:32.987,000 --> 0:13:33,000
Et pourtant cette personne,

264
0:13:34.327,000 --> 0:13:37,000
ainsi qu'un pan entier de professionnels similaires,

265
0:13:37.999,000 --> 0:13:4,000
va voir son travail radicalement transformé,

266
0:13:41.111,000 --> 0:13:43,000
voire carrément éliminé.

267
0:13:43.502,000 --> 0:13:44,000
On aime pourtant se dire

268
0:13:45.191,000 --> 0:13:47,000
que sur le long terme, la technologie crée des emplois,

269
0:13:47.793,000 --> 0:13:5,000
après une courte période temporaire de destruction d'emplois.

270
0:13:51.278,000 --> 0:13:54,000
C'est vrai pour la période de référence dans laquelle nous vivons,

271
0:13:54.388,000 --> 0:13:57,000
la Révolution Industrielle, car c'est précisément ce qui s'est passé.

272
0:13:57.717,000 --> 0:13:59,000
Mais on oublie un élément dans cette analyse.

273
0:14:00.47,000 --> 0:14:01,000
Il y a des catégories d'emplois

274
0:14:02.307,000 --> 0:14:05,000
qui sont simplement éliminées et ne sont pas remplacées.

275
0:14:05.341,000 --> 0:14:11,000
La Révolution Industrielle n'a pas été bonne pour les chevaux.

276
0:14:11.365,000 --> 0:14:13,000
Il va donc falloir être prudent,

277
0:14:13.76,000 --> 0:14:16,000
prendre les Big Data et les ajuster à nos besoins,

278
0:14:16.802,000 --> 0:14:19,000
nos besoins humains fondamentaux.

279
0:14:20.016,000 --> 0:14:22,000
Nous devons maîtriser cette technologie

280
0:14:22.152,000 --> 0:14:23,000
et non devenir ses esclaves.

281
0:14:23.572,000 --> 0:14:26,000
L'ère des Big Data vient tout juste de commencer

282
0:14:26.614,000 --> 0:14:29,000
et honnêtement, nous ne sommes pas très bons

283
0:14:29.924,000 --> 0:14:33,000
pour manipuler toutes ces données que nous collectons.

284
0:14:33.943,000 --> 0:14:36,000
Ce n'est pas juste un problème pour la NSA.

285
0:14:37.293,000 --> 0:14:4,000
Les entreprises collectent aussi beaucoup de données, et elles en abusent aussi.

286
0:14:41.107,000 --> 0:14:43,000
Il va falloir faire mieux, et cela va prendre du temps.

287
0:14:44.08,000 --> 0:14:45,000
C'est un peu comme le défi

288
0:14:45.816,000 --> 0:14:47,000
de l'homme préhistorique quand il a inventé le feu.

289
0:14:48.198,000 --> 0:14:49,000
C'est un outil, mais c'est un outil qui,

290
0:14:50.053,000 --> 0:14:53,000
si nous ne sommes pas prudents, va nous brûler.

291
0:14:56.222,000 --> 0:14:59,000
Les Big Data vont transformer nos modes de vie,

292
0:14:59.253,000 --> 0:15:01,000
de travail et de pensée.

293
0:15:01.95,000 --> 0:15:03,000
Elles nous aideront à gérer nos carrières,

294
0:15:03.962,000 --> 0:15:06,000
à mener une vie faite de satisfaction, d'espoir,

295
0:15:07.363,000 --> 0:15:09,000
de bonheur et de santé.

296
0:15:10.452,000 --> 0:15:13,000
Mais, par le passé, on a souvent regardé les technologies de l'information

297
0:15:13.976,000 --> 0:15:15,000
et nos yeux n'ont vu que le T,

298
0:15:16.317,000 --> 0:15:17,000
la Technologie, l'ordinateur,

299
0:15:17.813,000 --> 0:15:19,000
parce que c'est matériel et palpable.

300
0:15:19.979,000 --> 0:15:21,000
Il faut à présent tourner notre regard vers le I,

301
0:15:22.908,000 --> 0:15:24,000
l'Information, qui est moins visible,

302
0:15:25.601,000 --> 0:15:29,000
mais d'une certaine manière bien plus importante.

303
0:15:29.824,000 --> 0:15:35,000
L'humanité peut enfin apprendre des informations qu'elle collecte

304
0:15:35.864,000 --> 0:15:36,000
dans le cadre de sa quête

305
0:15:37.788,000 --> 0:15:4,000
pour comprendre le monde et la place de l'homme en son sein.

306
0:15:41.171,000 --> 0:15:45,000
Voilà pourquoi les Big Data sont si importantes.

307
0:15:45.566,000 --> 0:15:5,000
(Applaudissements)

