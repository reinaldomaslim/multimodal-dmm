1
0:00:,000 --> 0:00:07,000
Traductor: Paula Motter Revisor: Sebastian Betti

2
0:00:12.76,000 --> 0:00:14,000
Un fenómeno que últimamente se está difundiendo

3
0:00:15.05,000 --> 0:00:16,000
es la ansiedad por la automatización,

4
0:00:17,000 --> 0:00:18,000
el miedo de que en un futuro

5
0:00:18.84,000 --> 0:00:2,000
muchas tareas sean realizadas por máquinas

6
0:00:21.32,000 --> 0:00:22,000
y no por seres humanos,

7
0:00:22.68,000 --> 0:00:24,000
a juzgar por los grandes avances que se están logrando

8
0:00:25.64,000 --> 0:00:27,000
en el campo de la inteligencia artificial y de la robótica.

9
0:00:28.44,000 --> 0:00:3,000
Lo cierto es que habrá cambios importantes.

10
0:00:31.28,000 --> 0:00:34,000
Lo que no está tan claro es cómo serán esos cambios.

11
0:00:34.92,000 --> 0:00:36,000
La investigación que hice sugiere que el futuro

12
0:00:37.45,000 --> 0:00:39,000
es inquietante e interesante.

13
0:00:39.88,000 --> 0:00:42,000
La amenaza del desempleo tecnológico es real,

14
0:00:43.64,000 --> 0:00:45,000
pero aun así es un problema con ventajas.

15
0:00:45.72,000 --> 0:00:48,000
Y para explicar cómo llegué a esta conclusión,

16
0:00:48.96,000 --> 0:00:5,000
quiero hablar de tres mitos

17
0:00:51.57,000 --> 0:00:53,000
que en mi opinión hoy impiden tener un claro panorama

18
0:00:54.36,000 --> 0:00:55,000
de este futuro automatizado.

19
0:00:56.71,000 --> 0:00:58,000
Una imagen que solemos ver en las pantallas de TV,

20
0:00:59.466,000 --> 0:01:01,000
en libros, en películas, en las crónicas diarias,

21
0:01:01.756,000 --> 0:01:04,000
es la de un ejército de robots que llega a nuestro lugar de trabajo

22
0:01:05.2,000 --> 0:01:06,000
con un solo objetivo:

23
0:01:06.6,000 --> 0:01:08,000
desplazar a los seres humanos de sus trabajos.

24
0:01:09.12,000 --> 0:01:11,000
A esto le llamo el "mito del Exterminador".

25
0:01:11.84,000 --> 0:01:14,000
Es verdad, las máquinas desplazan a los humanos en tareas específicas.

26
0:01:15.84,000 --> 0:01:17,000
Pero no solo los reemplazan,

27
0:01:18.12,000 --> 0:01:19,000
también los complementan en otras tareas,

28
0:01:20.12,000 --> 0:01:23,000
haciendo que ese trabajo sea más valioso e importante.

29
0:01:23.76,000 --> 0:01:26,000
A veces las máquinas complementan a los humanos de manera directa,

30
0:01:27.12,000 --> 0:01:3,000
aumentando la productividad y la eficiencia en una tarea particular.

31
0:01:31.16,000 --> 0:01:35,000
Un taxista, por ejemplo, puede usar un GPS para orientarse en sitios desconocidos.

32
0:01:35.8,000 --> 0:01:38,000
Un arquitecto puede usar un software específico

33
0:01:39.16,000 --> 0:01:41,000
para diseñar edificios más grandes y complejos.

34
0:01:42.28,000 --> 0:01:43,000
Pero el progreso tecnológico

35
0:01:43.7,000 --> 0:01:45,000
no solo complementa al ser humano de manera directa.

36
0:01:46.26,000 --> 0:01:48,000
También lo hace indirectamente, de dos maneras.

37
0:01:49.36,000 --> 0:01:52,000
La primera es la siguiente: si concebimos la economía como una tarta,

38
0:01:52.72,000 --> 0:01:54,000
el progreso tecnológico aumenta el tamaño de esa tarta.

39
0:01:55.64,000 --> 0:01:58,000
A medida que la productividad aumenta, el ingreso sube y la demanda crece.

40
0:01:59.52,000 --> 0:02:,000
La tarta de Gran Bretaña, por ejemplo,

41
0:02:01.406,000 --> 0:02:04,000
es más de 100 veces mayor que hace 300 años.

42
0:02:05.92,000 --> 0:02:08,000
Así, quienes fueron desplazados de sus tareas en la viejo tarta

43
0:02:09.256,000 --> 0:02:11,000
encontraron en la nueva tarta otras tareas para hacer.

44
0:02:12.8,000 --> 0:02:15,000
Pero el progreso tecnológico no solo agranda la tarta,

45
0:02:16.76,000 --> 0:02:18,000
sino que también cambia sus ingredientes.

46
0:02:19.64,000 --> 0:02:22,000
Con el tiempo, la gente va cambiando la forma en que gasta su ingreso,

47
0:02:23.436,000 --> 0:02:26,000
distribuyéndolo de otra manera entre los productos disponibles,

48
0:02:26.536,000 --> 0:02:28,000
y desarrollando gustos por nuevos productos también.

49
0:02:29.2,000 --> 0:02:3,000
Se crean nuevas industrias,

50
0:02:31,000 --> 0:02:32,000
surgen nuevas tareas que realizar

51
0:02:32.84,000 --> 0:02:34,000
y por lo tanto habrá nuevas funciones que cumplir.

52
0:02:35.666,000 --> 0:02:36,000
Volvamos a la tarta de Gran Bretaña:

53
0:02:37.366,000 --> 0:02:39,000
hace 300 años, la mayoría de la gente trabajaba en granjas;

54
0:02:40.186,000 --> 0:02:42,000
hace 150 años, en fábricas;

55
0:02:42.28,000 --> 0:02:44,000
y hoy, en oficinas.

56
0:02:45.16,000 --> 0:02:48,000
De nuevo, quienes fueron desplazados de sus tareas en la vieja tarta

57
0:02:49.306,000 --> 0:02:51,000
pudieron asumir tareas en la porción de la nueva tarta.

58
0:02:52.72,000 --> 0:02:55,000
Los economistas llaman a estos efectos "complementariedades",

59
0:02:56.08,000 --> 0:02:59,000
que es en realidad un término elegante para expresar la forma diferente

60
0:02:59.516,000 --> 0:03:01,000
en que el progreso tecnológico puede ayudar a los humanos.

61
0:03:02.52,000 --> 0:03:04,000
Resolver este mito del Exterminador

62
0:03:04.64,000 --> 0:03:06,000
nos demostrará que hay dos fuerzas en juego:

63
0:03:06.836,000 --> 0:03:08,000
por un lado, el reemplazo de mano de obra por máquinas,

64
0:03:09.55,000 --> 0:03:1,000
que perjudica al trabajador,

65
0:03:10.91,000 --> 0:03:13,000
y por el otro estas complementariedades, que hacen lo contrario.

66
0:03:13.96,000 --> 0:03:14,000
Veamos el segundo mito,

67
0:03:15.36,000 --> 0:03:17,000
que yo llamo "el mito de la inteligencia".

68
0:03:18.44,000 --> 0:03:2,000
¿Qué tienen en común las siguientes tareas:

69
0:03:20.56,000 --> 0:03:22,000
conducir un automóvil, hacer un diagnóstico médico

70
0:03:23.06,000 --> 0:03:26,000
e identificar un pájaro con un rápido vistazo?

71
0:03:27.28,000 --> 0:03:29,000
Pues bien, hasta hace muy poco los economistas expertos

72
0:03:30.28,000 --> 0:03:33,000
consideraban que estas tareas no podían ser fácilmente automatizadas.

73
0:03:33.666,000 --> 0:03:36,000
Sin embargo, hoy en día todas pueden automatizarse.

74
0:03:36.84,000 --> 0:03:38,000
De hecho, las principales empresas automotrices

75
0:03:39.09,000 --> 0:03:41,000
cuentan con programas de conducción autónoma.

76
0:03:41.2,000 --> 0:03:44,000
Hay una infinidad de sistemas que pueden diagnosticar problemas médicos.

77
0:03:44.76,000 --> 0:03:46,000
Y hasta hay una aplicación que puede identificar un pájaro

78
0:03:47.616,000 --> 0:03:48,000
de un rápido vistazo.

79
0:03:48.92,000 --> 0:03:52,000
Ahora bien, no es que los economistas hayan tenido mala suerte y nada más.

80
0:03:53.32,000 --> 0:03:54,000
Se equivocaron,

81
0:03:54.64,000 --> 0:03:56,000
y lo importante es por qué se equivocaron.

82
0:03:57.16,000 --> 0:03:59,000
Se dejaron engañar por el mito de la inteligencia,

83
0:03:59.576,000 --> 0:04:01,000
por creer que las máquinas debían copiar la manera

84
0:04:02.36,000 --> 0:04:05,000
en que pensamos y razonamos para superarnos en rendimiento.

85
0:04:06.24,000 --> 0:04:08,000
Cuando estos economistas decidieron averiguar

86
0:04:08.48,000 --> 0:04:1,000
cuáles eran las tareas que las máquinas no podían hacer,

87
0:04:11.266,000 --> 0:04:13,000
imaginaron que la única forma de automatizar un trabajo

88
0:04:13.876,000 --> 0:04:14,000
era sentarse con un ser humano,

89
0:04:15.616,000 --> 0:04:17,000
pedir que les expliquen cómo hacían el trabajo,

90
0:04:17.92,000 --> 0:04:19,000
y luego tratar de plasmar esa explicación

91
0:04:20.6,000 --> 0:04:22,000
en una serie de instrucciones que la máquina debía seguir.

92
0:04:23.4,000 --> 0:04:27,000
En un punto, también se creía esto en el campo de la inteligencia artificial.

93
0:04:27.6,000 --> 0:04:29,000
Lo sé porque Richard Susskind,

94
0:04:29.8,000 --> 0:04:31,000
que es mi padre y mi coautor,

95
0:04:32.68,000 --> 0:04:33,000
hizo su doctorado en la década de 1980

96
0:04:34.63,000 --> 0:04:36,000
en la Universidad de Oxford,

97
0:04:36.76,000 --> 0:04:37,000
sobre la inteligencia artificial en el derecho

98
0:04:38.2,000 --> 0:04:39,000
y formó parte de la vanguardia.

99
0:04:39.8,000 --> 0:04:41,000
Junto con el profesor Phillip Capper

100
0:04:42.08,000 --> 0:04:44,000
y el editor de textos jurídicos Butterworths

101
0:04:44.446,000 --> 0:04:48,000
desarrollaron un sistema de inteligencia artificial para juristas,

102
0:04:48.67,000 --> 0:04:51,000
el primero disponible en el circuito comercial

103
0:04:51.94,000 --> 0:04:51,000
a nivel mundial.

104
0:04:52.92,000 --> 0:04:54,000
Este era el diseño de la pantalla de inicio.

105
0:04:55.56,000 --> 0:04:57,000
Según él, un diseño muy atractivo para la época.

106
0:04:58.28,000 --> 0:04:59,000
(Risas)

107
0:04:59.32,000 --> 0:05:,000
Nunca me convenció del todo.

108
0:05:01.04,000 --> 0:05:03,000
Lo publicó en forma de dos discos flexibles,

109
0:05:03.68,000 --> 0:05:06,000
en la época en que los discos flexibles eran flexibles en serio.

110
0:05:07.24,000 --> 0:05:09,000
Y usó la misma técnica que los economistas:

111
0:05:09.746,000 --> 0:05:1,000
sentarse con la abogada,

112
0:05:10.926,000 --> 0:05:13,000
pedirle que explique cómo resolvía un problema legal,

113
0:05:14.08,000 --> 0:05:17,000
y luego tratar de plasmar la explicación en una serie de reglas

114
0:05:17.26,000 --> 0:05:19,000
que la máquina debía seguir.

115
0:05:19.48,000 --> 0:05:22,000
En economía, si los seres humanos se pueden explicar de esta manera,

116
0:05:23.12,000 --> 0:05:26,000
los trabajos se llaman rutinarios, y pueden ser automatizados.

117
0:05:26.44,000 --> 0:05:28,000
Pero si las personas no se saben explicar,

118
0:05:28.8,000 --> 0:05:31,000
los trabajos se llaman no rutinarios, y se los considera inviables.

119
0:05:32.77,000 --> 0:05:33,000
Actualmente, esa distinción

120
0:05:34.08,000 --> 0:05:36,000
entre trabajo rutinario y no rutinario está muy difundida.

121
0:05:36.79,000 --> 0:05:37,000
Pensemos cuántas veces escuchamos

122
0:05:38.636,000 --> 0:05:41,000
que las máquinas solo pueden hacer tareas predecibles o repetitivas,

123
0:05:42.006,000 --> 0:05:44,000
basadas en reglas o con pautas bien definidas.

124
0:05:44.166,000 --> 0:05:47,000
Son todos términos distintos para referirse a tareas rutinarias.

125
0:05:47.276,000 --> 0:05:5,000
Recordemos los tres casos que mencioné al principio.

126
0:05:50.64,000 --> 0:05:52,000
Son todos típicos casos de tareas no rutinarias.

127
0:05:53.37,000 --> 0:05:56,000
Si preguntamos a una médica, por ejemplo, cómo hace un diagnóstico

128
0:05:56.56,000 --> 0:05:58,000
nos dirá que se basa en algunas reglas intuitivas,

129
0:05:59.24,000 --> 0:06:,000
pero en definitiva le costaría.

130
0:06:00.92,000 --> 0:06:04,000
Dirá que ese proceso requiere de creatividad, criterio e intuición.

131
0:06:05.76,000 --> 0:06:07,000
Pero no es fácil articular todo esto

132
0:06:08.16,000 --> 0:06:11,000
y por eso se creía que era muy difícil automatizar estas tareas.

133
0:06:11.496,000 --> 0:06:13,000
Si un ser humano no sabe explicarse,

134
0:06:13.84,000 --> 0:06:15,000
¿cómo diablos empezamos a escribir las instrucciones

135
0:06:16.76,000 --> 0:06:17,000
para que una máquina las siga?

136
0:06:18.64,000 --> 0:06:2,000
Hace 30 años, esta visión era correcta

137
0:06:21.24,000 --> 0:06:23,000
pero hoy en día es cuestionable

138
0:06:23.4,000 --> 0:06:25,000
y en el futuro perderá todo sustento.

139
0:06:25.68,000 --> 0:06:28,000
Los avances en la capacidad de procesamiento y almacenamiento de datos

140
0:06:29.516,000 --> 0:06:3,000
y en el diseño de algoritmos

141
0:06:31.186,000 --> 0:06:34,000
indican que esta distinción entre lo rutinario y lo no rutinario

142
0:06:34.196,000 --> 0:06:35,000
será cada vez menos útil.

143
0:06:35.416,000 --> 0:06:38,000
Para ilustrarlo, volvamos al caso del médico que hace un diagnóstico.

144
0:06:38.796,000 --> 0:06:38,000
A principio de año,

145
0:06:39.776,000 --> 0:06:42,000
un equipo de investigadores de Stanford anunció el desarrollo de un sistema

146
0:06:43.396,000 --> 0:06:46,000
que puede identificar si una mancha en la piel es cancerígena o no

147
0:06:46.536,000 --> 0:06:49,000
con la misma precisión del diagnóstico de dermatólogos de prestigio.

148
0:06:49.76,000 --> 0:06:49,000
¿Cómo funciona?

149
0:06:50.56,000 --> 0:06:55,000
No intenta imitar el criterio ni la intuición de un médico.

150
0:06:55.88,000 --> 0:06:57,000
No sabe ni entiende de medicina.

151
0:06:59.04,000 --> 0:07:01,000
En cambio, ejecuta un algoritmo de reconocimiento de patrones

152
0:07:01.996,000 --> 0:07:05,000
que recorre 129 450 casos previos,

153
0:07:06.32,000 --> 0:07:11,000
y busca similitudes entre esos casos y la lesión específica en cuestión.

154
0:07:12.08,000 --> 0:07:15,000
Realiza estas tareas de una manera no humana,

155
0:07:15.32,000 --> 0:07:16,000
analizando los casos más probables,

156
0:07:17.186,000 --> 0:07:2,000
que serían imposibles de revisar para cualquier médico en toda su vida.

157
0:07:20.526,000 --> 0:07:21,000
No importó si ese ser humano,

158
0:07:22.24,000 --> 0:07:24,000
si esa médica, no pudo explicar cómo había hecho la tarea.

159
0:07:25.64,000 --> 0:07:27,000
Ahora bien, hay quienes tienen sus reparos

160
0:07:28,000 --> 0:07:31,000
porque estas máquinas no están hechas a semejanza de un humano.

161
0:07:31.016,000 --> 0:07:34,000
Como ejemplo, tomemos a Watson, la supercomputadora de IBM

162
0:07:34.146,000 --> 0:07:37,000
que participó de un concurso en "Jeopardy!" en EE.UU. en 2011

163
0:07:37.28,000 --> 0:07:4,000
y le ganó a dos campeones humanos en el programa.

164
0:07:40.32,000 --> 0:07:41,000
Al día siguiente,

165
0:07:42.04,000 --> 0:07:45,000
el periódico Wall Street Journal publicó un artículo del filósofo John Searle

166
0:07:46.016,000 --> 0:07:48,000
titulado "Watson no sabe que ganó en 'Jeopardy!'"

167
0:07:48.76,000 --> 0:07:49,000
Brillante y cierto.

168
0:07:50.41,000 --> 0:07:51,000
Watson no gritó de felicidad.

169
0:07:52.77,000 --> 0:07:55,000
No llamó a sus padres para contarles de su logro.

170
0:07:56.05,000 --> 0:07:57,000
No fue al bar a tomar un trago.

171
0:07:58.72,000 --> 0:08:02,000
El sistema no pretendía copiar la forma en que jugaban los participantes humanos,

172
0:08:03.2,000 --> 0:08:04,000
pero no tenía importancia.

173
0:08:04.48,000 --> 0:08:05,000
Aun así, les ganó.

174
0:08:06.48,000 --> 0:08:07,000
Al resolver el mito de la inteligencia,

175
0:08:08.466,000 --> 0:08:11,000
podemos ver que nuestro limitado conocimiento de la inteligencia humana,

176
0:08:11.986,000 --> 0:08:13,000
de la manera en que pensamos y razonamos,

177
0:08:14.066,000 --> 0:08:16,000
ya no es una limitación para la automatización

178
0:08:16.286,000 --> 0:08:17,000
como lo era en el pasado.

179
0:08:17.54,000 --> 0:08:19,000
Más aun, hemos visto que cuando estas máquinas

180
0:08:19.936,000 --> 0:08:21,000
hacen tareas de un modo distinto al de los seres humanos,

181
0:08:22.61,000 --> 0:08:23,000
no hay motivo para pensar

182
0:08:23.816,000 --> 0:08:24,000
que lo que nosotros podemos hacer

183
0:08:25.776,000 --> 0:08:26,000
sería una especie de punto máximo

184
0:08:27.346,000 --> 0:08:29,000
de lo que estas máquinas llegarían a hacer en el futuro.

185
0:08:31.04,000 --> 0:08:32,000
Veamos el tercer mito,

186
0:08:32.32,000 --> 0:08:34,000
que yo llamo "el mito de la superioridad".

187
0:08:34.936,000 --> 0:08:38,000
Suele decirse que quienes olvidan el lado útil del progreso tecnológico,

188
0:08:39.816,000 --> 0:08:41,000
las complementariedades que mencioné,

189
0:08:42.04,000 --> 0:08:45,000
están cayendo en lo que se denomina la falacia de la cantidad fija de trabajo.

190
0:08:45.97,000 --> 0:08:48,000
Pues bien, el problema es que esta falacia es una falacia en sí misma;

191
0:08:49.919,000 --> 0:08:5,000
por eso la llamo

192
0:08:51.89,000 --> 0:08:54,000
la falacia de la falacia de la cantidad fija de trabajo.

193
0:08:56.26,000 --> 0:08:57,000
Paso a explicarla.

194
0:08:57.44,000 --> 0:09:,000
La falacia de la cantidad fija de trabajo es un viejo concepto.

195
0:09:00.446,000 --> 0:09:03,000
Un economista británico, David Schloss, le dio este nombre en 1892.

196
0:09:03.84,000 --> 0:09:05,000
Quedó asombrado cuando una vez vio a un estibador

197
0:09:06.68,000 --> 0:09:08,000
que había empezado a usar una máquina para hacer arandelas,

198
0:09:09.576,000 --> 0:09:12,000
esos pequeños discos metálicos que mantienen apretados los tornillos.

199
0:09:13.99,000 --> 0:09:15,000
Este estibador sentía culpa por aumentar su productividad.

200
0:09:17.51,000 --> 0:09:19,000
Claro que casi siempre ocurre lo contrario:

201
0:09:19.54,000 --> 0:09:2,000
sentimos culpa por no ser productivos,

202
0:09:21.386,000 --> 0:09:24,000
por pasar demasiado tiempo en Facebook o Twitter en el trabajo.

203
0:09:24.42,000 --> 0:09:26,000
Pero esta persona sentía culpa por ser más productiva,

204
0:09:26.97,000 --> 0:09:28,000
y lo explicó diciendo: "Sé que estoy haciendo lo incorrecto;

205
0:09:29.78,000 --> 0:09:31,000
le estoy quitando trabajo a otra persona".

206
0:09:32.76,000 --> 0:09:34,000
En su visión, había una cantidad fija de trabajo

207
0:09:35.76,000 --> 0:09:37,000
que debía dividirse entre él y sus compañeros,

208
0:09:37.986,000 --> 0:09:39,000
y al usar una máquina para aumentar la producción

209
0:09:40.396,000 --> 0:09:42,000
habría menos trabajo para sus compañeros.

210
0:09:42.446,000 --> 0:09:43,000
Schloss vio el error.

211
0:09:43.92,000 --> 0:09:44,000
La cantidad de trabajo no era fija.

212
0:09:45.8,000 --> 0:09:48,000
Cuando este trabajador usara la máquina y aumentara su producción,

213
0:09:48.976,000 --> 0:09:5,000
el precio de las arandelas caería, la demanda crecería,

214
0:09:51.64,000 --> 0:09:53,000
surgiría la necesidad de hacer más arandelas,

215
0:09:53.896,000 --> 0:09:55,000
y habría más trabajo para sus compañeros.

216
0:09:55.956,000 --> 0:09:56,000
La cantidad de trabajo aumentaría.

217
0:09:57.776,000 --> 0:10:,000
Schloss le llamó a esto "la falacia de la cantidad fija de trabajo".

218
0:10:01.06,000 --> 0:10:02,000
Actualmente se habla de esta falacia

219
0:10:02.92,000 --> 0:10:04,000
para referirse al futuro de todos los trabajos.

220
0:10:05.2,000 --> 0:10:07,000
No hay una cantidad fija de trabajo que deba dividirse

221
0:10:07.77,000 --> 0:10:08,000
entre las personas y las máquinas.

222
0:10:09.43,000 --> 0:10:11,000
Sí, es cierto que las máquinas sustituyen a los humanos

223
0:10:12.42,000 --> 0:10:14,000
y así disminuye la cantidad de trabajo,

224
0:10:14.52,000 --> 0:10:15,000
pero también los complementan

225
0:10:16.4,000 --> 0:10:18,000
y la cantidad de trabajo aumenta y cambia.

226
0:10:19.76,000 --> 0:10:21,000
Pero la falacia de esta falacia entraña un error:

227
0:10:22.8,000 --> 0:10:24,000
es correcto pensar que el progreso tecnológico

228
0:10:25.04,000 --> 0:10:26,000
aumenta la cantidad de trabajo.

229
0:10:27.04,000 --> 0:10:3,000
Algunas tareas se valorizan, nuevas tareas aparecen.

230
0:10:30.08,000 --> 0:10:33,000
Pero es incorrecto pensar que necesariamente los humanos

231
0:10:33.416,000 --> 0:10:35,000
estaremos en mejores condiciones de hacer esas tareas.

232
0:10:35.94,000 --> 0:10:36,000
Y este es "el mito de la superioridad".

233
0:10:37.866,000 --> 0:10:4,000
Efectivamente, la cantidad de trabajo puede ser mayor y cambiar,

234
0:10:40.92,000 --> 0:10:42,000
pero a medida que las máquinas se hacen más capaces,

235
0:10:43.38,000 --> 0:10:46,000
es posible que asuman esa cantidad extra de trabajo.

236
0:10:46.92,000 --> 0:10:49,000
El progreso tecnológico, más que complementar a los humanos,

237
0:10:50.2,000 --> 0:10:51,000
complementa a las máquinas.

238
0:10:52.92,000 --> 0:10:55,000
Para entenderlo, volvamos a la tarea de conducir un automóvil.

239
0:10:55.96,000 --> 0:10:56,000
Hoy en día, los sistemas de GPS

240
0:10:57.77,000 --> 0:10:59,000
nos complementan a los humanos de forma directa.

241
0:11:00.08,000 --> 0:11:02,000
Nos hacen mejores conductores.

242
0:11:02.92,000 --> 0:11:03,000
Pero en el futuro

243
0:11:04.2,000 --> 0:11:07,000
el software desplazará a los humanos del asiento del conductor,

244
0:11:07.32,000 --> 0:11:1,000
y estos sistemas de GPS, en lugar de complementar a los humanos,

245
0:11:10.456,000 --> 0:11:13,000
simplemente harán que los vehículos sin piloto sean más eficientes,

246
0:11:13.596,000 --> 0:11:14,000
y ayudarán a las máquinas.

247
0:11:14.886,000 --> 0:11:17,000
O vayamos a las complementariedades indirectas que mencioné antes.

248
0:11:18.32,000 --> 0:11:2,000
La tarta de la economía puede agrandarse,

249
0:11:20.336,000 --> 0:11:22,000
pero a medida que las máquinas se hagan más eficientes,

250
0:11:23.026,000 --> 0:11:26,000
es posible que haya mayor demanda de productos fabricados por máquinas

251
0:11:26.523,000 --> 0:11:27,000
y no por humanos.

252
0:11:27.95,000 --> 0:11:29,000
La tarta de la economía puede cambiar,

253
0:11:30.016,000 --> 0:11:32,000
pero a medida que las máquinas se hagan más capaces,

254
0:11:32.486,000 --> 0:11:35,000
es posible que estén mejor posicionadas para realizar las nuevas tareas.

255
0:11:36.65,000 --> 0:11:39,000
En definitiva, la demanda de tareas no implica demanda de trabajo humano.

256
0:11:40.32,000 --> 0:11:42,000
Los seres humanos se benefician únicamente

257
0:11:42.486,000 --> 0:11:45,000
si se mantienen a la delantera en todas estas tareas complementadas,

258
0:11:46.12,000 --> 0:11:48,000
pero a medida que las máquinas se hacen más capaces,

259
0:11:48.77,000 --> 0:11:49,000
esas posibilidades se reducen.

260
0:11:50.62,000 --> 0:11:52,000
Ahora bien, ¿qué nos enseñan estos tres mitos?

261
0:11:52.916,000 --> 0:11:53,000
Resolver el mito del Exterminador

262
0:11:54.52,000 --> 0:11:57,000
muestra que el futuro del trabajo depende del equilibrio entre dos fuerzas:

263
0:11:58.076,000 --> 0:12:,000
una, la sustitución de mano de obra por máquinas

264
0:12:00.416,000 --> 0:12:01,000
--que perjudica al trabajador--

265
0:12:01.99,000 --> 0:12:03,000
y la otra, las complementariedades

266
0:12:04.53,000 --> 0:12:05,000
que hacen lo opuesto.

267
0:12:05.66,000 --> 0:12:08,000
Y, hasta ahora, esta balanza se ha inclinado a favor de los humanos.

268
0:12:08.86,000 --> 0:12:09,000
Resolver el mito de la inteligencia

269
0:12:10.596,000 --> 0:12:13,000
muestra que esa primera fuerza, el reemplazo del trabajo por máquinas,

270
0:12:13.896,000 --> 0:12:14,000
se está imponiendo.

271
0:12:14.916,000 --> 0:12:16,000
Está claro que las máquinas no pueden hacer todo,

272
0:12:17.356,000 --> 0:12:17,000
pero sí mucho más,

273
0:12:18.336,000 --> 0:12:22,000
penetrando más aún en el terreno de las tareas hechas por nosotros.

274
0:12:22.6,000 --> 0:12:23,000
Además, no hay motivo para pensar

275
0:12:24.52,000 --> 0:12:27,000
que lo que los humanos podemos hacer hoy sería una especie de línea de llegada

276
0:12:28.18,000 --> 0:12:3,000
y que las máquinas se detendrán tranquilamente en su avance

277
0:12:30.956,000 --> 0:12:32,000
una vez que igualen la capacidad humana.

278
0:12:33.296,000 --> 0:12:35,000
Ahora bien, nada de esto tiene importancia

279
0:12:35.326,000 --> 0:12:37,000
mientras esos vientos favorables de la complementariedad

280
0:12:38.056,000 --> 0:12:39,000
soplen con suficiente fuerza.

281
0:12:39.506,000 --> 0:12:4,000
Pero resolver el mito de la superioridad

282
0:12:41.426,000 --> 0:12:43,000
nos muestra que ese proceso de invasión de tareas

283
0:12:44,000 --> 0:12:47,000
no solo robustece la fuerza de la sustitución del trabajo por máquinas

284
0:12:47.446,000 --> 0:12:5,000
sino que también debilita esas útiles complementariedades.

285
0:12:51.32,000 --> 0:12:52,000
Si reunimos estos tres mitos

286
0:12:53.28,000 --> 0:12:55,000
podremos tener una idea de ese inquietante futuro.

287
0:12:55.78,000 --> 0:12:57,000
Las máquinas siguen siendo cada vez más capaces,

288
0:12:58.28,000 --> 0:13:01,000
invadiendo cada vez más las tareas realizadas por seres humanos,

289
0:13:01.96,000 --> 0:13:04,000
robusteciendo la fuerza de la sustitución del trabajo por máquinas

290
0:13:05.3,000 --> 0:13:07,000
y debilitando la fuerza de las complementariedades.

291
0:13:08.2,000 --> 0:13:12,000
Y en un punto, la balanza se inclina a favor de las máquinas

292
0:13:12.52,000 --> 0:13:14,000
más que de los seres humanos.

293
0:13:14.6,000 --> 0:13:16,000
Este es el camino que hoy estamos transitando.

294
0:13:16.816,000 --> 0:13:19,000
Y digo "camino" a propósito porque no creo que hayamos llegado,

295
0:13:20.016,000 --> 0:13:23,000
pero no podemos negar que vamos en esa dirección.

296
0:13:24.64,000 --> 0:13:25,000
Esto es lo inquietante.

297
0:13:26.12,000 --> 0:13:29,000
Les diré ahora por qué considero que este es un problema con ventajas.

298
0:13:30.32,000 --> 0:13:33,000
En casi toda la historia de la humanidad, el problema económico dominante ha sido

299
0:13:34.296,000 --> 0:13:37,000
cómo hacer para que la tarta de la economía alcance para todos.

300
0:13:37.93,000 --> 0:13:39,000
Vayamos a comienzos del primer siglo de nuestra era,

301
0:13:40.436,000 --> 0:13:42,000
y veremos que si la tarta de la economía global

302
0:13:42.776,000 --> 0:13:45,000
se dividiera en porciones iguales para todas las personas del mundo,

303
0:13:46.176,000 --> 0:13:48,000
cada uno recibiría unos cientos de dólares.

304
0:13:48.316,000 --> 0:13:51,000
Casi todas las personas vivían al borde de la línea de pobreza, o cerca.

305
0:13:51.74,000 --> 0:13:52,000
Y si nos adelantamos mil años,

306
0:13:53.52,000 --> 0:13:55,000
sigue siendo igual, en líneas generales.

307
0:13:55.68,000 --> 0:13:58,000
Pero en los últimos cien años, la economía ha tomado vuelo.

308
0:13:59.28,000 --> 0:14:01,000
Esas tartas de la economía se han disparado en tamaño.

309
0:14:01.946,000 --> 0:14:02,000
El PIB mundial per cápita,

310
0:14:03.76,000 --> 0:14:06,000
el valor actual de esas porciones individuales de la tarta,

311
0:14:07.16,000 --> 0:14:09,000
es de unos USD 10 150.

312
0:14:1,000 --> 0:14:12,000
Si la economía sigue creciendo al ritmo del 2 %,

313
0:14:12.72,000 --> 0:14:14,000
nuestros hijos serán el doble de ricos que nosotros.

314
0:14:15.336,000 --> 0:14:17,000
Y si continúa su crecimiento en un modesto 1 %,

315
0:14:17.546,000 --> 0:14:19,000
nuestro nietos serán el doble de ricos que nosotros.

316
0:14:19.976,000 --> 0:14:22,000
En líneas generales, hemos resuelto ese tradicional problema económico.

317
0:14:24.2,000 --> 0:14:26,000
Ahora bien, si se produce el desempleo tecnológico,

318
0:14:27.55,000 --> 0:14:29,000
será, curiosamente, un síntoma de ese éxito.

319
0:14:30.48,000 --> 0:14:33,000
Habrá resuelto el problema de cómo agrandar la tarta,

320
0:14:34.36,000 --> 0:14:35,000
pero creará otro:

321
0:14:36.2,000 --> 0:14:38,000
cómo asegurarse de que todos reciban una porción.

322
0:14:39.76,000 --> 0:14:42,000
Tal y como piensan otros economistas, resolver este problema no será fácil.

323
0:14:43.36,000 --> 0:14:44,000
Actualmente, para la mayoría,

324
0:14:45.04,000 --> 0:14:47,000
el trabajo es nuestro asiento a la mesa de la economía,

325
0:14:47.656,000 --> 0:14:49,000
y en un mundo con menos trabajo o incluso sin trabajo,

326
0:14:50.386,000 --> 0:14:51,000
no está claro cómo obtendrán su porción.

327
0:14:52.376,000 --> 0:14:54,000
Mucho se ha debatido, por ejemplo,

328
0:14:54.44,000 --> 0:14:56,000
sobre las distintas formas de ingreso básico universal

329
0:14:57.16,000 --> 0:14:58,000
como una medida posible,

330
0:14:58.4,000 --> 0:14:59,000
y se están realizando ensayos

331
0:15:00.04,000 --> 0:15:02,000
en Estados Unidos, Finlandia y Kenia.

332
0:15:03,000 --> 0:15:06,000
Este es el desafío colectivo que debemos enfrentar,

333
0:15:06.2,000 --> 0:15:1,000
cómo hacer que esta prosperidad material generada por nuestro sistema económico

334
0:15:11.28,000 --> 0:15:12,000
sea disfrutado por todos,

335
0:15:13.28,000 --> 0:15:15,000
en un mundo donde el mecanismo tradicional de distribuir

336
0:15:16.056,000 --> 0:15:17,000
las porciones de la tarta,

337
0:15:17.6,000 --> 0:15:18,000
el trabajo que hace la gente,

338
0:15:19.56,000 --> 0:15:21,000
se debilita y quizá desaparezca.

339
0:15:22.28,000 --> 0:15:26,000
Resolver este problema nos obligará a pensar de otras maneras.

340
0:15:27.4,000 --> 0:15:3,000
Habrá grandes desacuerdos sobre el camino a seguir,

341
0:15:31.6,000 --> 0:15:34,000
pero es importante recordar que es mejor tener este problema

342
0:15:35.04,000 --> 0:15:37,000
que el que acechó a nuestros ancestros durante siglos:

343
0:15:37.88,000 --> 0:15:4,000
cómo hacer que esa tarta sea lo suficientemente grande.

344
0:15:41.28,000 --> 0:15:42,000
Muchas gracias.

345
0:15:42.56,000 --> 0:15:45,000
(Aplausos)

