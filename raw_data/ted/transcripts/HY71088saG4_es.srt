1
0:00:,000 --> 0:00:07,000
Traductor: Emilia Sotres Revisor: Lidia Cámara de la Fuente

2
0:00:12.833,000 --> 0:00:15,000
En el 2011 me cambié el nombre

3
0:00:16.255,000 --> 0:00:19,000
para participar en un campamento juvenil de extrema derecha en Hungría.

4
0:00:20.434,000 --> 0:00:24,000
Hacía el doctorado sobre la sociabilización política de los jóvenes

5
0:00:25.184,000 --> 0:00:28,000
por qué los jóvenes desarrollaban ideologías políticas

6
0:00:28.279,000 --> 0:00:3,000
en un marco postcomunista.

7
0:00:30.313,000 --> 0:00:33,000
Y observé que mucha gente joven con la que hablaba

8
0:00:33.57,000 --> 0:00:34,000
se unía a la extrema derecha,

9
0:00:35.194,000 --> 0:00:37,000
y esto me sorprendía.

10
0:00:37.374,000 --> 0:00:39,000
Así que quise inscribirme en este campamento

11
0:00:39.693,000 --> 0:00:42,000
para tener un mejor entendimiento de por qué la gente se unía.

12
0:00:42.853,000 --> 0:00:43,000
Un colega me registró

13
0:00:44.434,000 --> 0:00:46,000
y mi apellido suena demasiado judío.

14
0:00:47.68,000 --> 0:00:49,000
Así que Erin se convirtió en Iréna

15
0:00:50.449,000 --> 0:00:52,000
y Saltman se convirtió en Sós,

16
0:00:52.673,000 --> 0:00:54,000
que significa "salado" en húngaro.

17
0:00:55.618,000 --> 0:00:57,000
Y en húngaro el apellido va primero,

18
0:00:57.952,000 --> 0:01:01,000
así que mi nombre James Bond cambió a "Salada Irena",

19
0:01:02.39,000 --> 0:01:05,000
que no es lo que yo habría escogido para mí.

20
0:01:06.28,000 --> 0:01:07,000
Pero al llegar a este campamento,

21
0:01:08.211,000 --> 0:01:12,000
quedé aún más sorprendida de que en realidad era muy divertido.

22
0:01:13.18,000 --> 0:01:15,000
Hablaban muy poco sobre política.

23
0:01:15.419,000 --> 0:01:18,000
Era más bien sobre aprender a montar a caballo,

24
0:01:18.456,000 --> 0:01:19,000
disparar con arco y flecha,

25
0:01:20.348,000 --> 0:01:21,000
música en vivo por la noche,

26
0:01:22.059,000 --> 0:01:23,000
comida y alcohol gratis,

27
0:01:24.052,000 --> 0:01:26,000
también práctica de tiro al blanco con balas de aire

28
0:01:26.942,000 --> 0:01:29,000
utilizando las caras de políticos convencionales como blanco.

29
0:01:30.62,000 --> 0:01:33,000
Parecía realmente un grupo muy amistoso e inclusivo

30
0:01:34.371,000 --> 0:01:39,000
hasta que se hablaba o mencionaba el tema de la población gitana,

31
0:01:39.808,000 --> 0:01:41,000
la gente judía o los inmigrantes.

32
0:01:42.094,000 --> 0:01:46,000
Entonces el discurso se cargaba de odio rápidamente.

33
0:01:46.843,000 --> 0:01:48,000
Esto me llevó a mi trabajo actual,

34
0:01:49.677,000 --> 0:01:51,000
donde formulamos la pregunta:

35
0:01:52.082,000 --> 0:01:55,000
¿Por qué la gente se une a movimientos extremistas violentos

36
0:01:55.146,000 --> 0:01:58,000
y cómo contrarrestamos efectivamente estos procesos?

37
0:01:58.573,000 --> 0:02:01,000
Al evaluar los daños tras las horribles atrocidades y ataques

38
0:02:01.888,000 --> 0:02:04,000
en lugares como Bélgica, Francia, y por todo el mundo,

39
0:02:05.275,000 --> 0:02:06,000
a veces es más sencillo pensar:

40
0:02:07.132,000 --> 0:02:08,000
"Bueno, deben de ser sociópatas,

41
0:02:09.101,000 --> 0:02:12,000
deben ser individuos de naturaleza violenta."

42
0:02:12.189,000 --> 0:02:14,000
"Algo malo debe haber ocurrido durante su infancia."

43
0:02:14.809,000 --> 0:02:16,000
Y lo verdaderamente trágico es que

44
0:02:16.92,000 --> 0:02:18,000
muchas veces no existe un perfil único.

45
0:02:19.135,000 --> 0:02:22,000
Muchos de ellos tienen estudios avanzados,

46
0:02:22.413,000 --> 0:02:24,000
diferentes ambientes socioeconómicos,

47
0:02:24.533,000 --> 0:02:26,000
hombres y mujeres, distintas edades,

48
0:02:27.405,000 --> 0:02:29,000
algunos con familias, otros solteros.

49
0:02:29.707,000 --> 0:02:31,000
Así que, ¿por qué?, ¿cuál es el atractivo?

50
0:02:32.386,000 --> 0:02:34,000
Y de eso quiero hablarles,

51
0:02:34.459,000 --> 0:02:36,000
y de cómo desafiarlo en la era moderna.

52
0:02:38.711,000 --> 0:02:39,000
Sabemos por la investigación

53
0:02:40.218,000 --> 0:02:42,000
que hay un número de factores

54
0:02:42.598,000 --> 0:02:45,000
que afectan el proceso de radicalización de una persona,

55
0:02:45.973,000 --> 0:02:47,000
y los categorizamos en factores de atracción y disuasión.

56
0:02:48.767,000 --> 0:02:51,000
Y estos son similares para grupos de extrema derecha neonazis

57
0:02:52.204,000 --> 0:02:54,000
y para los islamistas radicales y grupos terroristas.

58
0:02:55.663,000 --> 0:02:58,000
Los factores de atracción son básicamente aquellos que nos hacen vulnerables

59
0:02:59.545,000 --> 0:03:,000
a un proceso de radicalización,

60
0:03:01.427,000 --> 0:03:03,000
a unirnos a un grupo extremista violento.

61
0:03:03.657,000 --> 0:03:05,000
Y estos pueden ser muy variados

62
0:03:05.807,000 --> 0:03:08,000
pero, a grandes rasgos, un sentido de enajenación, un sentido de aislamiento,

63
0:03:09.744,000 --> 0:03:11,000
cuestionarte tu propia identidad,

64
0:03:11.919,000 --> 0:03:13,000
pero también sentir que tu grupo está bajo ataque,

65
0:03:14.769,000 --> 0:03:17,000
y tu grupo puede estar basado en una nacionalidad, etnia,

66
0:03:18.586,000 --> 0:03:19,000
o una religión.

67
0:03:19.936,000 --> 0:03:22,000
Y sentir que quienes tienen el poder de ayudar no lo están haciendo.

68
0:03:24.075,000 --> 0:03:27,000
Los factores de atracción solo no te hacen un extremista violento,

69
0:03:27.52,000 --> 0:03:28,000
porque si así fuera,

70
0:03:28.974,000 --> 0:03:31,000
los mismos factores se aplicarían a grupos como los gitanos,

71
0:03:32.268,000 --> 0:03:34,000
y ellos no son un grupo con brotes violentos.

72
0:03:35.073,000 --> 0:03:37,000
Así que hay que ver los factores de atracción.

73
0:03:37.384,000 --> 0:03:4,000
¿Qué están ofreciendo estas organizaciones extremistas violentas

74
0:03:40.718,000 --> 0:03:41,000
que otros grupos no ofrecen?

75
0:03:42.687,000 --> 0:03:44,000
De hecho, suelen ser cosas muy positivas,

76
0:03:45.274,000 --> 0:03:47,000
cosas que parecieran dar poder,

77
0:03:47.315,000 --> 0:03:49,000
como fraternidad y hermandad

78
0:03:49.802,000 --> 0:03:5,000
y un sentido de pertenencia,

79
0:03:51.16,000 --> 0:03:53,000
así como darle a alguien un propósito espiritual,

80
0:03:54.058,000 --> 0:03:57,000
un propósito divino de construir una sociedad utópica,

81
0:03:57.797,000 --> 0:03:58,000
si sus metas pueden ser alcanzadas,

82
0:03:59.742,000 --> 0:04:01,000
pero también un sentido de empoderamiento y de aventura.

83
0:04:02.487,000 --> 0:04:04,000
Cuando vemos a los combatientes terroristas extranjeros,

84
0:04:05.22,000 --> 0:04:07,000
vemos a jóvenes con cabellos ondeados al viento

85
0:04:07.605,000 --> 0:04:09,000
en el desierto y a las mujeres que se les unen

86
0:04:09.869,000 --> 0:04:11,000
para casarse en el atardecer.

87
0:04:12.534,000 --> 0:04:15,000
Es muy romántico, y te conviertes en un héroe.

88
0:04:16.378,000 --> 0:04:18,000
Para ambos hombres y mujeres, así es la propaganda.

89
0:04:19.667,000 --> 0:04:21,000
Los grupos extremistas son muy buenos

90
0:04:22.333,000 --> 0:04:26,000
tomando un mundo muy complicado, confuso y matizado,

91
0:04:27.183,000 --> 0:04:3,000
y simplificarlo en blanco y negro,

92
0:04:30.45,000 --> 0:04:31,000
el mal y el bien.

93
0:04:31.684,000 --> 0:04:32,000
Y te conviertes en lo que es bueno,

94
0:04:33.589,000 --> 0:04:34,000
desafiando lo que es malo.

95
0:04:36.541,000 --> 0:04:39,000
Quiero hablar un poco de ISIS, Daesh,

96
0:04:40.429,000 --> 0:04:44,000
porque han sido revolucionarios en cómo vemos estos procesos,

97
0:04:44.831,000 --> 0:04:47,000
a través de sus materiales y sus tácticas.

98
0:04:48.061,000 --> 0:04:5,000
Son en todo sentido un movimiento moderno.

99
0:04:50.925,000 --> 0:04:54,000
Un aspecto es internet y el uso de redes sociales,

100
0:04:55.434,000 --> 0:04:59,000
como ya hemos visto en tuits y videos de decapitaciones.

101
0:04:59.84,000 --> 0:05:01,000
Pero internet por sí solo no te radicaliza.

102
0:05:02.339,000 --> 0:05:03,000
Es una herramienta.

103
0:05:03.57,000 --> 0:05:04,000
No vas a comprar zapatos en línea

104
0:05:05.45,000 --> 0:05:06,000
y accidentalmente te haces jihadista.

105
0:05:07.793,000 --> 0:05:1,000
No obstante, lo que sí hace internet es ser un catalizador.

106
0:05:11.206,000 --> 0:05:15,000
Ofrece herramientas, escala y rapidez

107
0:05:15.349,000 --> 0:05:16,000
que no existen en otro lado.

108
0:05:16.881,000 --> 0:05:18,000
Y con ISIS de pronto

109
0:05:19.366,000 --> 0:05:24,000
esta idea de un jihadista como una figura oscura y sombría cambió para nosotros.

110
0:05:24.708,000 --> 0:05:26,000
De repente nos encontrábamos en sus cocinas.

111
0:05:26.787,000 --> 0:05:27,000
Veíamos lo que comían para la cena.

112
0:05:28.81,000 --> 0:05:29,000
Estaban tuiteando.

113
0:05:29.985,000 --> 0:05:32,000
Había guerreros terroristas foráneos tuiteando en su propia lengua.

114
0:05:33.303,000 --> 0:05:35,000
Teníamos mujeres ahí hablando de sus bodas,

115
0:05:36.143,000 --> 0:05:37,000
del nacimiento de sus hijos.

116
0:05:37.914,000 --> 0:05:38,000
Teníamos una cultura de videojuegos

117
0:05:39.835,000 --> 0:05:42,000
y referencias al Grand Theft Auto.

118
0:05:43.471,000 --> 0:05:45,000
Así que, de pronto, eran familiares.

119
0:05:45.956,000 --> 0:05:46,000
Eran humanos.

120
0:05:47.131,000 --> 0:05:49,000
Y el problema es que, para contrarrestarlos,

121
0:05:49.369,000 --> 0:05:51,000
muchos gobiernos y compañías de redes sociales

122
0:05:51.703,000 --> 0:05:52,000
intentaron censurarlos.

123
0:05:52.838,000 --> 0:05:54,000
¿Cómo deshacernos del contenido terrorista?

124
0:05:54.899,000 --> 0:05:55,000
Se volvió un juego del gato y del ratón

125
0:05:56.858,000 --> 0:05:59,000
donde las cuentas que se cerraban rápidamente volvían a surgir,

126
0:05:59.936,000 --> 0:06:01,000
y la arrogancia de quien presumía su vigésima quinta cuenta

127
0:06:02.937,000 --> 0:06:05,000
y material diseminado por doquier.

128
0:06:06.055,000 --> 0:06:08,000
Pero también vimos una tendencia peligrosa

129
0:06:08.1,000 --> 0:06:13,000
pues los extremistas violentos también conocen las reglas de las redes sociales.

130
0:06:13.132,000 --> 0:06:17,000
Veíamos una conversación banal con un reclutador

131
0:06:17.156,000 --> 0:06:18,000
empezar en una plataforma convencional

132
0:06:19.153,000 --> 0:06:21,000
y en el punto en que esa conversación

133
0:06:21.258,000 --> 0:06:22,000
estaba por tornarse ilegar,

134
0:06:22.622,000 --> 0:06:24,000
cambiaban a una plataforma más pequeña, menos regulada

135
0:06:25.233,000 --> 0:06:26,000
y más encriptada.

136
0:06:26.794,000 --> 0:06:29,000
Así que de pronto no podíamos rastrear el avance de esa conversación.

137
0:06:30.351,000 --> 0:06:31,000
Este es un problema con la censura,

138
0:06:32.237,000 --> 0:06:35,000
y por ello tenemos que desarrollar alternativas a la censura.

139
0:06:36.035,000 --> 0:06:39,000
ISIS también es distinto porque está construyendo un estado.

140
0:06:39.409,000 --> 0:06:41,000
No sólo recluta combatientes,

141
0:06:41.505,000 --> 0:06:42,000
está intentando construir una nación.

142
0:06:43.431,000 --> 0:06:44,000
Y eso significa que repentinamente,

143
0:06:45.395,000 --> 0:06:47,000
tu modelo de reclutamiento es más amplio.

144
0:06:47.419,000 --> 0:06:49,000
No sólo tratas de conseguir combatientes,

145
0:06:49.492,000 --> 0:06:53,000
necesitas arquitectos, ingenieros, contadores, hackers y mujeres.

146
0:06:53.782,000 --> 0:06:55,000
Hemos visto crecer el número de mujeres

147
0:06:56.196,000 --> 0:06:59,000
en los últimos 24, pero especialmente en los últimos 12 meses.

148
0:06:59.719,000 --> 0:07:01,000
En algunos países una de cada cuatro personas que se afilian

149
0:07:02.632,000 --> 0:07:03,000
son mujeres.

150
0:07:03.895,000 --> 0:07:04,000
Y entonces, esto cambia

151
0:07:05.287,000 --> 0:07:07,000
hacia quién intentamos contrarrestrar en este proceso.

152
0:07:08.679,000 --> 0:07:09,000
Ahora bien, no todo es negro.

153
0:07:10.354,000 --> 0:07:12,000
Lo que quisiera ahora es hablar de algunas cosas positivas

154
0:07:13.338,000 --> 0:07:16,000
y la innovación en prevención y contraataque de violencia extremista.

155
0:07:17.206,000 --> 0:07:19,000
Prevenir es muy distinto a contraatacar,

156
0:07:19.503,000 --> 0:07:21,000
y de hecho, hay que pensarlo en términos médicos.

157
0:07:22.083,000 --> 0:07:24,000
La medicina preventiva es

158
0:07:24.329,000 --> 0:07:27,000
cómo hacer que simplemente seamos resilientes

159
0:07:27.527,000 --> 0:07:29,000
a este proceso de radicalización.

160
0:07:30.051,000 --> 0:07:31,000
Y eso será diferente

161
0:07:31.937,000 --> 0:07:33,000
si alguien ya muestra síntomas o una señal

162
0:07:34.62,000 --> 0:07:36,000
de pertenecer a una ideología extremista violenta.

163
0:07:37.195,000 --> 0:07:38,000
Y así en cuanto a medidas preventivas,

164
0:07:39.096,000 --> 0:07:41,000
hablamos de grupos más extensos de gente

165
0:07:41.811,000 --> 0:07:42,000
y exponerlos a ideas

166
0:07:43.652,000 --> 0:07:44,000
para hacerlos resilientes.

167
0:07:45.443,000 --> 0:07:46,000
Aunque es muy distinto

168
0:07:46.983,000 --> 0:07:49,000
si alguien comienza a cuestionar o estar de acuerdo con ciertas cosas en línea,

169
0:07:50.832,000 --> 0:07:53,000
y también es distinto a quien ya tiene un tatuaje con la esvástica

170
0:07:54.705,000 --> 0:07:56,000
y está muy incorporado en un grupo.

171
0:07:56.777,000 --> 0:07:57,000
¿Cómo llegas a esa gente?

172
0:07:58.785,000 --> 0:08:01,000
Me gustaría repasar tres ejemplos de cada uno de estos niveles

173
0:08:02.491,000 --> 0:08:03,000
y explicarles

174
0:08:03.73,000 --> 0:08:06,000
cuáles son algunos métodos nuevos para incorporar a esta gente.

175
0:08:07.374,000 --> 0:08:08,000
Uno es 'Diálogo extremo',

176
0:08:08.811,000 --> 0:08:11,000
y es un programa educativo que ayudamos a desarrollar.

177
0:08:11.915,000 --> 0:08:13,000
Este es de Canadá,

178
0:08:14.32,000 --> 0:08:18,000
y tiene como objetivo crear diálogos dentro del marco del aula de clases,

179
0:08:18.439,000 --> 0:08:19,000
utilizando la narrativa,

180
0:08:19.995,000 --> 0:08:22,000
porque la violencia extremista puede ser difícil de explicar,

181
0:08:23.17,000 --> 0:08:24,000
sobre todo a los más jóvenes.

182
0:08:25.305,000 --> 0:08:28,000
Así que tenemos una red de exfanáticos y sobrevivientes del extremismo

183
0:08:29.242,000 --> 0:08:32,000
que cuentan sus historias utilizando video y formulan cuestionarios en el aula,

184
0:08:33.203,000 --> 0:08:35,000
para iniciar una conversación del tema.

185
0:08:35.53,000 --> 0:08:37,000
Estos dos ejemplos muestran a Christianne,

186
0:08:38.086,000 --> 0:08:39,000
que perdió a su hijo,

187
0:08:39.261,000 --> 0:08:41,000
quien se radicalizó y murió luchando por ISIS.

188
0:08:41.778,000 --> 0:08:42,000
Y Daniel es un exneonazi

189
0:08:43.469,000 --> 0:08:45,000
extremadamente violento,

190
0:08:45.851,000 --> 0:08:49,000
y se cuestionan sobre sus vidas y dónde están ahora y qué lamentan,

191
0:08:50.033,000 --> 0:08:52,000
y obligan al aula a tener un diálogo al respecto.

192
0:08:53.175,000 --> 0:08:55,000
Ahora, enfocándonos en la media de los individuos,

193
0:08:56.184,000 --> 0:08:58,000
de hecho, necesitamos mucho las voces de la sociedad civil.

194
0:08:59.003,000 --> 0:09:02,000
¿Cómo interactúas con personas que están buscando información en línea,

195
0:09:02.376,000 --> 0:09:04,000
que están considerando una ideología,

196
0:09:04.742,000 --> 0:09:07,000
que hacen esas preguntas escrutadoras sobre su identidad?

197
0:09:07.83,000 --> 0:09:09,000
¿Cómo les ofrecemos alternativas?

198
0:09:09.996,000 --> 0:09:12,000
Y es ahí donde combinamos las voces de grupos sociales

199
0:09:13.41,000 --> 0:09:17,000
con creativos, tecnólogos, artistas, comediantes,

200
0:09:17.965,000 --> 0:09:19,000
para poder crear contenido muy específico

201
0:09:20.672,000 --> 0:09:24,000
y, en línea, diseminarlo entre audiencias estratégicas.

202
0:09:24.99,000 --> 0:09:26,000
Un ejemplo sería crear un video satírico

203
0:09:27.843,000 --> 0:09:29,000
que se burle de la islamofobia,

204
0:09:30.33,000 --> 0:09:33,000
y dirigirlo a jóvenes de entre 15 y 20 años que estén en línea

205
0:09:34.08,000 --> 0:09:36,000
interesados en música afín a la supremacía blanca

206
0:09:36.587,000 --> 0:09:38,000
y que viven específicamente en Manchester.

207
0:09:38.994,000 --> 0:09:41,000
Podemos utilizar estas herramientas para ser muy específicos,

208
0:09:42.049,000 --> 0:09:44,000
y saber cuándo alguien está viendo, observando

209
0:09:44.796,000 --> 0:09:45,000
y simpatizando con el contenido

210
0:09:46.309,000 --> 0:09:48,000
no es una persona común, no somos ni tú ni yo,

211
0:09:48.963,000 --> 0:09:51,000
es una audiencia muy específica que buscamos captar.

212
0:09:52.704,000 --> 0:09:55,000
Aún más profundo, desarrollamos un programa piloto llamado "Uno a uno",

213
0:09:56.427,000 --> 0:09:57,000
donde tomamos a exradicales

214
0:09:58,000 --> 0:10:02,000
y ellos contactaron directamente a un grupo que se consideraba neofascista

215
0:10:02.888,000 --> 0:10:03,000
así como extremista islámico,

216
0:10:04.536,000 --> 0:10:07,000
y con Facebook Messanger pusimos mensajes en sus bandejas de entrada

217
0:10:08.375,000 --> 0:10:1,000
diciendo: "Oye, sé a dónde vas, yo he estado ahí,

218
0:10:10.685,000 --> 0:10:11,000
aquí estoy si quieres hablar."

219
0:10:12.251,000 --> 0:10:15,000
En realidad esperábamos amenazas de muerte con estas interacciones.

220
0:10:15.529,000 --> 0:10:19,000
Es un poco alarmante tener a un exneonazi diciéndote: "¿Cómo estás?"

221
0:10:19.973,000 --> 0:10:21,000
Pero de hecho vimos que alrededor del 60 %

222
0:10:22.204,000 --> 0:10:24,000
de las personas contactadas contestaron,

223
0:10:24.782,000 --> 0:10:28,000
y de ellas, otro 60 % mantuvo el contacto,

224
0:10:28.891,000 --> 0:10:3,000
es decir que estaban conversando

225
0:10:30.971,000 --> 0:10:33,000
con los más difíciles de alcanzar sobre lo que estaban viviendo,

226
0:10:34.211,000 --> 0:10:35,000
plantando la duda

227
0:10:35.386,000 --> 0:10:37,000
y dándoles alternativas para hablar de estos temas,

228
0:10:38.402,000 --> 0:10:39,000
y eso es muy importante.

229
0:10:41.061,000 --> 0:10:43,000
Lo que estamos intentando hacer

230
0:10:43.308,000 --> 0:10:45,000
es traer a la mesa a sectores insólitos.

231
0:10:46.237,000 --> 0:10:48,000
Tenemos activistas increíbles en todo el mundo,

232
0:10:48.587,000 --> 0:10:5,000
pero a menudo, sus mensajes no son estratégicos

233
0:10:50.977,000 --> 0:10:52,000
o no alcanzan los foros que quieren alcanzar.

234
0:10:53.587,000 --> 0:10:55,000
Así que trabajamos con redes de antiguos extremistas.

235
0:10:56.17,000 --> 0:10:59,000
Trabajamos con redes de jóvenes en diferentes partes del mundo.

236
0:10:59.623,000 --> 0:11:01,000
Y trabajamos para traer el sector tecnológico a la mesa

237
0:11:02.417,000 --> 0:11:04,000
con artistas y creativos y expertos en mercadotecnia

238
0:11:05.259,000 --> 0:11:1,000
para que podamos tener un desafío más robusto contra el extremismo

239
0:11:10.284,000 --> 0:11:11,000
que funcione.

240
0:11:12.074,000 --> 0:11:14,000
Así que si estás en el público

241
0:11:14.678,000 --> 0:11:16,000
y casualmente eres un diseñador gráfico,

242
0:11:17.401,000 --> 0:11:19,000
un poeta, un experto en mercadotecnia,

243
0:11:19.607,000 --> 0:11:2,000
alguien que trabaja en RRPP,

244
0:11:21.54,000 --> 0:11:22,000
un comediante

245
0:11:22.917,000 --> 0:11:24,000
puedes creer o no que este es tu lugar,

246
0:11:25.092,000 --> 0:11:27,000
pero en realidad, el talento que tienes ahora

247
0:11:27.855,000 --> 0:11:29,000
puede ser exactamente lo que se necesita

248
0:11:29.882,000 --> 0:11:31,000
para combatir efectivamente el extremismo.

249
0:11:32.215,000 --> 0:11:33,000
Gracias

250
0:11:33.39,000 --> 0:11:37,000
(Aplausos)

