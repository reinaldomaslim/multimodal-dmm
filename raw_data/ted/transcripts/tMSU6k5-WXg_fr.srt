1
0:00:,000 --> 0:00:07,000
Traducteur: Elliot O'Sullivan Relecteur: Chris DeWavre

2
0:00:12.485,000 --> 0:00:14,000
Il y a 10 ans, j'ai écrit un livre intitulé

3
0:00:14.707,000 --> 0:00:17,000
« Notre dernier siècle ? ». Point d'interrogation.

4
0:00:17.8,000 --> 0:00:2,000
Mes éditeurs ont retiré le point d'interrogation. (Rires)

5
0:00:21.377,000 --> 0:00:22,000
Les éditeurs américains l'ont renommé

6
0:00:23.259,000 --> 0:00:26,000
« Notre Dernière Heure ».

7
0:00:27.168,000 --> 0:00:3,000
Les Américains aiment la satisfaction immédiate et l'autre extrême.

8
0:00:30.66,000 --> 0:00:31,000
(Rires)

9
0:00:32.368,000 --> 0:00:33,000
Le sujet du livre, c'est que

10
0:00:34.118,000 --> 0:00:38,000
notre Terre existe depuis 45 millions de siècles,

11
0:00:38.284,000 --> 0:00:4,000
mais ce siècle est spécial.

12
0:00:40.297,000 --> 0:00:43,000
C'est le tout premier où

13
0:00:43.313,000 --> 0:00:45,000
le futur de la planète dépend de nous

14
0:00:46.115,000 --> 0:00:47,000
Dans l'histoire de la Terre, en général

15
0:00:48.105,000 --> 0:00:49,000
les menaces sont venues de la nature -

16
0:00:50.041,000 --> 0:00:53,000
les maladies, les tremblements de terre, les asteroïdes etc.

17
0:00:53.537,000 --> 0:00:58,000
mais à partir de maintenant, les pires dangers viennent de nous-mêmes.

18
0:00:59.209,000 --> 0:01:02,000
Et à présent, il ne s'agit plus seulement de la menace nucléaire;

19
0:01:02.48,000 --> 0:01:03,000
Dans notre monde interconnecté,

20
0:01:04.231,000 --> 0:01:07,000
les pannes de réseau peuvent se répandre partout ;

21
0:01:07.394,000 --> 0:01:1,000
les voyages en avion peuvent répandre des pandémies en quelques jours ;

22
0:01:11.35,000 --> 0:01:14,000
et les media sociaux peuvent propager panique et rumeurs

23
0:01:14.677,000 --> 0:01:17,000
à la vitesse de la lumière, littéralement.

24
0:01:17.894,000 --> 0:01:2,000
On s'inquiète trop des risques mineurs :

25
0:01:21.119,000 --> 0:01:25,000
accidents d'avion improbables, alimentation cancérigène,

26
0:01:25.15,000 --> 0:01:27,000
exposition à de faibles doses de radiations, etc.

27
0:01:27.376,000 --> 0:01:29,000
Mais nous et nos politiciens

28
0:01:30.201,000 --> 0:01:34,000
nions les possibilités de scénarios catastrophiques.

29
0:01:34.404,000 --> 0:01:37,000
Heureusement le pire n'est pas encore arrivé.

30
0:01:37.442,000 --> 0:01:39,000
Probablement, il n'arrivera jamais.

31
0:01:39.638,000 --> 0:01:42,000
Mais s'il existe un évènement potentiellement dévastateur,

32
0:01:42.823,000 --> 0:01:44,000
ça vaut la peine de payer une prime élevée

33
0:01:45.691,000 --> 0:01:48,000
pour nous en protéger, même s'il est peu probable,

34
0:01:49.527,000 --> 0:01:53,000
comme on assure sa maison contre l'incendie.

35
0:01:54.04,000 --> 0:01:58,000
Et bien que la science offre des pouvoirs et des promesses de plus en plus grands

36
0:01:59.037,000 --> 0:02:02,000
ses inconvénients deviennent aussi de plus en plus effrayants.

37
0:02:02.903,000 --> 0:02:04,000
Nous devenons plus vulnérables que jamais.

38
0:02:05.142,000 --> 0:02:06,000
D'ici quelques décennies

39
0:02:06.98,000 --> 0:02:08,000
des millions de personnes seront capables

40
0:02:09.21,000 --> 0:02:12,000
d'abuser d'une biotechnologie très avancée

41
0:02:12.331,000 --> 0:02:15,000
comme ils abusent aujourd'hui de la cyber technologie.

42
0:02:15.884,000 --> 0:02:18,000
Freeman Dyson, dans une conférence de TED

43
0:02:19.083,000 --> 0:02:22,000
a prévu que des enfants concevraient et créeraient de nouveaux organismes

44
0:02:22.679,000 --> 0:02:26,000
aussi habituellement que sa génération jouait avec une boîte de chimie.

45
0:02:27.19,000 --> 0:02:29,000
Cela peut sembler être de la science fiction,

46
0:02:29.718,000 --> 0:02:32,000
mais même si seulement une partie de son scenario se produit,

47
0:02:32.901,000 --> 0:02:34,000
cela suggère que notre écologie et même notre espèce

48
0:02:35.638,000 --> 0:02:38,000
ne s'en sortirait certainement pas indemne.

49
0:02:39.627,000 --> 0:02:42,000
Par exemple, il y a des extrémistes écologistes

50
0:02:43.49,000 --> 0:02:45,000
qui pensent qu'il serait mieux pour la planète,

51
0:02:45.999,000 --> 0:02:48,000
pour Gaïa, s'il y avait beaucoup moins d'humains.

52
0:02:49.402,000 --> 0:02:51,000
Qu'arrivera-t-il quand ces personnes maîtriseront

53
0:02:52.119,000 --> 0:02:54,000
les techniques de la biologie synthétique

54
0:02:54.256,000 --> 0:02:56,000
qui seront répandues en 2050 ?

55
0:02:57.108,000 --> 0:03:,000
De là, d'autres cauchemars de la science-fiction

56
0:03:00.15,000 --> 0:03:01,000
pourraient devenir réalité :

57
0:03:01.86,000 --> 0:03:03,000
des robots dévoyés,

58
0:03:03.93,000 --> 0:03:05,000
ou un réseau qui développe son propre esprit.

59
0:03:06.347,000 --> 0:03:08,000
et menace tout le monde.

60
0:03:08.936,000 --> 0:03:09,000
Peut-on se prémunir contre ces risques

61
0:03:10.828,000 --> 0:03:11,000
par la régulation ?

62
0:03:12.72,000 --> 0:03:13,000
Il faut essayer, mais ces entreprises

63
0:03:14.613,000 --> 0:03:17,000
sont si compétitives, si mondialisées,

64
0:03:18.142,000 --> 0:03:19,000
et tellement motivées par la pression commerciale,

65
0:03:20.122,000 --> 0:03:23,000
que tout ce qui est possible sera tenté,

66
0:03:23.407,000 --> 0:03:25,000
quoiqu'en disent les régulations.

67
0:03:25.443,000 --> 0:03:28,000
Comme les lois sur la drogue sont autant d'échecs.

68
0:03:28.93,000 --> 0:03:31,000
Et le Village Mondial aura aussi ses idiots,

69
0:03:31.974,000 --> 0:03:34,000
qui auront une portée mondiale.

70
0:03:35.47,000 --> 0:03:37,000
Alors comme je dis dans mon livre,

71
0:03:37.761,000 --> 0:03:39,000
on va traverser une mauvaise passe au cours de ce siècle.

72
0:03:40.65,000 --> 0:03:43,000
Notre société connaîtra peut-être des revers.

73
0:03:44.14,000 --> 0:03:48,000
Il y a en effet 50% de chance d'un revers grave.

74
0:03:48.255,000 --> 0:03:5,000
Mais y a-t-il des évènements imaginables

75
0:03:51.169,000 --> 0:03:53,000
que seraient encore pires ?

76
0:03:53.33,000 --> 0:03:56,000
Des évènements qui pourraient éliminer toute vie ?

77
0:03:56.76,000 --> 0:03:58,000
Quand un nouvel accélérateur de particules a été mis en marche,

78
0:03:59.731,000 --> 0:04:,000
des gens anxieux ont demandé :

79
0:04:01.475,000 --> 0:04:03,000
pourrait-il détruire la Terre ? Ou pire,

80
0:04:03.725,000 --> 0:04:05,000
déchirer la structure de l'espace ?

81
0:04:06.384,000 --> 0:04:09,000
Heureusement, on a pu les rassurer.

82
0:04:09.927,000 --> 0:04:11,000
D'autres et moi-même avons indiqué que la nature

83
0:04:11.971,000 --> 0:04:12,000
a déjà mené les mêmes expériences

84
0:04:13.904,000 --> 0:04:15,000
des millions de fois,

85
0:04:16.09,000 --> 0:04:17,000
via des collisions de rayons cosmiques.

86
0:04:17.855,000 --> 0:04:2,000
Mais certainement les scientifiques devraient être prudents

87
0:04:20.909,000 --> 0:04:22,000
à propos des expériences qui génèrent des conditions

88
0:04:23.489,000 --> 0:04:25,000
sans précédent dans la nature.

89
0:04:25.972,000 --> 0:04:28,000
Les biologistes devraient éviter la dissémination dans l'environnement

90
0:04:29.395,000 --> 0:04:31,000
de pathogènes génétiquement modifiés potentiellement nuisibles.

91
0:04:32.11,000 --> 0:04:35,000
Et au fait, notre aversion particulière pour la possibilité

92
0:04:35.627,000 --> 0:04:38,000
d'un désastre existentiel

93
0:04:39.088,000 --> 0:04:42,000
dépend d'une question philosophique et éthique.

94
0:04:42.363,000 --> 0:04:43,000
La voici :

95
0:04:44.033,000 --> 0:04:46,000
considérez deux scénarios.

96
0:04:46.341,000 --> 0:04:51,000
Dans le scénario A, 90% de l'humanité est anéantie.

97
0:04:51.577,000 --> 0:04:54,000
Dans le scénario B, 100% de l'humanité est anéantie.

98
0:04:55.473,000 --> 0:04:57,000
À quel point B est-il pire que A ?

99
0:04:58.391,000 --> 0:05:01,000
Certains diraient 10% pire.

100
0:05:01.414,000 --> 0:05:04,000
Le nombre de morts est de 10% plus élevé.

101
0:05:04.564,000 --> 0:05:06,000
Moi, j'affirme que B est incomparablement pire.

102
0:05:07.47,000 --> 0:05:09,000
Comme astronome, je ne peux pas croire

103
0:05:10.099,000 --> 0:05:12,000
que les humains soient la fin de l'histoire.

104
0:05:12.566,000 --> 0:05:15,000
Il reste 5 milliards d'années avant que le soleil ne s'embrase,

105
0:05:15.889,000 --> 0:05:17,000
et l'univers pourrait durer éternellement.

106
0:05:18.6,000 --> 0:05:2,000
Alors l'évolution post-humaine,

107
0:05:20.892,000 --> 0:05:22,000
ici sur Terre et bien loin ailleurs,

108
0:05:23.082,000 --> 0:05:25,000
pourrait se prolonger autant que le processus darwinien,

109
0:05:25.796,000 --> 0:05:28,000
qui a abouti à nous, et à des choses encore plus merveilleuses.

110
0:05:29.077,000 --> 0:05:31,000
Et en effet, l'évolution future arrivera plus rapidement,

111
0:05:31.741,000 --> 0:05:33,000
à une échelle de temps technologique

112
0:05:33.94,000 --> 0:05:35,000
et non à l'échelle de la sélection naturelle.

113
0:05:36.239,000 --> 0:05:4,000
Par conséquent, compte tenu des enjeux immenses,

114
0:05:40.434,000 --> 0:05:43,000
nous ne devrions même pas accepter un risque de un sur un milliard

115
0:05:43.82,000 --> 0:05:47,000
que l'extinction de l'humanité tue cet énorme potentiel.

116
0:05:48.359,000 --> 0:05:51,000
En fait, certains scénarios pourraient relever de la science fiction,

117
0:05:52.001,000 --> 0:05:55,000
mais d'autres malheureusement pourraient s'avérer bien réels.

118
0:05:55.336,000 --> 0:05:57,000
Une importante maxime dit que

119
0:05:58.21,000 --> 0:06:,000
inconnu ne signifie pas improbable.

120
0:06:00.907,000 --> 0:06:02,000
Et c'est pourquoi à l'Université de Cambridge

121
0:06:03.305,000 --> 0:06:06,000
nous installons un centre de recherche pour examiner comment

122
0:06:06.68,000 --> 0:06:08,000
atténuer ces risques existentiels.

123
0:06:08.712,000 --> 0:06:11,000
Il semble qu'il vaille la peine pour quelques chercheurs

124
0:06:11.775,000 --> 0:06:13,000
de réfléchir aux catastrophes possibles.

125
0:06:14.091,000 --> 0:06:17,000
Et nous avons besoin de toute l'aide possible.

126
0:06:17.104,000 --> 0:06:19,000
Car nous sommes protecteurs

127
0:06:19.583,000 --> 0:06:22,000
d'un petit point bleu pâle si précieux dans ce vaste cosmos.

128
0:06:23.066,000 --> 0:06:26,000
Une planète qui a encore 50 millions de siècles à venir.

129
0:06:26.444,000 --> 0:06:28,000
Alors ne compromettons pas son avenir.

130
0:06:29,000 --> 0:06:3,000
Je terminerai par une citation

131
0:06:30.795,000 --> 0:06:33,000
du grand scientifique Peter Medawar.

132
0:06:34.296,000 --> 0:06:37,000
Je cite : « Les cloches qui sonnent pour l'humanité

133
0:06:37.569,000 --> 0:06:39,000
sont comme les cloches des vaches des Alpes.

134
0:06:40.213,000 --> 0:06:42,000
Elles sont attachées à nos propres cous

135
0:06:42.499,000 --> 0:06:44,000
et ce doit être notre faute si ces cloches

136
0:06:45.174,000 --> 0:06:47,000
ne font pas un son musical et mélodieux. »

137
0:06:47.305,000 --> 0:06:49,000
Merci beaucoup.

138
0:06:49.572,000 --> 0:06:51,000
(Applaudissements)

