1
0:00:,000 --> 0:00:07,000
Traducteur: Elisabeth Buffard Relecteur: Timothée Parrique

2
0:00:15.26,000 --> 0:00:17,000
La sécurité, c'est donc deux choses différentes:

3
0:00:17.26,000 --> 0:00:19,000
c'est une impression et c'est une réalité.

4
0:00:19.26,000 --> 0:00:21,000
Et c'est différent.

5
0:00:21.26,000 --> 0:00:23,000
Vous pouvez vous sentir en sécurité

6
0:00:23.26,000 --> 0:00:25,000
même si vous ne l'êtes pas.

7
0:00:25.26,000 --> 0:00:27,000
Et vous pouvez être en sécurité

8
0:00:27.26,000 --> 0:00:29,000
même si vous n'en avez pas l'impression.

9
0:00:29.26,000 --> 0:00:31,000
Nous avons vraiment deux concepts distincts

10
0:00:31.26,000 --> 0:00:33,000
rattachés au même terme.

11
0:00:33.26,000 --> 0:00:35,000
Et ce que je veux faire pendant cette conférence,

12
0:00:35.26,000 --> 0:00:37,000
c'est les séparer --

13
0:00:37.26,000 --> 0:00:39,000
comprendre quand ils diverent

14
0:00:39.26,000 --> 0:00:41,000
et comment ils convergent.

15
0:00:41.26,000 --> 0:00:43,000
Et le langage est en fait un problème ici

16
0:00:43.26,000 --> 0:00:45,000
Il n'y a pas beaucoup de mots adéquats

17
0:00:45.26,000 --> 0:00:48,000
pour les concepts dont nous allons parler ici.

18
0:00:48.26,000 --> 0:00:5,000
Alors si vous regardez la sécurité

19
0:00:50.26,000 --> 0:00:52,000
en termes économiques,

20
0:00:52.26,000 --> 0:00:54,000
c'est un échannge.

21
0:00:54.26,000 --> 0:00:56,000
Chaque fois que vous obtenez une certaine sécurité,

22
0:00:56.26,000 --> 0:00:58,000
vous donnez toujours quelque chose en échange.

23
0:00:58.26,000 --> 0:01:,000
Que ce soit une décision personnelle --

24
0:01:00.26,000 --> 0:01:02,000
que vous installiez une alarme chez vous --

25
0:01:02.26,000 --> 0:01:05,000
ou une décision nationale -- où vous allez envahir un pays étranger --

26
0:01:05.26,000 --> 0:01:07,000
vous allez donner quelque chose en échange,

27
0:01:07.26,000 --> 0:01:1,000
que ce soit de l'argent ou du temps, des commodités, des compétences,

28
0:01:10.26,000 --> 0:01:13,000
peut-être des libertés fondamentales.

29
0:01:13.26,000 --> 0:01:16,000
Et la question à poser quand on considère la sécurité de quelque chose

30
0:01:16.26,000 --> 0:01:19,000
n'est pas de savoir si ça nous protège mieux,

31
0:01:19.26,000 --> 0:01:22,000
mais si oui ou non l'échange vaut la peine.

32
0:01:22.26,000 --> 0:01:24,000
Ces dernières années, vous avez entendu dire

33
0:01:24.26,000 --> 0:01:26,000
que le monde est plus sûr parce que Saddam Hussein n'est pas au pouvoir.

34
0:01:26.26,000 --> 0:01:29,000
il se pourrait que ce soit vrai, mais ce n'est pas terriblement pertinent.

35
0:01:29.26,000 --> 0:01:32,000
La question est, est-ce que ça valait le coup?

36
0:01:32.26,000 --> 0:01:35,000
Et vous pouvez décider par vous-même,

37
0:01:35.26,000 --> 0:01:37,000
et ensuite vous déciderez si l'invasion en valait la peine.

38
0:01:37.26,000 --> 0:01:39,000
C'est de cette façon qu'on réfléchit à la sécurité --

39
0:01:39.26,000 --> 0:01:41,000
en termes d'échange.

40
0:01:41.26,000 --> 0:01:44,000
Maintenant c'est souvent qu'il n'i a ni raison ni tort ici.

41
0:01:44.26,000 --> 0:01:46,000
Certains d'entre nous ont des système d'alarme chez eux,

42
0:01:46.26,000 --> 0:01:48,000
et d'autres non.

43
0:01:48.26,000 --> 0:01:5,000
Et ça dépend de là où nous habitons,

44
0:01:50.26,000 --> 0:01:52,000
si nous habitons seul ou en famille,

45
0:01:52.26,000 --> 0:01:54,000
de la quantité de trucs chouettes que nous avons,

46
0:01:54.26,000 --> 0:01:56,000
du degré de risque de vol

47
0:01:56.26,000 --> 0:01:58,000
que nous acceptons.

48
0:01:58.26,000 --> 0:02:,000
En politique aussi,

49
0:02:00.26,000 --> 0:02:02,000
il y a des opinions différentes.

50
0:02:02.26,000 --> 0:02:04,000
Souvent, ces échanges

51
0:02:04.26,000 --> 0:02:06,000
concernent plus que la sécurité,

52
0:02:06.26,000 --> 0:02:08,000
et je pense que c'est vraiment important.

53
0:02:08.26,000 --> 0:02:1,000
Et les gens ont une intuition naturelle

54
0:02:10.26,000 --> 0:02:12,000
envers ces échanges.

55
0:02:12.26,000 --> 0:02:14,000
Nous en faisons tous les jours --

56
0:02:14.26,000 --> 0:02:16,000
la nuit dernière, dans ma chambre d'hôtel,

57
0:02:16.26,000 --> 0:02:18,000
quand j'ai décidé de fermer la porte à double tour,

58
0:02:18.26,000 --> 0:02:2,000
ou vous dans votre voiture en venant ici,

59
0:02:20.26,000 --> 0:02:22,000
quand nous allons déjeuner et que nous estimons

60
0:02:22.26,000 --> 0:02:25,000
que la nourriture n'est pas du poison et que nous la mangeons.

61
0:02:25.26,000 --> 0:02:27,000
Nous faisons sans cesse ces échanges

62
0:02:27.26,000 --> 0:02:29,000
plusieurs fois par jour.

63
0:02:29.26,000 --> 0:02:31,000
Souvent nous ne le remarquons même pas.

64
0:02:31.26,000 --> 0:02:33,000
lls font partie de la vie; nous le faisons tous

65
0:02:33.26,000 --> 0:02:36,000
Toutes les espèces le font.

66
0:02:36.26,000 --> 0:02:38,000
Imaginez un lapin dans un champ, qui mange de l'herbe,

67
0:02:38.26,000 --> 0:02:41,000
et le lapin va voir un renard.

68
0:02:41.26,000 --> 0:02:43,000
Ce lapin fera un échange de sécurité:

69
0:02:43.26,000 --> 0:02:45,000
"Je reste ou je m'enfuis?"

70
0:02:45.26,000 --> 0:02:47,000
Et si vous y réfléchissez,

71
0:02:47.26,000 --> 0:02:5,000
les lapins qui sont bons avec les échanges,

72
0:02:50.26,000 --> 0:02:52,000
auront tendance à vivre et à se reproduire,

73
0:02:52.26,000 --> 0:02:54,000
et les lapins qui sont mauvais

74
0:02:54.26,000 --> 0:02:56,000
seront mangés ou mourront de faim.

75
0:02:56.26,000 --> 0:02:58,000
Alors vous pourriez penser

76
0:02:58.26,000 --> 0:03:01,000
que nous, en tant qu'espèce prospère sur la planète --

77
0:03:01.26,000 --> 0:03:03,000
vous, moi, tout le monde --

78
0:03:03.26,000 --> 0:03:06,000
nous sommes vraiment bons en ce qui concerne ces genres d'échanges.

79
0:03:06.26,000 --> 0:03:08,000
Pourtant il semblerait, encore et encore,

80
0:03:08.26,000 --> 0:03:11,000
que nous soyons désespérément mauvais à cela.

81
0:03:11.26,000 --> 0:03:14,000
Et je pense que c'est une question fondamentalement intéressante.

82
0:03:14.26,000 --> 0:03:16,000
Je vous donnerai la réponse courte.

83
0:03:16.26,000 --> 0:03:18,000
La réponse est, nous réagissons à l'impression de sécurité

84
0:03:18.26,000 --> 0:03:21,000
et pas à la réalité.

85
0:03:21.26,000 --> 0:03:24,000
Et la plupart du temps, ça marche.

86
0:03:25.26,000 --> 0:03:27,000
La plupart du temps,

87
0:03:27.26,000 --> 0:03:3,000
l'impression et la réalité sont la même chose.

88
0:03:30.26,000 --> 0:03:32,000
C'est certainement vrai

89
0:03:32.26,000 --> 0:03:35,000
pendant la plus grande partie de la préhistoire.

90
0:03:35.26,000 --> 0:03:38,000
Nous avons développé cette capacité

91
0:03:38.26,000 --> 0:03:4,000
parce qu'elle a du sens du point de vue de l'évolution.

92
0:03:40.26,000 --> 0:03:42,000
Une manière de considérer ça

93
0:03:42.26,000 --> 0:03:44,000
est que nous sommes grandement optimisés

94
0:03:44.26,000 --> 0:03:46,000
pour les prises de risques

95
0:03:46.26,000 --> 0:03:49,000
qui sont endémiques à la vie en petits groupes familaux

96
0:03:49.26,000 --> 0:03:52,000
sur les plateaux de l'Afrique de l'Est en 100 000 avant J.-C. --

97
0:03:52.26,000 --> 0:03:55,000
en 2010 à New York, pas tellement.

98
0:03:56.26,000 --> 0:03:59,000
Maintenant, il y a plusieurs tendances dans la prise de risque.

99
0:03:59.26,000 --> 0:04:01,000
Beaucoup de bonnes expériences là dedans.

100
0:04:01.26,000 --> 0:04:04,000
Et vous pouvez voir que certaines tendances reviennent sans cesse.

101
0:04:04.26,000 --> 0:04:06,000
Alors je vais vous en donner quatre.

102
0:04:06.26,000 --> 0:04:09,000
Nous avons tendance à exagérer les risques rares et spectaculaires

103
0:04:09.26,000 --> 0:04:11,000
et à minimiser les risques courants --

104
0:04:11.26,000 --> 0:04:14,000
donc prendre l'avion par rapport à conduire.

105
0:04:14.26,000 --> 0:04:16,000
L'inconnu est perçu

106
0:04:16.26,000 --> 0:04:19,000
comme étant plus risqué que le familier.

107
0:04:20.26,000 --> 0:04:22,000
On pourrait citer comme exemple

108
0:04:22.26,000 --> 0:04:25,000
les gens qui ont peur d'être kidnappé par des inconnus,

109
0:04:25.26,000 --> 0:04:28,000
alors que les données montrent que les enlèvements par des parents sont bien plus courants.

110
0:04:28.26,000 --> 0:04:3,000
Il s'agit des enfants.

111
0:04:30.26,000 --> 0:04:33,000
Troisièmement, les risques personnifiés

112
0:04:33.26,000 --> 0:04:36,000
sont perçus comme étant plus grands que les risques anonymes --

113
0:04:36.26,000 --> 0:04:39,000
donc Ben Laden fait plus peur parce qu'il a un nom.

114
0:04:39.26,000 --> 0:04:41,000
Et le quatrième

115
0:04:41.26,000 --> 0:04:43,000
est que les gens sous-estiment les risques

116
0:04:43.26,000 --> 0:04:45,000
dans les situations qu'ils contrôlent

117
0:04:45.26,000 --> 0:04:49,000
et les surestiment dans les situations qu'ils ne contrôlent pas.

118
0:04:49.26,000 --> 0:04:52,000
Donc une fois que vous vous mettez à faire du parachute ou à fumer,

119
0:04:52.26,000 --> 0:04:54,000
vous minimisez les risques.

120
0:04:54.26,000 --> 0:04:57,000
Si un risque vous tombe dessus -- le terrorisme était un bon exemple --

121
0:04:57.26,000 --> 0:05:,000
vous le surévaluerez, parce que vous n'avez pas l'impression de le contrôler.

122
0:05:02.26,000 --> 0:05:05,000
il y a un tas d'autre tendances, ces tendances cognitives,

123
0:05:05.26,000 --> 0:05:08,000
qui affectent nos prises de risque.

124
0:05:08.26,000 --> 0:05:1,000
il y a l'heuristique de disponibilité,

125
0:05:10.26,000 --> 0:05:12,000
ce qui signifie en gros

126
0:05:12.26,000 --> 0:05:15,000
que nous estimons la probabilité de quelque chose

127
0:05:15.26,000 --> 0:05:19,000
en fonction de la facilité d'en concevoir des exemples.

128
0:05:19.26,000 --> 0:05:21,000
Vous pouvez donc imaginer comment ça fonctionne.

129
0:05:21.26,000 --> 0:05:24,000
Si vus entendez beaucoup parler d'attaques de tigres, il doit y avoir beaucoup de tigres dans le coin.

130
0:05:24.26,000 --> 0:05:27,000
Vous n'etendez pas beaucoup parler d'attaques de lions, il n'y a pas beaucoup de lions dans le coin.

131
0:05:27.26,000 --> 0:05:3,000
Ça fonctionne jusqu'à ce qu'on invente les journaux

132
0:05:30.26,000 --> 0:05:32,000
Parce que ce que font les journaux

133
0:05:32.26,000 --> 0:05:34,000
est qu'ils répètent encore et encore

134
0:05:34.26,000 --> 0:05:36,000
des risques rares.

135
0:05:36.26,000 --> 0:05:38,000
je dis aux gens, si c'est dans les infos, ne vous en inquiétez pas.

136
0:05:38.26,000 --> 0:05:4,000
Parce que par définition,

137
0:05:40.26,000 --> 0:05:43,000
les informations sont des choses qui n'arrivent presque jamais.

138
0:05:43.26,000 --> 0:05:45,000
(Rires)

139
0:05:45.26,000 --> 0:05:48,000
Quand quelque chose est si courant, ce n'est plus de l'information --

140
0:05:48.26,000 --> 0:05:5,000
les accidents de voiture, la violence domestique --

141
0:05:50.26,000 --> 0:05:53,000
voilà les risques dont on se préoccupe.

142
0:05:53.26,000 --> 0:05:55,000
Nous sommes aussi une espèce de conteurs.

143
0:05:55.26,000 --> 0:05:58,000
Nous réagissons aux histoires plus qu'aux données.

144
0:05:58.26,000 --> 0:06:,000
Et ce qu'il se passe, c'est une ignorance numérique élémentaire.

145
0:06:00.26,000 --> 0:06:03,000
Je veux dire, la plaisanterie "Un, Deux, Trois, Beaucoup" est assez vraie.

146
0:06:03.26,000 --> 0:06:06,000
Nous sommes vraiment bons avec les petits chiffres.

147
0:06:06.26,000 --> 0:06:08,000
Une mangue, deux mangues, trois mangues,

148
0:06:08.26,000 --> 0:06:1,000
10 000 mangues, 100 000 mangues --

149
0:06:10.26,000 --> 0:06:13,000
c'est toujours plus de mangues que vous ne pouvez manger avant qu'elles pourrissent.

150
0:06:13.26,000 --> 0:06:16,000
Donc un demi, un quart, un cinquième -- là nous sommes bons.

151
0:06:16.26,000 --> 0:06:18,000
Un sur un million, un sur un milliard --

152
0:06:18.26,000 --> 0:06:21,000
dans les deux cas, c'est presque jamais.

153
0:06:21.26,000 --> 0:06:23,000
Donc nous avons du mal avec les risques

154
0:06:23.26,000 --> 0:06:25,000
qui ne sont pas très courants.

155
0:06:25.26,000 --> 0:06:27,000
Et ce que ces tendances cognitives font,

156
0:06:27.26,000 --> 0:06:3,000
est qu'elles agissent comme des filtres entre la réalité et nous.

157
0:06:30.26,000 --> 0:06:32,000
Et le résultat

158
0:06:32.26,000 --> 0:06:34,000
est que l'impression et la réalité ne collent pas,

159
0:06:34.26,000 --> 0:06:37,000
ils diffèrent.

160
0:06:37.26,000 --> 0:06:4,000
Et vous avez soit une impression -- vous vous sentez plus en sécurité que vous ne l'êtes.

161
0:06:40.26,000 --> 0:06:42,000
C'est une fausse impression de sécurité.

162
0:06:42.26,000 --> 0:06:44,000
Ou le contraire,

163
0:06:44.26,000 --> 0:06:46,000
et c'est une fausse impression d'insécurité.

164
0:06:46.26,000 --> 0:06:49,000
J'écris beaucoup sur "le théâtre de la sécurité",

165
0:06:49.26,000 --> 0:06:52,000
et ce sont les produits qui rassurent les gens,

166
0:06:52.26,000 --> 0:06:54,000
mais qui en fait ne font rien.

167
0:06:54.26,000 --> 0:06:56,000
Il n'y a pas de monde réel pour les choses qui nous mettent en sécurité,

168
0:06:56.26,000 --> 0:06:58,000
mais ne nous en donnent pas l'impression.

169
0:06:58.26,000 --> 0:07:01,000
C'est peut-être ce que la CIA est sensée faire pour nous.

170
0:07:03.26,000 --> 0:07:05,000
Revenons donc à l'économie.

171
0:07:05.26,000 --> 0:07:09,000
Si l'économie, si le marché conduit la sécurité,

172
0:07:09.26,000 --> 0:07:11,000
et si les gens font des échanges

173
0:07:11.26,000 --> 0:07:14,000
d'après l'impression de sécurité,

174
0:07:14.26,000 --> 0:07:16,000
alors la chose intelligente à faire pour les entreprises

175
0:07:16.26,000 --> 0:07:18,000
pour que les motivations économiques

176
0:07:18.26,000 --> 0:07:21,000
permettent aux gens de se sentir plus en sécurité.

177
0:07:21.26,000 --> 0:07:24,000
Et il y a deux manières de le faire.

178
0:07:24.26,000 --> 0:07:26,000
Une, vous pouvez mettre vraiment les gens plus en sécurité

179
0:07:26.26,000 --> 0:07:28,000
et espérer qu'ils le remarquent.

180
0:07:28.26,000 --> 0:07:31,000
Ou deux, vous pouvez donner aux gens seulement une impression de sécurité

181
0:07:31.26,000 --> 0:07:34,000
et espérer qu'ils ne s'en aperçoivent pas.

182
0:07:35.26,000 --> 0:07:38,000
Alors qu'est-ce qui fait que les gens le remarquent?

183
0:07:38.26,000 --> 0:07:4,000
Et bien deux ou trois choses :

184
0:07:40.26,000 --> 0:07:42,000
comprendre la sécurité,

185
0:07:42.26,000 --> 0:07:44,000
les risques, les menaces

186
0:07:44.26,000 --> 0:07:47,000
des contre-mesures, comment elles fonctionnent.

187
0:07:47.26,000 --> 0:07:49,000
Mais si vous savez des trucs,

188
0:07:49.26,000 --> 0:07:52,000
vos impressions sont plus susceptibles de coller à la réalité.

189
0:07:52.26,000 --> 0:07:55,000
Avoir assez d'exemples dans le monde réel vous aide.

190
0:07:55.26,000 --> 0:07:58,000
Et nous connaissons tous le taux de criminalité dans notre quartier,

191
0:07:58.26,000 --> 0:08:01,000
parce que nous y vivons, et que nous en avons une impression

192
0:08:01.26,000 --> 0:08:04,000
qui en gros colle à la réalité.

193
0:08:04.26,000 --> 0:08:07,000
Le théâtre de sécurité est exposé

194
0:08:07.26,000 --> 0:08:1,000
quand il est évident qu'il ne fonctionne pas correctement.

195
0:08:10.26,000 --> 0:08:14,000
Bon, alors qu'est-ce qui fait que les gens ne remarquent pas?

196
0:08:14.26,000 --> 0:08:16,000
Et bien une mauvaise compréhension.

197
0:08:16.26,000 --> 0:08:19,000
Si vous ne comprenez pas les risques, vous ne comprenez pas les coûts,

198
0:08:19.26,000 --> 0:08:21,000
vous êtes susceptibles de ne pas faire les bons échanges,

199
0:08:21.26,000 --> 0:08:24,000
et votre impression ne colle pas à la réalité.

200
0:08:24.26,000 --> 0:08:26,000
Pas assez d'exemples

201
0:08:26.26,000 --> 0:08:28,000
C'est un problème inhérent

202
0:08:28.26,000 --> 0:08:3,000
aux évènements de faible probabilité.

203
0:08:30.26,000 --> 0:08:32,000
Si, par exemple,

204
0:08:32.26,000 --> 0:08:34,000
le terrorisme ne se produit presque jamais,

205
0:08:34.26,000 --> 0:08:36,000
il est vraiment difficile de juger

206
0:08:36.26,000 --> 0:08:39,000
l'efficacité de nos mesures anti-terrorisme.

207
0:08:40.26,000 --> 0:08:43,000
C'est pourquoi on continue à sacrifier des vierges,

208
0:08:43.26,000 --> 0:08:46,000
et pourquoi vos défenses de licorne fonctionnent parfaitement.

209
0:08:46.26,000 --> 0:08:49,000
Il n'y a pas assez d'exemples d'échecs.

210
0:08:50.26,000 --> 0:08:53,000
Aussi, les impressions qui rendent les problèmes confus --

211
0:08:53.26,000 --> 0:08:55,000
les tendances cognitives dont j'ai parlé plus tôt,

212
0:08:55.26,000 --> 0:08:58,000
les peurs, les croyances populaires,

213
0:08:58.26,000 --> 0:09:01,000
en gros un modèle inadéquat de réalité.

214
0:09:02.26,000 --> 0:09:05,000
Alors permettez-moi de compliquer les choses.

215
0:09:05.26,000 --> 0:09:07,000
J'ai l'impression et la réalité.

216
0:09:07.26,000 --> 0:09:1,000
Je veux ajouter un troisième élément. Je veux ajouter un modèle.

217
0:09:10.26,000 --> 0:09:12,000
L'impression et le modèle dans nos têtes,

218
0:09:12.26,000 --> 0:09:14,000
la réalité c'est le monde extérieur.

219
0:09:14.26,000 --> 0:09:17,000
Il ne change pas: il est réel.

220
0:09:17.26,000 --> 0:09:19,000
Donc l'impression se fonde sur notre intuition.

221
0:09:19.26,000 --> 0:09:21,000
Le modèle se fonde sur la raison.

222
0:09:21.26,000 --> 0:09:24,000
C'est en gros la différence.

223
0:09:24.26,000 --> 0:09:26,000
Dans un monde primitif et simple,

224
0:09:26.26,000 --> 0:09:29,000
il n'y a pas de raison pour un modèle.

225
0:09:29.26,000 --> 0:09:32,000
Parce que l'impression est proche de la réalité.

226
0:09:32.26,000 --> 0:09:34,000
On n'a pas besoin d'un modèle.

227
0:09:34.26,000 --> 0:09:36,000
Mais dans un monde moderne et complexe,

228
0:09:36.26,000 --> 0:09:38,000
on a besoin de modèles

229
0:09:38.26,000 --> 0:09:41,000
pour comprendre bon nombre des risques auxquels nous sommes confrontés.

230
0:09:42.26,000 --> 0:09:44,000
Il n'y a pas d'impression vis à vis des microbes.

231
0:09:44.26,000 --> 0:09:47,000
Il vous faut un modèle pour les comprendre.

232
0:09:47.26,000 --> 0:09:49,000
Donc ce modèle

233
0:09:49.26,000 --> 0:09:52,000
est une représentation intelligente de la réalité.

234
0:09:52.26,000 --> 0:09:55,000
Il est bien sûr limité par la science,

235
0:09:55.26,000 --> 0:09:57,000
par la technologie.

236
0:09:57.26,000 --> 0:10:,000
Nous ne pouvions pas écrire une théorie microbienne de la maladie

237
0:10:00.26,000 --> 0:10:03,000
avant d'avoir inventé le microscope pour les voir.

238
0:10:04.26,000 --> 0:10:07,000
Il est limité par nos tendances cognitives.

239
0:10:07.26,000 --> 0:10:09,000
Mais il a la capacité

240
0:10:09.26,000 --> 0:10:11,000
de l'emporter sur nos impressions.

241
0:10:11.26,000 --> 0:10:14,000
Où trouvons-nous ces modèles? Nous les trouvons chez les autres.

242
0:10:14.26,000 --> 0:10:17,000
Nous les trouvons dans la religion, la culture,

243
0:10:17.26,000 --> 0:10:19,000
chez les enseignants, chez nos aînés.

244
0:10:19.26,000 --> 0:10:21,000
Il y a deux ans,

245
0:10:21.26,000 --> 0:10:23,000
j'étais en Afrique du Sud en safari.

246
0:10:23.26,000 --> 0:10:26,000
Le pisteur avec qui j'étais a grandi dans le parc national Kruger.

247
0:10:26.26,000 --> 0:10:29,000
Il avait des modèles très complexes de façon de survivre.

248
0:10:29.26,000 --> 0:10:31,000
Et ça dépendait de si vous étiez attaqué

249
0:10:31.26,000 --> 0:10:33,000
par un lion, ou un léopard, ou un rhinocéros, ou un éléphant --

250
0:10:33.26,000 --> 0:10:36,000
et quand vous deviez fuir, et quand vous deviez grimper à un arbre --

251
0:10:36.26,000 --> 0:10:38,000
quand vous pouviez ne jamais grimper à un arbre.

252
0:10:38.26,000 --> 0:10:41,000
Je serais mort dans la journée,

253
0:10:41.26,000 --> 0:10:43,000
mais il était né là,

254
0:10:43.26,000 --> 0:10:45,000
et il comprenait comment survivre.

255
0:10:45.26,000 --> 0:10:47,000
Je suis né à New York City.

256
0:10:47.26,000 --> 0:10:5,000
J'aurais pu l'emmener à New York, et il serait mort dans la journée.

257
0:10:50.26,000 --> 0:10:52,000
(Rires)

258
0:10:52.26,000 --> 0:10:54,000
Parce que nous avions différents modèles

259
0:10:54.26,000 --> 0:10:57,000
fondés sur nos différentes expériences.

260
0:10:58.26,000 --> 0:11:,000
Les modèles peuvent venir des medias,

261
0:11:00.26,000 --> 0:11:03,000
de nos élus.

262
0:11:03.26,000 --> 0:11:06,000
Pensez aux modèles de terrorisme,

263
0:11:06.26,000 --> 0:11:09,000
d'enlèvement d'enfant,

264
0:11:09.26,000 --> 0:11:11,000
de sécurité aérienne, de sécurité automobile.

265
0:11:11.26,000 --> 0:11:14,000
Les modèles peuvent venir de l'industrie.

266
0:11:14.26,000 --> 0:11:16,000
Les deux que je suis sont les caméras de surveillance,

267
0:11:16.26,000 --> 0:11:18,000
les cartes d'identités,

268
0:11:18.26,000 --> 0:11:21,000
un bon nombre de nos modèles de sécurité informatique viennent de là.

269
0:11:21.26,000 --> 0:11:24,000
Beaucoup de modèles viennent de la science.

270
0:11:24.26,000 --> 0:11:26,000
Les modèles de santé sont un excellent exemple.

271
0:11:26.26,000 --> 0:11:29,000
Pensez au cancer, à la grippe aviaire, la grippe porcine, le SRAS.

272
0:11:29.26,000 --> 0:11:32,000
Toutes nos impressions de sécurité

273
0:11:32.26,000 --> 0:11:34,000
vis à vis de ces maladies

274
0:11:34.26,000 --> 0:11:36,000
viennent de modèles

275
0:11:36.26,000 --> 0:11:39,000
qu'on nous donne, vraiment, par la science filtrée par les médias.

276
0:11:40.26,000 --> 0:11:43,000
Donc les modèles changent.

277
0:11:43.26,000 --> 0:11:45,000
Les modèles ne sont pas statiques.

278
0:11:45.26,000 --> 0:11:48,000
Alors que nous sommes plus à l'aise avec nos environnements,

279
0:11:48.26,000 --> 0:11:52,000
notre modèle peut se rapprocher de nos impressions.

280
0:11:53.26,000 --> 0:11:55,000
Et on pourrait prendre pour exemple

281
0:11:55.26,000 --> 0:11:57,000
si on remonte à 100 en arrière

282
0:11:57.26,000 --> 0:12:,000
quand l'électricité est devenue courante pour la première fois,

283
0:12:00.26,000 --> 0:12:02,000
elle a généré beaucoup de peurs.

284
0:12:02.26,000 --> 0:12:04,000
Je veux dire qu'il y avait des gens qui avaient peur de sonner aux portes ;

285
0:12:04.26,000 --> 0:12:07,000
parce qu'il y avait de l'électricité dans les sonnettes, et que c'était dangereux.

286
0:12:07.26,000 --> 0:12:1,000
Pour nous, nous sommes à l'aise avec l'électricité.

287
0:12:10.26,000 --> 0:12:12,000
Nous changeons les ampoules

288
0:12:12.26,000 --> 0:12:14,000
sans même y réfléchir.

289
0:12:14.26,000 --> 0:12:18,000
Notre modèle de sécurité vis à vis de l'électricité

290
0:12:18.26,000 --> 0:12:21,000
est une chose dans laquelle nous sommes nés.

291
0:12:21.26,000 --> 0:12:24,000
Il n'a pas changé alors que nous grandissions.

292
0:12:24.26,000 --> 0:12:27,000
Et nous sommes bons là-dedans.

293
0:12:27.26,000 --> 0:12:29,000
Ou sinon, pensez aux risques

294
0:12:29.26,000 --> 0:12:31,000
sur internet entre générations --

295
0:12:31.26,000 --> 0:12:33,000
comment vos parents abordent la sécurité d'internet,

296
0:12:33.26,000 --> 0:12:35,000
par rapport à ce que vous faites,

297
0:12:35.26,000 --> 0:12:38,000
par rapport à comment vos enfants le feront.

298
0:12:38.26,000 --> 0:12:41,000
Les modèles finissent par se fondre dans le décor.

299
0:12:42.26,000 --> 0:12:45,000
Intuitif est synonyme de familier.

300
0:12:45.26,000 --> 0:12:47,000
Donc quand notre modèle est proche de la réalité,

301
0:12:47.26,000 --> 0:12:49,000
et qu'il converge avec les impressions,

302
0:12:49.26,000 --> 0:12:52,000
vous ignorez souvent qu'il est là.

303
0:12:52.26,000 --> 0:12:54,000
Et un bon exemple nous est venu

304
0:12:54.26,000 --> 0:12:57,000
l'an dernier avec la grippe porcine.

305
0:12:57.26,000 --> 0:12:59,000
Quand la grippe porcine est apparue pour la première fois,

306
0:12:59.26,000 --> 0:13:03,000
l'information initiale a provoqué beaucoup de réactions excessives.

307
0:13:03.26,000 --> 0:13:05,000
D'abord la maladie avait un nom,

308
0:13:05.26,000 --> 0:13:07,000
ce qui la rendait plus effrayante que la grippe traditionnelle,

309
0:13:07.26,000 --> 0:13:09,000
même si elle était plus mortelle.

310
0:13:09.26,000 --> 0:13:13,000
Et les gens pensaient que les médecins devraient pouvoir s'en occuper.

311
0:13:13.26,000 --> 0:13:15,000
Il y a donc eu un sentiment de manque de contrôle.

312
0:13:15.26,000 --> 0:13:17,000
Et ces deux choses

313
0:13:17.26,000 --> 0:13:19,000
ont fait que le risque semblait plus important qu'il n'était.

314
0:13:19.26,000 --> 0:13:22,000
Quand l'effet de nouveauté s'est estompé et que les mois ont passé,

315
0:13:22.26,000 --> 0:13:24,000
il y a eu une une certaine tolérance,

316
0:13:24.26,000 --> 0:13:26,000
les gens s'y sont habitués.

317
0:13:26.26,000 --> 0:13:29,000
Il n'y a pas eu de nouvelles données, mais il y a eu moins de peur.

318
0:13:29.26,000 --> 0:13:31,000
En automne,

319
0:13:31.26,000 --> 0:13:33,000
les gens pensaient

320
0:13:33.26,000 --> 0:13:35,000
que les médecins auraient déjà dû résoudre le problème.

321
0:13:35.26,000 --> 0:13:37,000
Et il y a eu un genre de tournant --

322
0:13:37.26,000 --> 0:13:39,000
les gens devaient choisir

323
0:13:39.26,000 --> 0:13:43,000
entre la peur et l'acceptation --

324
0:13:43.26,000 --> 0:13:45,000
en fait entre la peur et l'indifférence --

325
0:13:45.26,000 --> 0:13:48,000
ils ont choisi la méfiance.

326
0:13:48.26,000 --> 0:13:51,000
Et quand le vaccin est apparu l'hiver dernier,

327
0:13:51.26,000 --> 0:13:54,000
il y a eu beaucoup de gens -- un nombre surprenant --

328
0:13:54.26,000 --> 0:13:57,000
qui ont refusé de se faire vacciner --

329
0:13:58.26,000 --> 0:14:,000
et c'est un bon exemple

330
0:14:00.26,000 --> 0:14:03,000
de la façon dont les impressions de sécurité des gens changent,

331
0:14:03.26,000 --> 0:14:05,000
comment leurs modèles changent, de façon irraisonnée

332
0:14:05.26,000 --> 0:14:07,000
sans nouvelles informations,

333
0:14:07.26,000 --> 0:14:09,000
sans nouvel apport.

334
0:14:09.26,000 --> 0:14:12,000
Ce genre de chose se produit souvent.

335
0:14:12.26,000 --> 0:14:15,000
Et je vais apporter une complication supplémentaire.

336
0:14:15.26,000 --> 0:14:18,000
Nous avons l'impression, le modèle, la réalité.

337
0:14:18.26,000 --> 0:14:2,000
J'ai une vision très réaliste de la sécurité.

338
0:14:20.26,000 --> 0:14:23,000
Je pense qu'elle dépend de l'observateur.

339
0:14:23.26,000 --> 0:14:25,000
Et la plupart des décisions de sécurité

340
0:14:25.26,000 --> 0:14:29,000
ont des gens impliqués très différents .

341
0:14:29.26,000 --> 0:14:31,000
Et les actionnaires

342
0:14:31.26,000 --> 0:14:34,000
qui ont des échanges spécifiques

343
0:14:34.26,000 --> 0:14:36,000
essaieront d'influencer la décision.

344
0:14:36.26,000 --> 0:14:38,000
Et j'appelle ça leur programme.

345
0:14:38.26,000 --> 0:14:4,000
Et vous voyez un programme --

346
0:14:40.26,000 --> 0:14:43,000
c'est du marketing, c'est de la politique --

347
0:14:43.26,000 --> 0:14:46,000
essayez de vous convaincre que vous avez un modèle par rapport à un autre,

348
0:14:46.26,000 --> 0:14:48,000
essayez de vous convaincre d'ignorer un modèle

349
0:14:48.26,000 --> 0:14:51,000
et de vous fier à vos impressions,

350
0:14:51.26,000 --> 0:14:54,000
marginaliser les gens qui ont des modèles que vous n'aimez pas.

351
0:14:54.26,000 --> 0:14:57,000
Ce n'est pas rare,

352
0:14:57.26,000 --> 0:15:,000
Un exemple, un très bon exemple, c'est le risque du tabac.

353
0:15:01.26,000 --> 0:15:04,000
Dans l'histoire de ces 50 dernières années, le risque du tabac

354
0:15:04.26,000 --> 0:15:06,000
montre comment un modèle change,

355
0:15:06.26,000 --> 0:15:09,000
et il montre aussi comment une industrie combat

356
0:15:09.26,000 --> 0:15:11,000
un modèle qu'elle n'aime aps.

357
0:15:11.26,000 --> 0:15:14,000
Comparez ça au débat sur le tabagisme passif --

358
0:15:14.26,000 --> 0:15:17,000
probablement avec 20 ans de retard.

359
0:15:17.26,000 --> 0:15:19,000
Pensez aux ceintures de sécurité.

360
0:15:19.26,000 --> 0:15:21,000
Quand j'étais enfant, personne ne mettait de ceinture de sécurité.

361
0:15:21.26,000 --> 0:15:23,000
Aujourd'hui, pas un enfant ne vous laissera conduire

362
0:15:23.26,000 --> 0:15:25,000
si vous n'attachez pas votre ceinture de sécurité.

363
0:15:26.26,000 --> 0:15:28,000
Comparez ça au débat sur l'airbag --

364
0:15:28.26,000 --> 0:15:31,000
probablement avec 30 ans de retard.

365
0:15:31.26,000 --> 0:15:34,000
Ce sont tous des exemples de modèles qui changent.

366
0:15:36.26,000 --> 0:15:39,000
Ce que nous apprenons c'est qu'il est difficile de changer les modèles.

367
0:15:39.26,000 --> 0:15:41,000
Les modèles sont difficiles à déloger.

368
0:15:41.26,000 --> 0:15:43,000
S'ils correspondent à vos impressions,

369
0:15:43.26,000 --> 0:15:46,000
vous ne savez même pas que vous avez un modèle.

370
0:15:46.26,000 --> 0:15:48,000
Et il y a une autre tendance cognitive

371
0:15:48.26,000 --> 0:15:5,000
que j'appellerais une tendance de confirmation,

372
0:15:50.26,000 --> 0:15:53,000
quand nous tendons à accepter des données

373
0:15:53.26,000 --> 0:15:55,000
qui confirment ce que nous croyons

374
0:15:55.26,000 --> 0:15:58,000
et à rejeter des données qui contredisent ce que nous croyons.

375
0:15:59.26,000 --> 0:16:01,000
Donc nous sommes susceptibles

376
0:16:01.26,000 --> 0:16:04,000
d'ignorer les preuves qui contredisent notre modèle, même si elles sont flagrantes.

377
0:16:04.26,000 --> 0:16:07,000
Elle doivent être vraiment flagrantes avant que nous y prêtions attention.

378
0:16:08.26,000 --> 0:16:1,000
Les nouveaux modèles qui durent sur de longues périodes sont difficiles.

379
0:16:10.26,000 --> 0:16:12,000
Le réchauffement planétaire est un excellent exemple.

380
0:16:12.26,000 --> 0:16:14,000
Nous sommes très mauvais

381
0:16:14.26,000 --> 0:16:16,000
avec les modèles qui couvrent 80 ans.

382
0:16:16.26,000 --> 0:16:18,000
Nous pouvons aller jusqu'à la prochaine récolte.

383
0:16:18.26,000 --> 0:16:21,000
Nous pouvons souvent aller jusqu'à ce que nos enfants grandissent.

384
0:16:21.26,000 --> 0:16:24,000
Mais 80 ans, nous ne sommes pas bons avec ça.

385
0:16:24.26,000 --> 0:16:27,000
C'est donc un modèle très difficile à accepter.

386
0:16:27.26,000 --> 0:16:31,000
Nous pouvons avoir les deux modèles simultanément en tête,

387
0:16:31.26,000 --> 0:16:34,000
ou ce genre de problème

388
0:16:34.26,000 --> 0:16:37,000
où nous prenons ensemble ces deux choses en quoi nous croyons,

389
0:16:37.26,000 --> 0:16:39,000
ou la dissonance cognitive.

390
0:16:39.26,000 --> 0:16:41,000
Au final,

391
0:16:41.26,000 --> 0:16:44,000
le nouveau modèle remplacera l'ancien.

392
0:16:44.26,000 --> 0:16:47,000
Des impressions fortes peuvent créer un modèle.

393
0:16:47.26,000 --> 0:16:5,000
Le 11 septembre a créé un modèle de sécurité

394
0:16:50.26,000 --> 0:16:52,000
dans la tête de beaucoup de gens.

395
0:16:52.26,000 --> 0:16:55,000
Aussi, les expériences personnelles avec le crime peuvent le faire,

396
0:16:55.26,000 --> 0:16:57,000
les peurs pour la santé personnelle,

397
0:16:57.26,000 --> 0:16:59,000
une alerte de santé dans les informations.

398
0:16:59.26,000 --> 0:17:01,000
Vous verrez que les psychiatres

399
0:17:01.26,000 --> 0:17:03,000
les appellent des évènements flash.

400
0:17:03.26,000 --> 0:17:06,000
ils peuvent créer un modèle instantannément,

401
0:17:06.26,000 --> 0:17:09,000
parce qu'ils génèrent beaucoup d'émotion.

402
0:17:09.26,000 --> 0:17:11,000
Donc dans le monde technologique,

403
0:17:11.26,000 --> 0:17:13,000
nous n'avons pas l'expérience

404
0:17:13.26,000 --> 0:17:15,000
pour juger les modèles.

405
0:17:15.26,000 --> 0:17:17,000
Et nous comptons sur les autres. Nous comptons sur des intermédiaires.

406
0:17:17.26,000 --> 0:17:21,000
Je veux dire, ça marche tant qu'il s'agit de corriger les autres.

407
0:17:21.26,000 --> 0:17:23,000
Nous comptons sur les agences gouvernementales

408
0:17:23.26,000 --> 0:17:28,000
pour nous dire quels produits pharmaceutiques sont sûrs.

409
0:17:28.26,000 --> 0:17:3,000
Je suis venu en avion ici hier,

410
0:17:30.26,000 --> 0:17:32,000
je n'ai pas vérifié l'avion.

411
0:17:32.26,000 --> 0:17:34,000
j'ai compté sur un autre groupe

412
0:17:34.26,000 --> 0:17:37,000
pour déterminer si mon avion était sûr pour voler.

413
0:17:37.26,000 --> 0:17:4,000
Nous sommes ici, aucun de nous n'a peur que le toit s'effondre sur nous,

414
0:17:40.26,000 --> 0:17:43,000
pas parce que nous avons vérifié,

415
0:17:43.26,000 --> 0:17:45,000
mais parce que nous sommes sûrs

416
0:17:45.26,000 --> 0:17:48,000
que les codes de constructions sont bons ici.

417
0:17:48.26,000 --> 0:17:5,000
C'est un modèle que nous nous contentons d'accepter

418
0:17:50.26,000 --> 0:17:52,000
plutôt par foi.

419
0:17:52.26,000 --> 0:17:55,000
Et c'est bien.

420
0:17:57.26,000 --> 0:17:59,000
Maintenant, ce que nous voulons

421
0:17:59.26,000 --> 0:18:01,000
c'est que les gens se familiarisent suffisemment

422
0:18:01.26,000 --> 0:18:03,000
avec de meilleurs modèles --

423
0:18:03.26,000 --> 0:18:05,000
qui reflètent leurs impressions --

424
0:18:05.26,000 --> 0:18:09,000
pour leur permettre de faire des échanges de sécurité.

425
0:18:09.26,000 --> 0:18:11,000
Et quand ils ne collent pas,

426
0:18:11.26,000 --> 0:18:13,000
vous avez deux options.

427
0:18:13.26,000 --> 0:18:15,000
La première, vous pouvez changer les impressions des gens,

428
0:18:15.26,000 --> 0:18:17,000
un appel direct aux impressions.

429
0:18:17.26,000 --> 0:18:2,000
C'est de la manipulation, mais ça peut marcher.

430
0:18:20.26,000 --> 0:18:22,000
La deuxième, plus honnête,

431
0:18:22.26,000 --> 0:18:25,000
est en fait de modifier le modèle.

432
0:18:26.26,000 --> 0:18:28,000
Le changement se produit lentement.

433
0:18:28.26,000 --> 0:18:31,000
Le débat sur le tabac a pris 40 ans,

434
0:18:31.26,000 --> 0:18:34,000
et c'était facile.

435
0:18:34.26,000 --> 0:18:36,000
Certains de ces trucs sont difficiles.

436
0:18:36.26,000 --> 0:18:38,000
Je veux dire

437
0:18:38.26,000 --> 0:18:4,000
que les informations semblent être notre meilleur espoir.

438
0:18:40.26,000 --> 0:18:42,000
Et j'ai menti.

439
0:18:42.26,000 --> 0:18:44,000
Rappelez-vous quand j'ai dit impression, modèle, réalité.

440
0:18:44.26,000 --> 0:18:47,000
J'ai dit que la réalité ne change pas. En fait, si.

441
0:18:47.26,000 --> 0:18:49,000
Nous vivons dans u monde technologique ;

442
0:18:49.26,000 --> 0:18:52,000
la réalité change tout le temps.

443
0:18:52.26,000 --> 0:18:55,000
Il se pourrait donc que nous ayons -- pour la première fois dans l'histoire de notre espèce --

444
0:18:55.26,000 --> 0:18:58,000
l'impression qui court derrière le modèle, le modèle derrière la réalité, la réalité bouge --

445
0:18:58.26,000 --> 0:19:01,000
ils pourraient ne jamais se rattrapper.

446
0:19:02.26,000 --> 0:19:04,000
Nous ne le savons pas.

447
0:19:04.26,000 --> 0:19:06,000
Mais sur le long terme,

448
0:19:06.26,000 --> 0:19:09,000
l'impression et la réalité sont toutes deux importantes.

449
0:19:09.26,000 --> 0:19:12,000
Et je veut conclure avec deux histoires courtes pour illustrer cela.

450
0:19:12.26,000 --> 0:19:14,000
1982 -- je ne sais pas si les gens se souviendront de ça --

451
0:19:14.26,000 --> 0:19:17,000
il y a eu un épidémie de courte durée

452
0:19:17.26,000 --> 0:19:19,000
d'empoisonnements au Tylenol aux Etats-Unis.

453
0:19:19.26,000 --> 0:19:22,000
C'est une histoire horrible. Quelqu'un a pris une bouteille de Tylenol,

454
0:19:22.26,000 --> 0:19:25,000
a mis du poison dedans, l'a refermée, l'a remise dans le rayon.

455
0:19:25.26,000 --> 0:19:27,000
Quelqu'un d'autre l'a acheté et est mort.

456
0:19:27.26,000 --> 0:19:29,000
Ça a terrifié les gens.

457
0:19:29.26,000 --> 0:19:31,000
Il y a eu deux ou trois attaques par des imitateurs.

458
0:19:31.26,000 --> 0:19:34,000
Il n'y avait pas vraiment de risque réel, mais les gens étaient terrifiés.

459
0:19:34.26,000 --> 0:19:36,000
Et c'est comme ça

460
0:19:36.26,000 --> 0:19:38,000
que l'industrie du médicament scellé a été inventée.

461
0:19:38.26,000 --> 0:19:4,000
Ces bouchons scellés, c'est de là qu'ils viennent.

462
0:19:40.26,000 --> 0:19:42,000
C'est du théâtre de sécurité complet.

463
0:19:42.26,000 --> 0:19:44,000
Et en guise de devoir à la maison, réfléchissez à 10 manières de le contourner.

464
0:19:44.26,000 --> 0:19:47,000
Je vous en donne un, une seringue.

465
0:19:47.26,000 --> 0:19:5,000
Mais ça a rassuré les gens.

466
0:19:50.26,000 --> 0:19:52,000
Ça a rapproché leur impression de sécurité

467
0:19:52.26,000 --> 0:19:54,000
de la réalité.

468
0:19:54.26,000 --> 0:19:57,000
La dernière histoire, il y a quelques années, une de mes amies a eu un bébé.

469
0:19:57.26,000 --> 0:19:59,000
Je suis allé la voir à l'hôpital.

470
0:19:59.26,000 --> 0:20:01,000
Il s'avère que maintenant, quand un bébé naît,

471
0:20:01.26,000 --> 0:20:03,000
ils lui mettent un bracelet avec une puce RFID,

472
0:20:03.26,000 --> 0:20:05,000
en mettent un qui correspond à la mère,

473
0:20:05.26,000 --> 0:20:07,000
pour que si quelqu'un d'autre que la mère emmène le bébé hors de la maternité,

474
0:20:07.26,000 --> 0:20:09,000
un alarme se déclenche.

475
0:20:09.26,000 --> 0:20:11,000
J'ai dit, "C'est chouette.

476
0:20:11.26,000 --> 0:20:13,000
Je me demande à quel point l'enlèvement de bébés est en augmentation

477
0:20:13.26,000 --> 0:20:15,000
en dehors des hôpitaux."

478
0:20:15.26,000 --> 0:20:17,000
Je rentre chez moi, je vérifie.

479
0:20:17.26,000 --> 0:20:19,000
Ça n'arrive quasiment jamais.

480
0:20:19.26,000 --> 0:20:21,000
Mais si vous y réfléchissez,

481
0:20:21.26,000 --> 0:20:23,000
si vous êtes un hôpital,

482
0:20:23.26,000 --> 0:20:25,000
et que nous devez enlever un bébé à sa mère,

483
0:20:25.26,000 --> 0:20:27,000
le sortir de la pièce pour faire des examens,

484
0:20:27.26,000 --> 0:20:29,000
il vaut mieux que vous ayez un bon théâtre de sécurité,

485
0:20:29.26,000 --> 0:20:31,000
ou elle va vous arracher le bras.

486
0:20:31.26,000 --> 0:20:33,000
(Rires)

487
0:20:33.26,000 --> 0:20:35,000
C'est donc important pour nous,

488
0:20:35.26,000 --> 0:20:37,000
qui concevons des systèmes de sécurité,

489
0:20:37.26,000 --> 0:20:4,000
qui examinons la politique de sécurité,

490
0:20:40.26,000 --> 0:20:42,000
ou même la politique publique

491
0:20:42.26,000 --> 0:20:44,000
de manières qui affectent la sécurité.

492
0:20:44.26,000 --> 0:20:47,000
Il ne s'agit pas que de sécurité, il s'agit d'impression et de réalité.

493
0:20:47.26,000 --> 0:20:49,000
Ce qui est important

494
0:20:49.26,000 --> 0:20:51,000
est qu'elles soient en gros équivalentes,

495
0:20:51.26,000 --> 0:20:53,000
il est important que, si nos impressions collent à la réalité,

496
0:20:53.26,000 --> 0:20:55,000
nous faisons de meilleurs échanges de sécurité.

497
0:20:55.26,000 --> 0:20:57,000
Merci.

498
0:20:57.26,000 --> 0:20:59,000
(Applaudissements)

