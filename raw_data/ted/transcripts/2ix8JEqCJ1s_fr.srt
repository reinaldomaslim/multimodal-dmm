1
0:00:,000 --> 0:00:07,000
Traducteur: Claire Ghyselen Relecteur: Morgane Quilfen

2
0:00:12.612,000 --> 0:00:13,000
J’ai passé ces trois dernières années

3
0:00:14.373,000 --> 0:00:17,000
à discuter avec les pires personnes qu’on puisse rencontrer sur Internet.

4
0:00:18.441,000 --> 0:00:2,000
Si vous avez navigué en ligne récemment,

5
0:00:20.661,000 --> 0:00:23,000
vous aurez remarqué qu’on y trouve un ramassis de choses toxiques :

6
0:00:24.489,000 --> 0:00:28,000
des mèmes racistes, de la propagande misogyne et de la désinformation virale.

7
0:00:29.466,000 --> 0:00:31,000
Alors j’ai voulu savoir qui fabriquait tout ça

8
0:00:31.665,000 --> 0:00:33,000
et comment ils propageaient leurs idées.

9
0:00:34.003,000 --> 0:00:35,000
Et enfin, je voulais savoir

10
0:00:35.382,000 --> 0:00:37,000
quel impact cela pourrait avoir sur notre société.

11
0:00:38.055,000 --> 0:00:42,000
En 2016, j’ai commencé à tracer la source de certains de ces mèmes,

12
0:00:42.09,000 --> 0:00:45,000
pour trouver ceux qui les génèrent et qui les rendent viraux.

13
0:00:45.616,000 --> 0:00:46,000
Je les abordais ainsi :

14
0:00:46.804,000 --> 0:00:49,000
« Salut, je suis journaliste. Puis-je venir observer vos activités ? »

15
0:00:50.094,000 --> 0:00:51,000
La réaction normale était :

16
0:00:51.384,000 --> 0:00:52,000
« Pourquoi aurais-je envie de causer

17
0:00:53.125,000 --> 0:00:55,000
avec une tapette juive, cocue et mondialiste de Brooklyn

18
0:00:55.818,000 --> 0:00:57,000
qui s’est acoquinée avec les démocrates ? »

19
0:00:57.929,000 --> 0:00:58,000
(Rires)

20
0:00:59.205,000 --> 0:01:02,000
Ce à quoi j’aurais répondu : « Pas mal, mec, 57% de correct ! »

21
0:01:03.064,000 --> 0:01:04,000
(Rires)

22
0:01:04.633,000 --> 0:01:05,000
Mais j’ai souvent eu la réaction opposée.

23
0:01:06.597,000 --> 0:01:07,000
« Pourquoi pas, viens ! »

24
0:01:08.625,000 --> 0:01:1,000
C’est ainsi que j’ai débarqué dans le salon

25
0:01:10.63,000 --> 0:01:13,000
d’un propagandiste sur les réseaux sociaux dans le sud de la Californie.

26
0:01:14.386,000 --> 0:01:16,000
C'était un homme blanc, marié, fin de la trentaine.

27
0:01:16.791,000 --> 0:01:19,000
Il était assis à table, avec une tasse de café,

28
0:01:19.997,000 --> 0:01:2,000
un ordinateur pour tweeter,

29
0:01:21.591,000 --> 0:01:22,000
un téléphone pour les messages

30
0:01:23.463,000 --> 0:01:26,000
et un iPad pour une diffusion en direct sur Periscope et Youtube.

31
0:01:27.258,000 --> 0:01:28,000
C’est tout.

32
0:01:28.998,000 --> 0:01:29,000
Pourtant, avec ces outils,

33
0:01:30.292,000 --> 0:01:33,000
il était capable de propulser ses opinions toxiques et marginales

34
0:01:34.031,000 --> 0:01:36,000
dans le cœur des conversations en Amérique.

35
0:01:37.144,000 --> 0:01:39,000
Par exemple, un jour où j’étais avec lui,

36
0:01:39.191,000 --> 0:01:41,000
il y a eu une explosion à New York

37
0:01:42.367,000 --> 0:01:45,000
et le type accusé de l’avoir posée sonnait musulman d'après son nom.

38
0:01:45.866,000 --> 0:01:49,000
Ça semblait être du pain béni pour le propagandiste de Californie

39
0:01:50.032,000 --> 0:01:51,000
car une des choses qu’il revendique,

40
0:01:51.772,000 --> 0:01:53,000
c’est que les États-Unis empêchent toute immigration,

41
0:01:54.358,000 --> 0:01:56,000
principalement celle issue des pays majoritairement musulmans.

42
0:01:57.424,000 --> 0:01:59,000
Il a commencé à diffuser en direct,

43
0:01:59.503,000 --> 0:02:01,000
entraînant ses suiveurs dans une frénésie

44
0:02:01.763,000 --> 0:02:03,000
sur les périls mortels de l'ouverture des frontières

45
0:02:04.562,000 --> 0:02:05,000
et leur demandant de tweeter,

46
0:02:06.354,000 --> 0:02:07,000
d'utiliser des hashtags précis

47
0:02:07.847,000 --> 0:02:08,000
pour en faire une tendance.

48
0:02:09.729,000 --> 0:02:1,000
Et ils ont tweeté à mort.

49
0:02:10.972,000 --> 0:02:11,000
Des centaines et des centaines de tweets,

50
0:02:12.926,000 --> 0:02:14,000
souvent avec des illustrations comme celle-ci.

51
0:02:15.263,000 --> 0:02:16,000
Là c'est George Soros.

52
0:02:17.064,000 --> 0:02:19,000
C'est un milliardaire hongrois et un philanthrope.

53
0:02:19.733,000 --> 0:02:21,000
Dans l'esprit des conspirateurs en ligne,

54
0:02:22.328,000 --> 0:02:24,000
Soros est une sorte de croque-mitaine mondialiste,

55
0:02:24.944,000 --> 0:02:28,000
membre de la crème de l'élite manipulant secrètement le monde.

56
0:02:29.078,000 --> 0:02:32,000
Respirez un instant : si cette idée vous semble familière,

57
0:02:32.694,000 --> 0:02:34,000
l'idée qu'une élite contrôle le monde

58
0:02:35.11,000 --> 0:02:37,000
et que ses membres sont souvent de riches Juifs,

59
0:02:37.715,000 --> 0:02:4,000
c'est parce que c'est un des clichés les plus anti-sémites qui soient.

60
0:02:42.296,000 --> 0:02:45,000
Je mentionne en passant que l'homme qui a posé la bombe à New York

61
0:02:45.718,000 --> 0:02:46,000
était un citoyen américain.

62
0:02:47.785,000 --> 0:02:49,000
Ce qui se passait à New York, quoi que ce soit,

63
0:02:50.013,000 --> 0:02:52,000
n'avait pas de lien avec l'immigration.

64
0:02:53.332,000 --> 0:02:55,000
Le propagandiste en Californie comprenait bien ça.

65
0:02:56.188,000 --> 0:02:58,000
Il était cultivé et juriste de profession.

66
0:02:58.733,000 --> 0:02:59,000
Il connaissait les faits

67
0:03:00.444,000 --> 0:03:03,000
mais il savait qu'ils ne sont pas le moteur d'une conversation en ligne.

68
0:03:03.835,000 --> 0:03:05,000
Les conversations en ligne sont dirigées par l'émotion.

69
0:03:07.451,000 --> 0:03:1,000
Les prémices des réseaux sociaux sont qu'ils allaient nous rassembler,

70
0:03:11.028,000 --> 0:03:14,000
rendre le monde plus ouvert, plus tolérant et plus juste...

71
0:03:14.161,000 --> 0:03:15,000
C'est en partie arrivé.

72
0:03:16.503,000 --> 0:03:18,000
Mais leurs algorithmes n'ont jamais été conçus

73
0:03:19.25,000 --> 0:03:21,000
pour faire la distinction entre le vrai du faux,

74
0:03:21.612,000 --> 0:03:24,000
entre le bon du mauvais pour la société, entre le pro-social et l'anti-social.

75
0:03:25.965,000 --> 0:03:27,000
Ils ne sont pas là pour ça.

76
0:03:28.226,000 --> 0:03:3,000
Ils mesurent toutefois l'engagement :

77
0:03:30.805,000 --> 0:03:33,000
les clics, les commentaires, les partages, les retweets, tout ça.

78
0:03:33.866,000 --> 0:03:35,000
Quand on veut que le contenu suscite un engagement,

79
0:03:36.58,000 --> 0:03:37,000
il doit émouvoir,

80
0:03:38.257,000 --> 0:03:41,000
ce que la science du comportement nomme « émotion à haute excitation ».

81
0:03:42.343,000 --> 0:03:44,000
« Haute excitation » ne se limite pas à l'excitation sexuelle,

82
0:03:45.243,000 --> 0:03:47,000
même si c'est Internet donc cela fonctionne bien.

83
0:03:47.616,000 --> 0:03:51,000
C'est tout ce qui fait battre le cœur des gens, que ce soit positif ou négatif.

84
0:03:51.625,000 --> 0:03:53,000
J'ai passé du temps avec ces propagandistes,

85
0:03:53.684,000 --> 0:03:55,000
celui de Californie et des douzaines d'autres.

86
0:03:56.075,000 --> 0:03:59,000
Je les observais agir et réussir encore et encore,

87
0:03:59.847,000 --> 0:04:02,000
pas parce que c'étaient des hackers russes ou des prodiges en informatique,

88
0:04:03.479,000 --> 0:04:05,000
ni parce qu'ils avaient une vision politique,

89
0:04:05.772,000 --> 0:04:07,000
mais ils comprenaient le fonctionnement des réseaux sociaux

90
0:04:08.545,000 --> 0:04:09,000
et les exploitaient à leur avantage.

91
0:04:10.425,000 --> 0:04:13,000
Au début, je pensais être devant un phénomène marginal,

92
0:04:13.902,000 --> 0:04:14,000
circonscrit à Internet.

93
0:04:16.385,000 --> 0:04:19,000
Mais il n'y a plus vraiment de frontières entre Internet et le reste.

94
0:04:20.761,000 --> 0:04:22,000
Voici une publicité passée sur beaucoup de chaînes

95
0:04:23.115,000 --> 0:04:25,000
pendant la campagne électorale de 2018,

96
0:04:25.6,000 --> 0:04:27,000
prétendant avec peu de preuves qu'un des candidats

97
0:04:28.504,000 --> 0:04:3,000
était manipulé par le manipulateur mondial George Soros,

98
0:04:31.414,000 --> 0:04:34,000
la photo maladroitement retouchée avec une montagne d'argent.

99
0:04:35.296,000 --> 0:04:39,000
Ce tweet du président des États-Unis prétend, sans preuve à l'appui,

100
0:04:39.631,000 --> 0:04:42,000
que la politique américaine est manipulée par George Soros.

101
0:04:43.086,000 --> 0:04:46,000
Ce genre de choses qui nous paraissaient scandaleuses, marginales et insignifiantes

102
0:04:47.084,000 --> 0:04:49,000
sont devenues si normales qu'on les remarque à peine.

103
0:04:50.053,000 --> 0:04:52,000
J'ai passé trois ans dans ce monde-là.

104
0:04:52.143,000 --> 0:04:53,000
J'ai parlé à beaucoup de personnes.

105
0:04:53.813,000 --> 0:04:55,000
Certaines étaient agnostiques quel que soit le sujet.

106
0:04:56.327,000 --> 0:04:58,000
Elles semblaient faire très rationnellement le pari

107
0:04:58.934,000 --> 0:05:,000
que pour faire de l'argent ou attirer l'attention en ligne,

108
0:05:01.907,000 --> 0:05:03,000
elles devaient se comporter le plus outrageusement possible.

109
0:05:04.794,000 --> 0:05:06,000
Mais il y avait aussi des idéologues convaincus.

110
0:05:08.173,000 --> 0:05:11,000
Par soucis de limpidité, pas de conservatisme traditionnel.

111
0:05:12.078,000 --> 0:05:15,000
On parle de gens qui voulaient abolir le droit de vote des femmes,

112
0:05:15.48,000 --> 0:05:17,000
qui voulaient revenir à la ségrégation raciale.

113
0:05:18.131,000 --> 0:05:2,000
Certains voulaient même se débarrasser de la démocratie.

114
0:05:21.304,000 --> 0:05:23,000
Ces gens ne sont pas nés avec ces croyances.

115
0:05:23.92,000 --> 0:05:25,000
Ils ne les ont pas assimilées à l'école primaire.

116
0:05:26.832,000 --> 0:05:29,000
Ils sont nombreux ceux qui, avant de glisser dans ce trou virtuel,

117
0:05:29.944,000 --> 0:05:32,000
étaient libertaires ou même socialistes ou tout autre chose.

118
0:05:34.465,000 --> 0:05:35,000
Qu'est-ce qui se passait ?

119
0:05:36.918,000 --> 0:05:38,000
Je ne souhaite pas généraliser

120
0:05:39.004,000 --> 0:05:4,000
mais beaucoup de mes interlocuteurs

121
0:05:40.715,000 --> 0:05:43,000
semblent combiner un haut QI avec un faible QE.

122
0:05:44.619,000 --> 0:05:47,000
Ils semblent se sentir plus à l'aise dans les espaces anonymes en ligne

123
0:05:48.154,000 --> 0:05:5,000
que dans les connexions dans la vraie vie.

124
0:05:50.81,000 --> 0:05:52,000
Dès lors, ils se replient souvent sur les forums

125
0:05:53.287,000 --> 0:05:54,000
ou les subreddits,

126
0:05:54.483,000 --> 0:05:56,000
ces lieux où leurs pires pulsions sont amplifiées.

127
0:05:56.961,000 --> 0:05:59,000
Ils commencent souvent avec une blague de mauvais goût

128
0:06:00.044,000 --> 0:06:03,000
qui va recevoir un renforcement positif,

129
0:06:03.182,000 --> 0:06:05,000
ce qu'ils appellent des points Internet insignifiants,

130
0:06:06.137,000 --> 0:06:09,000
à un point tel qu'ils vont finir par croire à leur propre blague.

131
0:06:10.014,000 --> 0:06:13,000
J'ai discuté avec une jeune femme qui a grandi dans le New Jersey.

132
0:06:13.562,000 --> 0:06:15,000
Après le lycée, elle a déménagé ailleurs

133
0:06:15.692,000 --> 0:06:17,000
et s'est brutalement sentie aliénée et isolée.

134
0:06:18.34,000 --> 0:06:2,000
Alors elle s'est repliée sur son téléphone.

135
0:06:20.85,000 --> 0:06:21,000
Elle a trouvé des endroits sur Internet

136
0:06:22.826,000 --> 0:06:25,000
où les gens postent des choses aussi scandaleuses que haineuses.

137
0:06:25.936,000 --> 0:06:27,000
Elle trouvait cela vraiment écœurant

138
0:06:28.205,000 --> 0:06:3,000
mais d'une certaine manière, c'était fascinant,

139
0:06:30.754,000 --> 0:06:32,000
et elle ne pouvait pas s'empêcher de les lire.

140
0:06:33.304,000 --> 0:06:35,000
Elle a commencé à interagir en ligne avec ces personnes

141
0:06:36.16,000 --> 0:06:38,000
qui la faisaient se sentir intelligente, valorisée.

142
0:06:38.589,000 --> 0:06:4,000
Elle a développé un sentiment d'appartenance

143
0:06:40.706,000 --> 0:06:42,000
et se demandait si certains mèmes scandaleux

144
0:06:42.836,000 --> 0:06:44,000
ne recèleraient pas un peu de vérité.

145
0:06:46.151,000 --> 0:06:49,000
Quelques mois plus tard, elle a accompagné ses nouveaux amis d'Internet

146
0:06:49.49,000 --> 0:06:51,000
pour rejoindre Charlottesville en Virginie

147
0:06:51.54,000 --> 0:06:53,000
et manifester avec des torches au nom de la race blanche.

148
0:06:55.033,000 --> 0:06:57,000
De sympathisante d'Obama, elle est passée en quelques mois

149
0:06:57.774,000 --> 0:06:59,000
à suprémaciste blanche radicalisée.

150
0:07:01.03,000 --> 0:07:03,000
Dans le cas de cette jeune fille,

151
0:07:03.335,000 --> 0:07:07,000
elle a pu se libérer du joug du culte de la suprématie blanche.

152
0:07:08.418,000 --> 0:07:1,000
Mais ceux qui n'y arrivent pas sont nombreux.

153
0:07:10.518,000 --> 0:07:11,000
Je vais être franc.

154
0:07:12.248,000 --> 0:07:15,000
Je n'ai jamais été convaincu au point de devoir chercher des points communs

155
0:07:15.874,000 --> 0:07:16,000
avec chaque interlocuteur

156
0:07:17.325,000 --> 0:07:18,000
au point de pouvoir dire :

157
0:07:18.603,000 --> 0:07:21,000
« Vous savez, vous êtes un propagandiste fasciste, moi pas,

158
0:07:21.768,000 --> 0:07:24,000
laissons ça en suspens et nos différences finiront par s'estomper. »

159
0:07:25.208,000 --> 0:07:26,000
Pas du tout.

160
0:07:28.056,000 --> 0:07:31,000
Mais j'ai acquis la conviction que nous ne pouvons pas les ignorer.

161
0:07:31.601,000 --> 0:07:34,000
Nous devons comprendre ce phénomène car seule la compréhension

162
0:07:34.841,000 --> 0:07:37,000
nous permettra de nous protéger de son infection.

163
0:07:39.361,000 --> 0:07:42,000
Pendant ces trois années, j'ai reçu quelques appels déplaisants,

164
0:07:42.734,000 --> 0:07:43,000
quelques menaces même.

165
0:07:44.278,000 --> 0:07:47,000
Mais ce n'est rien en comparaison à ce que les femmes journalistes subissent.

166
0:07:48.791,000 --> 0:07:49,000
Certes, je suis juif,

167
0:07:50.206,000 --> 0:07:53,000
même si bizarrement, beaucoup de nazis ne s'en sont pas aperçus.

168
0:07:53.879,000 --> 0:07:55,000
Sincèrement, cela m'a vraiment déçu.

169
0:07:56.764,000 --> 0:07:57,000
(Rires)

170
0:07:58.588,000 --> 0:08:01,000
Plus sérieusement, c'est comme si l'anti-sémitisme était leur métier.

171
0:08:03.228,000 --> 0:08:05,000
Et rien chez moi ne les fait tiquer ?

172
0:08:05.674,000 --> 0:08:06,000
Vraiment rien ?

173
0:08:06.774,000 --> 0:08:07,000
(Rires)

174
0:08:09.983,000 --> 0:08:1,000
Ce n'est pas un secret.

175
0:08:11.202,000 --> 0:08:13,000
Je m'appelle Andrew Marantz, j'écris pour le New Yorker.

176
0:08:13.909,000 --> 0:08:15,000
C'est comme afficher une photo d'Alain Chabat

177
0:08:16.454,000 --> 0:08:17,000
dans une coopérative alimentaire.

178
0:08:18.315,000 --> 0:08:19,000
Toujours pas ?

179
0:08:19.501,000 --> 0:08:2,000
(Rires)

180
0:08:24.804,000 --> 0:08:28,000
Bref, ça aurait été sympa d'avoir une formule simple :

181
0:08:29.431,000 --> 0:08:32,000
smartphone plus gosse aliéné égale 12% de risque d'être nazi.

182
0:08:33.918,000 --> 0:08:34,000
Ce n'est évidemment pas si simple.

183
0:08:36.19,000 --> 0:08:37,000
Dans mes écrits,

184
0:08:37.377,000 --> 0:08:4,000
je me sens à l'aise dans le descriptif, pas dans le normatif.

185
0:08:41.049,000 --> 0:08:43,000
Mais c'est TED,

186
0:08:43.714,000 --> 0:08:44,000
osons être dans l'action.

187
0:08:45.725,000 --> 0:08:46,000
J'aimerais vous suggérer

188
0:08:47.375,000 --> 0:08:5,000
quelques actions que les citoyens d'Internet comme vous et moi

189
0:08:50.525,000 --> 0:08:53,000
pouvons réaliser pour rendre la situation moins toxique.

190
0:08:54.799,000 --> 0:08:56,000
La première est d'être un sceptique malin.

191
0:08:57.964,000 --> 0:08:59,000
Il y a deux sortes de scepticisme selon moi.

192
0:09:00.185,000 --> 0:09:04,000
Je ne vais pas vous noyer sous un jargon épistémologique :

193
0:09:04.437,000 --> 0:09:06,000
il y a le scepticisme malin et le scepticisme con.

194
0:09:08.176,000 --> 0:09:1,000
Le scepticisme malin :

195
0:09:10.683,000 --> 0:09:12,000
penser par soi-même, cultiver un esprit critique,

196
0:09:13.157,000 --> 0:09:14,000
exiger des preuves.

197
0:09:14.617,000 --> 0:09:15,000
C'est ça le vrai scepticisme.

198
0:09:17.397,000 --> 0:09:19,000
Le scepticisme con, par opposition, ressemble au scepticisme

199
0:09:20.207,000 --> 0:09:22,000
mais est plus proche de l'opposition viscérale.

200
0:09:23.817,000 --> 0:09:24,000
Tout le monde dit que la Terre est ronde ?

201
0:09:25.79,000 --> 0:09:25,000
Non, elle est plate.

202
0:09:26.794,000 --> 0:09:27,000
Tout le monde décrie le racisme ?

203
0:09:28.411,000 --> 0:09:3,000
On dit qu'on ne sait pas, qu'on est sceptique.

204
0:09:31.682,000 --> 0:09:35,000
Je ne sais pas combien de jeunes hommes blancs que j'ai rencontrés

205
0:09:35.825,000 --> 0:09:36,000
qui m'ont affirmé :

206
0:09:37.005,000 --> 0:09:4,000
« Les médias, mes professeurs, tous essaient de m'endoctriner

207
0:09:40.429,000 --> 0:09:42,000
et de me faire croire aux privilèges masculin et blanc,

208
0:09:43.002,000 --> 0:09:45,000
mais je ne suis vraiment pas convaincu. »

209
0:09:45.452,000 --> 0:09:48,000
Les ados blancs adeptes de la contradiction,

210
0:09:48.613,000 --> 0:09:5,000
écoutez,

211
0:09:50.755,000 --> 0:09:53,000
si vous êtes sceptique sur la forme de la Terre, sur les privilèges masculins

212
0:09:54.492,000 --> 0:09:56,000
et le fait que le racisme soit une mauvaise chose,

213
0:09:56.852,000 --> 0:09:58,000
vous n'êtes pas sceptique, vous êtes con.

214
0:09:59.175,000 --> 0:10:01,000
(Applaudissements)

215
0:10:04.394,000 --> 0:10:07,000
C'est important de penser pour soi, nous devrions tous agir ainsi,

216
0:10:07.854,000 --> 0:10:09,000
mais il convient de le faire intelligemment.

217
0:10:09.925,000 --> 0:10:11,000
Parlons donc un peu de la liberté de parole.

218
0:10:11.989,000 --> 0:10:14,000
Des personnes érudites affirment être en faveur de la liberté de parole.

219
0:10:15.781,000 --> 0:10:18,000
Elles affirment ça comme s'il n'y avait plus rien à ajouter.

220
0:10:19.078,000 --> 0:10:22,000
Alors qu'en fait, c'est le début d'une véritable conversation.

221
0:10:23.554,000 --> 0:10:25,000
Les choses intéressantes apparaissent juste après.

222
0:10:26.051,000 --> 0:10:28,000
Pour la liberté de parole, que voulez-vous dire ?

223
0:10:28.379,000 --> 0:10:3,000
Les suprémacistes David Duke et Richard Spencer

224
0:10:30.58,000 --> 0:10:32,000
ont-ils besoin d'avoir des comptes Twitter actifs ?

225
0:10:32.975,000 --> 0:10:34,000
N'importe qui peut-il harceler autrui en ligne

226
0:10:35.555,000 --> 0:10:36,000
pour n'importe quelle raison ?

227
0:10:37.031,000 --> 0:10:4,000
J'ai passé en revue toute la liste des orateurs TED de cette année.

228
0:10:40.173,000 --> 0:10:42,000
Aucun ne remet en doute la forme de la Terre.

229
0:10:42.403,000 --> 0:10:44,000
Est-ce une violation de la liberté de parole ?

230
0:10:45.086,000 --> 0:10:48,000
Nous sommes tous en faveur de la liberté de parole et c'est très bien

231
0:10:48.652,000 --> 0:10:5,000
mais si c'est tout ce que vous serinez sans plus,

232
0:10:51.297,000 --> 0:10:53,000
vous empêchez une conversation plus importante d'avoir lieu.

233
0:10:56.105,000 --> 0:10:59,000
Rendre la bienséance cool.

234
0:10:59.264,000 --> 0:11:,000
Super !

235
0:11:00.486,000 --> 0:11:01,000
(Applaudissements)

236
0:11:02.051,000 --> 0:11:04,000
Inutile d'expliquer.

237
0:11:04.181,000 --> 0:11:07,000
Mes recherches m'ont conduit sur Reddit, Youtube ou Facebook.

238
0:11:08.051,000 --> 0:11:1,000
Je faisais des recherches sur « la charia »

239
0:11:10.375,000 --> 0:11:12,000
ou sur « l'Holocauste ».

240
0:11:12.515,000 --> 0:11:15,000
Vous imaginez sans doute ce que les algorithmes m'ont montré.

241
0:11:16.386,000 --> 0:11:18,000
« La charia est-elle en train d'envahir les États-Unis ? »

242
0:11:19.34,000 --> 0:11:21,000
« L'Holocauste a-t-il eu lieu ? »

243
0:11:22.291,000 --> 0:11:23,000
Scepticisme con.

244
0:11:24.835,000 --> 0:11:26,000
Il y a une dynamique étrange en ligne :

245
0:11:27.24,000 --> 0:11:29,000
certains considèrent que la propagande bigote déchire,

246
0:11:29.782,000 --> 0:11:31,000
c'est à la fois audacieux et cool,

247
0:11:32.046,000 --> 0:11:35,000
que les faits et la décence humaine sont soit de la pudeur mal placée,

248
0:11:35.397,000 --> 0:11:37,000
soit un signe de vertu, soit ennuyeux.

249
0:11:38.329,000 --> 0:11:41,000
Les algorithmes des réseaux sociaux, intentionnellement ou pas,

250
0:11:41.642,000 --> 0:11:43,000
rendent cela séduisant

251
0:11:43.689,000 --> 0:11:45,000
car la propagande bigote est un bon agent d'engagement.

252
0:11:46.521,000 --> 0:11:48,000
Tout le monde clique et laisse des commentaires,

253
0:11:48.931,000 --> 0:11:49,000
qu'ils aiment ou détestent.

254
0:11:51.463,000 --> 0:11:53,000
La première chose à faire

255
0:11:53.775,000 --> 0:11:55,000
est donc que les réseaux sociaux corrigent leurs plateformes.

256
0:11:57.069,000 --> 0:11:59,000
(Applaudissements)

257
0:12:01.6,000 --> 0:12:04,000
Si quelqu'un qui travaille pour un réseau social m'écoute,

258
0:12:05.054,000 --> 0:12:07,000
si vous êtes actionnaire ou en possédez un,

259
0:12:08.598,000 --> 0:12:09,000
voici un conseil.

260
0:12:10.083,000 --> 0:12:13,000
Si vous optimisez pour un engagement émotionnel maximal

261
0:12:14.028,000 --> 0:12:17,000
et que celui-ci s'avère activement nuire au monde,

262
0:12:18.165,000 --> 0:12:2,000
l'heure est venue d'optimiser autre chose.

263
0:12:20.725,000 --> 0:12:22,000
(Applaudissements)

264
0:12:26.939,000 --> 0:12:29,000
Avec la pression qu'on peut appliquer pour qu'ils agissent,

265
0:12:30.476,000 --> 0:12:32,000
mais au lieu d'attendre et d'espérer,

266
0:12:33.134,000 --> 0:12:35,000
on peut aussi agir.

267
0:12:35.66,000 --> 0:12:39,000
On peut créer des meilleures trajectoires ou en suggérer

268
0:12:40.181,000 --> 0:12:41,000
pour que les ados rebelles s'y engagent.

269
0:12:42.196,000 --> 0:12:45,000
Quand on voit une chose vraiment créative et bien attentionnée,

270
0:12:45.499,000 --> 0:12:46,000
qu'on veut la partager, on peut le faire,

271
0:12:47.492,000 --> 0:12:49,000
même si cela ne nous inonde pas d'émotion excitante.

272
0:12:50.432,000 --> 0:12:52,000
Je suis conscient que c'est un petit pas.

273
0:12:52.576,000 --> 0:12:54,000
Mais il compte car il s'additionne à d'autres.

274
0:12:55.254,000 --> 0:12:57,000
Les algorithmes, aussi puissants soient-ils,

275
0:12:57.344,000 --> 0:12:59,000
sont influencés par nos comportements.

276
0:13:01.556,000 --> 0:13:02,000
Je vous quitterai avec ces mots :

277
0:13:03.701,000 --> 0:13:05,000
il y a quelques années, c'était à la mode

278
0:13:06.19,000 --> 0:13:08,000
d'affirmer qu'Internet était un outil révolutionnaire

279
0:13:08.823,000 --> 0:13:09,000
qui allait nous rassembler.

280
0:13:11.074,000 --> 0:13:13,000
Aujourd'hui, c'est devenu à la mode de dire

281
0:13:13.083,000 --> 0:13:16,000
qu'Internet est un monstrueux désastre total et irrémédiable.

282
0:13:16.787,000 --> 0:13:17,000
Aucune des caricatures n'est exacte.

283
0:13:18.643,000 --> 0:13:21,000
Internet est trop vaste et trop complexe pour être bon ou mauvais.

284
0:13:22.563,000 --> 0:13:24,000
Le danger de ces façons de penser,

285
0:13:24.674,000 --> 0:13:27,000
que ce soit la vue utopique qu'Internet va inévitablement nous sauver

286
0:13:28.051,000 --> 0:13:3,000
ou la vue dystopique qu'il va inévitablement nous détruire,

287
0:13:31.553,000 --> 0:13:33,000
c'est que nous nous en tirons à bon compte.

288
0:13:35.564,000 --> 0:13:37,000
Il n'y a rien d'inévitable dans notre avenir.

289
0:13:38.878,000 --> 0:13:4,000
Internet est constitué de personnes.

290
0:13:40.903,000 --> 0:13:42,000
Des gens prennent des décisions au sein des réseaux sociaux.

291
0:13:43.911,000 --> 0:13:45,000
Des gens font les tendances des hashtags.

292
0:13:46.586,000 --> 0:13:49,000
Des gens font progresser ou régresser la société.

293
0:13:51.12,000 --> 0:13:52,000
Quand on comprend bien ces faits,

294
0:13:52.705,000 --> 0:13:55,000
on peut cesser d'attendre un avenir inévitable

295
0:13:55.751,000 --> 0:13:56,000
et se mettre au travail maintenant.

296
0:13:58.842,000 --> 0:14:01,000
On nous a appris que l'arc de l'univers moral est long,

297
0:14:02.055,000 --> 0:14:04,000
mais il tend vers la justice.

298
0:14:06.489,000 --> 0:14:07,000
C'est possible.

299
0:14:08.814,000 --> 0:14:09,000
Peut-être un jour.

300
0:14:10.776,000 --> 0:14:12,000
Ça reste une aspiration.

301
0:14:13.277,000 --> 0:14:14,000
Ce n'est pas une garantie.

302
0:14:15.856,000 --> 0:14:17,000
L'arc ne penche pas par lui-même.

303
0:14:18.045,000 --> 0:14:21,000
Une force mystérieuse ne le fait pas pencher inévitablement.

304
0:14:21.744,000 --> 0:14:22,000
La vérité,

305
0:14:23.44,000 --> 0:14:25,000
bien plus effrayante mais aussi libératoire,

306
0:14:26.847,000 --> 0:14:28,000
c'est que c'est nous qui le faisons pencher.

307
0:14:29.002,000 --> 0:14:3,000
Merci.

308
0:14:30.176,000 --> 0:14:32,000
(Applaudissements)

