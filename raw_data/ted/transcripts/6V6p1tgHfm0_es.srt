1
0:00:,000 --> 0:00:07,000
Traductor: Sebastian Betti Revisor: Amalia Gómez

2
0:00:11.82,000 --> 0:00:14,000
A lo mejor tienen la impresión, como la mayoría de la gente,

3
0:00:15.66,000 --> 0:00:18,000
de que nuestro país está cada vez más polarizado;

4
0:00:19.34,000 --> 0:00:22,000
de que la división entre izquierda y derecha

5
0:00:22.82,000 --> 0:00:25,000
es mucho más grande de lo que hemos vivido nunca.

6
0:00:26.38,000 --> 0:00:31,000
Quizá se pregunten si hay investigaciones que respalden su intuición.

7
0:00:32.38,000 --> 0:00:36,000
Y en pocas palabras, la respuesta es tristemente que sí.

8
0:00:38.74,000 --> 0:00:4,000
Estudio tras estudio observamos

9
0:00:40.78,000 --> 0:00:43,000
que liberales y conservadores se han alejado cada vez más.

10
0:00:45.26,000 --> 0:00:49,000
Se aíslan cada vez más en unos silos ideológicos,

11
0:00:50.06,000 --> 0:00:54,000
leyendo diferentes noticias, hablando con gente con las mismas ideas

12
0:00:54.22,000 --> 0:00:57,000
y eligiendo, más y más, vivir en partes diferentes del país.

13
0:00:58.54,000 --> 0:01:01,000
Y creo que lo más alarmante

14
0:01:01.78,000 --> 0:01:04,000
es la creciente hostilidad de ambas partes.

15
0:01:06.26,000 --> 0:01:07,000
Liberales y conservadores,

16
0:01:07.94,000 --> 0:01:08,000
demócratas y republicanos,

17
0:01:09.86,000 --> 0:01:12,000
se gustan cada vez menos.

18
0:01:14.14,000 --> 0:01:16,000
Se puede observar en muchas actitudes.

19
0:01:16.18,000 --> 0:01:19,000
No quieren ser amigos. No quieren salir juntos.

20
0:01:19.86,000 --> 0:01:22,000
Si lo hacen y se enteran, se encuentran menos atractivos

21
0:01:23.18,000 --> 0:01:26,000
y quieren, cada vez menos, ver a sus hijos casados con

22
0:01:26.3,000 --> 0:01:27,000
partidarios de la contra,

23
0:01:28.02,000 --> 0:01:29,000
una estadística escalofriante.

24
0:01:31.46,000 --> 0:01:33,000
En mi laboratorio, hablo con mis estudiantes

25
0:01:34.3,000 --> 0:01:37,000
sobre patrones sociales.

26
0:01:37.78,000 --> 0:01:4,000
Soy un gran aficionado al cine y a veces pregunto:

27
0:01:41.34,000 --> 0:01:43,000
¿a qué película pertenecemos con este patrón?

28
0:01:44.9,000 --> 0:01:47,000
¿En qué tipo de película participamos con la polarización política?

29
0:01:48.9,000 --> 0:01:5,000
Podría ser una película de desastres.

30
0:01:52.7,000 --> 0:01:53,000
Desde luego parece un desastre.

31
0:01:54.74,000 --> 0:01:56,000
Podría ser una película de guerra.

32
0:01:57.46,000 --> 0:01:58,000
También encaja.

33
0:01:59.3,000 --> 0:02:02,000
Pero lo que yo creo es que estamos en una película de apocalipsis zombi.

34
0:02:03.14,000 --> 0:02:04,000
(Risas)

35
0:02:04.62,000 --> 0:02:06,000
¿Verdad? Ya saben de qué hablo.

36
0:02:06.94,000 --> 0:02:08,000
Hay gente vagando en grupos,

37
0:02:09.38,000 --> 0:02:1,000
sin pensar por sí mismos,

38
0:02:11.18,000 --> 0:02:12,000
siguiendo la ideología de la masa

39
0:02:12.82,000 --> 0:02:15,000
intentando extender su enfermedad y destruir a la sociedad.

40
0:02:17.3,000 --> 0:02:19,000
Y probablemente Uds. piensan, como yo,

41
0:02:19.66,000 --> 0:02:22,000
que son los buenos en la película del apocalipsis zombi

42
0:02:23.14,000 --> 0:02:26,000
y que este odio y esta polarización lo propagan los otros.

43
0:02:26.86,000 --> 0:02:27,000
Nosotros somos Brad Pitt, ¿no?

44
0:02:29.58,000 --> 0:02:31,000
Librepensadores, honrados,

45
0:02:32.5,000 --> 0:02:34,000
intentando aferrarnos a lo que nos importa,

46
0:02:34.82,000 --> 0:02:37,000
ya saben, no somos soldados del ejército de los no muertos.

47
0:02:38.42,000 --> 0:02:39,000
Eso no.

48
0:02:39.9,000 --> 0:02:4,000
Eso nunca.

49
0:02:41.9,000 --> 0:02:42,000
Pero este es el quid:

50
0:02:43.42,000 --> 0:02:45,000
¿En qué película piensan que están ellos?

51
0:02:47.3,000 --> 0:02:48,000
¿No?

52
0:02:48.54,000 --> 0:02:5,000
Ellos están convencidos de ser los buenos

53
0:02:51.1,000 --> 0:02:52,000
en la película del apocalipsis zombi.

54
0:02:52.98,000 --> 0:02:54,000
Y, créanlo, piensan que ellos son Brad Pitt

55
0:02:55.98,000 --> 0:02:57,000
y que nosotros somos los zombis.

56
0:03:00.94,000 --> 0:03:02,000
¿Y quién dice que se equivocan?

57
0:03:04.26,000 --> 0:03:07,000
Creo que la verdad es que todos somos parte de esto.

58
0:03:08.06,000 --> 0:03:11,000
Lo bueno es que podemos ser parte de la solución.

59
0:03:12.1,000 --> 0:03:14,000
Así que, ¿qué vamos a hacer?

60
0:03:15.14,000 --> 0:03:19,000
¿Qué podemos hacer para socavar la polarización en el día a día?

61
0:03:19.42,000 --> 0:03:22,000
¿Cómo podríamos conectarnos y comunicarnos

62
0:03:23.26,000 --> 0:03:24,000
con nuestros homólogos políticos?

63
0:03:25.54,000 --> 0:03:29,000
Esas eran exactamente las preguntas que a mi colega Matt Feinberg y a mí

64
0:03:29.7,000 --> 0:03:3,000
nos fascinaron hace unos años

65
0:03:31.582,000 --> 0:03:33,000
y empezamos a investigar sobre ese tema.

66
0:03:34.74,000 --> 0:03:36,000
Una de las primeras cosas que descubrimos,

67
0:03:37.74,000 --> 0:03:4,000
que creo muy útil para entender la polarización,

68
0:03:41.22,000 --> 0:03:42,000
es entender

69
0:03:42.46,000 --> 0:03:46,000
que la división política del país se basa en una división moral más profunda.

70
0:03:46.9,000 --> 0:03:5,000
Uno de los descubrimientos más importantes en la historia de la psicología política

71
0:03:51.7,000 --> 0:03:54,000
es este patrón identificado por Jon Haidt y Jesse Graham,

72
0:03:55.42,000 --> 0:03:56,000
psicólogos,

73
0:03:56.66,000 --> 0:04:,000
de que los liberales y los conservadores tienden a respaldar diferentes valores

74
0:04:00.7,000 --> 0:04:01,000
a diferentes niveles.

75
0:04:02.42,000 --> 0:04:07,000
Por ejemplo, descubrimos que los liberales tienden a apoyar valores como la igualdad,

76
0:04:07.94,000 --> 0:04:1,000
la justicia, el cuidado, y la protección contra el peligro

77
0:04:11.62,000 --> 0:04:13,000
más que los conservadores.

78
0:04:13.78,000 --> 0:04:18,000
Y los conservadores tienden a apoyar valores como la lealtad, el patriotismo,

79
0:04:19.06,000 --> 0:04:22,000
el respeto a la autoridad y la pureza moral

80
0:04:22.54,000 --> 0:04:24,000
más que los liberales.

81
0:04:25.74,000 --> 0:04:29,000
Matt y yo pensamos que es posible que esta división moral

82
0:04:29.82,000 --> 0:04:32,000
sea útil para entender cómo es que

83
0:04:32.94,000 --> 0:04:34,000
los liberales y los conservadores hablan

84
0:04:35.38,000 --> 0:04:37,000
y la mayor parte del tiempo no se escuchan

85
0:04:37.82,000 --> 0:04:38,000
al hablar.

86
0:04:39.06,000 --> 0:04:4,000
Así que realizamos un estudio

87
0:04:41.06,000 --> 0:04:44,000
donde buscamos liberales para un estudio

88
0:04:44.18,000 --> 0:04:46,000
en el que tenían que escribir un ensayo persuasivo

89
0:04:46.66,000 --> 0:04:5,000
y convincente para un conservador en apoyo al matrimonio homosexual.

90
0:04:51.62,000 --> 0:04:54,000
Nos dimos cuenta de que los liberales tendían a argumentar

91
0:04:54.9,000 --> 0:04:58,000
en términos de valores morales liberales de igualdad y de justicia.

92
0:04:59.1,000 --> 0:05:,000
Decían cosas como

93
0:05:00.86,000 --> 0:05:03,000
"Todo el mundo debería tener el derecho de amar a quien elija",

94
0:05:04.26,000 --> 0:05:06,000
y "Ellos" - "ellos" los estadounidenses gays --

95
0:05:06.86,000 --> 0:05:08,000
"merecen los mismos derechos que el resto de la población".

96
0:05:10.18,000 --> 0:05:13,000
En suma, descubrimos que el 69 % de los liberales

97
0:05:13.42,000 --> 0:05:18,000
recurrió a uno de los valores morales más liberales al escribir su ensayo,

98
0:05:18.86,000 --> 0:05:21,000
y que solo el 9 % recurrió a uno de los más conservadores,

99
0:05:22.58,000 --> 0:05:25,000
incluso cuando se supone que tenían que convencer a los conservadores.

100
0:05:26.02,000 --> 0:05:3,000
Cuando estudiamos a los conservadores al escribir argumentos convincentes

101
0:05:30.34,000 --> 0:05:32,000
para apoyar el hacer del inglés la lengua oficial de EE.UU.,

102
0:05:33.26,000 --> 0:05:35,000
una posición política clásica conservadora,

103
0:05:35.82,000 --> 0:05:37,000
descubrimos que no lo hicieron mejor que los liberales.

104
0:05:38.06,000 --> 0:05:39,000
El 59 % argumentó

105
0:05:39.7,000 --> 0:05:41,000
en términos de valores morales conservadores

106
0:05:42.42,000 --> 0:05:44,000
y solo un 8 % recurrió un valor moral liberal,

107
0:05:44.94,000 --> 0:05:47,000
incluso aunque se supone que estaban dirigiéndose a los liberales.

108
0:05:49.3,000 --> 0:05:53,000
Ven dónde está el problema, ¿no?

109
0:05:54.1,000 --> 0:05:57,000
Los valores morales de la gente son sus más profundas creencias.

110
0:05:57.62,000 --> 0:06:,000
La gente está dispuesta a luchar y a morir por sus valores.

111
0:06:01.54,000 --> 0:06:03,000
¿Por qué renunciar a ellos solo por coincidir con usted

112
0:06:04.26,000 --> 0:06:07,000
en algo sobre lo que de todas formas no quiero estar de acuerdo?

113
0:06:07.82,000 --> 0:06:1,000
Si ese convincente argumento que le hacen a su tío republicano

114
0:06:11.1,000 --> 0:06:13,000
significa que no solo tiene que cambiar su punto de vista,

115
0:06:13.54,000 --> 0:06:15,000
tiene que cambiar sus valores subyacentes, también.

116
0:06:15.73,000 --> 0:06:16,000
no van a llegar muy lejos.

117
0:06:17.9,000 --> 0:06:18,000
¿Qué funcionaría mejor?

118
0:06:20.02,000 --> 0:06:24,000
Creemos que una técnica que se llama reformulación moral

119
0:06:24.34,000 --> 0:06:26,000
y que hemos estudiado en una serie de experimentos.

120
0:06:26.98,000 --> 0:06:27,000
En uno de estos experimentos

121
0:06:28.5,000 --> 0:06:31,000
buscamos a liberales y conservadores para un estudio

122
0:06:31.66,000 --> 0:06:33,000
en el que leen tres ensayos

123
0:06:33.98,000 --> 0:06:36,000
antes de responder a una encuesta sobre su postura medioambiental.

124
0:06:37.46,000 --> 0:06:38,000
El primero de los ensayos

125
0:06:38.98,000 --> 0:06:41,000
era un ensayo proambiental relativamente convencional

126
0:06:42.38,000 --> 0:06:46,000
que recurría a los valores liberales de cuidado y protección ante el daño.

127
0:06:46.42,000 --> 0:06:48,000
Decía cosas como "estamos causando daños reales

128
0:06:48.98,000 --> 0:06:5,000
muy graves de muchas maneras a los lugares en los que vivimos"

129
0:06:51.82,000 --> 0:06:53,000
y "es imprescindible que empecemos a actuar

130
0:06:54.66,000 --> 0:06:56,000
para prevenir una mayor destrucción del planeta Tierra".

131
0:06:58.94,000 --> 0:06:59,000
A otro grupo de participantes

132
0:07:00.38,000 --> 0:07:02,000
se les asignó un ensayo muy diferente

133
0:07:02.62,000 --> 0:07:06,000
diseñado para apelar al valor conservador de pureza moral.

134
0:07:08.01,000 --> 0:07:09,000
También era un ensayo proambiental

135
0:07:10.02,000 --> 0:07:11,000
y decía cosas como

136
0:07:11.54,000 --> 0:07:15,000
"proteger nuestros bosques, agua y cielos puros es de vital importancia".

137
0:07:16.82,000 --> 0:07:17,000
"Deberíamos considerar la contaminación

138
0:07:18.34,000 --> 0:07:2,000
de los lugares en los que vivimos algo repugnante".

139
0:07:20.98,000 --> 0:07:22,000
Y "reducir la contaminación puede ayudarnos a preservar

140
0:07:23.1,000 --> 0:07:26,000
lo pureza y la belleza de los lugares en los que vivimos".

141
0:07:27.7,000 --> 0:07:28,000
Al tercer grupo

142
0:07:29.14,000 --> 0:07:31,000
se le asignó un ensayo no político.

143
0:07:31.66,000 --> 0:07:33,000
Era simplemente un grupo de comparación para tener una referencia.

144
0:07:34.42,000 --> 0:07:35,000
Descubrimos que cuando encuestamos a la gente

145
0:07:36.397,000 --> 0:07:38,000
sobre sus posturas medioambientales,

146
0:07:38.62,000 --> 0:07:4,000
descubrimos que no importaba qué ensayo hubiesen leído los liberales.

147
0:07:41.58,000 --> 0:07:44,000
En cualquier caso tendían a tener posturas proambientales.

148
0:07:44.7,000 --> 0:07:46,000
Los liberales apoyan la protección del medioambiente.

149
0:07:47.14,000 --> 0:07:48,000
Los conservadores, por el contrario,

150
0:07:48.38,000 --> 0:07:52,000
apoyaban mucho más las políticas medioambientales progresistas

151
0:07:52.82,000 --> 0:07:53,000
y la protección medioambiental

152
0:07:54.38,000 --> 0:07:56,000
si habían leído el ensayo de la pureza moral

153
0:07:56.46,000 --> 0:07:58,000
que si habían leído los otros dos ensayos.

154
0:07:59.98,000 --> 0:08:02,000
Incluso descubrimos que los conservadores que leyeron el ensayo de la pureza moral

155
0:08:03.1,000 --> 0:08:06,000
tenían mucha más tendencia a decir que creían en el calentamiento global

156
0:08:06.62,000 --> 0:08:07,000
y que les preocupaba

157
0:08:08.549,000 --> 0:08:1,000
incluso cuando el ensayo ni siquiera mencionaba el calentamiento global.

158
0:08:11.3,000 --> 0:08:13,000
Es simplemente un problema medioambiental relacionado.

159
0:08:13.78,000 --> 0:08:16,000
Pero así de fuerte era el efecto de la reformulación moral.

160
0:08:17.78,000 --> 0:08:2,000
Y lo hemos estudiado en un montón de problemas políticos.

161
0:08:21.54,000 --> 0:08:24,000
Si quieren llegar a los conservadores

162
0:08:25.3,000 --> 0:08:28,000
en cuestiones como el matrimonio homosexual o el seguro de salud nacional

163
0:08:28.42,000 --> 0:08:31,000
es útil relacionar estas cuestiones liberales con valores conservadores

164
0:08:31.9,000 --> 0:08:33,000
como el patriotismo y la pureza moral.

165
0:08:35.62,000 --> 0:08:37,000
También lo hemos estudiado al revés.

166
0:08:37.74,000 --> 0:08:4,000
Si quieren el apoyo de los liberales en cuestiones políticas conservadores

167
0:08:41.58,000 --> 0:08:45,000
como el gasto militar y hacer del inglés la lengua oficial de EE.UU.,

168
0:08:46.22,000 --> 0:08:47,000
serán más convincentes

169
0:08:47.9,000 --> 0:08:5,000
si relacionan esas cuestiones conservadoras a valores liberales

170
0:08:51.26,000 --> 0:08:52,000
como la igualdad y la justicia.

171
0:08:54.46,000 --> 0:08:56,000
Todos estos estudios tienen un mensaje claro:

172
0:08:57.34,000 --> 0:08:59,000
si quieren persuadir a alguien de alguna política

173
0:09:00.3,000 --> 0:09:03,000
es útil conectar esa política con sus valores morales subyacentes.

174
0:09:05.34,000 --> 0:09:08,000
Dicho así parece muy obvio, ¿no?

175
0:09:09.06,000 --> 0:09:1,000
Como ¿por qué hemos venido aquí esta noche?

176
0:09:10.86,000 --> 0:09:11,000
¿Por qué...

177
0:09:12.1,000 --> 0:09:13,000
(Risas)

178
0:09:13.66,000 --> 0:09:15,000
Es increíblemente intuitivo.

179
0:09:17.22,000 --> 0:09:2,000
Pues aunque lo es, es algo que cuesta mucho hacer.

180
0:09:20.54,000 --> 0:09:23,000
Parece ser que cuando vamos a persuadir a alguien de una cuestión política

181
0:09:24.42,000 --> 0:09:26,000
hablamos como si lo hiciéramos frente a un espejo.

182
0:09:27.18,000 --> 0:09:31,000
No persuadimos tanto sino que explicamos nuestras razones

183
0:09:31.58,000 --> 0:09:33,000
sobre por qué creemos un tipo de posición política.

184
0:09:35.22,000 --> 0:09:39,000
No paramos de repetir, al diseñar estos argumentos reformulados moralmente

185
0:09:39.66,000 --> 0:09:41,000
"empatía y respeto, empatía y respeto".

186
0:09:42.86,000 --> 0:09:43,000
Si pueden apelar a eso,

187
0:09:44.34,000 --> 0:09:45,000
pueden conectar

188
0:09:46.02,000 --> 0:09:48,000
y pueden ser capaces de persuadir a alguien en el país.

189
0:09:49.38,000 --> 0:09:51,000
Así que pensando, otra vez,

190
0:09:51.82,000 --> 0:09:53,000
sobre en qué película estamos,

191
0:09:55.02,000 --> 0:09:56,000
quizá antes me haya dejado llevar.

192
0:09:56.62,000 --> 0:09:57,000
Puede que no estemos en un apocalipsis zombi.

193
0:09:59.34,000 --> 0:10:,000
Puede que estemos en una peli de dos compañeros policía.

194
0:10:01.86,000 --> 0:10:03,000
(Risas)

195
0:10:03.9,000 --> 0:10:05,000
Tan solo déjense llevar, por favor.

196
0:10:05.94,000 --> 0:10:06,000
(Risas)

197
0:10:08.3,000 --> 0:10:1,000
Ya saben, hay un policía blanco y un policía negro

198
0:10:11.02,000 --> 0:10:13,000
o quizá un policía desastre y otro organizado.

199
0:10:13.18,000 --> 0:10:15,000
Da igual, no encajan

200
0:10:15.26,000 --> 0:10:16,000
por esta diferencia.

201
0:10:17.34,000 --> 0:10:2,000
Pero al final, cuando tienen que aunar esfuerzos y cooperar

202
0:10:20.58,000 --> 0:10:21,000
la solidaridad que sienten

203
0:10:22.54,000 --> 0:10:25,000
es mayor por ese puente que tuvieron que cruzar, ¿verdad?

204
0:10:27.1,000 --> 0:10:28,000
Y recuerden que en estas películas

205
0:10:29.1,000 --> 0:10:31,000
normalmente el peor es el segundo acto

206
0:10:32.02,000 --> 0:10:34,000
cuando ambas direcciones están más separadas que nunca.

207
0:10:35.26,000 --> 0:10:37,000
A lo mejor es ahí donde estamos en este país;

208
0:10:37.62,000 --> 0:10:39,000
al final del segundo acto en una película de policías

209
0:10:39.82,000 --> 0:10:41,000
(Risas)

210
0:10:42.42,000 --> 0:10:45,000
divididos pero a punto de ponernos de acuerdo.

211
0:10:47.22,000 --> 0:10:48,000
Suena bien,

212
0:10:48.9,000 --> 0:10:49,000
pero si queremos que pase,

213
0:10:50.78,000 --> 0:10:52,000
creo que la responsabilidad es nuestra.

214
0:10:54.34,000 --> 0:10:56,000
Por eso les pido:

215
0:10:57.3,000 --> 0:10:59,000
unamos otra vez a este país.

216
0:11:00.9,000 --> 0:11:03,000
Hagámoslo a pesar de los políticos,

217
0:11:03.98,000 --> 0:11:05,000
los medios, Facebook, Twitter,

218
0:11:06.86,000 --> 0:11:07,000
la división distrital del Congreso

219
0:11:08.42,000 --> 0:11:1,000
y todo eso, todo lo que nos divide.

220
0:11:12.18,000 --> 0:11:14,000
Hagámoslo porque es lo correcto.

221
0:11:15.74,000 --> 0:11:19,000
Y hagámoslo porque este odio y este desprecio

222
0:11:20.18,000 --> 0:11:22,000
que fluye a través de nosotros cada día

223
0:11:23.22,000 --> 0:11:26,000
nos afea y nos corrompe

224
0:11:26.42,000 --> 0:11:29,000
y amenaza al propio tejido de nuestra sociedad.

225
0:11:31.78,000 --> 0:11:33,000
Nos debemos los unos a los otros y a nuestro país

226
0:11:34.46,000 --> 0:11:36,000
tender la mano e intentar conectar.

227
0:11:37.82,000 --> 0:11:4,000
No podemos permitirnos odiarlos más,

228
0:11:42.02,000 --> 0:11:44,000
y no podemos permitirnos dejarles odiarnos tampoco.

229
0:11:45.7,000 --> 0:11:46,000
Empatía y respeto.

230
0:11:47.7,000 --> 0:11:48,000
Empatía y respeto.

231
0:11:49.74,000 --> 0:11:52,000
Si lo piensan, es lo mínimo que les debemos a nuestros conciudadanos.

232
0:11:54.22,000 --> 0:11:55,000
Gracias.

233
0:11:55.46,000 --> 0:11:58,000
(Aplausos)

