1
0:00:,000 --> 0:00:07,000
Traductor: Florencia Bracamonte Revisor: Sebastian Betti

2
0:00:13.675,000 --> 0:00:15,000
Belle Gibson era una feliz joven australiana.

3
0:00:16.619,000 --> 0:00:19,000
Vivía en Perth y le encantaba andar en patineta.

4
0:00:20.173,000 --> 0:00:23,000
Pero en 2009, Belle descubrió que tenía un tumor cerebral

5
0:00:23.254,000 --> 0:00:24,000
y cuatro meses de vida.

6
0:00:25.245,000 --> 0:00:28,000
Dos meses de quimioterapia y radioterapia no dieron resultado.

7
0:00:29.139,000 --> 0:00:32,000
Pero Belle estaba decidida. Había sido una luchadora toda la vida.

8
0:00:32.783,000 --> 0:00:35,000
Desde los seis años cocinaba para su hermano, que tenía autismo,

9
0:00:36.091,000 --> 0:00:38,000
y para su mamá, que tenía esclerosis múltiple.

10
0:00:38.569,000 --> 0:00:4,000
Su padre no estaba en la ecuación.

11
0:00:40.736,000 --> 0:00:43,000
Así que Belle luchó: se ejercitó, hizo meditación

12
0:00:44.006,000 --> 0:00:46,000
y cambió la carne por frutas y vegetales.

13
0:00:46.977,000 --> 0:00:48,000
Y se recuperó totalmente.

14
0:00:50.784,000 --> 0:00:51,000
La historia de Belle se hizo viral.

15
0:00:52.473,000 --> 0:00:55,000
Se compartió en Twitter, en blogs y llegó a millones de personas.

16
0:00:56.246,000 --> 0:00:59,000
Mostraba los beneficios de reemplazar la medicina tradicional

17
0:00:59.381,000 --> 0:01:,000
por dieta y ejercicios.

18
0:01:01.381,000 --> 0:01:02,000
En agosto del 2013,

19
0:01:03.063,000 --> 0:01:07,000
Belle lanzó la aplicación sobre alimentación saludable: the Whole Pantry,

20
0:01:07.236,000 --> 0:01:11,000
que fue descargada unas 200 000 veces durante el primer mes.

21
0:01:13.228,000 --> 0:01:16,000
Pero la historia de Belle era mentira.

22
0:01:17.227,000 --> 0:01:19,000
Belle nunca tuvo cáncer.

23
0:01:19.601,000 --> 0:01:23,000
La gente compartió su historia sin corroborar si era verdadera.

24
0:01:24.815,000 --> 0:01:27,000
Esto es un ejemplo típico del 'sesgo de confirmación'.

25
0:01:28.403,000 --> 0:01:3,000
Aceptamos una historia sin pensar demasiado,

26
0:01:31.074,000 --> 0:01:33,000
si esta confirma lo que quisiéramos que fuera verdad.

27
0:01:33.577,000 --> 0:01:35,000
Y rechazamos toda historia que la contradiga.

28
0:01:36.866,000 --> 0:01:37,000
¿Qué tan a menudo sucede esto

29
0:01:38.711,000 --> 0:01:41,000
con las historias que compartimos y con las que ignoramos?

30
0:01:41.961,000 --> 0:01:45,000
En el área de la política, los negocios y la salud.

31
0:01:47.068,000 --> 0:01:51,000
La nueva palabra del diccionario Oxford en el 2016 fue "posverdad".

32
0:01:51.722,000 --> 0:01:54,000
Y la aceptación de que actualmente vivimos en un mundo posverdad

33
0:01:55.375,000 --> 0:01:58,000
ha provocado una gran necesidad de corroborar los hechos.

34
0:01:59.177,000 --> 0:02:,000
Pero lo importante de mi presentación

35
0:02:00.947,000 --> 0:02:03,000
es que simplemente corroborar los hechos no es suficiente.

36
0:02:04.222,000 --> 0:02:06,000
Incluso si la historia de Belle fuera verdadera,

37
0:02:07.291,000 --> 0:02:09,000
sería igualmente irrelevante.

38
0:02:10.203,000 --> 0:02:11,000
¿Por qué?

39
0:02:12.039,000 --> 0:02:15,000
Veamos una de las técnicas más importantes de la estadística.

40
0:02:15.489,000 --> 0:02:17,000
Se denomina inferencia bayesiana.

41
0:02:18.251,000 --> 0:02:2,000
Y su versión más simple es la siguiente:

42
0:02:21.191,000 --> 0:02:24,000
Nos preocupamos por: "¿La información respalda la teoría?

43
0:02:25.053,000 --> 0:02:29,000
¿La información aumenta nuestra creencia de que la teoría es verdadera?"

44
0:02:29.52,000 --> 0:02:33,000
En cambio, nos preguntamos: "¿Es la información consistente con la teoría?"

45
0:02:34.838,000 --> 0:02:39,000
Ser consistente con la teoría no significa que la información respalde la teoría.

46
0:02:40.846,000 --> 0:02:41,000
¿Por qué?

47
0:02:42.083,000 --> 0:02:45,000
Debido a un tercer factor crucial pero olvidado:

48
0:02:45.752,000 --> 0:02:48,000
la información también podría ser consistente con teorías opuestas.

49
0:02:49.88,000 --> 0:02:53,000
Pero a causa del sesgo de confirmación nunca consideramos las teorías opuestas,

50
0:02:54.522,000 --> 0:02:57,000
por proteger nuestra teoría personal.

51
0:02:58.58,000 --> 0:03:,000
Consideremos esto en relación a la historia de Belle.

52
0:03:01.081,000 --> 0:03:04,000
Nos preocupamos por: "La historia de Belle ¿respalda la teoría

53
0:03:05.089,000 --> 0:03:06,000
de que las dietas curan el cáncer?"

54
0:03:06.916,000 --> 0:03:07,000
En cambio, terminamos preguntándonos:

55
0:03:08.736,000 --> 0:03:12,000
"La historia de Belle ¿es consistente con que las dietas curan el cáncer?"

56
0:03:13.665,000 --> 0:03:14,000
La respuesta es sí.

57
0:03:15.754,000 --> 0:03:19,000
Si las dietas curaran el cáncer veríamos historias como la de Belle.

58
0:03:20.511,000 --> 0:03:22,000
Pero incluso si las dietas no curaran el cáncer

59
0:03:23.368,000 --> 0:03:25,000
veríamos historias como la de Belle.

60
0:03:26.675,000 --> 0:03:3,000
Una única historia en la que un paciente, aparentemente,

61
0:03:31.595,000 --> 0:03:34,000
se cura solo por haber sido mal diagnosticado.

62
0:03:35.442,000 --> 0:03:38,000
De forma similar, incluso si fumar es malo para la salud,

63
0:03:38.756,000 --> 0:03:41,000
aun así veríamos la historia de un fumador que vivió hasta los 100 años.

64
0:03:42.716,000 --> 0:03:43,000
(Risas)

65
0:03:44.084,000 --> 0:03:46,000
De forma similar, si la educación es buena para el salario,

66
0:03:46.899,000 --> 0:03:48,000
aun así veríamos historias de algún multimillonario

67
0:03:49.464,000 --> 0:03:51,000
que no fue a la universidad.

68
0:03:51.504,000 --> 0:03:53,000
(Risas)

69
0:03:56.508,000 --> 0:03:59,000
El principal problema con la historia de Belle no es que era falsa.

70
0:03:59.977,000 --> 0:04:01,000
Sino que es solamente una historia.

71
0:04:03.094,000 --> 0:04:07,000
Puede que haya miles de otras historias en las que la dieta no funcionó,

72
0:04:07.435,000 --> 0:04:09,000
pero no llegan a nosotros.

73
0:04:09.913,000 --> 0:04:13,000
Compartimos las historias atípicas porque son novedosas y, por ende,

74
0:04:14.714,000 --> 0:04:15,000
son noticia.

75
0:04:16.438,000 --> 0:04:18,000
Nunca compartimos los casos comunes.

76
0:04:19.098,000 --> 0:04:22,000
Son demasiado comunes, son lo que comúnmente sucede.

77
0:04:23.002,000 --> 0:04:26,000
Y ese es el verdadero 99 % que ignoramos.

78
0:04:26.145,000 --> 0:04:3,000
No deberían prestar atención solo al 1 % de las historias atípicas

79
0:04:30.254,000 --> 0:04:32,000
e ignorar el 99 % de las historias más frecuentes.

80
0:04:33.706,000 --> 0:04:36,000
Porque ese es el segundo ejemplo del sesgo de confirmación:

81
0:04:37.292,000 --> 0:04:4,000
aceptamos un hecho como información.

82
0:04:40.729,000 --> 0:04:44,000
El principal problema no es que vivamos en un mundo posverdad,

83
0:04:45.138,000 --> 0:04:49,000
sino que vivimos en un mundo posinformación.

84
0:04:49.649,000 --> 0:04:53,000
Preferimos una única historia, antes que toneladas de información.

85
0:04:54.549,000 --> 0:04:56,000
Las historias son poderosas, son vívidas, cobran vida.

86
0:04:57.518,000 --> 0:04:59,000
Se aconseja comenzar cada charla con una historia.

87
0:04:59.862,000 --> 0:05:,000
Yo lo hice.

88
0:05:01.394,000 --> 0:05:05,000
Pero una única historia es absurda y engañosa

89
0:05:06.056,000 --> 0:05:1,000
a menos que sea respaldada por información a gran escala.

90
0:05:11.047,000 --> 0:05:13,000
Incluso si tenemos información a gran escala,

91
0:05:13.507,000 --> 0:05:15,000
puede que todavía no sea suficiente.

92
0:05:16.077,000 --> 0:05:19,000
Porque aún podría ser consistente con teóricas opuestas.

93
0:05:20.045,000 --> 0:05:21,000
Lo explicaré:

94
0:05:21.822,000 --> 0:05:24,000
Un estudio conocido, realizado por el psicólogo Peter Wason,

95
0:05:25.292,000 --> 0:05:3,000
presenta un grupo de tres números y pide determinar la regla que los generó.

96
0:05:30.454,000 --> 0:05:36,000
Entonces, si tenemos 2, 4 y 6, ¿cuál es la regla?

97
0:05:36.749,000 --> 0:05:39,000
La mayoría de la gente determinaría que se trata de números pares sucesivos.

98
0:05:40.515,000 --> 0:05:42,000
¿Cómo se pondría a prueba?

99
0:05:42.581,000 --> 0:05:45,000
Se propone otro grupo de números pares sucesivos:

100
0:05:45.736,000 --> 0:05:48,000
4, 6 y 8 o 12, 14 y 16.

101
0:05:49.438,000 --> 0:05:52,000
Y, según Peter, este segundo grupo también cumple la regla.

102
0:05:52.816,000 --> 0:05:54,000
Pero saber que este grupo también cumple la regla,

103
0:05:55.438,000 --> 0:05:59,000
que quizá cientos de grupos de números sucesivos cumplan la regla,

104
0:06:00.138,000 --> 0:06:01,000
no nos indica nada.

105
0:06:02.271,000 --> 0:06:05,000
Porque aún es consistente con teorías opuestas.

106
0:06:06.869,000 --> 0:06:09,000
Quizá la regla sea "cualquier grupo de 3 números pares".

107
0:06:10.799,000 --> 0:06:12,000
O "cualquier grupo de 3 números crecientes".

108
0:06:13.842,000 --> 0:06:16,000
Y ése es el tercer ejemplo del sesgo de confirmación:

109
0:06:17.473,000 --> 0:06:2,000
aceptar información como evidencia,

110
0:06:20.977,000 --> 0:06:22,000
incluso si es consistente con teorías opuestas.

111
0:06:24.63,000 --> 0:06:27,000
La información es un conjunto de hechos.

112
0:06:27.996,000 --> 0:06:33,000
La evidencia es información que respalda una teoría y descarta las demás.

113
0:06:34.386,000 --> 0:06:36,000
Por lo que la mejor forma de respaldar tu teoría

114
0:06:36.898,000 --> 0:06:39,000
es, de hecho, intentar refutarla, hacer de abogado del diablo.

115
0:06:41.328,000 --> 0:06:46,000
Pongan a prueba algo como 4, 12 y 26.

116
0:06:46.837,000 --> 0:06:52,000
Si la respuesta es 'sí', su teoría de números pares sucesivos sería refutada.

117
0:06:52.945,000 --> 0:06:54,000
Sin embargo, esta prueba es importante,

118
0:06:55.238,000 --> 0:06:57,000
porque si la respuesta es 'no', descartarían

119
0:06:58.032,000 --> 0:07:02,000
"cualquier grupo de 3 números pares" y "cualquier grupo de 3 números crecientes".

120
0:07:02.125,000 --> 0:07:05,000
Se descartarían las teorías opuestas, pero no la suya.

121
0:07:05.717,000 --> 0:07:09,000
Pero la mayoría de la gente teme poner a prueba algo como 4, 12 y 26,

122
0:07:10.712,000 --> 0:07:14,000
porque no quieren obtener un 'sí' y confirmar que su teoría no es verdadera.

123
0:07:16.477,000 --> 0:07:22,000
El sesgo de confirmación no solo refiere a no querer buscar nueva información,

124
0:07:22.541,000 --> 0:07:25,000
también refiere a la interpretación errónea de la información que se recibe.

125
0:07:26.117,000 --> 0:07:3,000
Esto se aplica fuera del laboratorio, a problemas importantes del mundo real.

126
0:07:30.133,000 --> 0:07:32,000
Thomas Edison dijo una vez:

127
0:07:32.931,000 --> 0:07:38,000
"No he fracasado, sino que he encontrado 10 000 formas en que eso no funciona".

128
0:07:39.9,000 --> 0:07:44,000
Admitir que estás equivocado es la única forma de descubrir qué es lo verdadero.

129
0:07:46.473,000 --> 0:07:49,000
Supongamos que eres el director del ingreso a la universidad

130
0:07:49.714,000 --> 0:07:51,000
y tu teoría es que únicamente a los alumnos con notas altas

131
0:07:52.697,000 --> 0:07:53,000
y de familias ricas les va bien.

132
0:07:54.61,000 --> 0:07:57,000
Limitas el ingreso a ese tipo de estudiantes y les va bien.

133
0:07:58.454,000 --> 0:08:01,000
Pero eso también es consistente con la teoría opuesta.

134
0:08:01.634,000 --> 0:08:05,000
Quizá a todos los estudiantes con buenas notas les va bien, ricos y pobres.

135
0:08:06.124,000 --> 0:08:1,000
Pero nunca pones a prueba esa teoría por no permitir el ingreso a alumnos pobres

136
0:08:10.447,000 --> 0:08:12,000
porque no quieres que se pruebe que estás equivocado.

137
0:08:14.327,000 --> 0:08:16,000
Entonces, ¿qué hemos aprendido?

138
0:08:17.058,000 --> 0:08:21,000
Una historia no constituye un hecho, ya que puede no ser verdadera.

139
0:08:21.485,000 --> 0:08:23,000
Un hecho no constituye información,

140
0:08:23.799,000 --> 0:08:27,000
ya que puede no ser representativo, si es un hecho atípico.

141
0:08:28.43,000 --> 0:08:3,000
Y la información no es evidencia,

142
0:08:30.779,000 --> 0:08:34,000
ya que puede no estar fundamentada si es consistente con teorías opuestas.

143
0:08:36.138,000 --> 0:08:38,000
Entonces, ¿qué hacer?

144
0:08:39.214,000 --> 0:08:42,000
Cuando atraviesan un momento importante en la vida,

145
0:08:42.308,000 --> 0:08:46,000
al decidir una estrategia para su negocio, cómo criar a sus hijos,

146
0:08:47.337,000 --> 0:08:49,000
o cómo mantener una buena salud,

147
0:08:49.673,000 --> 0:08:52,000
¿cómo asegurarse de que no se están guiando por una historia

148
0:08:52.847,000 --> 0:08:54,000
sino por la evidencia?

149
0:08:56.018,000 --> 0:08:57,000
Permítanme darles tres pistas.

150
0:08:58.472,000 --> 0:09:01,000
En primer lugar: busquen otras opiniones.

151
0:09:02.375,000 --> 0:09:06,000
Lean y escuchen a gente con la que no estén de acuerdo en lo absoluto.

152
0:09:06.379,000 --> 0:09:09,000
90 % de lo que ellos dicen será errado, según su postura personal.

153
0:09:10.52,000 --> 0:09:12,000
Pero ¿y si el 10 % es verdadero?

154
0:09:13.761,000 --> 0:09:16,000
Como dijo Aristóteles: "La característica de un hombre educado

155
0:09:17.754,000 --> 0:09:23,000
es la habilidad de considerar una idea, sin necesariamente aceptarla".

156
0:09:24.433,000 --> 0:09:3,000
Rodéense de gente que los motive y creen un ambiente que incentive el disenso.

157
0:09:31.047,000 --> 0:09:34,000
Algunos bancos padecieron el pensamiento de grupo, en el que los trabajadores

158
0:09:34.967,000 --> 0:09:36,000
tenían miedo de cuestionar las decisiones de la administración

159
0:09:37.883,000 --> 0:09:4,000
respecto a los préstamos, y esto contribuyó a la crisis financiera.

160
0:09:41.022,000 --> 0:09:45,000
En las reuniones, designen a alguien para que haga de defensor del diablo

161
0:09:45.258,000 --> 0:09:47,000
contra sus ideas personales.

162
0:09:47.609,000 --> 0:09:49,000
Y no es simplemente escuchar otras opiniones,

163
0:09:50.041,000 --> 0:09:52,000
hay que prestarles atención.

164
0:09:53.133,000 --> 0:09:58,000
Como el psicólogo Stephen Covey dijo: "Escucha con la intención de entender,

165
0:09:58.947,000 --> 0:10:,000
no con la intención de responder".

166
0:10:01.687,000 --> 0:10:04,000
Un punto de vista contrario es algo de lo que puede aprenderse,

167
0:10:04.908,000 --> 0:10:06,000
no solamente discutirse.

168
0:10:07.628,000 --> 0:10:11,000
Esto nos lleva a otro factor olvidado de la inferencia bayesiana.

169
0:10:12.022,000 --> 0:10:14,000
La información te permite aprender,

170
0:10:14.506,000 --> 0:10:17,000
pero el aprendizaje es relativo a un punto de inicio.

171
0:10:18.085,000 --> 0:10:23,000
Si comienzan con total certeza de que su teoría personal debe ser verdadera,

172
0:10:23.785,000 --> 0:10:24,000
entonces su opinión no cambiará,

173
0:10:25.772,000 --> 0:10:27,000
independientemente de la información que encuentren.

174
0:10:28.641,000 --> 0:10:32,000
Solamente si están en verdad abiertos a la posibilidad de estar equivocados,

175
0:10:33.056,000 --> 0:10:34,000
podrán aprender.

176
0:10:35.58,000 --> 0:10:37,000
Como León Tolstói escribió:

177
0:10:37.698,000 --> 0:10:42,000
"Los temas más difíciles pueden explicársele al hombre más torpe

178
0:10:42.93,000 --> 0:10:45,000
si él no se ha formado todavía ninguna idea de ellos;

179
0:10:46.115,000 --> 0:10:5,000
pero ni aun lo más sencillo puede aclarársele al hombre más inteligente

180
0:10:51.058,000 --> 0:10:55,000
si él está firmemente convencido de que ya conoce todo".

181
0:10:56.5,000 --> 0:10:59,000
Segunda pista: escuchen a los expertos.

182
0:11:01.04,000 --> 0:11:04,000
Puede que este sea el consejo menos popular para dar.

183
0:11:04.692,000 --> 0:11:05,000
(Risas)

184
0:11:05.806,000 --> 0:11:09,000
El político británico Michael Gove dijo que la gente en este país

185
0:11:10.562,000 --> 0:11:12,000
ya había escuchado suficiente a los expertos.

186
0:11:13.696,000 --> 0:11:17,000
Una encuesta reciente muestra que la gente confiaría más en sus peluqueros,

187
0:11:17.984,000 --> 0:11:18,000
(Risas)

188
0:11:19.477,000 --> 0:11:2,000
o en algún desconocido en la calle

189
0:11:21.43,000 --> 0:11:25,000
que en los líderes de industria, de la salud o, incluso, de entidades benéficas.

190
0:11:26.227,000 --> 0:11:3,000
Respetamos la fórmula de blanqueamiento dental descubierta por una mamá,

191
0:11:30.234,000 --> 0:11:33,000
escuchamos la opinión de una actriz respecto a la vacunación.

192
0:11:33.45,000 --> 0:11:36,000
Nos gusta la gente que explica en términos sencillos, les hacemos casos,

193
0:11:36.845,000 --> 0:11:38,000
y los llamamos 'auténticos'.

194
0:11:38.859,000 --> 0:11:41,000
Pero la intuición no es suficiente.

195
0:11:42.736,000 --> 0:11:46,000
La intuición sugería no dar agua a un bebé con diarrea,

196
0:11:47.166,000 --> 0:11:49,000
porque simplemente la expulsaría.

197
0:11:49.564,000 --> 0:11:52,000
El conocimiento experto indica lo contrario.

198
0:11:53.149,000 --> 0:11:56,000
Nunca le confiarían al extraño de la calle su cirugía.

199
0:11:56.887,000 --> 0:11:59,000
Querrían un experto, que ha pasado años realizando cirugías

200
0:12:00.498,000 --> 0:12:02,000
y conoce las mejores técnicas.

201
0:12:03.514,000 --> 0:12:06,000
Y debería ser así con todas sus decisiones.

202
0:12:07.255,000 --> 0:12:13,000
La política, los negocios, la salud requieren conocimiento experto,

203
0:12:13.321,000 --> 0:12:15,000
al igual que una cirugía.

204
0:12:16.154,000 --> 0:12:2,000
Entonces, ¿por qué desconfiamos tanto de los expertos?

205
0:12:20.981,000 --> 0:12:23,000
Una razón es que no se los considera involucrados:

206
0:12:24.27,000 --> 0:12:28,000
Un CEO millonario seguramente no sabe nada del hombre promedio.

207
0:12:29.455,000 --> 0:12:32,000
Pero el verdadero conocimiento experto se basa en la evidencia.

208
0:12:33.447,000 --> 0:12:37,000
Y la evidencia protege al hombre promedio de la élite.

209
0:12:38.456,000 --> 0:12:4,000
Porque la evidencia los obliga a corroborarla.

210
0:12:41.774,000 --> 0:12:46,000
La evidencia evita que la élite pueda imponerles sus ideas sin tener pruebas.

211
0:12:48.956,000 --> 0:12:5,000
Una segunda razón por la que no se confía en los expertos

212
0:12:51.627,000 --> 0:12:53,000
es que distintos expertos dicen cosas distintas.

213
0:12:54.248,000 --> 0:12:58,000
Por cada experto que afirmaba que dejar la UE sería malo para Gran Bretaña,

214
0:12:58.652,000 --> 0:13:,000
aparecía otro que afirmaba que sería algo bueno.

215
0:13:01.211,000 --> 0:13:05,000
La mitad de estos supuestos expertos va a estar equivocado.

216
0:13:05.774,000 --> 0:13:08,000
Y debo admitir que la mayoría de los artículos escritos por expertos

217
0:13:09.62,000 --> 0:13:1,000
están equivocados.

218
0:13:10.85,000 --> 0:13:13,000
O, en el mejor de los casos, hacen afirmaciones que la evidencia no respalda.

219
0:13:14.986,000 --> 0:13:17,000
Así que no podemos confiar ciegamente en los expertos.

220
0:13:18.737,000 --> 0:13:23,000
En noviembre de 2016, un estudio sobre el salario de los ejecutivos

221
0:13:23.759,000 --> 0:13:24,000
llegó a los titulares nacionales,

222
0:13:25.389,000 --> 0:13:29,000
a pesar de que ninguno de los medios que escribió sobre el estudio lo había leído.

223
0:13:30.548,000 --> 0:13:32,000
Ni siquiera estaba publicado.

224
0:13:32.908,000 --> 0:13:36,000
Simplemente confiaron en la palabra del autor, como pasó con Belle.

225
0:13:38.093,000 --> 0:13:41,000
Esto tampoco significa que podemos escoger cualquier estudio que respalde

226
0:13:41.649,000 --> 0:13:44,000
nuestras opiniones; eso sería un sesgo de confirmación.

227
0:13:44.715,000 --> 0:13:48,000
Tampoco significa que si siete estudios presentan A y tres estudios, B,

228
0:13:48.906,000 --> 0:13:5,000
entonces A debe ser verdadero.

229
0:13:51.109,000 --> 0:13:57,000
Lo que importa es la calidad y no la cantidad del conocimiento experto.

230
0:13:57.879,000 --> 0:13:59,000
Entonces deberíamos hacer dos cosas:

231
0:14:00.434,000 --> 0:14:04,000
primero, examinar críticamente las credenciales de los autores.

232
0:14:05.807,000 --> 0:14:09,000
Así como examinarían críticamente las credenciales de un potencial cirujano.

233
0:14:10.347,000 --> 0:14:15,000
¿Son verdaderos expertos en la materia? ¿O tienen otros intereses prefijados?

234
0:14:16.243,000 --> 0:14:18,000
Segundo: deberíamos prestar especial atención

235
0:14:18.988,000 --> 0:14:22,000
a los trabajos publicados en las revistas científicas más prestigiosas.

236
0:14:23.775,000 --> 0:14:25,000
Es verdad que a los científicos usualmente se los acusa

237
0:14:26.378,000 --> 0:14:28,000
de estar divorciados del mundo real.

238
0:14:28.689,000 --> 0:14:31,000
Pero esa separación les otorga años para dedicarse a sus estudios,

239
0:14:32.365,000 --> 0:14:35,000
para realmente llegar a resultados, descartar todas las teorías opuestas

240
0:14:36.307,000 --> 0:14:39,000
y para distinguir la correlación de la causalidad.

241
0:14:40.172,000 --> 0:14:43,000
Las revistas científicas tienen revisión de pares.

242
0:14:43.583,000 --> 0:14:45,000
Esto significa que cada artículo es rigurosamente escrutado

243
0:14:46.357,000 --> 0:14:47,000
(Risas)

244
0:14:47.414,000 --> 0:14:49,000
por los expertos en el área.

245
0:14:50.434,000 --> 0:14:52,000
Las mejores revistas científicas tienen altos estándares.

246
0:14:53.19,000 --> 0:14:58,000
Las revistas élite rechazan el 95 % de los artículos.

247
0:14:59.434,000 --> 0:15:02,000
La evidencia científica no es todo.

248
0:15:03.109,000 --> 0:15:05,000
La experiencia en el mundo real también es crítica.

249
0:15:06.465,000 --> 0:15:09,000
Y la revisión de pares no es perfecta, se comenten errores.

250
0:15:10.53,000 --> 0:15:14,000
Pero es mejor confiar en algo revisado que en algo no revisado.

251
0:15:14.696,000 --> 0:15:17,000
Si nos limitamos a un estudio porque nos gustan sus resultados

252
0:15:17.955,000 --> 0:15:2,000
y no consideramos quién lo escribió o si fue revisado,

253
0:15:21.801,000 --> 0:15:24,000
hay una gran probabilidad de que ese estudio sea engañoso.

254
0:15:26.894,000 --> 0:15:28,000
Y quienes afirmemos ser expertos

255
0:15:29.514,000 --> 0:15:32,000
deberíamos reconocer las limitaciones de nuestros análisis.

256
0:15:33.244,000 --> 0:15:37,000
Es muy raro poder predecir o probar algo con absoluta certeza,

257
0:15:38.292,000 --> 0:15:42,000
y aun así es tan tentador hacer una afirmación desinformada.

258
0:15:43.069,000 --> 0:15:47,000
Es más sencillo así llegar a los titulares o a los 140 caracteres de Twitter.

259
0:15:48.417,000 --> 0:15:51,000
Pero incluso la evidencia puede no ser prueba suficiente.

260
0:15:52.481,000 --> 0:15:56,000
Puede no ser generalizable, quizá no pueda aplicarse a otros contextos.

261
0:15:57.252,000 --> 0:16:01,000
Entonces no afirmen "los que toman vino tinto viven más",

262
0:16:02.196,000 --> 0:16:05,000
cuando la evidencia sugiere solamente que existe una correlación

263
0:16:05.439,000 --> 0:16:06,000
entre el vino tinto y una vida más larga,

264
0:16:07.418,000 --> 0:16:09,000
y únicamente en personas que se ejercitan.

265
0:16:12.089,000 --> 0:16:16,000
Tercer pista: haz una pausa antes de compartir algo.

266
0:16:16.726,000 --> 0:16:19,000
El juramento hipocrático dice: "No lastimaré a nadie".

267
0:16:20.714,000 --> 0:16:23,000
Lo que compartimos es potencialmente contagioso,

268
0:16:24.197,000 --> 0:16:28,000
por lo que hay que ser muy cuidadosos con lo que divulgamos.

269
0:16:28.278,000 --> 0:16:31,000
Nuestro objetivo no debería ser conseguir 'me gusta' y retuits.

270
0:16:31.619,000 --> 0:16:35,000
Porque así solo compartimos el consenso, no cuestionamos la mentalidad de nadie.

271
0:16:35.956,000 --> 0:16:38,000
De esa forma solo compartimos lo que suena lindo,

272
0:16:39.003,000 --> 0:16:41,000
sin importar si está sustentado con evidencia.

273
0:16:42.093,000 --> 0:16:44,000
En vez de eso, deberíamos preguntarnos:

274
0:16:45.465,000 --> 0:16:47,000
Si es una historia, ¿es verdad?

275
0:16:47.841,000 --> 0:16:49,000
Si es verdad, ¿está sustentada con evidencia a gran escala?

276
0:16:50.716,000 --> 0:16:52,000
Si es así, ¿quién la escribió? ¿Cuáles son sus credenciales?

277
0:16:53.683,000 --> 0:16:55,000
¿Está publicada? ¿Qué tan rigurosa es la revista científica?

278
0:16:56.85,000 --> 0:17:,000
Y háganse la pregunta del millón: si la misma historia fuera escrita

279
0:17:01.44,000 --> 0:17:04,000
por los mismos autores, con las mismas credenciales,

280
0:17:05.218,000 --> 0:17:07,000
pero arribase a resultados diferentes,

281
0:17:07.764,000 --> 0:17:11,000
¿aún estarían dispuestos a creerla y a compartirla?

282
0:17:13.092,000 --> 0:17:17,000
Abordar cualquier problema, ya sea un problema económico de una nación

283
0:17:17.702,000 --> 0:17:2,000
o un problema de salud de una persona, es difícil.

284
0:17:21.255,000 --> 0:17:25,000
Debemos asegurarnos de que tenemos la mejor evidencia para orientarnos.

285
0:17:26.471,000 --> 0:17:28,000
Solamente si es verdadero puede considerarse un hecho.

286
0:17:29.569,000 --> 0:17:32,000
Solamente si es representativo puede considerarse información.

287
0:17:32.867,000 --> 0:17:35,000
Solamente si está sustentado puede considerarse evidencia.

288
0:17:36.2,000 --> 0:17:4,000
Y solamente con evidencia podemos avanzar de un mundo posverdad

289
0:17:41.133,000 --> 0:17:43,000
a un mundo proverdad.

290
0:17:44.051,000 --> 0:17:45,000
Muchas gracias.

291
0:17:45.443,000 --> 0:17:49,000
(Aplausos)

