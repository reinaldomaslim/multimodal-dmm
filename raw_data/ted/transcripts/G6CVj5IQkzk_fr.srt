1
0:00:,000 --> 0:00:07,000
Traducteur: Hugues Marty Relecteur: Salome Hevin

2
0:00:25,000 --> 0:00:28,000
Je fais deux choses. Je conçois des ordinateurs portables, et j'étudie le cerveau.

3
0:00:29,000 --> 0:00:31,000
La conférence d'aujourd'hui parlera du cerveau, et

4
0:00:31,000 --> 0:00:33,000
super, il y a un fan des cerveaux dans la salle !

5
0:00:33,000 --> 0:00:35,000
(Rires)

6
0:00:35,000 --> 0:00:37,000
Maintenant, si on peut afficher mon premier slide là-haut,

7
0:00:37,000 --> 0:00:41,000
vous verrez le titre de ma conférence et mes deux affiliations.

8
0:00:41,000 --> 0:00:45,000
Donc, mon sujet sera la raison pour laquelle on n'a pas de bonne théorie de cerveau,

9
0:00:45,000 --> 0:00:48,000
pourquoi il est important qu'on en développe une, et ce qu'on peut faire pour ça.

10
0:00:48,000 --> 0:00:51,000
Et j'essayerai de faire tout ça en 20 minutes. J'ai deux affiliations.

11
0:00:51,000 --> 0:00:54,000
La plupart d'entre vous me connaissent par mon travail chez Palm et Handsprings,

12
0:00:54,000 --> 0:00:57,000
mais je gère aussi un institut de recherche à but non lucratif,

13
0:00:57,000 --> 0:00:59,000
appelé "Redwood Neuroscience Institute", à Menlo Park,

14
0:00:59,000 --> 0:01:01,000
où on étudie la neuroscience théorique

15
0:01:01,000 --> 0:01:03,000
et comment fonctionne le néocortex.

16
0:01:03,000 --> 0:01:05,000
C'est de cela en particulier que je vais parler.

17
0:01:05,000 --> 0:01:08,000
J'ai un slide qui concerne mon autre vie, ma vie informatique, c'est celui-là.

18
0:01:08,000 --> 0:01:11,000
Voici quelques uns des produits sur lesquels j'ai travaillé ces 20 dernières années,

19
0:01:11,000 --> 0:01:15,000
du tout premier ordinateur portable à certaines des premières tablettes informatiques,

20
0:01:15,000 --> 0:01:17,000
et ainsi de suite jusqu'au Treo le plus récemment,

21
0:01:17,000 --> 0:01:19,000
et on continue à travailler dessus.

22
0:01:19,000 --> 0:01:21,000
J'ai fait cela car je crois vraiment que l'informatique mobile

23
0:01:21,000 --> 0:01:24,000
est le futur de l'informatique personnelle, et j'essaie de rendre le monde

24
0:01:24,000 --> 0:01:27,000
un peu meilleur en travaillant sur ces choses.

25
0:01:27,000 --> 0:01:29,000
Mais tout cela était, je dois l'avouer, totalement un accident.

26
0:01:29,000 --> 0:01:31,000
En fait, je ne voulais faire aucun de ces produits

27
0:01:31,000 --> 0:01:33,000
et très tôt dans ma carrière j'ai décidé

28
0:01:33,000 --> 0:01:36,000
que je n'irais pas dans l'industrie informatique.

29
0:01:36,000 --> 0:01:38,000
Et avant que je ne vous raconte ça, il faut juste que je vous parle

30
0:01:38,000 --> 0:01:4,000
de cette petite image de graffiti que j'ai récupéré sur Internet l'autre jour.

31
0:01:4,000 --> 0:01:43,000
Je cherchais une image de graffiti, un petit langage de saisie de texte,

32
0:01:43,000 --> 0:01:46,000
et j'ai trouvé le site dédié aux enseignants qui veulent en faire,

33
0:01:46,000 --> 0:01:49,000
vous savez, le script qui écrit des choses en haut de leur tableau,

34
0:01:49,000 --> 0:01:52,000
et ils y avaient ajouté des graffiti, ce dont je suis désolé.

35
0:01:52,000 --> 0:01:54,000
(Rires)

36
0:01:54,000 --> 0:01:59,000
Donc, ce qui c'est passé, c'est que dans ma jeunesse, après être sorti de l'école d'ingénieur

37
0:01:59,000 --> 0:02:03,000
Cornell en 1979, j'ai décidé d'aller travailler pour Intel.

38
0:02:03,000 --> 0:02:06,000
J'étais dans l'industrie informatique, et au bout de trois mois là-dedans,

39
0:02:06,000 --> 0:02:1,000
je suis tombé amoureux d'autre chose, et je me suis dit: "Je me suis trompé de carrière",

40
0:02:1,000 --> 0:02:13,000
et je suis tombé amoureux des cerveaux.

41
0:02:13,000 --> 0:02:16,000
Ça n'est pas un vrai cerveau. C'est une image, un dessin.

42
0:02:16,000 --> 0:02:19,000
Je ne me souviens pas exactement comment ça s'est passé,

43
0:02:19,000 --> 0:02:22,000
mais j'ai un souvenir, assez net dans mon esprit.

44
0:02:22,000 --> 0:02:25,000
En septembre 1979, le magazine Scientific American

45
0:02:25,000 --> 0:02:28,000
avec un numéro spécial sur le cerveau. Et il était assez bon.

46
0:02:28,000 --> 0:02:31,000
Ce fut l'un de leurs meilleurs numéros. Ils parlaient de neurones,

47
0:02:31,000 --> 0:02:33,000
du leurs développement et de leurs maladies, de la vue,

48
0:02:33,000 --> 0:02:36,000
et de tout ce qu'on pouvait désirer savoir sur le cerveau. C'était vraiment impressionnant.

49
0:02:36,000 --> 0:02:39,000
On pouvait avoir l'impression qu'on connaissant vraiment beaucoup de choses sur le cerveau.

50
0:02:39,000 --> 0:02:43,000
Mais le dernier article de ce numéro était écrit par Francis Crick, connu pour l'ADN.

51
0:02:43,000 --> 0:02:46,000
C'est aujourd'hui, je pense, le 50ème anniversaire de la découverte de l'ADN.

52
0:02:46,000 --> 0:02:48,000
Et il avait écrit un article qui disait, en gros,

53
0:02:48,000 --> 0:02:51,000
tout ça c'est bien joli, mais vous savez quoi,

54
0:02:51,000 --> 0:02:53,000
on n'y connaît que dalle sur le cerveau

55
0:02:53,000 --> 0:02:55,000
et personne ne sait comment ce truc fonctionne,

56
0:02:55,000 --> 0:02:57,000
alors, ne croyez pas ce que quiconque vous dira.

57
0:02:57,000 --> 0:03:,000
Dans un extrait de l'article, il dit : "Ce qui manque ostensiblement",

58
0:03:,000 --> 0:03:04,000
c'était un vrai gentleman anglais, donc, "ce qui manque ostensiblement,

59
0:03:04,000 --> 0:03:07,000
c'est un vaste cadre d'idées au sein duquel interpréter ces différentes approches."

60
0:03:07,000 --> 0:03:09,000
J'ai pensé que le terme de "cadre" était formidable.

61
0:03:09,000 --> 0:03:11,000
Il n'a pas dit qu'on n'avait même pas de théorie. Il dit,

62
0:03:11,000 --> 0:03:13,000
on ne sait même pas par où commencer à y penser,

63
0:03:13,000 --> 0:03:15,000
on n'a même pas de cadre.

64
0:03:15,000 --> 0:03:18,000
On est dans un stade pré-paradigmatique, en se référant à Thomas Kohn.

65
0:03:18,000 --> 0:03:21,000
Je suis tombé amoureux de cela, et j'ai dit, regarde,

66
0:03:21,000 --> 0:03:24,000
on a tout ces connaissances à propos du cerveau. C'est si difficile que ça ?

67
0:03:24,000 --> 0:03:27,000
C'est quelque chose sur quoi on peut travailler aujourd'hui. J'ai senti que je pouvais faire une différence,

68
0:03:27,000 --> 0:03:31,000
et j'ai donc essayé de sortir de l'industrie informatique, pour entrer dans le domaine du cerveau.

69
0:03:31,000 --> 0:03:33,000
Premièrement, je suis entré au MIT, où se trouvait le A.l Lab (NdT : Laboratoire d'Intelligence Artificielle du M.I.T)

70
0:03:33,000 --> 0:03:35,000
et je me suis dit, je veux construire des machines intelligentes moi aussi,

71
0:03:35,000 --> 0:03:38,000
mais pour faire ça, je vais commencer par étudier le fonctionnement du cerveau.

72
0:03:38,000 --> 0:03:41,000
Et ils ont dit, oh, vous n'avez pas besoin de faire ça.

73
0:03:41,000 --> 0:03:43,000
On va juste programmer des ordinateurs, c'est tout ce qu'on doit faire.

74
0:03:43,000 --> 0:03:46,000
Et j'ai dit, non, vous devriez vraiment étudier le cerveau. Ils ont dit, oh, vous savez,

75
0:03:46,000 --> 0:03:48,000
vous avez tort. Et j'ai dit, non, vous avez tort, et je n'ai pas été pris.

76
0:03:48,000 --> 0:03:49,000
(Rires)

77
0:03:5,000 --> 0:03:52,000
Mais j'étais un peu déçu - assez jeune, mais j'y suis retourné

78
0:03:52,000 --> 0:03:55,000
quelques années plus tard, cette fois en Californie, et je suis allé à Berkeley.

79
0:03:55,000 --> 0:03:59,000
Et je me suis dit, je vais y aller par le côté biologique.

80
0:03:59,000 --> 0:04:02,000
Donc j'ai été pris - dans un programme doctoral en Biophysique.

81
0:04:02,000 --> 0:04:05,000
J'étudiais enfin le cerveau, et je me suis dit, bon, je veux étudier la théorie.

82
0:04:05,000 --> 0:04:07,000
Et ils ont dit, oh non, vous ne pouvez pas étudier la théorie à propos du cerveau.

83
0:04:07,000 --> 0:04:09,000
Ce n'est pas quelque chose qu'on fait. Vous n'aurez pas de subventions pour ça.

84
0:04:09,000 --> 0:04:13,000
En tant qu'étudiant en troisième cycle, vous ne pouvez pas faire ça. Donc je me suis dit, oh mon dieu.

85
0:04:13,000 --> 0:04:15,000
J'étais très déprimé. J'ai dit, je peux faire une différence dans ce domaine.

86
0:04:15,000 --> 0:04:18,000
Donc ce que j'ai fait, c'est de retourner dans l'industrie informatique,

87
0:04:18,000 --> 0:04:2,000
et je me suis dit, bon, il faut que je travaille là-dedans pendant un temps, il faut que je fasse quelque chose.

88
0:04:2,000 --> 0:04:23,000
C'est là que j'ai créé tous ces produits informatiques.

89
0:04:23,000 --> 0:04:24,000
(Rires)

90
0:04:24,000 --> 0:04:27,000
Je me suis dit, je vais faire ça pendant quatre ans, me faire de l'argent,

91
0:04:27,000 --> 0:04:31,000
comme j'avais une famille, et je deviendrais un peu plus mûr,

92
0:04:31,000 --> 0:04:34,000
et peut-être que les neurosciences mûriraient aussi un peu.

93
0:04:34,000 --> 0:04:37,000
Ça a mis plus longtemps que quatre ans. Ça a pris 16 ans.

94
0:04:37,000 --> 0:04:39,000
Mais je le fais maintenant, et je vais vous en parler.

95
0:04:39,000 --> 0:04:42,000
Donc, pourquoi devrions-nous avoir une bonne théorie du cerveau ?

96
0:04:42,000 --> 0:04:45,000
À vrai dire, il y a beaucoup de raisons pour lesquelles les gens font des sciences.

97
0:04:45,000 --> 0:04:48,000
L'une d'elle - la plus basique - est que les gens aiment connaître les choses.

98
0:04:48,000 --> 0:04:5,000
Nous sommes curieux, et nous allons juste chercher des connaissances, vous voyez ?

99
0:04:5,000 --> 0:04:52,000
Pourquoi est-ce qu'on étudie les fourmis ? Parce que c'est intéressant.

100
0:04:52,000 --> 0:04:55,000
Peut-être qu'on y apprendra quelque chose d'utile, mais c'est intéressant et fascinant.

101
0:04:55,000 --> 0:04:57,000
Mais parfois, une science a d'autres attributs,

102
0:04:57,000 --> 0:04:59,000
qui la rendent vraiment, vraiment intéressante.

103
0:04:59,000 --> 0:05:02,000
Parfois, une science nous dira quelque chose sur nous-mêmes,

104
0:05:02,000 --> 0:05:03,000
elle nous dira qui nous sommes.

105
0:05:03,000 --> 0:05:06,000
Pas souvent, mais la théorie de l'évolution a eu cet effet. Copernic aussi,

106
0:05:06,000 --> 0:05:08,000
et nous avons une meilleure compréhension de qui nous sommes.

107
0:05:08,000 --> 0:05:12,000
Et après tout, nous sommes notre cerveau. Mon cerveau parle à votre cerveau.

108
0:05:12,000 --> 0:05:15,000
Nos corps suivent, mais c'est mon cerveau qui parle à votre cerveau.

109
0:05:15,000 --> 0:05:18,000
Et si nous voulons comprendre qui nous sommes, comment nous ressentons et percevons,

110
0:05:18,000 --> 0:05:2,000
il faut vraiment comprendre ce qu'est le cerveau.

111
0:05:2,000 --> 0:05:22,000
Un autre élément est que parfois la science

112
0:05:22,000 --> 0:05:24,000
nous mène à de vraiment gros avantages sociaux et technologiques,

113
0:05:24,000 --> 0:05:26,000
ou commerciaux, ou autres, qui en sont issus. Et c'en est un, aussi,

114
0:05:26,000 --> 0:05:29,000
car quand nous comprenondrons comment le cerveau fonctionne, nous serons capables

115
0:05:29,000 --> 0:05:32,000
de construire des machines intelligentes, et à vrai dire je pense que c'est une bonne chose globalement,

116
0:05:32,000 --> 0:05:34,000
cela va avoir des avantages immenses pour la société,

117
0:05:34,000 --> 0:05:36,000
comme une technologie fondamentale.

118
0:05:36,000 --> 0:05:38,000
Donc, pourquoi n'avons-nous pas de bonne théorie du cerveau ?

119
0:05:38,000 --> 0:05:41,000
Et il y a des gens qui ont travaillé là-dessus depuis 100 ans.

120
0:05:41,000 --> 0:05:43,000
Tout d'abord, regardons ce à quoi ressemble la science normale.

121
0:05:43,000 --> 0:05:45,000
Voilà la science normale.

122
0:05:45,000 --> 0:05:49,000
La science normale est un équilibre entre théories et expérimentations.

123
0:05:49,000 --> 0:05:51,000
Le théoricien dit, voilà, je pense que c'est ce qui se passe,

124
0:05:51,000 --> 0:05:53,000
et l'expérimentateur dit, non, vous avez tort.

125
0:05:53,000 --> 0:05:55,000
Et ça fait des allers-retours, vous voyez ?

126
0:05:55,000 --> 0:05:57,000
Ça marche pour la physique. Et pour la géologie. Mais si c'est ça la science normale,

127
0:05:57,000 --> 0:06:,000
à quoi ressemble la neuroscience ? Voilà à quoi la neuroscience ressemble.

128
0:06:,000 --> 0:06:05,000
On a cette montagne de données, l'anatomie, la physiologie, le comportement.

129
0:06:05,000 --> 0:06:08,000
Vous n'imaginez pas combien de détails on connaît à propos du cerveau.

130
0:06:08,000 --> 0:06:12,000
Il y a 28000 personnes qui sont allées à la conférence sur la neuroscience cette année,

131
0:06:12,000 --> 0:06:14,000
et chacune d'entre elles faisaient des recherches sur le cerveau.

132
0:06:14,000 --> 0:06:18,000
Beaucoup de données. Mais il n'y a pas de théorie. Il y a une petite boîte timide là-haut.

133
0:06:18,000 --> 0:06:23,000
Et la théorie n'a joué aucun rôle majeur en neurosciences.

134
0:06:23,000 --> 0:06:26,000
C'est vraiment dommage. Comment ça se fait ?

135
0:06:26,000 --> 0:06:28,000
Si vous demandez à des neuroscientifiques pourquoi il en est ainsi,

136
0:06:28,000 --> 0:06:31,000
déjà, ils confirmeront. Mais si vous leur demandez, ils vous diront,

137
0:06:31,000 --> 0:06:34,000
eh bien, il y a diverses raisons pour lesquelles on n'a pas de bonne théorie du cerveau.

138
0:06:34,000 --> 0:06:36,000
Certains diront qu'on n'a pas encore assez de données,

139
0:06:36,000 --> 0:06:39,000
on doit rassembler plus d'informations, il y a toutes ces choses qu'on ignore.

140
0:06:39,000 --> 0:06:42,000
Mais je vous ai dit qu'on croule sous les données.

141
0:06:42,000 --> 0:06:45,000
On a tant d'informations qu'on ne sait pas par où commencer pour les organiser.

142
0:06:45,000 --> 0:06:47,000
À quoi servirait d'en avoir plus ?

143
0:06:47,000 --> 0:06:5,000
On sera peut-être chanceux et on découvrira quelque chose de magique, mais je n'y crois pas.

144
0:06:5,000 --> 0:06:53,000
C'est en fait simplement un symptôme de l'absence de théorie.

145
0:06:53,000 --> 0:06:56,000
On n'a pas besoin de plus de données, on a besoin d'une bonne théorie à leur sujet.

146
0:06:56,000 --> 0:06:59,000
Parfois, les gens disent que le cerveau est si complexe

147
0:06:59,000 --> 0:07:01,000
que ça prendra 50 ans de plus.

148
0:07:01,000 --> 0:07:03,000
Je crois même que Chris a dit quelque chose comme ça hier.

149
0:07:03,000 --> 0:07:05,000
Je ne suis pas sûr de ce que vous avez dit, Chris, mais c'était quelque chose dans le genre de :

150
0:07:05,000 --> 0:07:08,000
"C'est l'une des choses les plus compliquées de l'univers." Ce n'est pas vrai.

151
0:07:08,000 --> 0:07:1,000
Vous êtes plus compliqué que votre cerveau. Vous avez un cerveau.

152
0:07:1,000 --> 0:07:12,000
Et c'est aussi que, bien que le cerveau semble très compliqué,

153
0:07:12,000 --> 0:07:15,000
les choses semblent compliquées jusqu'à ce qu'on les comprennent.

154
0:07:15,000 --> 0:07:18,000
Ça a toujours été le cas. Donc tout ce que nous pouvons dire,

155
0:07:18,000 --> 0:07:22,000
c'est que mon néocortex, qui est la partie du cerveau qui m'intéresse, a 30 milliards de cellules.

156
0:07:22,000 --> 0:07:24,000
Mais vous savez quoi ? Il est vraiment très simple.

157
0:07:24,000 --> 0:07:27,000
En fait, on dirait que c'est la même chose qui se répète encore et encore et encore.

158
0:07:27,000 --> 0:07:3,000
Il n'est pas aussi compliqué qu'en apparence. Ce n'est pas le problème.

159
0:07:3,000 --> 0:07:32,000
Certains disent que le cerveau ne peut pas comprendre le cerveau.

160
0:07:32,000 --> 0:07:35,000
C'est très zen comme idée. Wow ! Vous savez...

161
0:07:35,000 --> 0:07:36,000
(Rires)

162
0:07:36,000 --> 0:07:39,000
Ça sonne bien mais pourquoi dire ça ? Ça mène à quoi ?

163
0:07:39,000 --> 0:07:42,000
C'est juste un tas de cellules. Vous comprenez votre foie.

164
0:07:42,000 --> 0:07:44,000
Il est aussi composé de beaucoup de cellules, pas vrai ?

165
0:07:44,000 --> 0:07:46,000
Donc je ne pense pas que ça soit très juste de dire ça.

166
0:07:46,000 --> 0:07:48,000
Et finalement, d'autres personnes disent

167
0:07:48,000 --> 0:07:52,000
qu'elles ne se sentent pas être un tas de cellules. Qu'elles sont conscientes.

168
0:07:52,000 --> 0:07:54,000
Je fais cette expérience, je vis dans ce monde.

169
0:07:54,000 --> 0:07:56,000
Je ne peux pas être simplement un tas de cellules.

170
0:07:56,000 --> 0:07:59,000
Les gens avaient l'habitude de penser qu'il y avait une force vitale,

171
0:07:59,000 --> 0:08:01,000
et on sait aujourd'hui que ce n'est pas du tout vrai.

172
0:08:01,000 --> 0:08:04,000
Et il n'y a vraiment pas de preuve qui dise... Enfin, à part les gens

173
0:08:04,000 --> 0:08:06,000
qui ne croient pas que les cellules puissent faire ce qu'elles font.

174
0:08:06,000 --> 0:08:09,000
Et donc, même si des gens sont tombés dans la fosse du dualisme métaphysique,

175
0:08:09,000 --> 0:08:12,000
même des gens très intelligents, hé bien on peut rejeter tout ça.

176
0:08:12,000 --> 0:08:14,000
(Rires)

177
0:08:14,000 --> 0:08:17,000
Non, je vais vous dire qu'il y a quelque chose d'autre,

178
0:08:17,000 --> 0:08:19,000
et c'est vraiment fondamental. Voilà ce qu'il en est :

179
0:08:19,000 --> 0:08:21,000
il y a une autre raison pour laquelle nous n'avons pas de théorie du cerveau satisfaisante,

180
0:08:21,000 --> 0:08:24,000
c'est parce qu'on a une supposition intuitive, très ferme,

181
0:08:24,000 --> 0:08:29,000
mais incorrecte qui nous empêche de vois la réponse.

182
0:08:29,000 --> 0:08:32,000
Il y a quelque chose qu'on croît évident, mais qui est faux.

183
0:08:32,000 --> 0:08:36,000
Il y a une histoire de ce type en science, et avant que je ne vous dise laquelle,

184
0:08:36,000 --> 0:08:38,000
je vais vous en dire un peu plus sur l'histoire à ce sujet en science.

185
0:08:38,000 --> 0:08:4,000
Si vous regardez certaines des autres révolutions scientifiques,

186
0:08:4,000 --> 0:08:42,000
dans le cas présent, je parle du système solaire, avec Corpernic,

187
0:08:42,000 --> 0:08:45,000
l'évolution de Darwin, et les plaques tectoniques de Wegener.

188
0:08:45,000 --> 0:08:48,000
Elles ont toutes beaucoup en commun avec la science du cerveau.

189
0:08:48,000 --> 0:08:51,000
Tout d'abord, il y avait toutes ces données inexpliquées. Un tas de données.

190
0:08:51,000 --> 0:08:54,000
Mais elles sont devenues gérables une fois qu'il y a eu une théorie.

191
0:08:54,000 --> 0:08:57,000
Les meilleurs esprits séchaient, des gens vraiment, vraiment intelligents.

192
0:08:57,000 --> 0:08:59,000
Nous ne sommes pas plus intelligents maintenant qu'à leur époque.

193
0:08:59,000 --> 0:09:01,000
Il s'avère juste qu'il est vraiment très difficile de penser les choses,

194
0:09:01,000 --> 0:09:03,000
mais une fois que vous y avez pensé, il est relativement aisé de les comprendre.

195
0:09:03,000 --> 0:09:05,000
Mes filles ont compris ces trois théories

196
0:09:05,000 --> 0:09:08,000
dans leur cadre général en maternelle.

197
0:09:08,000 --> 0:09:11,000
Ce n'est pas si dure, vous savez, voilà la pomme, voilà l'orange,

198
0:09:11,000 --> 0:09:14,000
la Terre tourne, et tout ça.

199
0:09:14,000 --> 0:09:16,000
Enfin, une autre chose est que la réponse était là depuis le début,

200
0:09:16,000 --> 0:09:19,000
mais on l'avait plus ou moins ignorée à cause de cette chose évidente.

201
0:09:19,000 --> 0:09:22,000
C'est cette croyance intuitive et fermement ancrée qui était fausse.

202
0:09:22,000 --> 0:09:25,000
Dans le cas du système solaire, l'idée que la Terre tournait

203
0:09:25,000 --> 0:09:28,000
et que la surface de la Terre bougeait à disons 1500 km/h,

204
0:09:28,000 --> 0:09:31,000
et que la Terre fonce à travers le système solaire à environ 1500000 km/h.

205
0:09:31,000 --> 0:09:33,000
C'est du délire. Tout le monde sait que la Terre ne bouge pas.

206
0:09:33,000 --> 0:09:35,000
Est-ce que vous sentez que vous bougez à 1500km/h ?

207
0:09:35,000 --> 0:09:37,000
Bien sûr que non. Et quelqu'un qui disait,

208
0:09:37,000 --> 0:09:39,000
en fait, elle tourne dans l'espace et est énorme,

209
0:09:39,000 --> 0:09:41,000
ils l'enfermaient, c'est ce qu'ils faisaient à cette époque.

210
0:09:41,000 --> 0:09:42,000
(Rires)

211
0:09:42,000 --> 0:09:45,000
Donc c'était intuitif et évident. Et maintenant, qu'en est-il pour l'évolution ?

212
0:09:45,000 --> 0:09:48,000
C'est la même chose pour l'évolution. On enseignait à nos enfants que la Bible dit

213
0:09:48,000 --> 0:09:5,000
que Dieu a créé toutes ces espèces, que les chats sont des chats, les chiens sont des chiens,

214
0:09:5,000 --> 0:09:53,000
les gens sont des gens, les plantes sont des plantes, donc ils ne changent pas.

215
0:09:53,000 --> 0:09:57,000
Noé les a mis dans son Arche dans cet ordre, bla bla bla.

216
0:09:57,000 --> 0:10:01,000
Et vous savez, le fait est que si vous croyez en l'évolution, nous avons tous un ancêtre commun,

217
0:10:01,000 --> 0:10:04,000
et nous avons tous une parenté commune avec la plant dans le hall.

218
0:10:04,000 --> 0:10:07,000
C'est ce que l'évolution nous enseigne. Et c'est vrai. C'est assez incroyable.

219
0:10:07,000 --> 0:10:1,000
Et c'est la même chose avec les plaques tectoniques.

220
0:10:1,000 --> 0:10:12,000
Toutes les montages et les continents flottent de-ci de-là

221
0:10:12,000 --> 0:10:16,000
sur la surface de la Terre. Ça ne fait aucun sens.

222
0:10:16,000 --> 0:10:2,000
Donc quelle est la supposition intuitive, mais incorrecte,

223
0:10:2,000 --> 0:10:22,000
qui nous empêche de comprendre le cerveau ?

224
0:10:22,000 --> 0:10:24,000
Je vais vous la dire, et il va sembler évident que c'est juste,

225
0:10:24,000 --> 0:10:26,000
et c'est là le but, non ? Ensuite je vais devoir expliquer

226
0:10:26,000 --> 0:10:28,000
pourquoi vous avez tort avec l'autre supposition.

227
0:10:28,000 --> 0:10:31,000
La chose intuitive et évidente est que quelque part l'intelligence

228
0:10:31,000 --> 0:10:33,000
est définie par le comportement,

229
0:10:33,000 --> 0:10:35,000
que nous sommes intelligents par la façon dont nous faisons les choses

230
0:10:35,000 --> 0:10:38,000
et la façon dont nous agissons intelligemment. Je vais vous dire que c'est une erreur.

231
0:10:38,000 --> 0:10:4,000
Le fait est que l'intelligence est définie par la capacité de prédiction.

232
0:10:4,000 --> 0:10:43,000
Je vais vous guider avec quelques slides,

233
0:10:43,000 --> 0:10:47,000
vous donner un exemple de ce que ça signifie. Voilà le système.

234
0:10:47,000 --> 0:10:5,000
Les ingénieurs aiment regarder les systèmes ainsi. Les scientifiques, eux, aiment regarder les systèmes comme ça.

235
0:10:5,000 --> 0:10:53,000
Ils disent "Bon, on a une chose dans une boîte, et il y a ses données d'entrée et de sortie."

236
0:10:53,000 --> 0:10:56,000
Les gens d'IA (intelligence artificielle) disent que cette chose dans la boîte est un ordinateur programmable

237
0:10:56,000 --> 0:10:58,000
car c'est équivalent à un cerveau. On lui fournit des données

238
0:10:58,000 --> 0:11:,000
et on lui fait faire quelque chose, manifester des comportements.

239
0:11:,000 --> 0:11:03,000
Et Alan Turing a défini le test de Turing, qui dit en gros

240
0:11:03,000 --> 0:11:06,000
qu'on saura si quelque chose est intelligent s'il se comporte comme un humain.

241
0:11:06,000 --> 0:11:09,000
C'est une mesure comportementale de ce qu'est l'intelligence,

242
0:11:09,000 --> 0:11:12,000
et c'est resté collé dans notre esprit pendant un long moment.

243
0:11:12,000 --> 0:11:14,000
La réalité, cependant, je l'appelle la véritable intelligence.

244
0:11:14,000 --> 0:11:16,000
La véritable intelligence est fondée sur quelque chose d'autre.

245
0:11:16,000 --> 0:11:2,000
On expérimente le monde à travers une séquence de motifs, qu'on stocke

246
0:11:2,000 --> 0:11:23,000
et dont on se rappelle. Et quand on s'en rappelle, on les confronte à la réalité,

247
0:11:23,000 --> 0:11:27,000
on fait des prédictions en permanence.

248
0:11:27,000 --> 0:11:3,000
C'est une mesure permanente. Il y a une mesure permanente à notre sujet, qui nous dit en gros,

249
0:11:3,000 --> 0:11:33,000
est-ce que je comprends le monde ? Est-ce que je fais des prédictions ? Et ainsi de suite.

250
0:11:33,000 --> 0:11:35,000
Vous êtes tous intelligents à cet instant présent, mais vous ne faites rien.

251
0:11:35,000 --> 0:11:37,000
Peut-être que vous vous grattez, ou vous vous mettez votre doigt dans le nez,

252
0:11:37,000 --> 0:11:39,000
je ne sais pas, mais vous ne faites rien à cet instant,

253
0:11:39,000 --> 0:11:42,000
mais vous êtes intelligents, vous comprenez ce que je dis.

254
0:11:42,000 --> 0:11:44,000
Parce que vous êtes intelligents et vous parlez anglais,

255
0:11:44,000 --> 0:11:45,000
vous savez quel mot se trouve à la fin de cette... (Silence)

256
0:11:45,000 --> 0:11:47,000
phrase.

257
0:11:47,000 --> 0:11:5,000
Le mot vous est venu à l'esprit, et vous faites ce type de prédiction tout le temps.

258
0:11:5,000 --> 0:11:52,000
Donc, ce que je dis,

259
0:11:52,000 --> 0:11:54,000
c'est que la prédiction permanente est l'output du néocortex.

260
0:11:54,000 --> 0:11:57,000
Et que d'une certaine façon, la prédiction mène à un comportement intelligent.

261
0:11:57,000 --> 0:12:,000
Voilà comment ça se passe. Commençons avec un cerveau non-intelligent.

262
0:12:,000 --> 0:12:04,000
Bon, je propose un cerveau non-intelligent, on a un vieux cerveau,

263
0:12:04,000 --> 0:12:07,000
on va dire que ce n'est pas un mammifère, plutôt un reptile,

264
0:12:07,000 --> 0:12:09,000
disons un alligator, on a un alligator.

265
0:12:09,000 --> 0:12:12,000
Et l'alligator a des sens très sophistiqués.

266
0:12:12,000 --> 0:12:15,000
Il a de bon yeux, de bonnes oreilles, un bon sens tactile, et ainsi de suite

267
0:12:15,000 --> 0:12:19,000
une bouche, un nez. Il a un comportement complexe.

268
0:12:19,000 --> 0:12:23,000
Il peut courir et se cacher. Il connaît la peur et les émotions. Il peut vous manger, vous savez.

269
0:12:23,000 --> 0:12:27,000
Il peut attaquer. Il peut faire tout ces trucs.

270
0:12:27,000 --> 0:12:32,000
Mais on ne considère pas que l'alligator est très intelligent, pas dans un sens humain.

271
0:12:32,000 --> 0:12:34,000
Mais il a déjà un comportement complexe.

272
0:12:34,000 --> 0:12:36,000
Que c'est-il passé dans l'évolution ?

273
0:12:36,000 --> 0:12:39,000
La première chose qui est arrivée dans l'évolution des mammifères,

274
0:12:39,000 --> 0:12:41,000
c'est que nous avons développé une chose appelée le néocortex.

275
0:12:41,000 --> 0:12:43,000
Je vais représenter un néocortex ici,

276
0:12:43,000 --> 0:12:45,000
par cette boîte qui vient se coller au-dessus du vieux cerveau.

277
0:12:45,000 --> 0:12:48,000
Le néocortex implique une nouvelle couche. C'est une nouvelle couche au-dessus de votre cerveau.

278
0:12:48,000 --> 0:12:51,000
Si vous ne le savez pas, c'est la chose ridée sur le dessus de la tête,

279
0:12:51,000 --> 0:12:54,000
elle a des rides parce qu'elle a été fourrée là-dedans et n'a pas la bonne taille.

280
0:12:54,000 --> 0:12:55,000
(Rires)

281
0:12:55,000 --> 0:12:57,000
Non, vraiment, c'est ça. Il a à peu près la taille d'une serviette de table.

282
0:12:57,000 --> 0:13:,000
Et il ne tient pas là-dedans, donc il s'est ridé. Maintenant, regardez comment j'ai dessiné ça ici.

283
0:13:,000 --> 0:13:04,000
Le vieux cerveau est toujours là. Vous avez toujours le cerveau d'alligator.

284
0:13:04,000 --> 0:13:06,000
Vous l'avez. C'est votre cerveau émotionnel.

285
0:13:06,000 --> 0:13:09,000
C'est toutes ces choses, toutes ces réactions instinctives que vous avez.

286
0:13:09,000 --> 0:13:12,000
Et par dessus, on a ce système de mémoire appelé néocortex.

287
0:13:12,000 --> 0:13:16,000
Et ce système de mémoire est posé sur la partie sensorielle du cerveau.

288
0:13:16,000 --> 0:13:19,000
Donc quand les données sensorielles arrivent du vieux cerveau,

289
0:13:19,000 --> 0:13:23,000
ells montent aussi dans le néocortex. Et le néocortex, c'est simplement la mémorisation.

290
0:13:23,000 --> 0:13:27,000
Il reste là à dire "Ah, je vais mémoriser toutes ces choses qui se produisent,

291
0:13:27,000 --> 0:13:29,000
où je suis allé, les gens que j'ai vus, les choses que j'ai entendues, et tout ça."

292
0:13:29,000 --> 0:13:33,000
Et dans le futur, quand il verra quelque chose de similaire à nouveau,

293
0:13:33,000 --> 0:13:36,000
dans un environnement similaire, ou exactement le même,

294
0:13:36,000 --> 0:13:38,000
il le rejouera. Il se mettra à le rejouer.

295
0:13:38,000 --> 0:13:4,000
"Oh, je suis déjà venu ici. Et quand tu es venu ici,

296
0:13:4,000 --> 0:13:43,000
ceci s'est produit ensuite". Cela vous permet de prédire le futur.

297
0:13:43,000 --> 0:13:47,000
Il renvoie littéralement le signal à votre cerveau,

298
0:13:47,000 --> 0:13:49,000
et vous laisse voir ce qui va se produire ensuite,

299
0:13:49,000 --> 0:13:52,000
vous laisse entendre le mot dans ma phrase avant que je ne l'ai dit.

300
0:13:52,000 --> 0:13:55,000
Et c'est ce renvoi de signal dans le vieux cerveau

301
0:13:55,000 --> 0:13:58,000
qui vous permet de prendre des décisions bien plus intelligentes.

302
0:13:58,000 --> 0:14:01,000
C'est le slide le plus important de mon propos, donc je vais m'attarder dessus un petit peu.

303
0:14:01,000 --> 0:14:05,000
Et donc, vous dites tout le temps, "oh je peux prédire les choses".

304
0:14:05,000 --> 0:14:08,000
Si vous êtes un rat qui parcourt un labyrinthe, et que vous apprenez à le connaître,

305
0:14:08,000 --> 0:14:1,000
la prochaine fois que vous vous y trouverez, vous aurez le même comportement,

306
0:14:1,000 --> 0:14:12,000
mais brusquement, vous êtes plus intelligents,

307
0:14:12,000 --> 0:14:15,000
parce que vous vous dites, "oh, je reconnais ce labyrinthe, je sais de quel côté aller,

308
0:14:15,000 --> 0:14:18,000
je suis déjà venu ici, je peux voir le future." Et c'est ce qui se produit.

309
0:14:18,000 --> 0:14:21,000
Chez l'homme, mais c'est valable pour tous les mammifères, au passage.

310
0:14:21,000 --> 0:14:23,000
C'est vrai pour tous les mammifères, et chez l'homme, c'est devenu encore pire.

311
0:14:23,000 --> 0:14:26,000
L'homme a en fait développé la partie frontale du néocortex,

312
0:14:26,000 --> 0:14:3,000
appelée partie antérieure du néocortex. Et la nature a fait un petit truc ici.

313
0:14:3,000 --> 0:14:32,000
Elle a copié la partie postérieure, la partie à l'arrière, qui est sensorielle,

314
0:14:32,000 --> 0:14:34,000
et l'a mise dans la partie avant.

315
0:14:34,000 --> 0:14:36,000
Et l'homme uniquement a le même mécanisme sur l'avant,

316
0:14:36,000 --> 0:14:38,000
mais l'utilise pour le contrôle moteur.

317
0:14:38,000 --> 0:14:41,000
Donc on peut maintenant effectuer des actions motrices planifiées très sophistiquées, des choses comme ça.

318
0:14:41,000 --> 0:14:44,000
Je n'ai pas le temps de poursuivre dans les détails, mais si vous voulez comprendre comment fonctionne un cerveau,

319
0:14:44,000 --> 0:14:47,000
vous devez comprendre comment la première partie du néocortex des mammifères fonctionne,

320
0:14:47,000 --> 0:14:49,000
et comment elle stocke des motifs et fait des prédictions.

321
0:14:49,000 --> 0:14:52,000
Laissez-moi donc vous donner quelques exemples de prédictions.

322
0:14:52,000 --> 0:14:54,000
J'ai déjà évoqué la complétion d'une phrase. En musique,

323
0:14:54,000 --> 0:14:57,000
si vous avez déjà entendu une chanson, si vous avez déjà entendu Jill chanter ces chansons auparavant,

324
0:14:57,000 --> 0:15:,000
quand elle les chante, la prochaine note apparaît déjà dans votre esprit,

325
0:15:,000 --> 0:15:02,000
vous l'anticipé au fur et à mesure. Si c'était un album de musique,

326
0:15:02,000 --> 0:15:05,000
à la fin d'un album, la prochaine chanson apparaît dans votre tête.

327
0:15:05,000 --> 0:15:07,000
Et ces choses arrivent tout le temps. Vous faites ces prédictions.

328
0:15:07,000 --> 0:15:1,000
J'ai cette expérience de pensée, dite de la porte modifiée,

329
0:15:1,000 --> 0:15:13,000
elle dit que vous avez une porte chez vous,

330
0:15:13,000 --> 0:15:16,000
et pendant que vous êtes ici, je la change, j'ai un type

331
0:15:16,000 --> 0:15:18,000
chez vous en ce moment même, qui change la porte,

332
0:15:18,000 --> 0:15:2,000
il va prendre la poignée et la bouger de cinq centimètres.

333
0:15:2,000 --> 0:15:22,000
Quand vous allez rentrer chez vous ce soir, vous allez avancer votre main

334
0:15:22,000 --> 0:15:24,000
pour attraper la poignée, et vous allez remarquer

335
0:15:24,000 --> 0:15:27,000
qu'elle se trouve au mauvais endroit, et vous vous direz, ola, quelque chose est arrivé.

336
0:15:27,000 --> 0:15:29,000
Ça prendra peut-être une seconde pour vous en rendre compte, mais quelque chose a changé.

337
0:15:29,000 --> 0:15:31,000
Mais je pourrais changer votre poignée de porte d'autres façons.

338
0:15:31,000 --> 0:15:33,000
Je peux la rendre plus grosse ou plus petite, je peux la faire passer de laiton à argentée,

339
0:15:33,000 --> 0:15:35,000
je peux changer son type. Je peux changer votre porte, la peindre,

340
0:15:35,000 --> 0:15:38,000
y mettre une fenêtre. Je peux changer mille chose sur votre porte,

341
0:15:38,000 --> 0:15:4,000
et dans les deux secondes qu'il faut pour ouvrir la porte,

342
0:15:4,000 --> 0:15:43,000
vous allez remarquer que quelque chose a changé.

343
0:15:43,000 --> 0:15:45,000
Maintenant, l'approche d'ingénieur, l'approche d'IA,

344
0:15:45,000 --> 0:15:48,000
c'est de créer une base de données sur la porte. Elle a tous les attributs de la porte.

345
0:15:48,000 --> 0:15:51,000
Et quand vous allez vers la porte, vous savez, vous les vérifier un à un.

346
0:15:51,000 --> 0:15:53,000
Porte, porte, porte, couleur, enfin vous voyez de quoi je parle.

347
0:15:53,000 --> 0:15:55,000
On ne fait pas ça. Votre cerveau ne fait pas ça.

348
0:15:55,000 --> 0:15:57,000
Ce que fait votre cerveau, c'est de constamment établir des prédictions

349
0:15:57,000 --> 0:15:59,000
sur ce qui va se produire dans votre environnement.

350
0:15:59,000 --> 0:16:02,000
Quand je pose ma main sur cette table, je m'attends à la sentir s'arrêter.

351
0:16:02,000 --> 0:16:05,000
Quand je marche, pour chaque pas, si j'en manquais un d'une fraction de centimètre,

352
0:16:05,000 --> 0:16:07,000
je saurais que quelque chose a changé.

353
0:16:07,000 --> 0:16:09,000
Vous faites constamment des prédictions sur votre environnement.

354
0:16:09,000 --> 0:16:12,000
Je vais parler brièvement de la vue ici. Voici l'image d'une femme.

355
0:16:12,000 --> 0:16:14,000
Quand vous regardez des gens, vos yeux sont attirés

356
0:16:14,000 --> 0:16:15,000
deux ou trois fois par seconde.

357
0:16:15,000 --> 0:16:17,000
Vous n'en avez pas conscience, mais vos yeux bougent tout le temps.

358
0:16:17,000 --> 0:16:19,000
Et donc quand vous regardez le visage de quelqu'un,

359
0:16:19,000 --> 0:16:21,000
vous passez typiquement d'un oeil à l'autre et du nez à la bouche.

360
0:16:21,000 --> 0:16:23,000
Quand votre oeil se déplace d'un oeil à l'autre,

361
0:16:23,000 --> 0:16:25,000
s'il y a quelque chose d'autre à cet endroit, comme un nez,

362
0:16:25,000 --> 0:16:27,000
vous verriez un nez où un oeil était attendu,

363
0:16:27,000 --> 0:16:3,000
et vous vous diriez : "Oh merde !", vous voyez...

364
0:16:3,000 --> 0:16:31,000
(Rires)

365
0:16:31,000 --> 0:16:33,000
"Il y a quelque chose qui cloche sur cette personne."

366
0:16:33,000 --> 0:16:35,000
C'est parce que vous faites une prédiction.

367
0:16:35,000 --> 0:16:37,000
Ce n'est pas comme si vous regardiez là et vous demandiez ce que vous voyez.

368
0:16:37,000 --> 0:16:4,000
Un nez, c'est bon. Non, vous vous attendez à voir quelque chose de particulier.

369
0:16:4,000 --> 0:16:41,000
(Rires)

370
0:16:41,000 --> 0:16:45,000
Tout le temps. Et, enfin, regardons à la façon dont on teste l'intelligence.

371
0:16:45,000 --> 0:16:48,000
On la teste par la prédiction : quel est le prochain mot ici ?

372
0:16:48,000 --> 0:16:51,000
Ceci est à cela ce que ceci est à cela. Quel est le prochain chiffre dans cette phrase ?

373
0:16:51,000 --> 0:16:53,000
Voici trois vues d'un objet.

374
0:16:53,000 --> 0:16:57,000
Quelle est la quatrième ? Voilà comment on la teste. C'est la prédiction.

375
0:16:57,000 --> 0:17:,000
Dès lors, quelle est la recette pour une théorie du cerveau ?

376
0:17:,000 --> 0:17:03,000
Premièrement, nous devons avoir le bon cadre de travail.

377
0:17:03,000 --> 0:17:05,000
C'est un système de mémoire,

378
0:17:05,000 --> 0:17:07,000
pas un système de calcul ou de comportement. C'est un système de mémoire.

379
0:17:07,000 --> 0:17:11,000
Comment est-ce que vous enregistrez et réutilisez ces séquences ou motifs ? Ce sont des motifs spatio-temporels.

380
0:17:11,000 --> 0:17:14,000
Maintenant, dans ce système, vous prenez un tas de théoriciens .

381
0:17:14,000 --> 0:17:16,000
Les biologistes ne sont généralement pas de bons théoriciens.

382
0:17:16,000 --> 0:17:2,000
Ce n'est pas toujours vrai, mais en général, il n'y a pas une bonne histoire de la théorie en biologie.

383
0:17:2,000 --> 0:17:23,000
J'ai trouvé que les meilleures personnes avec qui travailler sont les physiciens,

384
0:17:23,000 --> 0:17:26,000
les ingénieurs et les mathématiciens, qui ont tendance à penser avec des algorithmes.

385
0:17:26,000 --> 0:17:29,000
Ensuite, ils doivent apprendre l'anatomie et la physiologie.

386
0:17:29,000 --> 0:17:33,000
Vous devez rendre ces théories très réalistes en termes anatomiques.

387
0:17:33,000 --> 0:17:37,000
Quiconque se lève et vous expose sa théorie sur le fonctionnement du cerveau

388
0:17:37,000 --> 0:17:39,000
et ne vous explique pas exactement comment le cerveau fonctionne

389
0:17:39,000 --> 0:17:41,000
et comment les connexions cérébrales fonctionnent, ça ne fait pas une théorie.

390
0:17:41,000 --> 0:17:44,000
C'est ce que nous faisons au Redwood Neuroscience Institute.

391
0:17:44,000 --> 0:17:48,000
J'adorerai avoir plus de temps pour vous parler des fantastiques progrès que l'on fait là-dedans,

392
0:17:48,000 --> 0:17:5,000
et j'espère revenir une autre fois sur cette estrade,

393
0:17:5,000 --> 0:17:52,000
peut-être dans un avenir assez proche, et je vous en parlerai alors.

394
0:17:52,000 --> 0:17:55,000
Je suis vraiment très excité. Ça ne va absolument pas prendre 50 ans.

395
0:17:55,000 --> 0:17:57,000
À quoi ressemblera une théorie du cerveau ?

396
0:17:57,000 --> 0:17:59,000
D'abord, ça sera une théorie sur la mémoire.

397
0:17:59,000 --> 0:18:02,000
Pas comme de la mémoire informatique. Ça ne ressemble en rien à la mémoire informatique.

398
0:18:02,000 --> 0:18:04,000
C'est vraiment très différent. Et c'est une mémoire

399
0:18:04,000 --> 0:18:07,000
de motifs de grandes dimensions, comme les choses qui viennent de vos yeux.

400
0:18:07,000 --> 0:18:09,000
C'est aussi une mémoire de séquences.

401
0:18:09,000 --> 0:18:11,000
Vous ne pouvez pas apprendre ni vous rappeler quelque chose en dehors d'une séquence.

402
0:18:11,000 --> 0:18:14,000
Une chanson doit être entendue en séquence dans le temps,

403
0:18:14,000 --> 0:18:17,000
et vous devez la rejouer en séquence de la même façon.

404
0:18:17,000 --> 0:18:2,000
On se souvient de ces séquences de façon auto-associées, donc si je vois quelque chose,

405
0:18:2,000 --> 0:18:23,000
j'entends quelque chose, ça me le rappelle, et ça le rejoue automatiquement.

406
0:18:23,000 --> 0:18:27,000
C'est un playback automatique. Et la prédiction des futures données d'entrée, ce sont les données de sortie souhaitées.

407
0:18:27,000 --> 0:18:3,000
Et comme je l'ai dit, la théorie doit être exacte d'un point de vue biologique,

408
0:18:3,000 --> 0:18:32,000
elle doit être testable, et on doit pouvoir la construire.

409
0:18:32,000 --> 0:18:36,000
Si on ne la construit pas, on ne la comprend pas. Voici un dernier slide.

410
0:18:36,000 --> 0:18:4,000
Quel va être le résultat de tout cela ? Est-ce qu'on va vraiment construire des machines intelligentes ?

411
0:18:4,000 --> 0:18:44,000
Absolument. Et ça va être différent de ce que pensent les gens.

412
0:18:44,000 --> 0:18:47,000
Ça va arriver, ça ne fait aucun doute dans mon esprit.

413
0:18:47,000 --> 0:18:51,000
D'abord, on va le construire, créer le truc à partir de silicone.

414
0:18:51,000 --> 0:18:54,000
On utilisera les mêmes techniques

415
0:18:54,000 --> 0:18:55,000
que pour construire la mémoire informatique en silicone.

416
0:18:55,000 --> 0:18:57,000
Mais ce sont des types très différents de mémoires.

417
0:18:57,000 --> 0:18:59,000
Et on va attacher ces mémoires à des capteurs,

418
0:18:59,000 --> 0:19:02,000
et ceux-ci auront une expérience des données du monde réel, en temps réel,

419
0:19:02,000 --> 0:19:04,000
et ces choses apprendront des choses sur leur environnement.

420
0:19:04,000 --> 0:19:07,000
Il est très peu probable que les premières choses que vous verrez soient des robots.

421
0:19:07,000 --> 0:19:1,000
Non pas que les robots sont inutiles, et les gens savent construire des robots.

422
0:19:1,000 --> 0:19:14,000
Mais la partie robotique est la plus dure. C'est le vieux cerveau. C'est vraiment difficile.

423
0:19:14,000 --> 0:19:16,000
Le nouveau cerveau est en fait plutôt facile en comparaison avec le vieux cerveau.

424
0:19:16,000 --> 0:19:19,000
Donc les premières choses qu'on fera seront celles qui ne requièrent pas beaucoup de robotique.

425
0:19:19,000 --> 0:19:21,000
Donc vous ne verrez pas de C-3PO.

426
0:19:21,000 --> 0:19:23,000
Vous verrez des choses comme, disons, des voitures intelligentes

427
0:19:23,000 --> 0:19:26,000
qui comprennent vraiment ce qu'est le trafic, et ce qu'est conduire,

428
0:19:26,000 --> 0:19:29,000
et qui ont appris que certains types de voitures qui ont le clignotant allumé pendant trente secondes

429
0:19:29,000 --> 0:19:31,000
ne vont probablement pas tourner, des choses comme ça.

430
0:19:31,000 --> 0:19:32,000
(Rires)

431
0:19:32,000 --> 0:19:34,000
On peut aussi faire des systèmes de sécurité intelligents.

432
0:19:34,000 --> 0:19:38,000
Là où nous avons besoin de notre cerveau, en gros, mais pas de beaucoup de mécanismes.

433
0:19:38,000 --> 0:19:4,000
Ce sont les choses qui arriveront en premier.

434
0:19:4,000 --> 0:19:42,000
Mais après cela, la limite, c'est le monde.

435
0:19:42,000 --> 0:19:44,000
Je ne sais pas où cela va mener.

436
0:19:44,000 --> 0:19:46,000
Je connais beaucoup de ceux qui ont inventé le microprocesseur

437
0:19:46,000 --> 0:19:51,000
et si vous leur parlez, ils savaient que ce qu'ils faisaient était vraiment important,

438
0:19:51,000 --> 0:19:54,000
mais ils ne savaient pas vraiment ce qui allait se passer.

439
0:19:54,000 --> 0:19:59,000
Ils ne pouvaient pas anticiper les téléphones portables, Internet, et tous ces trucs.

440
0:19:59,000 --> 0:20:01,000
Ils savaient que, eh, ils allaient construire des calculatrices

441
0:20:01,000 --> 0:20:03,000
et des feux de signalisation. Mais ça allait être énorme.

442
0:20:03,000 --> 0:20:06,000
De la même façon, la science du cerveau et ces mémoires

443
0:20:06,000 --> 0:20:09,000
vont être une technologie fondamentale, et ça va mener

444
0:20:09,000 --> 0:20:12,000
à des changements incroyables dans les 100 prochaines années.

445
0:20:12,000 --> 0:20:16,000
Et je suis très excité quant à la façon dont on on les utilisera en science.

446
0:20:16,000 --> 0:20:19,000
Je pense que j'arrive à la limite de mon temps, donc je vais terminer mon discours

447
0:20:19,000 --> 0:20:2,000
maintenant.

