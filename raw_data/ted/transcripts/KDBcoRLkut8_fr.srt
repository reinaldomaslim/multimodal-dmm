1
0:00:,000 --> 0:00:07,000
Traducteur: Elliot O'Sullivan Relecteur: Coralie Charbonnel

2
0:00:12.844,000 --> 0:00:14,000
Quand on réfléchit aux idées reçues et aux préjugés,

3
0:00:15.452,000 --> 0:00:17,000
on pense souvent aux gens mal intentionnés

4
0:00:17.696,000 --> 0:00:19,000
qui font des choses stupides et mauvaises.

5
0:00:20.29,000 --> 0:00:24,000
Le critique britannique William Hazlitt résume bien cette idée :

6
0:00:25.08,000 --> 0:00:27,000
« Le préjugé naît de l'ignorance. »

7
0:00:27.753,000 --> 0:00:3,000
Je veux essayer ici de vous convaincre que c'est une erreur.

8
0:00:31.425,000 --> 0:00:32,000
Je veux essayer de vous convaincre

9
0:00:33.322,000 --> 0:00:37,000
que les idées reçues et les préjugés sont naturels, souvent rationnels,

10
0:00:38.145,000 --> 0:00:39,000
et qu'ils sont même plutôt moraux.

11
0:00:39.944,000 --> 0:00:4,000
Et je pense qu'une fois que l'on a compris cela,

12
0:00:41.866,000 --> 0:00:43,000
on est mieux placé pour leur donner un sens

13
0:00:44.375,000 --> 0:00:46,000
si ça tourne mal, s'ils ont des conséquences horribles.

14
0:00:47.252,000 --> 0:00:51,000
Nous saurons mieux comment réagir lorsque cela se produit.

15
0:00:51.315,000 --> 0:00:53,000
Commençons par les clichés.

16
0:00:53.424,000 --> 0:00:55,000
Vous me regardez, vous connaissez mon nom,

17
0:00:55.49,000 --> 0:00:57,000
d'autres choses sur moi et vous pourriez vous faire un avis.

18
0:00:58.459,000 --> 0:01:01,000
Vous pourriez deviner mon origine ethnique

19
0:01:01.752,000 --> 0:01:03,000
mon appartenance politique, mes croyances religieuses.

20
0:01:04.563,000 --> 0:01:06,000
Et de fait, ces préjugés peuvent se vérifier.

21
0:01:06.882,000 --> 0:01:07,000
On est très bon à ce genre de choses.

22
0:01:08.724,000 --> 0:01:12,000
Et on y arrive très bien car notre capacité à stéréotyper les gens

23
0:01:12.957,000 --> 0:01:15,000
n'est pas une anomalie de l'esprit

24
0:01:16.194,000 --> 0:01:18,000
mais plutôt la preuve particulière

25
0:01:18.511,000 --> 0:01:19,000
d'un processus plus général

26
0:01:20.166,000 --> 0:01:21,000
basé sur notre expérience

27
0:01:21.785,000 --> 0:01:23,000
des choses et des gens que l'on peut catégoriser.

28
0:01:24.646,000 --> 0:01:26,000
On peut utiliser notre expérience pour généraliser

29
0:01:27.221,000 --> 0:01:29,000
et faire de nouvelles occurrences de ces catégories.

30
0:01:29.72,000 --> 0:01:31,000
Tout le monde ici a beaucoup d'experience

31
0:01:31.757,000 --> 0:01:33,000
au sujet des chaises, des pommes et des chiens.

32
0:01:34.01,000 --> 0:01:37,000
À partir de ça on peut rencontrer des exemples inconnus

33
0:01:37.512,000 --> 0:01:39,000
et en déduire qu'on s'assied sur la chaise,

34
0:01:39.664,000 --> 0:01:41,000
et qu'on mange la pomme que le chien aboiera.

35
0:01:42.139,000 --> 0:01:43,000
On pourrait se tromper.

36
0:01:44.113,000 --> 0:01:45,000
La chaise pourrait s'effondrer,

37
0:01:45.783,000 --> 0:01:47,000
la pomme être toxique et le chien ne pas aboyer

38
0:01:48.115,000 --> 0:01:51,000
et d'ailleurs là c'est ma chienne, Tessie, qui n'aboie pas.

39
0:01:51.215,000 --> 0:01:53,000
Mais dans la plupart des cas on est bon.

40
0:01:53.294,000 --> 0:01:54,000
Dans la plupart des cas, on devine bien

41
0:01:55.21,000 --> 0:01:57,000
que ce soit socialement parlant ou non

42
0:01:57.414,000 --> 0:01:58,000
et si ce n'était pas le cas,

43
0:01:58.973,000 --> 0:02:01,000
si on ne pouvait pas faire de déduction des nouveaux cas rencontrés

44
0:02:02.269,000 --> 0:02:03,000
on ne survivrait pas.

45
0:02:03.82,000 --> 0:02:07,000
Hazlitt le concède d'ailleurs ensuite dans son brillant essai.

46
0:02:08.289,000 --> 0:02:1,000
Il dit : « Sans l'aide des préjugés et des habitudes,

47
0:02:10.806,000 --> 0:02:12,000
je ne serais pas capable de traverser une pièce,

48
0:02:13.096,000 --> 0:02:15,000
de savoir comment agir selon les circonstances,

49
0:02:15.798,000 --> 0:02:18,000
ou ce que je dois ressentir dans n'importe quelle relation de ma vie"

50
0:02:19.531,000 --> 0:02:2,000
Parlons-nous de la partialité.

51
0:02:21.039,000 --> 0:02:22,000
Parfois on divise le monde en deux :

52
0:02:22.747,000 --> 0:02:25,000
nous face à eux, les membres d'un groupe face aux autres

53
0:02:25.749,000 --> 0:02:26,000
et lorsque l'on fait ça,

54
0:02:26.91,000 --> 0:02:27,000
on sait parfois que c'est mal

55
0:02:28.467,000 --> 0:02:29,000
et en quelque sorte on en a honte.

56
0:02:30.14,000 --> 0:02:31,000
D'autres fois on en est fiers.

57
0:02:31.623,000 --> 0:02:32,000
On l'admet ouvertement.

58
0:02:33.436,000 --> 0:02:36,000
Mon exemple préféré de cela est une question posée par le public

59
0:02:37.128,000 --> 0:02:39,000
lors d'un débat républicain avant les dernières élections.

60
0:02:40.107,000 --> 0:02:42,000
(Vidéo) Anderson Cooper : passons à vos questions,

61
0:02:42.549,000 --> 0:02:45,000
la question est sur l'aide étrangère ? Oui Madame.

62
0:02:46.31,000 --> 0:02:48,000
Femme : Aujourd'hui les américains

63
0:02:48.506,000 --> 0:02:5,000
souffrent dans notre pays.

64
0:02:51.183,000 --> 0:02:54,000
Pourquoi continue-t-on à envoyer de l'aide étrangère

65
0:02:54.531,000 --> 0:02:55,000
aux autres pays

66
0:02:55.847,000 --> 0:02:59,000
alors que l'on a déjà besoin de toute cette aide pour nous mêmes ?

67
0:02:59.95,000 --> 0:03:02,000
AC : Gouverneur Perry qu'en pensez-vous ? (Applaudissements)

68
0:03:03.105,000 --> 0:03:05,000
Perry : Absolument, je pense que --

69
0:03:05.35,000 --> 0:03:08,000
Paul Bloom : Tous les gens sur scène étaient d'accord avec la question,

70
0:03:09,000 --> 0:03:12,000
de dire qu'en tant qu'américains on devrait plus se soucier des américains

71
0:03:12.58,000 --> 0:03:13,000
que des autres.

72
0:03:13.796,000 --> 0:03:15,000
En général les gens sont influencés

73
0:03:16.091,000 --> 0:03:19,000
par un sentiment de loyauté, de solidarité, de fierté, de patriotisme

74
0:03:19.599,000 --> 0:03:21,000
envers leur pays ou leur groupe ethnique.

75
0:03:22.315,000 --> 0:03:25,000
Sans lien politique, beaucoup sont fiers d'être americains

76
0:03:25.4,000 --> 0:03:27,000
ils préfèrent les américains aux autres.

77
0:03:27.462,000 --> 0:03:29,000
Les habitants d'autres pays réagissent pareil pour leur pays

78
0:03:30.312,000 --> 0:03:32,000
et nous faisons de même pour notre groupe ethnique

79
0:03:32.798,000 --> 0:03:33,000
Certains ici peuvent rejeter ça.

80
0:03:34.482,000 --> 0:03:35,000
Certains peuvent être cosmopolites

81
0:03:36.213,000 --> 0:03:38,000
au point de penser que l'ethnicité, la nationalité

82
0:03:38.547,000 --> 0:03:4,000
ne devraient pas avoir d'influence morale.

83
0:03:41.11,000 --> 0:03:43,000
Mais même ceux là admettent

84
0:03:43.462,000 --> 0:03:45,000
que le groupe tend à tirer à soi

85
0:03:45.516,000 --> 0:03:47,000
des gens par rapport à leurs amis et familles,

86
0:03:47.997,000 --> 0:03:48,000
leurs proches,

87
0:03:49.418,000 --> 0:03:52,000
et alors même vous, faites une distinction entre eux et nous.

88
0:03:52.954,000 --> 0:03:54,000
Cette distinction est plutôt naturelle,

89
0:03:55.557,000 --> 0:03:58,000
et souvent plutôt morale, mais elle peut aussi mal tourner.

90
0:03:58.631,000 --> 0:04:02,000
et c'est une partie des recherches menées par le brillant psychologue Henri Tajfel.

91
0:04:03.22,000 --> 0:04:05,000
Tajifel es né en Pologne en 1919.

92
0:04:06.004,000 --> 0:04:07,000
Il est allé étudier en France car,

93
0:04:07.713,000 --> 0:04:09,000
étant Juif, il ne pouvait pas étudier à la fac en Pologne.

94
0:04:10.498,000 --> 0:04:12,000
Il s'est alors engagé dans l'armée française pendant

95
0:04:13.028,000 --> 0:04:14,000
la 2nde guerre mondiale.

96
0:04:14.251,000 --> 0:04:17,000
On l'a capturé et emmené dans un camp de prisonniers de guerre

97
0:04:17.72,000 --> 0:04:18,000
et c'était un moment terrifiant pour lui

98
0:04:19.628,000 --> 0:04:2,000
car si l'on découvrait sa religion

99
0:04:21.316,000 --> 0:04:23,000
il pouvait être envoyé dans un camp de concentration,

100
0:04:23.898,000 --> 0:04:24,000
où il n'aurait pas survécu.

101
0:04:25.797,000 --> 0:04:27,000
En fait, quand on l'a relâché à la fin de la guerre,

102
0:04:28.471,000 --> 0:04:3,000
la plupart de ses proches étaient morts.

103
0:04:30.809,000 --> 0:04:32,000
Il a participé à beaucoup d'activités.

104
0:04:32.829,000 --> 0:04:33,000
Il a aidé les orphelins de guerre.

105
0:04:34.481,000 --> 0:04:37,000
Mais son intérêt de longue date portait sur la science des préjugés,

106
0:04:37.526,000 --> 0:04:4,000
et donc quand une bourse prestigieuse s'est ouverte sur les stéréotypes,

107
0:04:41.281,000 --> 0:04:43,000
il y a postulé et il l'a remporté

108
0:04:43.318,000 --> 0:04:45,000
et il a commencé une carrière incroyable.

109
0:04:45.677,000 --> 0:04:46,000
Ce qui a débuté sa carrière,

110
0:04:47.367,000 --> 0:04:49,000
c'est l'idée que la façon dont la plupart de gens

111
0:04:49.663,000 --> 0:04:51,000
pensait à l'holocauste était incorrecte.

112
0:04:52.019,000 --> 0:04:56,000
Beaucoup de gens, voire la plupart à l'époque, considéraient l'holocauste

113
0:04:56.13,000 --> 0:04:59,000
comme la représentation d'un défaut tragique des allemands

114
0:04:59.594,000 --> 0:05:03,000
une sorte de faiblesse génétique, le signe d'une personnalité autoritaire.

115
0:05:03.626,000 --> 0:05:04,000
Tajfel a rejeté cette idée.

116
0:05:05.499,000 --> 0:05:07,000
Il a dit que ce que nous voyons dans l'holocauste

117
0:05:08.4,000 --> 0:05:09,000
est juste une exagération

118
0:05:10.248,000 --> 0:05:12,000
des processus psychologiques normaux

119
0:05:12.409,000 --> 0:05:13,000
qui existent chez n'importe qui.

120
0:05:14.124,000 --> 0:05:16,000
Et pour approfondir cela, il a réalisé une série d'études

121
0:05:16.688,000 --> 0:05:17,000
auprès d'adolescents britanniques.

122
0:05:18.557,000 --> 0:05:19,000
Au cours de l'une de ses études,

123
0:05:20.019,000 --> 0:05:22,000
il a posé toutes sortes de questions aux adolescents

124
0:05:22.463,000 --> 0:05:23,000
et au vu de leurs réponses, il a conclu :

125
0:05:24.39,000 --> 0:05:26,000
"J'ai regardé vos réponses et à partir de cela,

126
0:05:26.737,000 --> 0:05:29,000
j'ai déterminé que vous étiez--", il a dit ça à une moitié des ados,

127
0:05:29.933,000 --> 0:05:32,000
"un amateur de Kandinsky, vous aimez son oeuvre."

128
0:05:33.068,000 --> 0:05:35,000
Ou : "Vous êtes un amateur de Klee, vous aimez son oeuvre."

129
0:05:35.924,000 --> 0:05:36,000
C'était entièrement truqué.

130
0:05:37.714,000 --> 0:05:39,000
L'artiste n'avait rien à voir avec leurs réponses.

131
0:05:40.032,000 --> 0:05:42,000
Ils n'avaient probablement pas entendu parler des artistes.

132
0:05:42.772,000 --> 0:05:44,000
Il les a juste divisés arbitrairement en deux groupes.

133
0:05:45.513,000 --> 0:05:48,000
Mais ce qu'il a découvert, c'est l'importance de ces catégories.

134
0:05:48.664,000 --> 0:05:5,000
Et plus tard, quand il a donné de l'argent aux gens,

135
0:05:51.09,000 --> 0:05:54,000
ils préféreraient le donner aux membres de leur propre groupe

136
0:05:54.553,000 --> 0:05:55,000
qu'à ceux de l'autre groupe.

137
0:05:56.54,000 --> 0:05:58,000
Pire, ils s'étaient surtout attachés

138
0:05:59.126,000 --> 0:06:03,000
à la mise en place d'une différence entre leur groupe et les autres,

139
0:06:03.21,000 --> 0:06:05,000
ils donneraient donc à leur propre groupe

140
0:06:05.378,000 --> 0:06:09,000
si cela signifiait qu'ils donneraient encore moins à l'autre groupe.

141
0:06:10.256,000 --> 0:06:12,000
Cette préférence semble se révéler très tot.

142
0:06:12.756,000 --> 0:06:14,000
Ma collègue et femme, Karen Wynn, à Yale

143
0:06:15.067,000 --> 0:06:16,000
a mené des études auprès de bébés

144
0:06:16.969,000 --> 0:06:18,000
qu'elle expose à des peluches

145
0:06:19.524,000 --> 0:06:21,000
qui ont différentes préférences alimentaires.

146
0:06:21.616,000 --> 0:06:23,000
Par exemple, l'une aime les haricots verts

147
0:06:23.871,000 --> 0:06:25,000
et l'autre aime les crackers.

148
0:06:26.15,000 --> 0:06:28,000
On analyse les préférences alimentaires des bébés,

149
0:06:29.06,000 --> 0:06:31,000
et typiquement ils préfèrent les crackers.

150
0:06:31.362,000 --> 0:06:33,000
Mais est-ce que leur préférence influence la façon

151
0:06:34.128,000 --> 0:06:36,000
dont ils se comportent avec les peluches? Oui, beaucoup.

152
0:06:37.087,000 --> 0:06:41,000
En général, ils préfèrent celle qui a les même goûts alimentaires,

153
0:06:41.786,000 --> 0:06:43,000
et pire, ils préfèrent même les peluches

154
0:06:44.621,000 --> 0:06:46,000
qui punissent celles qui ont des goûts différents.

155
0:06:47.608,000 --> 0:06:49,000
(Rires)

156
0:06:50.28,000 --> 0:06:53,000
On retrouve ce clivage psychologique 'eux/nous' tout le temps.

157
0:06:53.854,000 --> 0:06:57,000
Que ce soit en débats politiques, entre des groupes idéologiquement opposés.

158
0:06:57.888,000 --> 0:07:,000
C'est même poussé à l'extrême en cas de guerre,

159
0:07:01.189,000 --> 0:07:04,000
où 'les autres' ne sont pas seulement lésés

160
0:07:04.373,000 --> 0:07:05,000
mais déshumanisés,

161
0:07:06.003,000 --> 0:07:08,000
à l'instar des Nazis considérant les Juifs

162
0:07:08.63,000 --> 0:07:09,000
comme de la vermine ou des poux,

163
0:07:10.416,000 --> 0:07:14,000
ou les américains comparant les Japonais à des rats.

164
0:07:14.66,000 --> 0:07:16,000
Les clichés peuvent aussi mal tourner.

165
0:07:16.871,000 --> 0:07:18,000
Ils sont souvent rationnels et utiles,

166
0:07:18.915,000 --> 0:07:19,000
mais parfois ils ne le sont pas,

167
0:07:20.451,000 --> 0:07:21,000
ils donnent les mauvaises solutions

168
0:07:22.258,000 --> 0:07:25,000
et à d'autres moments ils entraînent des conséquences immorales.

169
0:07:25.661,000 --> 0:07:27,000
Le cas qui a été le plus examiné

170
0:07:28.278,000 --> 0:07:29,000
est celui de la race.

171
0:07:29.985,000 --> 0:07:32,000
Une étude fascinante avant l'élection de 2008

172
0:07:33.349,000 --> 0:07:36,000
avait analysé à quel point

173
0:07:36.547,000 --> 0:07:39,000
les candidats étaient associés aux États-Unis

174
0:07:39.872,000 --> 0:07:42,000
comme dans une association inconsciente avec le drapeau américain.

175
0:07:43.268,000 --> 0:07:45,000
Dans l'une de leurs études ils comparaient Obama et McCain,

176
0:07:46.062,000 --> 0:07:49,000
et le résultat montrait que McCain était considéré comme plus américain,

177
0:07:49.925,000 --> 0:07:51,000
Et d'un certain côté, les gens n'en sont pas trop surpris.

178
0:07:52.923,000 --> 0:07:54,000
McCain est un héros de guerre,

179
0:07:55.046,000 --> 0:07:56,000
et beaucoup de gens diraient même

180
0:07:56.616,000 --> 0:07:58,000
qu'il représente plus qu'Obama l'histoire américaine.

181
0:07:59.113,000 --> 0:08:,000
Mais ils comparaient aussi Obama

182
0:08:00.979,000 --> 0:08:02,000
à Tony Blair, l'ancien premier ministre britannique,

183
0:08:03.65,000 --> 0:08:04,000
et ils se sont aperçus

184
0:08:05.127,000 --> 0:08:08,000
que Blair était aussi considéré plus américain qu'Obama,

185
0:08:08.26,000 --> 0:08:12,000
même si les sujets comprenaient clairement qu'il n'est pas du tout américain.

186
0:08:13.22,000 --> 0:08:16,000
En fait, ils se fiaient surtout à la couleur de sa peau.

187
0:08:17.896,000 --> 0:08:2,000
Ces stéréotypes et préjugés ont des conséquences sur le monde réel

188
0:08:21.516,000 --> 0:08:23,000
à la fois subtiles et très importantes.

189
0:08:23.82,000 --> 0:08:27,000
Dans une étude récente, des chercheurs ont posté des pubs sur eBay

190
0:08:28.419,000 --> 0:08:29,000
pour la vente de cartes de base-ball.

191
0:08:30.183,000 --> 0:08:32,000
Certains étaient tenues par des mains blanches,

192
0:08:32.851,000 --> 0:08:33,000
d'autres par des mains noires.

193
0:08:34.36,000 --> 0:08:35,000
Les cartes étaient les mêmes.

194
0:08:36.064,000 --> 0:08:38,000
Celles des mains noires ont reçu des offres inférieures

195
0:08:38.995,000 --> 0:08:4,000
à celles des mains blanches.

196
0:08:41.437,000 --> 0:08:43,000
Dans une recherche de l'université de Stanford

197
0:08:43.797,000 --> 0:08:46,000
des psychologues ont étudié le cas de personnes

198
0:08:47.776,000 --> 0:08:5,000
condamnées pour le meurtre d'une personne blanche.

199
0:08:51.27,000 --> 0:08:54,000
Il s'avère que, à situation totalement égale,

200
0:08:54.39,000 --> 0:08:56,000
il est plus probable d'être exécuté

201
0:08:56.887,000 --> 0:08:59,000
si on ressemble à l'homme de droite qu'à l'homme de gauche,

202
0:09:00.51,000 --> 0:09:01,000
et c'est essentiellement parce que

203
0:09:02.454,000 --> 0:09:04,000
l'homme de droite a plus l'air d'être noir

204
0:09:04.854,000 --> 0:09:06,000
plus typiquement afro-américain,

205
0:09:07.193,000 --> 0:09:1,000
et ça influence apparemment les gens au moment de décider de sa sentence.

206
0:09:11.67,000 --> 0:09:13,000
Alors maintenant qu'on le sait, comment lutter contre cela?

207
0:09:14.499,000 --> 0:09:16,000
Il y a différentes façons.

208
0:09:16.523,000 --> 0:09:19,000
L'une consiste à faire appel aux réactions émotionnelles des gens,

209
0:09:20.132,000 --> 0:09:21,000
à leur empathie,

210
0:09:21.685,000 --> 0:09:23,000
on le fait souvent par des histoires.

211
0:09:24.22,000 --> 0:09:26,000
Par exemple, si vous êtes un parent liberal

212
0:09:26.502,000 --> 0:09:28,000
et que vous voulez pousser vos enfants

213
0:09:28.616,000 --> 0:09:3,000
à croire au mérite des familles non-traditionnelles

214
0:09:30.959,000 --> 0:09:32,000
vous pourriez leur offrir "Heather a deux mamans"

215
0:09:33.415,000 --> 0:09:35,000
Si vous êtes conservateur, vous offririez plutôt celui-là:

216
0:09:36.246,000 --> 0:09:38,000
"A l'aide! Des libéraux sous mon lit!"

217
0:09:38.452,000 --> 0:09:41,000
Mais en général, une histoire peut transformer

218
0:09:41.723,000 --> 0:09:43,000
de sombres inconnus en individus qui comptent,

219
0:09:43.958,000 --> 0:09:45,000
et l'idée que l'on tient à des gens

220
0:09:46.48,000 --> 0:09:47,000
lorsque l'on les reconnait en tant qu'individus,

221
0:09:48.479,000 --> 0:09:5,000
est une idée apparue au cours de l'Histoire.

222
0:09:50.982,000 --> 0:09:52,000
D'ailleurs, on dit que Staline aurait dit,

223
0:09:53.229,000 --> 0:09:56,000
"Un mort est une tragédie, un million de morts, c'est statistique."

224
0:09:56.759,000 --> 0:09:57,000
Mère Teresa disait,

225
0:09:58.1,000 --> 0:10:01,000
"Si je regarde la foule je n'agirai jamais si je regarde une personne, je le ferai."

226
0:10:01.976,000 --> 0:10:02,000
Les psychologues ont étudié cela.

227
0:10:03.717,000 --> 0:10:05,000
Par exemple, dans une étude

228
0:10:05.76,000 --> 0:10:08,000
on a donné aux sujets une liste de faits à propos d'une crise

229
0:10:08.776,000 --> 0:10:11,000
et on a observé combien ils donneraient

230
0:10:12.33,000 --> 0:10:13,000
pour résoudre cette crise,

231
0:10:14.117,000 --> 0:10:16,000
un autre groupe n'avait pas la liste,

232
0:10:16.225,000 --> 0:10:17,000
mais on leur parlait d'un individu,

233
0:10:18.055,000 --> 0:10:2,000
en donnant un nom et un visage,

234
0:10:20.554,000 --> 0:10:23,000
et il se trouve que ceux là ont donné bien plus que les autres.

235
0:10:23.835,000 --> 0:10:24,000
Tout cela ce n'est pas un secret

236
0:10:25.636,000 --> 0:10:27,000
pour ceux qui font du bénévolat.

237
0:10:27.844,000 --> 0:10:3,000
En général, on ne bombarde pas les gens de faits et de statistiques

238
0:10:31.499,000 --> 0:10:33,000
On leur montre plutôt des visages, des personnes.

239
0:10:34.285,000 --> 0:10:38,000
Il est possible qu'en élargissant notre sympathie à un individu,

240
0:10:38.453,000 --> 0:10:42,000
cela se propage au groupe auquel la personne appartient.

241
0:10:42.991,000 --> 0:10:44,000
Voici Harriet Beecher Stowe.

242
0:10:45.1,000 --> 0:10:49,000
L'histoire, peut-être inventée, raconte que le président Lincoln l'avait invitée

243
0:10:49.514,000 --> 0:10:51,000
à la maison blanche pendant la guerre civile

244
0:10:51.948,000 --> 0:10:52,000
et lui avait dit:

245
0:10:52.952,000 --> 0:10:54,000
"Alors c'est toi la femme à l'origine de cette grande guerre."

246
0:10:55.847,000 --> 0:10:57,000
il parlait de "La Case de l'oncle Tom."

247
0:10:57.878,000 --> 0:10:59,000
Ce livre n'est pas une grande oeuvre philosophique

248
0:11:00.182,000 --> 0:11:03,000
ou théologique ou peut-être même littéraire,

249
0:11:03.217,000 --> 0:11:05,000
mais ce qu'il fait bien

250
0:11:05.415,000 --> 0:11:08,000
c'est d'aider les gens à se mettre à la place d'autres

251
0:11:08.858,000 --> 0:11:1,000
alors qu'ils ne le feraient pas autrement,

252
0:11:11.01,000 --> 0:11:12,000
à se mettre à la place des esclaves.

253
0:11:12.971,000 --> 0:11:15,000
Et ça a très bien pu être le catalyseur pour le grand changement social.

254
0:11:16.625,000 --> 0:11:18,000
Plus récemment à propos d'Étas-Unis

255
0:11:19.004,000 --> 0:11:22,000
au cours des dernières décennies, on a des raisons de croire

256
0:11:22.873,000 --> 0:11:24,000
que des programmes comme "The Cosby Show",

257
0:11:25.141,000 --> 0:11:27,000
ont changé l'attitude des Américains envers les Afro-Américains,

258
0:11:27.884,000 --> 0:11:29,000
et que des programmes comme "Will et Grace" et "Modern Family"

259
0:11:30.817,000 --> 0:11:32,000
ont modifié les comportements envers les homosexuels.

260
0:11:33.472,000 --> 0:11:34,000
Il n'est pas exagéré de dire

261
0:11:35.463,000 --> 0:11:38,000
que le grand catalyseur du changement moral aux Etats-Unis

262
0:11:38.716,000 --> 0:11:39,000
a été le sitcom.

263
0:11:41.092,000 --> 0:11:42,000
Il ne s'agit pas seulement d'émotions.

264
0:11:43.058,000 --> 0:11:46,000
Je terminerai en faisant appel à la raison.

265
0:11:46.104,000 --> 0:11:49,000
Dans ce livre merveilleux "The Better Angels of Our Nature,"

266
0:11:49.492,000 --> 0:11:5,000
Steven Pinker soulève que

267
0:11:51.014,000 --> 0:11:54,000
l'Ancien Testament dicte d'aimer son prochain

268
0:11:54.336,000 --> 0:11:56,000
le Nouveau Testament dicte d'aimer son ennemi,

269
0:11:56.932,000 --> 0:11:58,000
mais je n'aime ni l'un ni l'autre, sincèrement,

270
0:11:59.459,000 --> 0:12:,000
mais je ne veux pas les tuer.

271
0:12:01.325,000 --> 0:12:02,000
Je comprends mes obligations envers eux,

272
0:12:03.315,000 --> 0:12:06,000
mais mes sentiments pour eux, mes convictions morales,

273
0:12:06.398,000 --> 0:12:08,000
et la façon dont je me comporte,

274
0:12:08.445,000 --> 0:12:09,000
ne sont pas basés sur l'amour.

275
0:12:10.174,000 --> 0:12:12,000
Ils sont basés sur une compréhension des droits de l'homme,

276
0:12:12.977,000 --> 0:12:15,000
que leur vie vaut pour eux autant que la mienne pour moi.

277
0:12:16.639,000 --> 0:12:2,000
Et pour soutenir cela, il raconte une histoire du philosophe Adam Smith,

278
0:12:20.857,000 --> 0:12:21,000
et je veux la raconter aussi,

279
0:12:22.401,000 --> 0:12:24,000
mais je vais l'adapter un peu à nos temps modernes.

280
0:12:25.109,000 --> 0:12:29,000
Adam Smith commence en vous demandant d'imaginer la mort de milliers de gens

281
0:12:29.27,000 --> 0:12:33,000
et d'imaginer que ces gens se trouvent dans un pays que vous ne connaissez pas.

282
0:12:33.449,000 --> 0:12:36,000
Cela peut-être en Chine, en Inde ou dans un pays africain.

283
0:12:36.898,000 --> 0:12:38,000
Et Smith demande comment vous répondriez?

284
0:12:39.305,000 --> 0:12:41,000
Et vous diriez que c'est dommage,

285
0:12:41.391,000 --> 0:12:43,000
et vous continueriez votre vie.

286
0:12:43.4,000 --> 0:12:45,000
Si vous ouvriez le NY Times en ligne, ou autre,

287
0:12:46.11,000 --> 0:12:48,000
et que vous découvriez cela, ce qui arrive souvent,

288
0:12:48.791,000 --> 0:12:49,000
on vaque à ses occupations.

289
0:12:50.525,000 --> 0:12:53,000
Mais imaginez maintenant, nous dit Smith, vous découvriez que demain

290
0:12:53.999,000 --> 0:12:55,000
vous vous apprêtez à vous faire couper le petit doigt.

291
0:12:56.767,000 --> 0:12:57,000
Cela vous importerait beaucoup.

292
0:12:58.668,000 --> 0:13:,000
Vous passeriez la nuit debout à y réfléchir.

293
0:13:01.081,000 --> 0:13:03,000
Alors cela soulève la question :

294
0:13:03.187,000 --> 0:13:05,000
Est-ce que vous sacrifieriez des milliers de vies

295
0:13:05.736,000 --> 0:13:06,000
pour sauver votre petit doigt?

296
0:13:07.414,000 --> 0:13:09,000
Répondez à cela dans votre tête,

297
0:13:09.923,000 --> 0:13:11,000
mais Smith répond, absolument pas,

298
0:13:12.725,000 --> 0:13:14,000
quelle idée horrible.

299
0:13:14.776,000 --> 0:13:17,000
Et cela soulève donc la question comme Smith l'exprime,

300
0:13:17.957,000 --> 0:13:19,000
"Si nos sentiments passifs sont presque toujours

301
0:13:20.245,000 --> 0:13:21,000
aussi sordides et égoïstes,

302
0:13:21.68,000 --> 0:13:22,000
pourquoi nos principes actifs

303
0:13:23.343,000 --> 0:13:25,000
devrait souvent être aussi généreux et nobles?"

304
0:13:25.613,000 --> 0:13:26,000
La réponse de Smith est :

305
0:13:26.938,000 --> 0:13:29,000
"C'est la raison, les principes, la conscience qui nous influencent

306
0:13:30.829,000 --> 0:13:33,000
pour surmonter la plus présomptueuse de nos passions

307
0:13:34.386,000 --> 0:13:35,000
qui est que nous sommes un parmi d'autres

308
0:13:36.342,000 --> 0:13:38,000
en aucun cas meilleur que n'importe lequel autre"

309
0:13:38.917,000 --> 0:13:42,000
Cette dernière partie est ce qu'on décrit souvent comme le principe d’impartialité.

310
0:13:43.805,000 --> 0:13:47,000
Et ce principe est présent dans toutes les religions du monde,

311
0:13:48.179,000 --> 0:13:5,000
dans toutes les versions de la règle d'or,

312
0:13:50.643,000 --> 0:13:52,000
et toutes les philosophies morales du monde

313
0:13:52.7,000 --> 0:13:53,000
qui se différencient mais

314
0:13:54.304,000 --> 0:13:57,000
partagent le présupposé qu'on devrait juger la morale

315
0:13:57.569,000 --> 0:13:59,000
d'un point de vue plus ou moins impartial.

316
0:14:00.191,000 --> 0:14:02,000
La meilleur explication de cette idée

317
0:14:02.276,000 --> 0:14:05,000
est à mon avis, non pas celle d'un théologien ou d'un philosophe,

318
0:14:05.573,000 --> 0:14:07,000
mais celle de Humphrey Bogart à la fin du film "Casablanca"

319
0:14:08.39,000 --> 0:14:11,000
Alors, alerte spoiler, il dit à son amante

320
0:14:11.596,000 --> 0:14:14,000
qu'ils doivent se séparer pour le bien de tout le monde,

321
0:14:14.829,000 --> 0:14:15,000
et il dit --je ne ferai pas l'accent--

322
0:14:16.665,000 --> 0:14:19,000
il lui dit : "Je n'ai rien de magnanime mais avouons que nos petits problèmes

323
0:14:20.304,000 --> 0:14:22,000
n'ont pas grande importance dans ce monde en folie."

324
0:14:23.184,000 --> 0:14:25,000
Notre raison pourrait nous faire surmonter nos passions.

325
0:14:26.05,000 --> 0:14:28,000
Notre raison pourrait nous motiver à montrer plus d'empathie,

326
0:14:28.981,000 --> 0:14:3,000
à écrire un livre comme "La Case de l'oncle Tom"

327
0:14:31.494,000 --> 0:14:32,000
ou à lire un tel livre,

328
0:14:33.278,000 --> 0:14:37,000
et notre raison peut nous motiver à créer des coutumes, des tabous et des lois

329
0:14:37.498,000 --> 0:14:4,000
qui nous empêcheront d'agir de façon impulsive

330
0:14:40.924,000 --> 0:14:43,000
quand, en tant qu'êtres rationnels on devrait se sentir obligés.

331
0:14:43.989,000 --> 0:14:45,000
C'est ça une constitution.

332
0:14:46.22,000 --> 0:14:48,000
Une constitution c'est une chose qu'on a installé dans le passé

333
0:14:49.219,000 --> 0:14:5,000
qui s'applique à présent et qui dit,

334
0:14:51.041,000 --> 0:14:55,000
qu'indépendamment du désir de réélire un président populaire une troisième fois,

335
0:14:55.834,000 --> 0:14:56,000
indépendamment du désir

336
0:14:57.382,000 --> 0:15:,000
des américains blancs de rétablir l'esclavage,

337
0:15:01.12,000 --> 0:15:02,000
on ne le peut pas.

338
0:15:02.373,000 --> 0:15:03,000
Nous nous sommes limités nous-mêmes.

339
0:15:04.12,000 --> 0:15:06,000
Et nous nous sommes aussi liés d'une autre manière.

340
0:15:06.498,000 --> 0:15:08,000
On sait, que lorsque l'on doit choisir quelqu'un

341
0:15:09.129,000 --> 0:15:12,000
pour un travail ou pour une récompense,

342
0:15:12.147,000 --> 0:15:14,000
on est fortement influencé par sa race,

343
0:15:14.953,000 --> 0:15:16,000
on est influencé par son genre,

344
0:15:17.018,000 --> 0:15:19,000
ou par le charme de la personne,

345
0:15:19.539,000 --> 0:15:21,000
et parfois on dirait : "C'est comme ça que ça doit être."

346
0:15:22.226,000 --> 0:15:24,000
Mais d'autres fois, on dirait : "C'est injuste."

347
0:15:24.325,000 --> 0:15:25,000
Alors pour lutter contre cela,

348
0:15:26.196,000 --> 0:15:28,000
non seulement on doit faire plus d'efforts

349
0:15:28.687,000 --> 0:15:3,000
mais on doit surtout construire des situations dans lesquelles

350
0:15:31.666,000 --> 0:15:34,000
on ne peut pas être influencés par d'autres sources d'informations.

351
0:15:34.811,000 --> 0:15:37,000
Ainsi, beaucoup d'orchestres auditionnent les musiciens derrière un écran

352
0:15:38.426,000 --> 0:15:4,000
afin qu'ils aient seulement l'information importante

353
0:15:40.891,000 --> 0:15:41,000
et pas tout le reste.

354
0:15:42.696,000 --> 0:15:44,000
Je pense que les idées reçues et les préjugés

355
0:15:45.373,000 --> 0:15:47,000
illustrent une dualité fondamentale de la nature humaine.

356
0:15:48.219,000 --> 0:15:51,000
On a des intuitions, des instincts et des émotions

357
0:15:52.21,000 --> 0:15:54,000
qui influencent nos jugements et nos actes,

358
0:15:54.541,000 --> 0:15:55,000
pour le bien et le mal,

359
0:15:56.443,000 --> 0:15:59,000
mais nous sommes aussi capables de mener une réflexion rationnelle

360
0:15:59.908,000 --> 0:16:,000
et une préparation intelligente

361
0:16:01.632,000 --> 0:16:03,000
que l'on peut utiliser pour, dans certains cas,

362
0:16:04.085,000 --> 0:16:06,000
accélérer et alimenter nos émotions,

363
0:16:06.343,000 --> 0:16:08,000
et d'autres fois les apaiser.

364
0:16:08.947,000 --> 0:16:11,000
C'est ainsi que la raison nous aide à créer un monde meilleur.

365
0:16:12.884,000 --> 0:16:13,000
Merci.

366
0:16:13.979,000 --> 0:16:15,000
(Applaudissements)

