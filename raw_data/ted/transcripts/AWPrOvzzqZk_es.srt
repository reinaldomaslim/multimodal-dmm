1
0:00:,000 --> 0:00:07,000
Traductor: Angela Escobar Revisor: mariana vergnano

2
0:00:13.354,000 --> 0:00:16,000
La tecnología nos ha dado mucho:

3
0:00:16.489,000 --> 0:00:18,000
el alunizaje, el internet,

4
0:00:18.508,000 --> 0:00:2,000
lograr secuenciar el genoma humano.

5
0:00:21.133,000 --> 0:00:24,000
También llega a nuestros miedos más hondos

6
0:00:24.857,000 --> 0:00:25,000
y hace 30 años aproximadamente,

7
0:00:26.713,000 --> 0:00:28,000
el crítico cultural Neil Postman escribió un libro

8
0:00:29.266,000 --> 0:00:31,000
llamado "Divertirse hasta morir",

9
0:00:31.381,000 --> 0:00:33,000
en el que resalta esta verdad brillantemente.

10
0:00:34.14,000 --> 0:00:35,000
Aquí esta lo que dijo

11
0:00:35.79,000 --> 0:00:37,000
comparando las distópicas visiones

12
0:00:38.053,000 --> 0:00:41,000
de George Orwell y Aldous Huxley.

13
0:00:41.626,000 --> 0:00:44,000
Dijo: Orwell temía que nos volviéramos

14
0:00:44.752,000 --> 0:00:46,000
una cultura cautiva.

15
0:00:47,000 --> 0:00:5,000
Huxley, en una trivial.

16
0:00:50.752,000 --> 0:00:52,000
Orwell temía que la verdad

17
0:00:52.897,000 --> 0:00:53,000
nos sería ocultada,

18
0:00:54.82,000 --> 0:00:56,000
y Huxley que seríamos ahogados

19
0:00:57.01,000 --> 0:00:59,000
en un océano de irrelevancia.

20
0:00:59.703,000 --> 0:01:01,000
En resumen, es escoger entre

21
0:01:01.873,000 --> 0:01:03,000
el Gran hermano viéndote

22
0:01:04.473,000 --> 0:01:06,000
y tu viendo al Gran Hermano.

23
0:01:06.969,000 --> 0:01:07,000
(Risas)

24
0:01:08.9,000 --> 0:01:09,000
Pero no tiene que ser así.

25
0:01:10.634,000 --> 0:01:11,000
No somos consumidores pasivos

26
0:01:12.547,000 --> 0:01:13,000
de datos y tecnología.

27
0:01:14.09,000 --> 0:01:16,000
Decidimos el rol que juega en nuestra vida

28
0:01:16.563,000 --> 0:01:17,000
y cómo le damos significado,

29
0:01:18.503,000 --> 0:01:19,000
pero para hacerlo,

30
0:01:20.106,000 --> 0:01:21,000
tenemos que poner mucha atención

31
0:01:21.953,000 --> 0:01:22,000
desde cómo pensamos

32
0:01:23.8,000 --> 0:01:24,000
hasta cómo codificamos.

33
0:01:25.649,000 --> 0:01:28,000
Tenemos que hacer preguntas, preguntas difíciles,

34
0:01:28.747,000 --> 0:01:29,000
para pasar de contar cosas

35
0:01:30.616,000 --> 0:01:32,000
a entenderlas.

36
0:01:33.218,000 --> 0:01:35,000
Estamos bombardeados constantemente por historias

37
0:01:35.664,000 --> 0:01:37,000
de los muchos datos que hay en el mundo,

38
0:01:38.14,000 --> 0:01:39,000
pero cuando se refiere a datos masivos,

39
0:01:40.03,000 --> 0:01:42,000
y los retos de interpretarlos,

40
0:01:42.316,000 --> 0:01:44,000
el tamaño no lo es todo.

41
0:01:44.404,000 --> 0:01:45,000
También está la velocidad

42
0:01:46.347,000 --> 0:01:47,000
a la que se mueven,

43
0:01:47.47,000 --> 0:01:48,000
las muchas variantes de tipos de datos,

44
0:01:49.403,000 --> 0:01:51,000
he aquí algunos ejemplos:

45
0:01:51.501,000 --> 0:01:53,000
imágenes,

46
0:01:53.699,000 --> 0:01:57,000
texto,

47
0:01:57.706,000 --> 0:01:59,000
video,

48
0:01:59.801,000 --> 0:02:,000
audio.

49
0:02:01.631,000 --> 0:02:04,000
Lo que une estos diferentes tipos de datos

50
0:02:04.673,000 --> 0:02:06,000
es que son creados por gente

51
0:02:06.894,000 --> 0:02:08,000
y requieren contextos.

52
0:02:09.669,000 --> 0:02:11,000
Hay un grupo de científicos de datos

53
0:02:12.114,000 --> 0:02:14,000
de la Universidad de Illinois-Chicago,

54
0:02:14.419,000 --> 0:02:16,000
llamados Colaboración para la Salud en Medios,

55
0:02:16.873,000 --> 0:02:17,000
trabajando con los Centros de

56
0:02:18.367,000 --> 0:02:19,000
Control de Enfermedades

57
0:02:19.701,000 --> 0:02:2,000
para entender mejor

58
0:02:21.065,000 --> 0:02:23,000
cómo la gente habla sobre dejar de fumar,

59
0:02:23.913,000 --> 0:02:25,000
cómo hablan de cigarros electrónicos,

60
0:02:26.593,000 --> 0:02:27,000
y qué pueden hacer colectivamente

61
0:02:28.578,000 --> 0:02:29,000
para ayudarse a dejarlo.

62
0:02:30.562,000 --> 0:02:32,000
Lo interesante es que, si quieres entender

63
0:02:32.575,000 --> 0:02:34,000
cómo la gente habla sobre dejar de fumar,

64
0:02:34.791,000 --> 0:02:35,000
primero tienes que entender

65
0:02:36.692,000 --> 0:02:38,000
a qué se refieren al decir "fumar".

66
0:02:39.257,000 --> 0:02:42,000
En Twitter, hay 4 categorías principales:

67
0:02:43.183,000 --> 0:02:45,000
la primera, fumar cigarros;

68
0:02:46.18,000 --> 0:02:48,000
la segunda, fumar marihuana;

69
0:02:48.987,000 --> 0:02:5,000
la tercera, ahumar costillas;

70
0:02:51.63,000 --> 0:02:54,000
y la cuarta, chicas ardientes.

71
0:02:55.183,000 --> 0:02:57,000
(Risas)

72
0:02:58.176,000 --> 0:03:,000
Entonces, tenemos que pensar,

73
0:03:00.432,000 --> 0:03:02,000
¿cómo habla la gente de cigarros electrónicos?

74
0:03:02.742,000 --> 0:03:04,000
Y hay tantas maneras diferentes

75
0:03:04.767,000 --> 0:03:05,000
en las que la gente lo hace,

76
0:03:06.503,000 --> 0:03:07,000
y se puede ver del lado de

77
0:03:08.239,000 --> 0:03:09,000
es un tipo complejo de búsqueda.

78
0:03:09.976,000 --> 0:03:12,000
Y lo que nos recuerda es que

79
0:03:13.2,000 --> 0:03:15,000
el lenguaje es creado por la gente

80
0:03:15.611,000 --> 0:03:17,000
y la gente es enrevesada y somos complejos

81
0:03:17.951,000 --> 0:03:19,000
y usamos metáforas y argots y jergas

82
0:03:20.718,000 --> 0:03:21,000
24 horas por 7 días a la semana.

83
0:03:22.255,000 --> 0:03:23,000
en muchos idiomas.

84
0:03:24.142,000 --> 0:03:27,000
Y luego de un momento a otro, cambiamos.

85
0:03:27.221,000 --> 0:03:32,000
Así como estos anuncios que la CDC puso,

86
0:03:32.339,000 --> 0:03:34,000
estos anuncios de TV que tenían mujeres

87
0:03:34.769,000 --> 0:03:36,000
con un hoyo en las gargantas, muy gráficos

88
0:03:36.79,000 --> 0:03:37,000
y perturbadores,

89
0:03:38.694,000 --> 0:03:39,000
¿realmente tuvieron impacto

90
0:03:40.579,000 --> 0:03:42,000
en que la gente dejara de fumar?

91
0:03:43.25,000 --> 0:03:46,000
Colaboración para la Salud en Medios respeto los límites de sus datos,

92
0:03:46.71,000 --> 0:03:47,000
pero fueron capaces de concluir

93
0:03:48.562,000 --> 0:03:51,000
que esos anuncios —y los pueden haber visto—

94
0:03:51.874,000 --> 0:03:53,000
tenían el efecto de llevar a las personas

95
0:03:54.465,000 --> 0:03:55,000
hacia un proceso de pensamiento

96
0:03:56.287,000 --> 0:03:59,000
que podía impactar su comportamiento futuro.

97
0:03:59.954,000 --> 0:04:02,000
Lo que admiro y aprecio de este proyecto,

98
0:04:03.685,000 --> 0:04:04,000
aparte del hecho, e incluyendo que

99
0:04:05.594,000 --> 0:04:08,000
está basado en una necesidad humana real,

100
0:04:09.391,000 --> 0:04:11,000
es que es un ejemplo fantástico de coraje

101
0:04:12.207,000 --> 0:04:16,000
en medio de un océano de irrelevancia.

102
0:04:16.53,000 --> 0:04:19,000
No son solo los datos masivos los que producen

103
0:04:19.865,000 --> 0:04:2,000
retos de interpretación,

104
0:04:21.022,000 --> 0:04:22,000
porque enfrentémoslo,

105
0:04:22.04,000 --> 0:04:25,000
los humanos tenemos una historia muy rica

106
0:04:25.14,000 --> 0:04:27,000
de tomar una cantidad de datos, no importa lo pequeña,

107
0:04:27.873,000 --> 0:04:28,000
y arruinarlo.

108
0:04:29.49,000 --> 0:04:32,000
Así, hace muchos años, quizá recuerden

109
0:04:33.227,000 --> 0:04:35,000
que el antiguo presidente Ronald Reagan

110
0:04:35.5,000 --> 0:04:36,000
fue muy criticado por una declaración

111
0:04:37.491,000 --> 0:04:4,000
de que los hechos son cosas estúpidas.

112
0:04:40.501,000 --> 0:04:42,000
Se le fue la lengua, seamos justos.

113
0:04:42.915,000 --> 0:04:43,000
En realidad quería citar la defensa

114
0:04:44.678,000 --> 0:04:45,000
de Jhon Adams

115
0:04:46.151,000 --> 0:04:47,000
a los soldados británicos

116
0:04:47.626,000 --> 0:04:49,000
en los juicios de la Masacre de Boston

117
0:04:49.801,000 --> 0:04:5,000
de que los hechos son tozudos.

118
0:04:51.626,000 --> 0:04:53,000
Pero creo que hay algo de sabiduría

119
0:04:54.25,000 --> 0:04:57,000
accidental en lo que dijo

120
0:04:57.668,000 --> 0:04:59,000
porque los hechos son tozudos,

121
0:05:00.444,000 --> 0:05:02,000
pero a veces también son estúpidos.

122
0:05:03.367,000 --> 0:05:04,000
Quiero contarles una historia personal

123
0:05:05.255,000 --> 0:05:08,000
de porque esto importa tanto para mí.

124
0:05:08.803,000 --> 0:05:1,000
Necesito tomar aire.

125
0:05:11.24,000 --> 0:05:13,000
Mi hijo Isaac, cuando tenía 2 años,

126
0:05:13.994,000 --> 0:05:15,000
fue diagnosticado con autismo,

127
0:05:16.411,000 --> 0:05:18,000
y era este alegre, hilarante,

128
0:05:18.572,000 --> 0:05:19,000
amoroso, y afectuoso niñito,

129
0:05:20.407,000 --> 0:05:22,000
pero las métricas en sus evaluaciones

130
0:05:22.511,000 --> 0:05:23,000
de desarrollo,

131
0:05:23.855,000 --> 0:05:24,000
que ven cosas cómo el número de palabras

132
0:05:25.839,000 --> 0:05:28,000
—en ese momento, ninguna—

133
0:05:29.236,000 --> 0:05:3,000
gestos comunicativos y

134
0:05:31.217,000 --> 0:05:32,000
poco contacto visual,

135
0:05:33.198,000 --> 0:05:34,000
pusieron su nivel de desarrollo

136
0:05:35.179,000 --> 0:05:38,000
en el de un bebé de nueve meses.

137
0:05:38.92,000 --> 0:05:39,000
Y el diagnóstico estaba bien

138
0:05:40.509,000 --> 0:05:41,000
según los hechos,

139
0:05:42.108,000 --> 0:05:45,000
pero no contaba la historia completa.

140
0:05:45.309,000 --> 0:05:46,000
Después de un año y medio,

141
0:05:46.71,000 --> 0:05:48,000
cuando tenía aproximadamente cuatro,

142
0:05:48.812,000 --> 0:05:5,000
lo encontré frente a la computadora un día

143
0:05:51.175,000 --> 0:05:56,000
buscando mujeres en Google,

144
0:05:56.628,000 --> 0:05:59,000
deletreado "m-i-j-e-r-e-s".

145
0:06:00.244,000 --> 0:06:01,000
E hice lo que cualquier padre

146
0:06:01.791,000 --> 0:06:02,000
obsesionado haría:

147
0:06:03.248,000 --> 0:06:04,000
empezar a presionar el botón "atrás"

148
0:06:05.185,000 --> 0:06:08,000
para ver que más había buscado.

149
0:06:08.248,000 --> 0:06:1,000
Y estaban en orden: hombres,

150
0:06:10.419,000 --> 0:06:17,000
escuela, autobús y computadora.

151
0:06:17.686,000 --> 0:06:19,000
Estaba sorprendida,

152
0:06:19.756,000 --> 0:06:21,000
porque no sabíamos que podía deletrear,

153
0:06:21.758,000 --> 0:06:22,000
mucho menos leer, y le pregunte,

154
0:06:23.524,000 --> 0:06:25,000
"Isaac, ¿cómo lo hiciste?"

155
0:06:25.717,000 --> 0:06:27,000
Él me miró muy serio y dijo,

156
0:06:28.395,000 --> 0:06:31,000
"Escribí en la cajita".

157
0:06:31.747,000 --> 0:06:33,000
Estaba enseñándose a sí mismo

158
0:06:33.993,000 --> 0:06:34,000
a comunicarse.

159
0:06:35.359,000 --> 0:06:36,000
Pero estábamos buscando

160
0:06:36.916,000 --> 0:06:37,000
en el lugar equivocado.

161
0:06:38.583,000 --> 0:06:4,000
Y esto pasa cuando las tareas y los

162
0:06:40.78,000 --> 0:06:42,000
análisis sobrevaloran alguna métrica

163
0:06:43.176,000 --> 0:06:45,000
—en este caso, la comunicación verbal—

164
0:06:45.785,000 --> 0:06:46,000
y devalúan otras,

165
0:06:47.375,000 --> 0:06:5,000
cómo la resolución creativa de problemas.

166
0:06:51.125,000 --> 0:06:53,000
La comunicación era difícil para Isaac,

167
0:06:53.795,000 --> 0:06:54,000
así que encontró una alternativa

168
0:06:55.707,000 --> 0:06:57,000
para encontrar lo que necesitaba saber.

169
0:06:58.564,000 --> 0:06:59,000
Al pensarlo, tiene mucho sentido,

170
0:07:00.454,000 --> 0:07:02,000
porque hacer una pregunta

171
0:07:02.535,000 --> 0:07:04,000
es un proceso muy complejo,

172
0:07:05.1,000 --> 0:07:07,000
pero él pudo evitar mucho de eso

173
0:07:07.622,000 --> 0:07:11,000
poniendo una palabra en el buscador.

174
0:07:11.714,000 --> 0:07:13,000
Y ese pequeño momento

175
0:07:14.65,000 --> 0:07:16,000
tuvo un profundo impacto en mí

176
0:07:17.486,000 --> 0:07:18,000
y nuestra familia

177
0:07:18.795,000 --> 0:07:19,000
porque nos ayudó a cambiar

178
0:07:20.578,000 --> 0:07:21,000
el marco de referencia

179
0:07:22.191,000 --> 0:07:23,000
sobre lo que le pasaba a él,

180
0:07:24.144,000 --> 0:07:26,000
y preocuparnos menos y apreciar más

181
0:07:27.12,000 --> 0:07:29,000
su forma de obtener recursos.

182
0:07:29.302,000 --> 0:07:31,000
Los hechos son cosas estúpidas.

183
0:07:32.163,000 --> 0:07:34,000
Y se pueden usar mal,

184
0:07:34.56,000 --> 0:07:35,000
manipular u otras cosas.

185
0:07:36.213,000 --> 0:07:38,000
Tengo una amiga, Emily Willinghan

186
0:07:38.345,000 --> 0:07:39,000
que es científica,

187
0:07:39.497,000 --> 0:07:4,000
y escribió un artículo para Forbes

188
0:07:41.374,000 --> 0:07:42,000
no hace mucho,

189
0:07:42.511,000 --> 0:07:43,000
titulado "Las 10 cosas más raras

190
0:07:44.08,000 --> 0:07:45,000
ligadas al Autismo".

191
0:07:45.83,000 --> 0:07:48,000
Es una buena lista

192
0:07:48.835,000 --> 0:07:51,000
"El Internet" es culpado por todo ¿cierto?,

193
0:07:52.367,000 --> 0:07:55,000
y claro las madres, porque sí.

194
0:07:56.124,000 --> 0:07:57,000
Y en realidad, esperen, hay más,

195
0:07:57.711,000 --> 0:07:58,000
un grupo completo

196
0:07:59.079,000 --> 0:08:01,000
en la categoría de "madre" aquí.

197
0:08:02.057,000 --> 0:08:03,000
Pueden ver que es una lista

198
0:08:03.907,000 --> 0:08:05,000
muy rica e interesante.

199
0:08:06.117,000 --> 0:08:08,000
Soy una gran fan de

200
0:08:08.149,000 --> 0:08:1,000
"embarazarse cerca de autopistas".

201
0:08:10.326,000 --> 0:08:11,000
(Risas)

202
0:08:11.643,000 --> 0:08:12,000
La última es interesante,

203
0:08:13.392,000 --> 0:08:16,000
porque el término "madre de refrigerador"

204
0:08:16.395,000 --> 0:08:18,000
fue en realidad la hipótesis original

205
0:08:19,000 --> 0:08:2,000
para la causa del autismo,

206
0:08:20.598,000 --> 0:08:21,000
y se refería a una persona fría

207
0:08:22.298,000 --> 0:08:22,000
y no amorosa.

208
0:08:23.238,000 --> 0:08:24,000
En este momento, pueden pensar:

209
0:08:24.728,000 --> 0:08:25,000
"Está bien, Susan, lo entendemos,

210
0:08:26.385,000 --> 0:08:26,000
puedes tomar datos,

211
0:08:27.336,000 --> 0:08:28,000
y hacer que signifiquen lo que sea".

212
0:08:29.127,000 --> 0:08:32,000
Y es cierto, absolutamente cierto.

213
0:08:32.87,000 --> 0:08:37,000
Pero el reto es que

214
0:08:38.48,000 --> 0:08:4,000
tenemos la oportunidad

215
0:08:40.928,000 --> 0:08:42,000
de darles significado nosotros mismos,

216
0:08:43.212,000 --> 0:08:44,000
porque francamente,

217
0:08:44.531,000 --> 0:08:46,000
los datos no crean un significado.

218
0:08:46.67,000 --> 0:08:48,000
Nosotros se los damos.

219
0:08:48.869,000 --> 0:08:49,000
Así que como personas de negocios,

220
0:08:50.699,000 --> 0:08:51,000
como consumidores,

221
0:08:52.529,000 --> 0:08:53,000
como pacientes, como ciudadanos,

222
0:08:54.359,000 --> 0:08:56,000
tenemos una responsabilidad, creo,

223
0:08:56.755,000 --> 0:08:57,000
de pasar más tiempo

224
0:08:58.689,000 --> 0:08:59,000
enfocándonos

225
0:08:59.975,000 --> 0:09:,000
en nuestras capacidades críticas.

226
0:09:01.581,000 --> 0:09:02,000
¿Por qué?

227
0:09:02.897,000 --> 0:09:03,000
Porque en este punto de la historia,

228
0:09:04.695,000 --> 0:09:05,000
como hemos escuchado

229
0:09:06.153,000 --> 0:09:07,000
muchas veces,

230
0:09:07.781,000 --> 0:09:08,000
podemos procesar exabytes de datos

231
0:09:09.762,000 --> 0:09:11,000
a la velocidad de la luz,

232
0:09:11.915,000 --> 0:09:12,000
y tenemos el potencial

233
0:09:13.698,000 --> 0:09:14,000
de tomar malas decisiones

234
0:09:15.481,000 --> 0:09:16,000
mucho más rápidamente, eficientemente,

235
0:09:17.324,000 --> 0:09:21,000
y con mucho más impacto que en el pasado.

236
0:09:22.292,000 --> 0:09:23,000
Genial, ¿no es cierto?

237
0:09:23.68,000 --> 0:09:26,000
Y lo que necesitamos hacer en su lugar

238
0:09:26.71,000 --> 0:09:28,000
es pasar un poco más de tiempo

239
0:09:29.04,000 --> 0:09:31,000
en cosas como las humanidades

240
0:09:31.786,000 --> 0:09:34,000
y sociología, y las ciencias sociales,

241
0:09:35.25,000 --> 0:09:37,000
retórica, filosofía, ética,

242
0:09:37.558,000 --> 0:09:38,000
porque nos dan el contexto

243
0:09:39.368,000 --> 0:09:4,000
que es tan importante

244
0:09:40.868,000 --> 0:09:42,000
para los datos masivos, y porque

245
0:09:42.99,000 --> 0:09:42,000
nos ayudan

246
0:09:43.698,000 --> 0:09:44,000
a volvernos mejores pensadores críticos.

247
0:09:45.616,000 --> 0:09:48,000
Porque después de todo, si puedo ver

248
0:09:48.935,000 --> 0:09:49,000
un problema en un argumento,

249
0:09:50.49,000 --> 0:09:52,000
no importa mucho,

250
0:09:52.495,000 --> 0:09:54,000
que este expresado en palabras o números.

251
0:09:54.86,000 --> 0:09:55,000
Y esto significa

252
0:09:56.379,000 --> 0:09:58,000
enseñarnos a nosotros mismos

253
0:09:58.86,000 --> 0:10:,000
a encontrar esos sesgos confirmatorios

254
0:10:01.341,000 --> 0:10:02,000
y falsas correlaciones,

255
0:10:03.272,000 --> 0:10:04,000
y a ser capaces de ver una afirmación

256
0:10:05.061,000 --> 0:10:06,000
puramente emocional

257
0:10:06.238,000 --> 0:10:07,000
desde 10 metros,

258
0:10:07.622,000 --> 0:10:09,000
porque que algo que pase después de otra cosa

259
0:10:10.144,000 --> 0:10:11,000
no significa que pasó por eso

260
0:10:11.617,000 --> 0:10:12,000
necesariamente,

261
0:10:13.24,000 --> 0:10:15,000
y si me dejan ser geek por un segundo,

262
0:10:15.345,000 --> 0:10:16,000
los romanos lo llamaban:

263
0:10:16.696,000 --> 0:10:19,000
"post hoc ergo propter hoc",

264
0:10:19.897,000 --> 0:10:21,000
"después de esto, entonces por esto".

265
0:10:22.278,000 --> 0:10:24,000
Y significa cuestionar disciplinas

266
0:10:24.59,000 --> 0:10:26,000
como la demografía.

267
0:10:26.682,000 --> 0:10:26,000
¿Por qué?

268
0:10:27.585,000 --> 0:10:29,000
Porque están basadas en asumir cosas,

269
0:10:29.788,000 --> 0:10:31,000
sobre quiénes somos con base en nuestro género

270
0:10:32.031,000 --> 0:10:33,000
nuestra edad y dónde vivimos,

271
0:10:33.429,000 --> 0:10:35,000
opuestos a datos de qué es lo que pensamos

272
0:10:35.43,000 --> 0:10:36,000
y hacemos en realidad.

273
0:10:36.477,000 --> 0:10:37,000
Y dado que tenemos estos datos,

274
0:10:38.124,000 --> 0:10:39,000
necesitamos tratarlos con adecuados

275
0:10:39.882,000 --> 0:10:4,000
controles de privacidad

276
0:10:41.56,000 --> 0:10:44,000
y al consumir optar por inclusión,

277
0:10:44.839,000 --> 0:10:46,000
y más allá de eso necesitamos ser claros

278
0:10:47.832,000 --> 0:10:49,000
en nuestras hipótesis,

279
0:10:49.935,000 --> 0:10:51,000
las metodologías que usamos,

280
0:10:52.531,000 --> 0:10:54,000
y nuestro nivel de confianza en el resultado.

281
0:10:55.335,000 --> 0:10:57,000
Cómo decía mi maestro de álgebra:

282
0:10:57.809,000 --> 0:10:58,000
"muestra tus matemáticas,

283
0:10:59.34,000 --> 0:11:02,000
porque si no sé qué pasos usaste,

284
0:11:02.781,000 --> 0:11:03,000
no sé qué pasos no tomaste,

285
0:11:04.772,000 --> 0:11:06,000
y si no sé qué preguntas hiciste,

286
0:11:07.21,000 --> 0:11:09,000
no sé qué preguntas no hiciste".

287
0:11:09.887,000 --> 0:11:1,000
Significa preguntarnos a nosotros mismos,

288
0:11:11.871,000 --> 0:11:12,000
la pregunta más difícil de todas:

289
0:11:13.459,000 --> 0:11:16,000
¿Los datos en realidad nos lo muestran,

290
0:11:16.909,000 --> 0:11:18,000
o el resultado nos hace sentir

291
0:11:19.22,000 --> 0:11:22,000
más exitosos y más cómodos?

292
0:11:23.098,000 --> 0:11:25,000
Así que los de Colaboración por la Salud en Medios

293
0:11:25.682,000 --> 0:11:26,000
al final del proyecto, pudieron

294
0:11:27.381,000 --> 0:11:3,000
encontrar 87 % de tweets

295
0:11:30.789,000 --> 0:11:32,000
sobre esos muy gráficos y perturbadores

296
0:11:32.933,000 --> 0:11:33,000
anuncios para dejar de fumar

297
0:11:34.477,000 --> 0:11:36,000
que expresaban miedo,

298
0:11:36.861,000 --> 0:11:37,000
pero ¿concluyeron que hicieron

299
0:11:38.777,000 --> 0:11:41,000
que la gente dejara de fumar?

300
0:11:41.988,000 --> 0:11:43,000
No. Es ciencia, no magia.

301
0:11:44.53,000 --> 0:11:47,000
Así que si vamos a abrir

302
0:11:47.72,000 --> 0:11:49,000
el poder de los datos,

303
0:11:50.582,000 --> 0:11:53,000
no tenemos que ir a ciegas en la visión

304
0:11:54.23,000 --> 0:11:57,000
de Orwell de un futuro totalitario,

305
0:11:57.466,000 --> 0:12:,000
o la visión de Huxley de uno trivial,

306
0:12:00.583,000 --> 0:12:03,000
o un horrible cóctel de ambos.

307
0:12:03.603,000 --> 0:12:06,000
Lo que tenemos que hacer es tratar

308
0:12:06.642,000 --> 0:12:08,000
al pensamiento crítico con respeto

309
0:12:08.7,000 --> 0:12:1,000
y ser inspirados por ejemplos

310
0:12:10.729,000 --> 0:12:12,000
cómo el de Colaboración por la Salud en Medios

311
0:12:12.925,000 --> 0:12:13,000
y como dicen

312
0:12:14.122,000 --> 0:12:15,000
en las películas de superhéroes:

313
0:12:15.945,000 --> 0:12:16,000
"Usemos nuestros poderes para el bien".

314
0:12:17.919,000 --> 0:12:17,000
Gracias.

315
0:12:18.64,000 --> 0:12:18,000
(Aplausos)

