1
0:00:12.371,000 --> 0:00:14,000
Steve Ramirez: My first year of grad school,

2
0:00:14.491,000 --> 0:00:15,000
I found myself in my bedroom

3
0:00:15.931,000 --> 0:00:17,000
eating lots of Ben & Jerry's

4
0:00:18.231,000 --> 0:00:19,000
watching some trashy TV

5
0:00:19.915,000 --> 0:00:22,000
and maybe, maybe listening to Taylor Swift.

6
0:00:23.142,000 --> 0:00:24,000
I had just gone through a breakup.

7
0:00:24.883,000 --> 0:00:25,000
(Laughter)

8
0:00:26.33,000 --> 0:00:28,000
So for the longest time, all I would do

9
0:00:28.526,000 --> 0:00:31,000
is recall the memory of this person over and over again,

10
0:00:32.342,000 --> 0:00:34,000
wishing that I could get rid of that gut-wrenching,

11
0:00:34.835,000 --> 0:00:36,000
visceral "blah" feeling.

12
0:00:37.368,000 --> 0:00:39,000
Now, as it turns out, I'm a neuroscientist,

13
0:00:39.651,000 --> 0:00:41,000
so I knew that the memory of that person

14
0:00:42.053,000 --> 0:00:45,000
and the awful, emotional undertones that color in that memory,

15
0:00:45.193,000 --> 0:00:47,000
are largely mediated by separate brain systems.

16
0:00:47.827,000 --> 0:00:49,000
And so I thought, what if we could go into the brain

17
0:00:50.328,000 --> 0:00:51,000
and edit out that nauseating feeling

18
0:00:52.282,000 --> 0:00:54,000
but while keeping the memory of that person intact?

19
0:00:55.252,000 --> 0:00:57,000
Then I realized, maybe that's a little bit lofty for now.

20
0:00:57.943,000 --> 0:00:59,000
So what if we could start off by going into the brain

21
0:01:00.456,000 --> 0:01:02,000
and just finding a single memory to begin with?

22
0:01:03.089,000 --> 0:01:05,000
Could we jump-start that memory back to life,

23
0:01:05.603,000 --> 0:01:08,000
maybe even play with the contents of that memory?

24
0:01:09.471,000 --> 0:01:11,000
All that said, there is one person in the entire world right now

25
0:01:11.7,000 --> 0:01:13,000
that I really hope is not watching this talk.

26
0:01:13.867,000 --> 0:01:16,000
(Laughter)

27
0:01:17.696,000 --> 0:01:2,000
So there is a catch. There is a catch.

28
0:01:20.985,000 --> 0:01:22,000
These ideas probably remind you of "Total Recall,"

29
0:01:23.773,000 --> 0:01:24,000
"Eternal Sunshine of the Spotless Mind,"

30
0:01:25.747,000 --> 0:01:26,000
or of "Inception."

31
0:01:27.05,000 --> 0:01:28,000
But the movie stars that we work with

32
0:01:28.836,000 --> 0:01:29,000
are the celebrities of the lab.

33
0:01:30.569,000 --> 0:01:31,000
Xu Liu: Test mice.

34
0:01:32.469,000 --> 0:01:33,000
(Laughter)

35
0:01:33.597,000 --> 0:01:36,000
As neuroscientists, we work in the lab with mice

36
0:01:36.751,000 --> 0:01:39,000
trying to understand how memory works.

37
0:01:40.161,000 --> 0:01:42,000
And today, we hope to convince you that now

38
0:01:42.73,000 --> 0:01:45,000
we are actually able to activate a memory in the brain

39
0:01:45.946,000 --> 0:01:47,000
at the speed of light.

40
0:01:48.116,000 --> 0:01:51,000
To do this, there's only two simple steps to follow.

41
0:01:51.222,000 --> 0:01:54,000
First, you find and label a memory in the brain,

42
0:01:54.732,000 --> 0:01:57,000
and then you activate it with a switch.

43
0:01:58.362,000 --> 0:01:59,000
As simple as that.

44
0:01:59.807,000 --> 0:02:,000
(Laughter)

45
0:02:01.629,000 --> 0:02:02,000
SR: Are you convinced?

46
0:02:03.474,000 --> 0:02:06,000
So, turns out finding a memory in the brain isn't all that easy.

47
0:02:07.195,000 --> 0:02:09,000
XL: Indeed. This is way more difficult than, let's say,

48
0:02:09.998,000 --> 0:02:11,000
finding a needle in a haystack,

49
0:02:12.402,000 --> 0:02:14,000
because at least, you know, the needle is still something

50
0:02:15.141,000 --> 0:02:17,000
you can physically put your fingers on.

51
0:02:17.491,000 --> 0:02:18,000
But memory is not.

52
0:02:19.468,000 --> 0:02:22,000
And also, there's way more cells in your brain

53
0:02:22.506,000 --> 0:02:27,000
than the number of straws in a typical haystack.

54
0:02:27.572,000 --> 0:02:29,000
So yeah, this task does seem to be daunting.

55
0:02:30.451,000 --> 0:02:33,000
But luckily, we got help from the brain itself.

56
0:02:34.13,000 --> 0:02:36,000
It turned out that all we need to do is basically

57
0:02:36.585,000 --> 0:02:37,000
to let the brain form a memory,

58
0:02:38.578,000 --> 0:02:41,000
and then the brain will tell us which cells are involved

59
0:02:42.408,000 --> 0:02:43,000
in that particular memory.

60
0:02:44.174,000 --> 0:02:46,000
SR: So what was going on in my brain

61
0:02:46.531,000 --> 0:02:48,000
while I was recalling the memory of an ex?

62
0:02:48.625,000 --> 0:02:5,000
If you were to just completely ignore human ethics for a second

63
0:02:51.027,000 --> 0:02:52,000
and slice up my brain right now,

64
0:02:52.695,000 --> 0:02:54,000
you would see that there was an amazing number

65
0:02:54.91,000 --> 0:02:56,000
of brain regions that were active while recalling that memory.

66
0:02:57.891,000 --> 0:02:59,000
Now one brain region that would be robustly active

67
0:03:00.803,000 --> 0:03:01,000
in particular is called the hippocampus,

68
0:03:02.81,000 --> 0:03:04,000
which for decades has been implicated in processing

69
0:03:05.265,000 --> 0:03:07,000
the kinds of memories that we hold near and dear,

70
0:03:07.681,000 --> 0:03:09,000
which also makes it an ideal target to go into

71
0:03:10.255,000 --> 0:03:12,000
and to try and find and maybe reactivate a memory.

72
0:03:13.04,000 --> 0:03:15,000
XL: When you zoom in into the hippocampus,

73
0:03:15.434,000 --> 0:03:17,000
of course you will see lots of cells,

74
0:03:17.782,000 --> 0:03:2,000
but we are able to find which cells are involved

75
0:03:20.813,000 --> 0:03:21,000
in a particular memory,

76
0:03:22.289,000 --> 0:03:24,000
because whenever a cell is active,

77
0:03:24.907,000 --> 0:03:25,000
like when it's forming a memory,

78
0:03:26.455,000 --> 0:03:29,000
it will also leave a footprint that will later allow us to know

79
0:03:30.128,000 --> 0:03:32,000
these cells are recently active.

80
0:03:32.83,000 --> 0:03:34,000
SR: So the same way that building lights at night

81
0:03:35.188,000 --> 0:03:38,000
let you know that somebody's probably working there at any given moment,

82
0:03:38.641,000 --> 0:03:4,000
in a very real sense, there are biological sensors

83
0:03:41.226,000 --> 0:03:42,000
within a cell that are turned on

84
0:03:43.18,000 --> 0:03:45,000
only when that cell was just working.

85
0:03:45.315,000 --> 0:03:47,000
They're sort of biological windows that light up

86
0:03:47.625,000 --> 0:03:49,000
to let us know that that cell was just active.

87
0:03:49.84,000 --> 0:03:51,000
XL: So we clipped part of this sensor,

88
0:03:51.998,000 --> 0:03:54,000
and attached that to a switch to control the cells,

89
0:03:55.145,000 --> 0:03:58,000
and we packed this switch into an engineered virus

90
0:03:59.045,000 --> 0:04:01,000
and injected that into the brain of the mice.

91
0:04:01.633,000 --> 0:04:03,000
So whenever a memory is being formed,

92
0:04:04.267,000 --> 0:04:06,000
any active cells for that memory

93
0:04:06.615,000 --> 0:04:08,000
will also have this switch installed.

94
0:04:09.357,000 --> 0:04:11,000
SR: So here is what the hippocampus looks like

95
0:04:11.572,000 --> 0:04:13,000
after forming a fear memory, for example.

96
0:04:13.822,000 --> 0:04:15,000
The sea of blue that you see here

97
0:04:15.962,000 --> 0:04:16,000
are densely packed brain cells,

98
0:04:17.914,000 --> 0:04:18,000
but the green brain cells,

99
0:04:19.459,000 --> 0:04:21,000
the green brain cells are the ones that are holding on

100
0:04:22.055,000 --> 0:04:23,000
to a specific fear memory.

101
0:04:23.398,000 --> 0:04:24,000
So you are looking at the crystallization

102
0:04:25.377,000 --> 0:04:27,000
of the fleeting formation of fear.

103
0:04:27.764,000 --> 0:04:3,000
You're actually looking at the cross-section of a memory right now.

104
0:04:31.261,000 --> 0:04:33,000
XL: Now, for the switch we have been talking about,

105
0:04:33.714,000 --> 0:04:35,000
ideally, the switch has to act really fast.

106
0:04:36.639,000 --> 0:04:38,000
It shouldn't take minutes or hours to work.

107
0:04:39.218,000 --> 0:04:43,000
It should act at the speed of the brain, in milliseconds.

108
0:04:43.482,000 --> 0:04:44,000
SR: So what do you think, Xu?

109
0:04:44.912,000 --> 0:04:46,000
Could we use, let's say, pharmacological drugs

110
0:04:47.514,000 --> 0:04:48,000
to activate or inactivate brain cells?

111
0:04:49.352,000 --> 0:04:53,000
XL: Nah. Drugs are pretty messy. They spread everywhere.

112
0:04:53.415,000 --> 0:04:55,000
And also it takes them forever to act on cells.

113
0:04:56.423,000 --> 0:04:59,000
So it will not allow us to control a memory in real time.

114
0:05:00.072,000 --> 0:05:04,000
So Steve, how about let's zap the brain with electricity?

115
0:05:04.366,000 --> 0:05:06,000
SR: So electricity is pretty fast,

116
0:05:06.671,000 --> 0:05:07,000
but we probably wouldn't be able to target it

117
0:05:08.41,000 --> 0:05:1,000
to just the specific cells that hold onto a memory,

118
0:05:10.863,000 --> 0:05:11,000
and we'd probably fry the brain.

119
0:05:12.642,000 --> 0:05:15,000
XL: Oh. That's true. So it looks like, hmm,

120
0:05:15.837,000 --> 0:05:17,000
indeed we need to find a better way

121
0:05:18.448,000 --> 0:05:21,000
to impact the brain at the speed of light.

122
0:05:21.743,000 --> 0:05:26,000
SR: So it just so happens that light travels at the speed of light.

123
0:05:26.829,000 --> 0:05:29,000
So maybe we could activate or inactive memories

124
0:05:30.312,000 --> 0:05:31,000
by just using light --

125
0:05:31.809,000 --> 0:05:32,000
XL: That's pretty fast.

126
0:05:33.164,000 --> 0:05:34,000
SR: -- and because normally brain cells

127
0:05:35.049,000 --> 0:05:36,000
don't respond to pulses of light,

128
0:05:36.645,000 --> 0:05:37,000
so those that would respond to pulses of light

129
0:05:38.603,000 --> 0:05:4,000
are those that contain a light-sensitive switch.

130
0:05:41.059,000 --> 0:05:42,000
Now to do that, first we need to trick brain cells

131
0:05:43.005,000 --> 0:05:44,000
to respond to laser beams.

132
0:05:44.467,000 --> 0:05:45,000
XL: Yep. You heard it right.

133
0:05:45.537,000 --> 0:05:47,000
We are trying to shoot lasers into the brain.

134
0:05:47.704,000 --> 0:05:48,000
(Laughter)

135
0:05:49.414,000 --> 0:05:52,000
SR: And the technique that lets us do that is optogenetics.

136
0:05:52.738,000 --> 0:05:55,000
Optogenetics gave us this light switch that we can use

137
0:05:56.02,000 --> 0:05:57,000
to turn brain cells on or off,

138
0:05:57.528,000 --> 0:05:59,000
and the name of that switch is channelrhodopsin,

139
0:06:00.045,000 --> 0:06:02,000
seen here as these green dots attached to this brain cell.

140
0:06:02.582,000 --> 0:06:05,000
You can think of channelrhodopsin as a sort of light-sensitive switch

141
0:06:05.892,000 --> 0:06:07,000
that can be artificially installed in brain cells

142
0:06:08.508,000 --> 0:06:09,000
so that now we can use that switch

143
0:06:10.422,000 --> 0:06:13,000
to activate or inactivate the brain cell simply by clicking it,

144
0:06:13.446,000 --> 0:06:15,000
and in this case we click it on with pulses of light.

145
0:06:15.994,000 --> 0:06:18,000
XL: So we attach this light-sensitive switch of channelrhodopsin

146
0:06:19.689,000 --> 0:06:21,000
to the sensor we've been talking about

147
0:06:21.897,000 --> 0:06:23,000
and inject this into the brain.

148
0:06:24.352,000 --> 0:06:27,000
So whenever a memory is being formed,

149
0:06:27.563,000 --> 0:06:29,000
any active cell for that particular memory

150
0:06:29.79,000 --> 0:06:32,000
will also have this light-sensitive switch installed in it

151
0:06:33.274,000 --> 0:06:35,000
so that we can control these cells

152
0:06:35.675,000 --> 0:06:39,000
by the flipping of a laser just like this one you see.

153
0:06:39.939,000 --> 0:06:41,000
SR: So let's put all of this to the test now.

154
0:06:42.803,000 --> 0:06:44,000
What we can do is we can take our mice

155
0:06:44.938,000 --> 0:06:46,000
and then we can put them in a box that looks exactly like this box here,

156
0:06:47.866,000 --> 0:06:49,000
and then we can give them a very mild foot shock

157
0:06:50.206,000 --> 0:06:52,000
so that they form a fear memory of this box.

158
0:06:52.278,000 --> 0:06:54,000
They learn that something bad happened here.

159
0:06:54.361,000 --> 0:06:56,000
Now with our system, the cells that are active

160
0:06:56.703,000 --> 0:06:58,000
in the hippocampus in the making of this memory,

161
0:06:59.493,000 --> 0:07:01,000
only those cells will now contain channelrhodopsin.

162
0:07:02.376,000 --> 0:07:04,000
XL: When you are as small as a mouse,

163
0:07:05.393,000 --> 0:07:08,000
it feels as if the whole world is trying to get you.

164
0:07:08.988,000 --> 0:07:09,000
So your best response of defense

165
0:07:10.736,000 --> 0:07:12,000
is trying to be undetected.

166
0:07:13.218,000 --> 0:07:15,000
Whenever a mouse is in fear,

167
0:07:15.251,000 --> 0:07:16,000
it will show this very typical behavior

168
0:07:17.133,000 --> 0:07:18,000
by staying at one corner of the box,

169
0:07:18.902,000 --> 0:07:2,000
trying to not move any part of its body,

170
0:07:21.664,000 --> 0:07:24,000
and this posture is called freezing.

171
0:07:24.959,000 --> 0:07:28,000
So if a mouse remembers that something bad happened in this box,

172
0:07:29.253,000 --> 0:07:31,000
and when we put them back into the same box,

173
0:07:31.876,000 --> 0:07:32,000
it will basically show freezing

174
0:07:33.68,000 --> 0:07:35,000
because it doesn't want to be detected

175
0:07:35.965,000 --> 0:07:37,000
by any potential threats in this box.

176
0:07:38.66,000 --> 0:07:39,000
SR: So you can think of freezing as,

177
0:07:40.015,000 --> 0:07:42,000
you're walking down the street minding your own business,

178
0:07:42.23,000 --> 0:07:44,000
and then out of nowhere you almost run into

179
0:07:44.302,000 --> 0:07:45,000
an ex-girlfriend or ex-boyfriend,

180
0:07:46.147,000 --> 0:07:48,000
and now those terrifying two seconds

181
0:07:48.281,000 --> 0:07:49,000
where you start thinking, "What do I do? Do I say hi?

182
0:07:50.157,000 --> 0:07:51,000
Do I shake their hand? Do I turn around and run away?

183
0:07:51.525,000 --> 0:07:53,000
Do I sit here and pretend like I don't exist?"

184
0:07:53.554,000 --> 0:07:56,000
Those kinds of fleeting thoughts that physically incapacitate you,

185
0:07:56.738,000 --> 0:07:58,000
that temporarily give you that deer-in-headlights look.

186
0:07:59.484,000 --> 0:08:02,000
XL: However, if you put the mouse in a completely different

187
0:08:02.775,000 --> 0:08:05,000
new box, like the next one,

188
0:08:05.936,000 --> 0:08:07,000
it will not be afraid of this box

189
0:08:08.083,000 --> 0:08:12,000
because there's no reason that it will be afraid of this new environment.

190
0:08:12.812,000 --> 0:08:15,000
But what if we put the mouse in this new box

191
0:08:15.992,000 --> 0:08:18,000
but at the same time, we activate the fear memory

192
0:08:19.603,000 --> 0:08:21,000
using lasers just like we did before?

193
0:08:22.282,000 --> 0:08:24,000
Are we going to bring back the fear memory

194
0:08:25.136,000 --> 0:08:28,000
for the first box into this completely new environment?

195
0:08:29.133,000 --> 0:08:31,000
SR: All right, and here's the million-dollar experiment.

196
0:08:31.868,000 --> 0:08:33,000
Now to bring back to life the memory of that day,

197
0:08:34.781,000 --> 0:08:36,000
I remember that the Red Sox had just won,

198
0:08:36.964,000 --> 0:08:37,000
it was a green spring day,

199
0:08:38.873,000 --> 0:08:39,000
perfect for going up and down the river

200
0:08:40.755,000 --> 0:08:42,000
and then maybe going to the North End

201
0:08:43.024,000 --> 0:08:45,000
to get some cannolis, #justsaying.

202
0:08:45.183,000 --> 0:08:48,000
Now Xu and I, on the other hand,

203
0:08:48.285,000 --> 0:08:5,000
were in a completely windowless black room

204
0:08:51.115,000 --> 0:08:54,000
not making any ocular movement that even remotely resembles an eye blink

205
0:08:54.775,000 --> 0:08:56,000
because our eyes were fixed onto a computer screen.

206
0:08:57.242,000 --> 0:08:59,000
We were looking at this mouse here trying to activate a memory

207
0:09:00.219,000 --> 0:09:01,000
for the first time using our technique.

208
0:09:02.102,000 --> 0:09:04,000
XL: And this is what we saw.

209
0:09:04.369,000 --> 0:09:06,000
When we first put the mouse into this box,

210
0:09:06.571,000 --> 0:09:09,000
it's exploring, sniffing around, walking around,

211
0:09:09.684,000 --> 0:09:1,000
minding its own business,

212
0:09:11.373,000 --> 0:09:12,000
because actually by nature,

213
0:09:13.074,000 --> 0:09:14,000
mice are pretty curious animals.

214
0:09:15.053,000 --> 0:09:17,000
They want to know, what's going on in this new box?

215
0:09:17.675,000 --> 0:09:18,000
It's interesting.

216
0:09:19.206,000 --> 0:09:22,000
But the moment we turned on the laser, like you see now,

217
0:09:22.657,000 --> 0:09:25,000
all of a sudden the mouse entered this freezing mode.

218
0:09:25.689,000 --> 0:09:29,000
It stayed here and tried not to move any part of its body.

219
0:09:30.12,000 --> 0:09:31,000
Clearly it's freezing.

220
0:09:31.748,000 --> 0:09:33,000
So indeed, it looks like we are able to bring back

221
0:09:34.331,000 --> 0:09:36,000
the fear memory for the first box

222
0:09:36.395,000 --> 0:09:39,000
in this completely new environment.

223
0:09:39.762,000 --> 0:09:41,000
While watching this, Steve and I

224
0:09:41.874,000 --> 0:09:43,000
are as shocked as the mouse itself.

225
0:09:44.007,000 --> 0:09:45,000
(Laughter)

226
0:09:45.269,000 --> 0:09:48,000
So after the experiment, the two of us just left the room

227
0:09:48.576,000 --> 0:09:49,000
without saying anything.

228
0:09:50.329,000 --> 0:09:53,000
After a kind of long, awkward period of time,

229
0:09:53.725,000 --> 0:09:55,000
Steve broke the silence.

230
0:09:55.937,000 --> 0:09:57,000
SR: "Did that just work?"

231
0:09:58.278,000 --> 0:10:,000
XL: "Yes," I said. "Indeed it worked!"

232
0:10:01.252,000 --> 0:10:03,000
We're really excited about this.

233
0:10:03.369,000 --> 0:10:05,000
And then we published our findings

234
0:10:05.993,000 --> 0:10:06,000
in the journal Nature.

235
0:10:07.689,000 --> 0:10:09,000
Ever since the publication of our work,

236
0:10:10.16,000 --> 0:10:12,000
we've been receiving numerous comments

237
0:10:12.575,000 --> 0:10:14,000
from all over the Internet.

238
0:10:14.7,000 --> 0:10:17,000
Maybe we can take a look at some of those.

239
0:10:18.45,000 --> 0:10:2,000
["OMGGGGG FINALLY... so much more to come, virtual reality, neural manipulation, visual dream emulation... neural coding, 'writing and re-writing of memories', mental illnesses. Ahhh the future is awesome"]

240
0:10:20.907,000 --> 0:10:21,000
SR: So the first thing that you'll notice is that people

241
0:10:22.907,000 --> 0:10:24,000
have really strong opinions about this kind of work.

242
0:10:25.81,000 --> 0:10:27,000
Now I happen to completely agree with the optimism

243
0:10:28.364,000 --> 0:10:28,000
of this first quote,

244
0:10:29.18,000 --> 0:10:31,000
because on a scale of zero to Morgan Freeman's voice,

245
0:10:31.988,000 --> 0:10:33,000
it happens to be one of the most evocative accolades

246
0:10:34.489,000 --> 0:10:35,000
that I've heard come our way.

247
0:10:36.039,000 --> 0:10:37,000
(Laughter)

248
0:10:37.857,000 --> 0:10:38,000
But as you'll see, it's not the only opinion that's out there.

249
0:10:39.808,000 --> 0:10:4,000
["This scares the hell out of me... What if they could do that easily in humans in a couple of years?! OH MY GOD WE'RE DOOMED"]

250
0:10:41.372,000 --> 0:10:43,000
XL: Indeed, if we take a look at the second one,

251
0:10:43.682,000 --> 0:10:45,000
I think we can all agree that it's, meh,

252
0:10:45.789,000 --> 0:10:46,000
probably not as positive.

253
0:10:47.772,000 --> 0:10:49,000
But this also reminds us that,

254
0:10:49.957,000 --> 0:10:51,000
although we are still working with mice,

255
0:10:52.143,000 --> 0:10:55,000
it's probably a good idea to start thinking and discussing

256
0:10:55.66,000 --> 0:10:57,000
about the possible ethical ramifications

257
0:10:58.651,000 --> 0:10:59,000
of memory control.

258
0:11:00.599,000 --> 0:11:02,000
SR: Now, in the spirit of the third quote,

259
0:11:02.799,000 --> 0:11:03,000
we want to tell you about a recent project that we've been

260
0:11:04.773,000 --> 0:11:06,000
working on in lab that we've called Project Inception.

261
0:11:07.369,000 --> 0:11:1,000
["They should make a movie about this. Where they plant ideas into peoples minds, so they can control them for their own personal gain. We'll call it: Inception."]

262
0:11:10.612,000 --> 0:11:13,000
So we reasoned that now that we can reactivate a memory,

263
0:11:14.178,000 --> 0:11:16,000
what if we do so but then begin to tinker with that memory?

264
0:11:17.13,000 --> 0:11:2,000
Could we possibly even turn it into a false memory?

265
0:11:20.163,000 --> 0:11:24,000
XL: So all memory is sophisticated and dynamic,

266
0:11:24.262,000 --> 0:11:26,000
but if just for simplicity, let's imagine memory

267
0:11:27.241,000 --> 0:11:28,000
as a movie clip.

268
0:11:28.643,000 --> 0:11:3,000
So far what we've told you is basically we can control

269
0:11:31.313,000 --> 0:11:32,000
this "play" button of the clip

270
0:11:33.244,000 --> 0:11:37,000
so that we can play this video clip any time, anywhere.

271
0:11:37.829,000 --> 0:11:39,000
But is there a possibility that we can actually get

272
0:11:40.36,000 --> 0:11:42,000
inside the brain and edit this movie clip

273
0:11:43.22,000 --> 0:11:45,000
so that we can make it different from the original?

274
0:11:46.116,000 --> 0:11:48,000
Yes we can.

275
0:11:48.294,000 --> 0:11:5,000
Turned out that all we need to do is basically

276
0:11:50.509,000 --> 0:11:54,000
reactivate a memory using lasers just like we did before,

277
0:11:54.699,000 --> 0:11:57,000
but at the same time, if we present new information

278
0:11:58.138,000 --> 0:12:01,000
and allow this new information to incorporate into this old memory,

279
0:12:02.112,000 --> 0:12:04,000
this will change the memory.

280
0:12:04.55,000 --> 0:12:07,000
It's sort of like making a remix tape.

281
0:12:08.213,000 --> 0:12:1,000
SR: So how do we do this?

282
0:12:11.071,000 --> 0:12:12,000
Rather than finding a fear memory in the brain,

283
0:12:13.028,000 --> 0:12:14,000
we can start by taking our animals,

284
0:12:14.744,000 --> 0:12:16,000
and let's say we put them in a blue box like this blue box here

285
0:12:17.721,000 --> 0:12:19,000
and we find the brain cells that represent that blue box

286
0:12:20.368,000 --> 0:12:22,000
and we trick them to respond to pulses of light

287
0:12:22.631,000 --> 0:12:23,000
exactly like we had said before.

288
0:12:24.365,000 --> 0:12:26,000
Now the next day, we can take our animals and place them

289
0:12:26.489,000 --> 0:12:28,000
in a red box that they've never experienced before.

290
0:12:29.188,000 --> 0:12:31,000
We can shoot light into the brain to reactivate

291
0:12:31.451,000 --> 0:12:32,000
the memory of the blue box.

292
0:12:33.323,000 --> 0:12:34,000
So what would happen here if, while the animal

293
0:12:35.067,000 --> 0:12:36,000
is recalling the memory of the blue box,

294
0:12:36.996,000 --> 0:12:38,000
we gave it a couple of mild foot shocks?

295
0:12:39.604,000 --> 0:12:41,000
So here we're trying to artificially make an association

296
0:12:42.297,000 --> 0:12:43,000
between the memory of the blue box

297
0:12:44.212,000 --> 0:12:45,000
and the foot shocks themselves.

298
0:12:45.715,000 --> 0:12:46,000
We're just trying to connect the two.

299
0:12:47.501,000 --> 0:12:48,000
So to test if we had done so,

300
0:12:49.037,000 --> 0:12:5,000
we can take our animals once again

301
0:12:50.365,000 --> 0:12:51,000
and place them back in the blue box.

302
0:12:52.311,000 --> 0:12:54,000
Again, we had just reactivated the memory of the blue box

303
0:12:55.05,000 --> 0:12:57,000
while the animal got a couple of mild foot shocks,

304
0:12:57.455,000 --> 0:12:59,000
and now the animal suddenly freezes.

305
0:12:59.586,000 --> 0:13:02,000
It's as though it's recalling being mildly shocked in this environment

306
0:13:02.944,000 --> 0:13:04,000
even though that never actually happened.

307
0:13:05.79,000 --> 0:13:06,000
So it formed a false memory,

308
0:13:07.652,000 --> 0:13:09,000
because it's falsely fearing an environment

309
0:13:09.724,000 --> 0:13:1,000
where, technically speaking,

310
0:13:11.082,000 --> 0:13:13,000
nothing bad actually happened to it.

311
0:13:13.266,000 --> 0:13:15,000
XL: So, so far we are only talking about

312
0:13:15.719,000 --> 0:13:17,000
this light-controlled "on" switch.

313
0:13:18.085,000 --> 0:13:21,000
In fact, we also have a light-controlled "off" switch,

314
0:13:21.373,000 --> 0:13:23,000
and it's very easy to imagine that

315
0:13:23.453,000 --> 0:13:25,000
by installing this light-controlled "off" switch,

316
0:13:25.931,000 --> 0:13:3,000
we can also turn off a memory, any time, anywhere.

317
0:13:31.519,000 --> 0:13:33,000
So everything we've been talking about today

318
0:13:33.733,000 --> 0:13:37,000
is based on this philosophically charged principle of neuroscience

319
0:13:38.41,000 --> 0:13:42,000
that the mind, with its seemingly mysterious properties,

320
0:13:42.528,000 --> 0:13:45,000
is actually made of physical stuff that we can tinker with.

321
0:13:46.173,000 --> 0:13:47,000
SR: And for me personally,

322
0:13:47.648,000 --> 0:13:48,000
I see a world where we can reactivate

323
0:13:49.434,000 --> 0:13:5,000
any kind of memory that we'd like.

324
0:13:51.345,000 --> 0:13:54,000
I also see a world where we can erase unwanted memories.

325
0:13:54.643,000 --> 0:13:56,000
Now, I even see a world where editing memories

326
0:13:56.81,000 --> 0:13:57,000
is something of a reality,

327
0:13:58.118,000 --> 0:13:59,000
because we're living in a time where it's possible

328
0:13:59.823,000 --> 0:14:01,000
to pluck questions from the tree of science fiction

329
0:14:02.276,000 --> 0:14:04,000
and to ground them in experimental reality.

330
0:14:04.468,000 --> 0:14:05,000
XL: Nowadays, people in the lab

331
0:14:06.351,000 --> 0:14:08,000
and people in other groups all over the world

332
0:14:08.737,000 --> 0:14:11,000
are using similar methods to activate or edit memories,

333
0:14:12.554,000 --> 0:14:15,000
whether that's old or new, positive or negative,

334
0:14:16.395,000 --> 0:14:18,000
all sorts of memories so that we can understand

335
0:14:19.067,000 --> 0:14:2,000
how memory works.

336
0:14:20.931,000 --> 0:14:21,000
SR: For example, one group in our lab

337
0:14:22.715,000 --> 0:14:24,000
was able to find the brain cells that make up a fear memory

338
0:14:25.353,000 --> 0:14:27,000
and converted them into a pleasurable memory, just like that.

339
0:14:28.128,000 --> 0:14:31,000
That's exactly what I mean about editing these kinds of processes.

340
0:14:31.295,000 --> 0:14:33,000
Now one dude in lab was even able to reactivate

341
0:14:33.558,000 --> 0:14:34,000
memories of female mice in male mice,

342
0:14:35.503,000 --> 0:14:37,000
which rumor has it is a pleasurable experience.

343
0:14:38.498,000 --> 0:14:42,000
XL: Indeed, we are living in a very exciting moment

344
0:14:42.615,000 --> 0:14:45,000
where science doesn't have any arbitrary speed limits

345
0:14:46.42,000 --> 0:14:49,000
but is only bound by our own imagination.

346
0:14:49.607,000 --> 0:14:51,000
SR: And finally, what do we make of all this?

347
0:14:51.774,000 --> 0:14:52,000
How do we push this technology forward?

348
0:14:53.725,000 --> 0:14:55,000
These are the questions that should not remain

349
0:14:55.94,000 --> 0:14:56,000
just inside the lab,

350
0:14:57.237,000 --> 0:14:59,000
and so one goal of today's talk was to bring everybody

351
0:14:59.833,000 --> 0:15:01,000
up to speed with the kind of stuff that's possible

352
0:15:02.238,000 --> 0:15:03,000
in modern neuroscience,

353
0:15:03.512,000 --> 0:15:04,000
but now, just as importantly,

354
0:15:05.022,000 --> 0:15:08,000
to actively engage everybody in this conversation.

355
0:15:08.354,000 --> 0:15:1,000
So let's think together as a team about what this all means

356
0:15:11.14,000 --> 0:15:12,000
and where we can and should go from here,

357
0:15:13.157,000 --> 0:15:15,000
because Xu and I think we all have

358
0:15:15.255,000 --> 0:15:17,000
some really big decisions ahead of us.

359
0:15:17.791,000 --> 0:15:18,000
Thank you. XL: Thank you.

360
0:15:18.916,000 --> 0:15:19,000
(Applause)

