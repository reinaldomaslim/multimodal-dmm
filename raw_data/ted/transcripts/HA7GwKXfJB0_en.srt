1
0:00:17.26,000 --> 0:00:2,000
We live in in a remarkable time,

2
0:00:20.26,000 --> 0:00:23,000
the age of genomics.

3
0:00:23.26,000 --> 0:00:26,000
Your genome is the entire sequence of your DNA.

4
0:00:26.26,000 --> 0:00:29,000
Your sequence and mine are slightly different.

5
0:00:29.26,000 --> 0:00:31,000
That's why we look different.

6
0:00:31.26,000 --> 0:00:33,000
I've got brown eyes;

7
0:00:33.26,000 --> 0:00:36,000
you might have blue or gray.

8
0:00:36.26,000 --> 0:00:38,000
But it's not just skin-deep.

9
0:00:38.26,000 --> 0:00:4,000
The headlines tell us

10
0:00:40.26,000 --> 0:00:43,000
that genes can give us scary diseases,

11
0:00:43.26,000 --> 0:00:46,000
maybe even shape our personality,

12
0:00:46.26,000 --> 0:00:49,000
or give us mental disorders.

13
0:00:49.26,000 --> 0:00:52,000
Our genes seem to have

14
0:00:52.26,000 --> 0:00:55,000
awesome power over our destinies.

15
0:00:56.26,000 --> 0:00:59,000
And yet, I would like to think

16
0:00:59.26,000 --> 0:01:02,000
that I am more than my genes.

17
0:01:04.26,000 --> 0:01:06,000
What do you guys think?

18
0:01:06.26,000 --> 0:01:09,000
Are you more than your genes?

19
0:01:09.26,000 --> 0:01:11,000
(Audience: Yes.) Yes?

20
0:01:13.26,000 --> 0:01:15,000
I think some people agree with me.

21
0:01:15.26,000 --> 0:01:17,000
I think we should make a statement.

22
0:01:17.26,000 --> 0:01:19,000
I think we should say it all together.

23
0:01:20.26,000 --> 0:01:23,000
All right: "I'm more than my genes" -- all together.

24
0:01:23.26,000 --> 0:01:27,000
Everybody: I am more than my genes.

25
0:01:27.26,000 --> 0:01:29,000
(Cheering)

26
0:01:30.26,000 --> 0:01:32,000
Sebastian Seung: What am I?

27
0:01:32.26,000 --> 0:01:35,000
(Laughter)

28
0:01:35.26,000 --> 0:01:38,000
I am my connectome.

29
0:01:40.26,000 --> 0:01:42,000
Now, since you guys are really great,

30
0:01:42.26,000 --> 0:01:44,000
maybe you can humor me and say this all together too.

31
0:01:44.26,000 --> 0:01:46,000
(Laughter)

32
0:01:46.26,000 --> 0:01:48,000
Right. All together now.

33
0:01:48.26,000 --> 0:01:51,000
Everybody: I am my connectome.

34
0:01:53.26,000 --> 0:01:55,000
SS: That sounded great.

35
0:01:55.26,000 --> 0:01:57,000
You know, you guys are so great, you don't even know what a connectome is,

36
0:01:57.26,000 --> 0:01:59,000
and you're willing to play along with me.

37
0:01:59.26,000 --> 0:02:02,000
I could just go home now.

38
0:02:02.26,000 --> 0:02:05,000
Well, so far only one connectome is known,

39
0:02:05.26,000 --> 0:02:08,000
that of this tiny worm.

40
0:02:08.26,000 --> 0:02:1,000
Its modest nervous system

41
0:02:10.26,000 --> 0:02:12,000
consists of just 300 neurons.

42
0:02:12.26,000 --> 0:02:14,000
And in the 1970s and '80s,

43
0:02:14.26,000 --> 0:02:16,000
a team of scientists

44
0:02:16.26,000 --> 0:02:18,000
mapped all 7,000 connections

45
0:02:18.26,000 --> 0:02:2,000
between the neurons.

46
0:02:21.26,000 --> 0:02:23,000
In this diagram, every node is a neuron,

47
0:02:23.26,000 --> 0:02:25,000
and every line is a connection.

48
0:02:25.26,000 --> 0:02:27,000
This is the connectome

49
0:02:27.26,000 --> 0:02:31,000
of the worm C. elegans.

50
0:02:31.26,000 --> 0:02:34,000
Your connectome is far more complex than this

51
0:02:34.26,000 --> 0:02:36,000
because your brain

52
0:02:36.26,000 --> 0:02:38,000
contains 100 billion neurons

53
0:02:38.26,000 --> 0:02:41,000
and 10,000 times as many connections.

54
0:02:41.26,000 --> 0:02:43,000
There's a diagram like this for your brain,

55
0:02:43.26,000 --> 0:02:46,000
but there's no way it would fit on this slide.

56
0:02:47.26,000 --> 0:02:5,000
Your connectome contains one million times more connections

57
0:02:50.26,000 --> 0:02:53,000
than your genome has letters.

58
0:02:53.26,000 --> 0:02:55,000
That's a lot of information.

59
0:02:55.26,000 --> 0:02:58,000
What's in that information?

60
0:02:59.26,000 --> 0:03:02,000
We don't know for sure, but there are theories.

61
0:03:02.26,000 --> 0:03:05,000
Since the 19th century, neuroscientists have speculated

62
0:03:05.26,000 --> 0:03:07,000
that maybe your memories --

63
0:03:07.26,000 --> 0:03:09,000
the information that makes you, you --

64
0:03:09.26,000 --> 0:03:11,000
maybe your memories are stored

65
0:03:11.26,000 --> 0:03:13,000
in the connections between your brain's neurons.

66
0:03:15.26,000 --> 0:03:17,000
And perhaps other aspects of your personal identity --

67
0:03:17.26,000 --> 0:03:2,000
maybe your personality and your intellect --

68
0:03:20.26,000 --> 0:03:22,000
maybe they're also encoded

69
0:03:22.26,000 --> 0:03:25,000
in the connections between your neurons.

70
0:03:26.26,000 --> 0:03:29,000
And so now you can see why I proposed this hypothesis:

71
0:03:29.26,000 --> 0:03:32,000
I am my connectome.

72
0:03:32.26,000 --> 0:03:35,000
I didn't ask you to chant it because it's true;

73
0:03:35.26,000 --> 0:03:37,000
I just want you to remember it.

74
0:03:37.26,000 --> 0:03:39,000
And in fact, we don't know if this hypothesis is correct,

75
0:03:39.26,000 --> 0:03:41,000
because we have never had technologies

76
0:03:41.26,000 --> 0:03:43,000
powerful enough to test it.

77
0:03:44.26,000 --> 0:03:47,000
Finding that worm connectome

78
0:03:47.26,000 --> 0:03:5,000
took over a dozen years of tedious labor.

79
0:03:50.26,000 --> 0:03:53,000
And to find the connectomes of brains more like our own,

80
0:03:53.26,000 --> 0:03:56,000
we need more sophisticated technologies, that are automated,

81
0:03:56.26,000 --> 0:03:59,000
that will speed up the process of finding connectomes.

82
0:03:59.26,000 --> 0:04:02,000
And in the next few minutes, I'll tell you about some of these technologies,

83
0:04:02.26,000 --> 0:04:04,000
which are currently under development

84
0:04:04.26,000 --> 0:04:07,000
in my lab and the labs of my collaborators.

85
0:04:08.26,000 --> 0:04:11,000
Now you've probably seen pictures of neurons before.

86
0:04:11.26,000 --> 0:04:13,000
You can recognize them instantly

87
0:04:13.26,000 --> 0:04:16,000
by their fantastic shapes.

88
0:04:16.26,000 --> 0:04:19,000
They extend long and delicate branches,

89
0:04:19.26,000 --> 0:04:22,000
and in short, they look like trees.

90
0:04:22.26,000 --> 0:04:25,000
But this is just a single neuron.

91
0:04:25.26,000 --> 0:04:27,000
In order to find connectomes,

92
0:04:27.26,000 --> 0:04:3,000
we have to see all the neurons at the same time.

93
0:04:30.26,000 --> 0:04:32,000
So let's meet Bobby Kasthuri,

94
0:04:32.26,000 --> 0:04:34,000
who works in the laboratory of Jeff Lichtman

95
0:04:34.26,000 --> 0:04:36,000
at Harvard University.

96
0:04:36.26,000 --> 0:04:38,000
Bobby is holding fantastically thin slices

97
0:04:38.26,000 --> 0:04:4,000
of a mouse brain.

98
0:04:40.26,000 --> 0:04:43,000
And we're zooming in by a factor of 100,000 times

99
0:04:44.26,000 --> 0:04:46,000
to obtain the resolution,

100
0:04:46.26,000 --> 0:04:49,000
so that we can see the branches of neurons all at the same time.

101
0:04:50.26,000 --> 0:04:53,000
Except, you still may not really recognize them,

102
0:04:53.26,000 --> 0:04:56,000
and that's because we have to work in three dimensions.

103
0:04:56.26,000 --> 0:04:58,000
If we take many images of many slices of the brain

104
0:04:58.26,000 --> 0:05:,000
and stack them up,

105
0:05:00.26,000 --> 0:05:02,000
we get a three-dimensional image.

106
0:05:02.26,000 --> 0:05:04,000
And still, you may not see the branches.

107
0:05:04.26,000 --> 0:05:06,000
So we start at the top,

108
0:05:06.26,000 --> 0:05:09,000
and we color in the cross-section of one branch in red,

109
0:05:09.26,000 --> 0:05:11,000
and we do that for the next slice

110
0:05:11.26,000 --> 0:05:13,000
and for the next slice.

111
0:05:13.26,000 --> 0:05:15,000
And we keep on doing that,

112
0:05:15.26,000 --> 0:05:18,000
slice after slice.

113
0:05:18.26,000 --> 0:05:2,000
If we continue through the entire stack,

114
0:05:20.26,000 --> 0:05:23,000
we can reconstruct the three-dimensional shape

115
0:05:23.26,000 --> 0:05:26,000
of a small fragment of a branch of a neuron.

116
0:05:26.26,000 --> 0:05:28,000
And we can do that for another neuron in green.

117
0:05:28.26,000 --> 0:05:3,000
And you can see that the green neuron touches the red neuron

118
0:05:30.26,000 --> 0:05:32,000
at two locations,

119
0:05:32.26,000 --> 0:05:34,000
and these are what are called synapses.

120
0:05:34.26,000 --> 0:05:36,000
Let's zoom in on one synapse,

121
0:05:36.26,000 --> 0:05:39,000
and keep your eyes on the interior of the green neuron.

122
0:05:39.26,000 --> 0:05:41,000
You should see small circles --

123
0:05:41.26,000 --> 0:05:44,000
these are called vesicles.

124
0:05:44.26,000 --> 0:05:47,000
They contain a molecule know as a neurotransmitter.

125
0:05:47.26,000 --> 0:05:49,000
And so when the green neuron wants to communicate,

126
0:05:49.26,000 --> 0:05:51,000
it wants to send a message to the red neuron,

127
0:05:51.26,000 --> 0:05:54,000
it spits out neurotransmitter.

128
0:05:54.26,000 --> 0:05:56,000
At the synapse, the two neurons

129
0:05:56.26,000 --> 0:05:58,000
are said to be connected

130
0:05:58.26,000 --> 0:06:01,000
like two friends talking on the telephone.

131
0:06:02.26,000 --> 0:06:04,000
So you see how to find a synapse.

132
0:06:04.26,000 --> 0:06:07,000
How can we find an entire connectome?

133
0:06:07.26,000 --> 0:06:1,000
Well, we take this three-dimensional stack of images

134
0:06:10.26,000 --> 0:06:13,000
and treat it as a gigantic three-dimensional coloring book.

135
0:06:13.26,000 --> 0:06:16,000
We color every neuron in, in a different color,

136
0:06:16.26,000 --> 0:06:18,000
and then we look through all of the images,

137
0:06:18.26,000 --> 0:06:2,000
find the synapses

138
0:06:20.26,000 --> 0:06:23,000
and note the colors of the two neurons involved in each synapse.

139
0:06:23.26,000 --> 0:06:26,000
If we can do that throughout all the images,

140
0:06:26.26,000 --> 0:06:28,000
we could find a connectome.

141
0:06:29.26,000 --> 0:06:31,000
Now, at this point,

142
0:06:31.26,000 --> 0:06:33,000
you've learned the basics of neurons and synapses.

143
0:06:33.26,000 --> 0:06:35,000
And so I think we're ready to tackle

144
0:06:35.26,000 --> 0:06:38,000
one of the most important questions in neuroscience:

145
0:06:39.26,000 --> 0:06:42,000
how are the brains of men and women different?

146
0:06:42.26,000 --> 0:06:44,000
(Laughter)

147
0:06:44.26,000 --> 0:06:46,000
According to this self-help book,

148
0:06:46.26,000 --> 0:06:48,000
guys brains are like waffles;

149
0:06:48.26,000 --> 0:06:51,000
they keep their lives compartmentalized in boxes.

150
0:06:51.26,000 --> 0:06:54,000
Girls' brains are like spaghetti;

151
0:06:54.26,000 --> 0:06:57,000
everything in their life is connected to everything else.

152
0:06:57.26,000 --> 0:06:59,000
(Laughter)

153
0:06:59.26,000 --> 0:07:01,000
You guys are laughing,

154
0:07:01.26,000 --> 0:07:03,000
but you know, this book changed my life.

155
0:07:03.26,000 --> 0:07:05,000
(Laughter)

156
0:07:07.26,000 --> 0:07:1,000
But seriously, what's wrong with this?

157
0:07:10.26,000 --> 0:07:13,000
You already know enough to tell me -- what's wrong with this statement?

158
0:07:20.26,000 --> 0:07:23,000
It doesn't matter whether you're a guy or girl,

159
0:07:23.26,000 --> 0:07:26,000
everyone's brains are like spaghetti.

160
0:07:26.26,000 --> 0:07:29,000
Or maybe really, really fine capellini with branches.

161
0:07:30.26,000 --> 0:07:32,000
Just as one strand of spaghetti

162
0:07:32.26,000 --> 0:07:35,000
contacts many other strands on your plate,

163
0:07:35.26,000 --> 0:07:37,000
one neuron touches many other neurons

164
0:07:37.26,000 --> 0:07:39,000
through their entangled branches.

165
0:07:39.26,000 --> 0:07:42,000
One neuron can be connected to so many other neurons,

166
0:07:42.26,000 --> 0:07:44,000
because there can be synapses

167
0:07:44.26,000 --> 0:07:47,000
at these points of contact.

168
0:07:49.26,000 --> 0:07:52,000
By now, you might have sort of lost perspective

169
0:07:52.26,000 --> 0:07:55,000
on how large this cube of brain tissue actually is.

170
0:07:55.26,000 --> 0:07:58,000
And so let's do a series of comparisons to show you.

171
0:07:58.26,000 --> 0:08:01,000
I assure you, this is very tiny. It's just six microns on a side.

172
0:08:03.26,000 --> 0:08:06,000
So, here's how it stacks up against an entire neuron.

173
0:08:06.26,000 --> 0:08:09,000
And you can tell that, really, only the smallest fragments of branches

174
0:08:09.26,000 --> 0:08:12,000
are contained inside this cube.

175
0:08:12.26,000 --> 0:08:15,000
And a neuron, well, that's smaller than brain.

176
0:08:17.26,000 --> 0:08:19,000
And that's just a mouse brain --

177
0:08:21.26,000 --> 0:08:24,000
it's a lot smaller than a human brain.

178
0:08:25.26,000 --> 0:08:27,000
So when show my friends this,

179
0:08:27.26,000 --> 0:08:29,000
sometimes they've told me,

180
0:08:29.26,000 --> 0:08:32,000
"You know, Sebastian, you should just give up.

181
0:08:32.26,000 --> 0:08:34,000
Neuroscience is hopeless."

182
0:08:34.26,000 --> 0:08:36,000
Because if you look at a brain with your naked eye,

183
0:08:36.26,000 --> 0:08:38,000
you don't really see how complex it is,

184
0:08:38.26,000 --> 0:08:4,000
but when you use a microscope,

185
0:08:40.26,000 --> 0:08:43,000
finally the hidden complexity is revealed.

186
0:08:45.26,000 --> 0:08:47,000
In the 17th century,

187
0:08:47.26,000 --> 0:08:49,000
the mathematician and philosopher, Blaise Pascal,

188
0:08:49.26,000 --> 0:08:52,000
wrote of his dread of the infinite,

189
0:08:52.26,000 --> 0:08:54,000
his feeling of insignificance

190
0:08:54.26,000 --> 0:08:57,000
at contemplating the vast reaches of outer space.

191
0:08:59.26,000 --> 0:09:01,000
And, as a scientist,

192
0:09:01.26,000 --> 0:09:04,000
I'm not supposed to talk about my feelings --

193
0:09:04.26,000 --> 0:09:06,000
too much information, professor.

194
0:09:06.26,000 --> 0:09:08,000
(Laughter)

195
0:09:08.26,000 --> 0:09:1,000
But may I?

196
0:09:10.26,000 --> 0:09:12,000
(Laughter)

197
0:09:12.26,000 --> 0:09:14,000
(Applause)

198
0:09:14.26,000 --> 0:09:16,000
I feel curiosity,

199
0:09:16.26,000 --> 0:09:18,000
and I feel wonder,

200
0:09:18.26,000 --> 0:09:21,000
but at times I have also felt despair.

201
0:09:22.26,000 --> 0:09:24,000
Why did I choose to study

202
0:09:24.26,000 --> 0:09:27,000
this organ that is so awesome in its complexity

203
0:09:27.26,000 --> 0:09:29,000
that it might well be infinite?

204
0:09:29.26,000 --> 0:09:31,000
It's absurd.

205
0:09:31.26,000 --> 0:09:33,000
How could we even dare to think

206
0:09:33.26,000 --> 0:09:36,000
that we might ever understand this?

207
0:09:38.26,000 --> 0:09:41,000
And yet, I persist in this quixotic endeavor.

208
0:09:41.26,000 --> 0:09:44,000
And indeed, these days I harbor new hopes.

209
0:09:45.26,000 --> 0:09:47,000
Someday,

210
0:09:47.26,000 --> 0:09:49,000
a fleet of microscopes will capture

211
0:09:49.26,000 --> 0:09:51,000
every neuron and every synapse

212
0:09:51.26,000 --> 0:09:54,000
in a vast database of images.

213
0:09:54.26,000 --> 0:09:57,000
And some day, artificially intelligent supercomputers

214
0:09:57.26,000 --> 0:10:,000
will analyze the images without human assistance

215
0:10:00.26,000 --> 0:10:03,000
to summarize them in a connectome.

216
0:10:04.26,000 --> 0:10:07,000
I do not know, but I hope that I will live to see that day,

217
0:10:08.26,000 --> 0:10:1,000
because finding an entire human connectome

218
0:10:10.26,000 --> 0:10:13,000
is one of the greatest technological challenges of all time.

219
0:10:13.26,000 --> 0:10:16,000
It will take the work of generations to succeed.

220
0:10:17.26,000 --> 0:10:2,000
At the present time, my collaborators and I,

221
0:10:20.26,000 --> 0:10:22,000
what we're aiming for is much more modest --

222
0:10:22.26,000 --> 0:10:24,000
just to find partial connectomes

223
0:10:24.26,000 --> 0:10:27,000
of tiny chunks of mouse and human brain.

224
0:10:27.26,000 --> 0:10:3,000
But even that will be enough for the first tests of this hypothesis

225
0:10:30.26,000 --> 0:10:33,000
that I am my connectome.

226
0:10:35.26,000 --> 0:10:38,000
For now, let me try to convince you of the plausibility of this hypothesis,

227
0:10:38.26,000 --> 0:10:41,000
that it's actually worth taking seriously.

228
0:10:42.26,000 --> 0:10:44,000
As you grow during childhood

229
0:10:44.26,000 --> 0:10:47,000
and age during adulthood,

230
0:10:47.26,000 --> 0:10:5,000
your personal identity changes slowly.

231
0:10:50.26,000 --> 0:10:52,000
Likewise, every connectome

232
0:10:52.26,000 --> 0:10:54,000
changes over time.

233
0:10:55.26,000 --> 0:10:57,000
What kinds of changes happen?

234
0:10:57.26,000 --> 0:10:59,000
Well, neurons, like trees,

235
0:10:59.26,000 --> 0:11:01,000
can grow new branches,

236
0:11:01.26,000 --> 0:11:04,000
and they can lose old ones.

237
0:11:04.26,000 --> 0:11:07,000
Synapses can be created,

238
0:11:07.26,000 --> 0:11:1,000
and they can be eliminated.

239
0:11:10.26,000 --> 0:11:12,000
And synapses can grow larger,

240
0:11:12.26,000 --> 0:11:15,000
and they can grow smaller.

241
0:11:15.26,000 --> 0:11:17,000
Second question:

242
0:11:17.26,000 --> 0:11:2,000
what causes these changes?

243
0:11:20.26,000 --> 0:11:22,000
Well, it's true.

244
0:11:22.26,000 --> 0:11:25,000
To some extent, they are programmed by your genes.

245
0:11:25.26,000 --> 0:11:27,000
But that's not the whole story,

246
0:11:27.26,000 --> 0:11:29,000
because there are signals, electrical signals,

247
0:11:29.26,000 --> 0:11:31,000
that travel along the branches of neurons

248
0:11:31.26,000 --> 0:11:33,000
and chemical signals

249
0:11:33.26,000 --> 0:11:35,000
that jump across from branch to branch.

250
0:11:35.26,000 --> 0:11:38,000
These signals are called neural activity.

251
0:11:38.26,000 --> 0:11:4,000
And there's a lot of evidence

252
0:11:40.26,000 --> 0:11:43,000
that neural activity

253
0:11:43.26,000 --> 0:11:46,000
is encoding our thoughts, feelings and perceptions,

254
0:11:46.26,000 --> 0:11:48,000
our mental experiences.

255
0:11:48.26,000 --> 0:11:51,000
And there's a lot of evidence that neural activity

256
0:11:51.26,000 --> 0:11:54,000
can cause your connections to change.

257
0:11:54.26,000 --> 0:11:57,000
And if you put those two facts together,

258
0:11:57.26,000 --> 0:11:59,000
it means that your experiences

259
0:11:59.26,000 --> 0:12:02,000
can change your connectome.

260
0:12:02.26,000 --> 0:12:04,000
And that's why every connectome is unique,

261
0:12:04.26,000 --> 0:12:07,000
even those of genetically identical twins.

262
0:12:08.26,000 --> 0:12:11,000
The connectome is where nature meets nurture.

263
0:12:12.26,000 --> 0:12:14,000
And it might true

264
0:12:14.26,000 --> 0:12:16,000
that just the mere act of thinking

265
0:12:16.26,000 --> 0:12:18,000
can change your connectome --

266
0:12:18.26,000 --> 0:12:21,000
an idea that you may find empowering.

267
0:12:24.26,000 --> 0:12:26,000
What's in this picture?

268
0:12:28.26,000 --> 0:12:31,000
A cool and refreshing stream of water, you say.

269
0:12:32.26,000 --> 0:12:34,000
What else is in this picture?

270
0:12:37.26,000 --> 0:12:39,000
Do not forget that groove in the Earth

271
0:12:39.26,000 --> 0:12:42,000
called the stream bed.

272
0:12:42.26,000 --> 0:12:45,000
Without it, the water would not know in which direction to flow.

273
0:12:45.26,000 --> 0:12:47,000
And with the stream,

274
0:12:47.26,000 --> 0:12:49,000
I would like to propose a metaphor

275
0:12:49.26,000 --> 0:12:51,000
for the relationship between neural activity

276
0:12:51.26,000 --> 0:12:53,000
and connectivity.

277
0:12:54.26,000 --> 0:12:57,000
Neural activity is constantly changing.

278
0:12:57.26,000 --> 0:13:,000
It's like the water of the stream; it never sits still.

279
0:13:00.26,000 --> 0:13:02,000
The connections

280
0:13:02.26,000 --> 0:13:04,000
of the brain's neural network

281
0:13:04.26,000 --> 0:13:06,000
determines the pathways

282
0:13:06.26,000 --> 0:13:08,000
along which neural activity flows.

283
0:13:08.26,000 --> 0:13:11,000
And so the connectome is like bed of the stream;

284
0:13:13.26,000 --> 0:13:16,000
but the metaphor is richer than that,

285
0:13:16.26,000 --> 0:13:19,000
because it's true that the stream bed

286
0:13:19.26,000 --> 0:13:21,000
guides the flow of the water,

287
0:13:21.26,000 --> 0:13:23,000
but over long timescales,

288
0:13:23.26,000 --> 0:13:26,000
the water also reshapes the bed of the stream.

289
0:13:26.26,000 --> 0:13:28,000
And as I told you just now,

290
0:13:28.26,000 --> 0:13:31,000
neural activity can change the connectome.

291
0:13:33.26,000 --> 0:13:35,000
And if you'll allow me to ascend

292
0:13:35.26,000 --> 0:13:38,000
to metaphorical heights,

293
0:13:38.26,000 --> 0:13:41,000
I will remind you that neural activity

294
0:13:41.26,000 --> 0:13:43,000
is the physical basis -- or so neuroscientists think --

295
0:13:43.26,000 --> 0:13:46,000
of thoughts, feelings and perceptions.

296
0:13:46.26,000 --> 0:13:48,000
And so we might even speak of

297
0:13:48.26,000 --> 0:13:5,000
the stream of consciousness.

298
0:13:50.26,000 --> 0:13:53,000
Neural activity is its water,

299
0:13:53.26,000 --> 0:13:56,000
and the connectome is its bed.

300
0:13:57.26,000 --> 0:13:59,000
So let's return from the heights of metaphor

301
0:13:59.26,000 --> 0:14:01,000
and return to science.

302
0:14:01.26,000 --> 0:14:03,000
Suppose our technologies for finding connectomes

303
0:14:03.26,000 --> 0:14:05,000
actually work.

304
0:14:05.26,000 --> 0:14:07,000
How will we go about testing the hypothesis

305
0:14:07.26,000 --> 0:14:1,000
"I am my connectome?"

306
0:14:10.26,000 --> 0:14:13,000
Well, I propose a direct test.

307
0:14:13.26,000 --> 0:14:15,000
Let us attempt

308
0:14:15.26,000 --> 0:14:18,000
to read out memories from connectomes.

309
0:14:18.26,000 --> 0:14:2,000
Consider the memory

310
0:14:20.26,000 --> 0:14:23,000
of long temporal sequences of movements,

311
0:14:23.26,000 --> 0:14:26,000
like a pianist playing a Beethoven sonata.

312
0:14:26.26,000 --> 0:14:29,000
According to a theory that dates back to the 19th century,

313
0:14:29.26,000 --> 0:14:31,000
such memories are stored

314
0:14:31.26,000 --> 0:14:34,000
as chains of synaptic connections inside your brain.

315
0:14:35.26,000 --> 0:14:38,000
Because, if the first neurons in the chain are activated,

316
0:14:38.26,000 --> 0:14:41,000
through their synapses they send messages to the second neurons, which are activated,

317
0:14:41.26,000 --> 0:14:43,000
and so on down the line,

318
0:14:43.26,000 --> 0:14:45,000
like a chain of falling dominoes.

319
0:14:45.26,000 --> 0:14:47,000
And this sequence of neural activation

320
0:14:47.26,000 --> 0:14:5,000
is hypothesized to be the neural basis

321
0:14:50.26,000 --> 0:14:52,000
of those sequence of movements.

322
0:14:52.26,000 --> 0:14:54,000
So one way of trying to test the theory

323
0:14:54.26,000 --> 0:14:56,000
is to look for such chains

324
0:14:56.26,000 --> 0:14:58,000
inside connectomes.

325
0:14:58.26,000 --> 0:15:01,000
But it won't be easy, because they're not going to look like this.

326
0:15:01.26,000 --> 0:15:03,000
They're going to be scrambled up.

327
0:15:03.26,000 --> 0:15:05,000
So we'll have to use our computers

328
0:15:05.26,000 --> 0:15:08,000
to try to unscramble the chain.

329
0:15:08.26,000 --> 0:15:1,000
And if we can do that,

330
0:15:10.26,000 --> 0:15:13,000
the sequence of the neurons we recover from that unscrambling

331
0:15:13.26,000 --> 0:15:16,000
will be a prediction of the pattern of neural activity

332
0:15:16.26,000 --> 0:15:19,000
that is replayed in the brain during memory recall.

333
0:15:19.26,000 --> 0:15:21,000
And if that were successful,

334
0:15:21.26,000 --> 0:15:24,000
that would be the first example of reading a memory from a connectome.

335
0:15:28.26,000 --> 0:15:3,000
(Laughter)

336
0:15:30.26,000 --> 0:15:32,000
What a mess --

337
0:15:33.26,000 --> 0:15:35,000
have you ever tried to wire up a system

338
0:15:35.26,000 --> 0:15:37,000
as complex as this?

339
0:15:37.26,000 --> 0:15:39,000
I hope not.

340
0:15:39.26,000 --> 0:15:42,000
But if you have, you know it's very easy to make a mistake.

341
0:15:45.26,000 --> 0:15:47,000
The branches of neurons are like the wires of the brain.

342
0:15:47.26,000 --> 0:15:51,000
Can anyone guess: what's the total length of wires in your brain?

343
0:15:54.26,000 --> 0:15:56,000
I'll give you a hint. It's a big number.

344
0:15:56.26,000 --> 0:15:58,000
(Laughter)

345
0:15:59.26,000 --> 0:16:02,000
I estimate, millions of miles,

346
0:16:02.26,000 --> 0:16:05,000
all packed in your skull.

347
0:16:05.26,000 --> 0:16:07,000
And if you appreciate that number,

348
0:16:07.26,000 --> 0:16:09,000
you can easily see

349
0:16:09.26,000 --> 0:16:11,000
there is huge potential for mis-wiring of the brain.

350
0:16:11.26,000 --> 0:16:14,000
And indeed, the popular press loves headlines like,

351
0:16:14.26,000 --> 0:16:16,000
"Anorexic brains are wired differently,"

352
0:16:16.26,000 --> 0:16:18,000
or "Autistic brains are wired differently."

353
0:16:18.26,000 --> 0:16:2,000
These are plausible claims,

354
0:16:20.26,000 --> 0:16:22,000
but in truth,

355
0:16:22.26,000 --> 0:16:24,000
we can't see the brain's wiring clearly enough

356
0:16:24.26,000 --> 0:16:26,000
to tell if these are really true.

357
0:16:26.26,000 --> 0:16:29,000
And so the technologies for seeing connectomes

358
0:16:29.26,000 --> 0:16:31,000
will allow us to finally

359
0:16:31.26,000 --> 0:16:33,000
read mis-wiring of the brain,

360
0:16:33.26,000 --> 0:16:36,000
to see mental disorders in connectomes.

361
0:16:40.26,000 --> 0:16:43,000
Sometimes the best way to test a hypothesis

362
0:16:43.26,000 --> 0:16:46,000
is to consider its most extreme implication.

363
0:16:46.26,000 --> 0:16:49,000
Philosophers know this game very well.

364
0:16:50.26,000 --> 0:16:53,000
If you believe that I am my connectome,

365
0:16:53.26,000 --> 0:16:56,000
I think you must also accept the idea

366
0:16:56.26,000 --> 0:16:58,000
that death is the destruction

367
0:16:58.26,000 --> 0:17:01,000
of your connectome.

368
0:17:02.26,000 --> 0:17:05,000
I mention this because there are prophets today

369
0:17:05.26,000 --> 0:17:08,000
who claim that technology

370
0:17:08.26,000 --> 0:17:11,000
will fundamentally alter the human condition

371
0:17:11.26,000 --> 0:17:14,000
and perhaps even transform the human species.

372
0:17:14.26,000 --> 0:17:17,000
One of their most cherished dreams

373
0:17:17.26,000 --> 0:17:19,000
is to cheat death

374
0:17:19.26,000 --> 0:17:21,000
by that practice known as cryonics.

375
0:17:21.26,000 --> 0:17:23,000
If you pay 100,000 dollars,

376
0:17:23.26,000 --> 0:17:26,000
you can arrange to have your body frozen after death

377
0:17:26.26,000 --> 0:17:28,000
and stored in liquid nitrogen

378
0:17:28.26,000 --> 0:17:3,000
in one of these tanks in an Arizona warehouse,

379
0:17:30.26,000 --> 0:17:32,000
awaiting a future civilization

380
0:17:32.26,000 --> 0:17:35,000
that is advanced to resurrect you.

381
0:17:36.26,000 --> 0:17:38,000
Should we ridicule the modern seekers of immortality,

382
0:17:38.26,000 --> 0:17:4,000
calling them fools?

383
0:17:40.26,000 --> 0:17:42,000
Or will they someday chuckle

384
0:17:42.26,000 --> 0:17:44,000
over our graves?

385
0:17:45.26,000 --> 0:17:47,000
I don't know --

386
0:17:47.26,000 --> 0:17:5,000
I prefer to test their beliefs, scientifically.

387
0:17:50.26,000 --> 0:17:52,000
I propose that we attempt to find a connectome

388
0:17:52.26,000 --> 0:17:54,000
of a frozen brain.

389
0:17:54.26,000 --> 0:17:56,000
We know that damage to the brain

390
0:17:56.26,000 --> 0:17:58,000
occurs after death and during freezing.

391
0:17:58.26,000 --> 0:18:01,000
The question is: has that damage erased the connectome?

392
0:18:01.26,000 --> 0:18:04,000
If it has, there is no way that any future civilization

393
0:18:04.26,000 --> 0:18:07,000
will be able to recover the memories of these frozen brains.

394
0:18:07.26,000 --> 0:18:09,000
Resurrection might succeed for the body,

395
0:18:09.26,000 --> 0:18:11,000
but not for the mind.

396
0:18:11.26,000 --> 0:18:14,000
On the other hand, if the connectome is still intact,

397
0:18:14.26,000 --> 0:18:17,000
we cannot ridicule the claims of cryonics so easily.

398
0:18:20.26,000 --> 0:18:22,000
I've described a quest

399
0:18:22.26,000 --> 0:18:25,000
that begins in the world of the very small,

400
0:18:25.26,000 --> 0:18:28,000
and propels us to the world of the far future.

401
0:18:28.26,000 --> 0:18:31,000
Connectomes will mark a turning point in human history.

402
0:18:32.26,000 --> 0:18:34,000
As we evolved from our ape-like ancestors

403
0:18:34.26,000 --> 0:18:36,000
on the African savanna,

404
0:18:36.26,000 --> 0:18:39,000
what distinguished us was our larger brains.

405
0:18:40.26,000 --> 0:18:42,000
We have used our brains to fashion

406
0:18:42.26,000 --> 0:18:45,000
ever more amazing technologies.

407
0:18:45.26,000 --> 0:18:48,000
Eventually, these technologies will become so powerful

408
0:18:48.26,000 --> 0:18:51,000
that we will use them to know ourselves

409
0:18:51.26,000 --> 0:18:54,000
by deconstructing and reconstructing

410
0:18:54.26,000 --> 0:18:57,000
our own brains.

411
0:18:57.26,000 --> 0:19:,000
I believe that this voyage of self-discovery

412
0:19:00.26,000 --> 0:19:03,000
is not just for scientists,

413
0:19:03.26,000 --> 0:19:05,000
but for all of us.

414
0:19:05.26,000 --> 0:19:08,000
And I'm grateful for the opportunity to share this voyage with you today.

415
0:19:08.26,000 --> 0:19:1,000
Thank you.

416
0:19:10.26,000 --> 0:19:18,000
(Applause)

