1
0:00:,000 --> 0:00:07,000
Translator: Joseph Geni Reviewer: Morton Bast

2
0:00:12.691,000 --> 0:00:15,000
I write fiction sci-fi thrillers,

3
0:00:15.849,000 --> 0:00:17,000
so if I say "killer robots,"

4
0:00:18.042,000 --> 0:00:2,000
you'd probably think something like this.

5
0:00:20.403,000 --> 0:00:22,000
But I'm actually not here to talk about fiction.

6
0:00:22.958,000 --> 0:00:24,000
I'm here to talk about very real killer robots,

7
0:00:25.906,000 --> 0:00:28,000
autonomous combat drones.

8
0:00:29.028,000 --> 0:00:32,000
Now, I'm not referring to Predator and Reaper drones,

9
0:00:32.655,000 --> 0:00:35,000
which have a human making targeting decisions.

10
0:00:35.915,000 --> 0:00:38,000
I'm talking about fully autonomous robotic weapons

11
0:00:39.044,000 --> 0:00:41,000
that make lethal decisions about human beings

12
0:00:41.698,000 --> 0:00:43,000
all on their own.

13
0:00:44.115,000 --> 0:00:48,000
There's actually a technical term for this: lethal autonomy.

14
0:00:48.115,000 --> 0:00:5,000
Now, lethally autonomous killer robots

15
0:00:50.971,000 --> 0:00:53,000
would take many forms -- flying, driving,

16
0:00:54.04,000 --> 0:00:56,000
or just lying in wait.

17
0:00:56.786,000 --> 0:00:59,000
And actually, they're very quickly becoming a reality.

18
0:00:59.895,000 --> 0:01:01,000
These are two automatic sniper stations

19
0:01:02.379,000 --> 0:01:06,000
currently deployed in the DMZ between North and South Korea.

20
0:01:06.516,000 --> 0:01:08,000
Both of these machines are capable of automatically

21
0:01:08.687,000 --> 0:01:11,000
identifying a human target and firing on it,

22
0:01:12.211,000 --> 0:01:16,000
the one on the left at a distance of over a kilometer.

23
0:01:16.535,000 --> 0:01:19,000
Now, in both cases, there's still a human in the loop

24
0:01:20.124,000 --> 0:01:22,000
to make that lethal firing decision,

25
0:01:22.496,000 --> 0:01:27,000
but it's not a technological requirement. It's a choice.

26
0:01:27.909,000 --> 0:01:3,000
And it's that choice that I want to focus on,

27
0:01:31.002,000 --> 0:01:33,000
because as we migrate lethal decision-making

28
0:01:33.643,000 --> 0:01:36,000
from humans to software,

29
0:01:36.752,000 --> 0:01:39,000
we risk not only taking the humanity out of war,

30
0:01:40.228,000 --> 0:01:43,000
but also changing our social landscape entirely,

31
0:01:43.754,000 --> 0:01:45,000
far from the battlefield.

32
0:01:45.978,000 --> 0:01:49,000
That's because the way humans resolve conflict

33
0:01:50.487,000 --> 0:01:51,000
shapes our social landscape.

34
0:01:52.22,000 --> 0:01:54,000
And this has always been the case, throughout history.

35
0:01:54.853,000 --> 0:01:56,000
For example, these were state-of-the-art weapons systems

36
0:01:57.514,000 --> 0:01:59,000
in 1400 A.D.

37
0:01:59.593,000 --> 0:02:02,000
Now they were both very expensive to build and maintain,

38
0:02:02.737,000 --> 0:02:05,000
but with these you could dominate the populace,

39
0:02:05.977,000 --> 0:02:08,000
and the distribution of political power in feudal society reflected that.

40
0:02:09.866,000 --> 0:02:11,000
Power was focused at the very top.

41
0:02:12.553,000 --> 0:02:15,000
And what changed? Technological innovation.

42
0:02:16.081,000 --> 0:02:17,000
Gunpowder, cannon.

43
0:02:17.952,000 --> 0:02:2,000
And pretty soon, armor and castles were obsolete,

44
0:02:21.769,000 --> 0:02:23,000
and it mattered less who you brought to the battlefield

45
0:02:24.302,000 --> 0:02:27,000
versus how many people you brought to the battlefield.

46
0:02:28.081,000 --> 0:02:31,000
And as armies grew in size, the nation-state arose

47
0:02:31.719,000 --> 0:02:34,000
as a political and logistical requirement of defense.

48
0:02:35.399,000 --> 0:02:37,000
And as leaders had to rely on more of their populace,

49
0:02:37.775,000 --> 0:02:38,000
they began to share power.

50
0:02:39.608,000 --> 0:02:41,000
Representative government began to form.

51
0:02:42.207,000 --> 0:02:45,000
So again, the tools we use to resolve conflict

52
0:02:45.495,000 --> 0:02:48,000
shape our social landscape.

53
0:02:48.799,000 --> 0:02:52,000
Autonomous robotic weapons are such a tool,

54
0:02:52.863,000 --> 0:02:57,000
except that, by requiring very few people to go to war,

55
0:02:58.031,000 --> 0:03:02,000
they risk re-centralizing power into very few hands,

56
0:03:02.871,000 --> 0:03:08,000
possibly reversing a five-century trend toward democracy.

57
0:03:09.386,000 --> 0:03:1,000
Now, I think, knowing this,

58
0:03:11.143,000 --> 0:03:15,000
we can take decisive steps to preserve our democratic institutions,

59
0:03:15.495,000 --> 0:03:18,000
to do what humans do best, which is adapt.

60
0:03:19.474,000 --> 0:03:21,000
But time is a factor.

61
0:03:21.479,000 --> 0:03:23,000
Seventy nations are developing remotely-piloted

62
0:03:24.33,000 --> 0:03:26,000
combat drones of their own,

63
0:03:26.487,000 --> 0:03:28,000
and as you'll see, remotely-piloted combat drones

64
0:03:29.08,000 --> 0:03:33,000
are the precursors to autonomous robotic weapons.

65
0:03:33.552,000 --> 0:03:35,000
That's because once you've deployed remotely-piloted drones,

66
0:03:36.319,000 --> 0:03:39,000
there are three powerful factors pushing decision-making

67
0:03:39.703,000 --> 0:03:43,000
away from humans and on to the weapon platform itself.

68
0:03:44.303,000 --> 0:03:49,000
The first of these is the deluge of video that drones produce.

69
0:03:49.562,000 --> 0:03:52,000
For example, in 2004, the U.S. drone fleet produced

70
0:03:53.415,000 --> 0:03:58,000
a grand total of 71 hours of video surveillance for analysis.

71
0:03:58.727,000 --> 0:04:02,000
By 2011, this had gone up to 300,000 hours,

72
0:04:03.226,000 --> 0:04:06,000
outstripping human ability to review it all,

73
0:04:06.375,000 --> 0:04:09,000
but even that number is about to go up drastically.

74
0:04:10.039,000 --> 0:04:12,000
The Pentagon's Gorgon Stare and Argus programs

75
0:04:12.614,000 --> 0:04:15,000
will put up to 65 independently operated camera eyes

76
0:04:15.778,000 --> 0:04:17,000
on each drone platform,

77
0:04:17.816,000 --> 0:04:2,000
and this would vastly outstrip human ability to review it.

78
0:04:21.119,000 --> 0:04:23,000
And that means visual intelligence software will need

79
0:04:23.279,000 --> 0:04:27,000
to scan it for items of interest.

80
0:04:27.327,000 --> 0:04:28,000
And that means very soon

81
0:04:28.675,000 --> 0:04:3,000
drones will tell humans what to look at,

82
0:04:31.422,000 --> 0:04:33,000
not the other way around.

83
0:04:33.919,000 --> 0:04:35,000
But there's a second powerful incentive pushing

84
0:04:36.392,000 --> 0:04:39,000
decision-making away from humans and onto machines,

85
0:04:39.775,000 --> 0:04:41,000
and that's electromagnetic jamming,

86
0:04:42.647,000 --> 0:04:44,000
severing the connection between the drone

87
0:04:44.883,000 --> 0:04:46,000
and its operator.

88
0:04:47.697,000 --> 0:04:49,000
Now we saw an example of this in 2011

89
0:04:50.315,000 --> 0:04:52,000
when an American RQ-170 Sentinel drone

90
0:04:53.271,000 --> 0:04:57,000
got a bit confused over Iran due to a GPS spoofing attack,

91
0:04:57.578,000 --> 0:05:02,000
but any remotely-piloted drone is susceptible to this type of attack,

92
0:05:02.692,000 --> 0:05:04,000
and that means drones

93
0:05:04.744,000 --> 0:05:07,000
will have to shoulder more decision-making.

94
0:05:08.364,000 --> 0:05:11,000
They'll know their mission objective,

95
0:05:11.407,000 --> 0:05:15,000
and they'll react to new circumstances without human guidance.

96
0:05:16.252,000 --> 0:05:18,000
They'll ignore external radio signals

97
0:05:18.833,000 --> 0:05:2,000
and send very few of their own.

98
0:05:21.163,000 --> 0:05:23,000
Which brings us to, really, the third

99
0:05:23.169,000 --> 0:05:26,000
and most powerful incentive pushing decision-making

100
0:05:27.031,000 --> 0:05:3,000
away from humans and onto weapons:

101
0:05:30.373,000 --> 0:05:33,000
plausible deniability.

102
0:05:33.666,000 --> 0:05:35,000
Now we live in a global economy.

103
0:05:36.553,000 --> 0:05:4,000
High-tech manufacturing is occurring on most continents.

104
0:05:40.887,000 --> 0:05:42,000
Cyber espionage is spiriting away advanced designs

105
0:05:43.801,000 --> 0:05:44,000
to parts unknown,

106
0:05:45.687,000 --> 0:05:47,000
and in that environment, it is very likely

107
0:05:47.701,000 --> 0:05:51,000
that a successful drone design will be knocked off in contract factories,

108
0:05:52.435,000 --> 0:05:54,000
proliferate in the gray market.

109
0:05:54.605,000 --> 0:05:56,000
And in that situation, sifting through the wreckage

110
0:05:57.065,000 --> 0:05:59,000
of a suicide drone attack, it will be very difficult to say

111
0:06:00.025,000 --> 0:06:04,000
who sent that weapon.

112
0:06:04.425,000 --> 0:06:06,000
This raises the very real possibility

113
0:06:07.225,000 --> 0:06:09,000
of anonymous war.

114
0:06:10.16,000 --> 0:06:12,000
This could tilt the geopolitical balance on its head,

115
0:06:12.774,000 --> 0:06:15,000
make it very difficult for a nation to turn its firepower

116
0:06:16.265,000 --> 0:06:18,000
against an attacker, and that could shift the balance

117
0:06:19.113,000 --> 0:06:22,000
in the 21st century away from defense and toward offense.

118
0:06:22.877,000 --> 0:06:25,000
It could make military action a viable option

119
0:06:26.001,000 --> 0:06:28,000
not just for small nations,

120
0:06:28.289,000 --> 0:06:3,000
but criminal organizations, private enterprise,

121
0:06:30.834,000 --> 0:06:32,000
even powerful individuals.

122
0:06:33.313,000 --> 0:06:36,000
It could create a landscape of rival warlords

123
0:06:36.641,000 --> 0:06:39,000
undermining rule of law and civil society.

124
0:06:40.321,000 --> 0:06:43,000
Now if responsibility and transparency

125
0:06:43.937,000 --> 0:06:45,000
are two of the cornerstones of representative government,

126
0:06:46.321,000 --> 0:06:5,000
autonomous robotic weapons could undermine both.

127
0:06:50.641,000 --> 0:06:51,000
Now you might be thinking that

128
0:06:52.187,000 --> 0:06:54,000
citizens of high-tech nations

129
0:06:54.433,000 --> 0:06:56,000
would have the advantage in any robotic war,

130
0:06:57.136,000 --> 0:07:,000
that citizens of those nations would be less vulnerable,

131
0:07:00.769,000 --> 0:07:04,000
particularly against developing nations.

132
0:07:05.057,000 --> 0:07:08,000
But I think the truth is the exact opposite.

133
0:07:08.581,000 --> 0:07:1,000
I think citizens of high-tech societies

134
0:07:10.832,000 --> 0:07:13,000
are more vulnerable to robotic weapons,

135
0:07:14.561,000 --> 0:07:18,000
and the reason can be summed up in one word: data.

136
0:07:19.026,000 --> 0:07:22,000
Data powers high-tech societies.

137
0:07:22.507,000 --> 0:07:25,000
Cell phone geolocation, telecom metadata,

138
0:07:25.697,000 --> 0:07:28,000
social media, email, text, financial transaction data,

139
0:07:29.169,000 --> 0:07:32,000
transportation data, it's a wealth of real-time data

140
0:07:32.701,000 --> 0:07:35,000
on the movements and social interactions of people.

141
0:07:36.074,000 --> 0:07:39,000
In short, we are more visible to machines

142
0:07:39.849,000 --> 0:07:41,000
than any people in history,

143
0:07:42.091,000 --> 0:07:47,000
and this perfectly suits the targeting needs of autonomous weapons.

144
0:07:47.707,000 --> 0:07:48,000
What you're looking at here

145
0:07:49.445,000 --> 0:07:52,000
is a link analysis map of a social group.

146
0:07:52.691,000 --> 0:07:55,000
Lines indicate social connectedness between individuals.

147
0:07:56.325,000 --> 0:07:58,000
And these types of maps can be automatically generated

148
0:07:59.205,000 --> 0:08:03,000
based on the data trail modern people leave behind.

149
0:08:03.92,000 --> 0:08:05,000
Now it's typically used to market goods and services

150
0:08:06.397,000 --> 0:08:1,000
to targeted demographics, but it's a dual-use technology,

151
0:08:10.813,000 --> 0:08:13,000
because targeting is used in another context.

152
0:08:14.173,000 --> 0:08:16,000
Notice that certain individuals are highlighted.

153
0:08:16.733,000 --> 0:08:19,000
These are the hubs of social networks.

154
0:08:20.013,000 --> 0:08:23,000
These are organizers, opinion-makers, leaders,

155
0:08:23.603,000 --> 0:08:25,000
and these people also can be automatically identified

156
0:08:26.285,000 --> 0:08:28,000
from their communication patterns.

157
0:08:28.667,000 --> 0:08:3,000
Now, if you're a marketer, you might then target them

158
0:08:30.813,000 --> 0:08:32,000
with product samples, try to spread your brand

159
0:08:33.356,000 --> 0:08:35,000
through their social group.

160
0:08:36.185,000 --> 0:08:37,000
But if you're a repressive government

161
0:08:38.138,000 --> 0:08:42,000
searching for political enemies, you might instead remove them,

162
0:08:42.948,000 --> 0:08:44,000
eliminate them, disrupt their social group,

163
0:08:45.708,000 --> 0:08:48,000
and those who remain behind lose social cohesion

164
0:08:48.877,000 --> 0:08:5,000
and organization.

165
0:08:51.498,000 --> 0:08:54,000
Now in a world of cheap, proliferating robotic weapons,

166
0:08:54.822,000 --> 0:08:56,000
borders would offer very little protection

167
0:08:57.457,000 --> 0:08:58,000
to critics of distant governments

168
0:08:59.403,000 --> 0:09:02,000
or trans-national criminal organizations.

169
0:09:03.049,000 --> 0:09:06,000
Popular movements agitating for change

170
0:09:06.542,000 --> 0:09:09,000
could be detected early and their leaders eliminated

171
0:09:10.151,000 --> 0:09:12,000
before their ideas achieve critical mass.

172
0:09:13.062,000 --> 0:09:15,000
And ideas achieving critical mass

173
0:09:15.653,000 --> 0:09:18,000
is what political activism in popular government is all about.

174
0:09:19.589,000 --> 0:09:22,000
Anonymous lethal weapons could make lethal action

175
0:09:23.586,000 --> 0:09:26,000
an easy choice for all sorts of competing interests.

176
0:09:27.368,000 --> 0:09:3,000
And this would put a chill on free speech

177
0:09:31.102,000 --> 0:09:36,000
and popular political action, the very heart of democracy.

178
0:09:36.41,000 --> 0:09:38,000
And this is why we need an international treaty

179
0:09:39.324,000 --> 0:09:42,000
on robotic weapons, and in particular a global ban

180
0:09:42.864,000 --> 0:09:45,000
on the development and deployment of killer robots.

181
0:09:46.772,000 --> 0:09:49,000
Now we already have international treaties

182
0:09:50.026,000 --> 0:09:53,000
on nuclear and biological weapons, and, while imperfect,

183
0:09:53.412,000 --> 0:09:55,000
these have largely worked.

184
0:09:55.7,000 --> 0:09:58,000
But robotic weapons might be every bit as dangerous,

185
0:09:59.468,000 --> 0:10:02,000
because they will almost certainly be used,

186
0:10:02.756,000 --> 0:10:07,000
and they would also be corrosive to our democratic institutions.

187
0:10:07.783,000 --> 0:10:1,000
Now in November 2012 the U.S. Department of Defense

188
0:10:11.251,000 --> 0:10:13,000
issued a directive requiring

189
0:10:13.709,000 --> 0:10:17,000
a human being be present in all lethal decisions.

190
0:10:18.228,000 --> 0:10:22,000
This temporarily effectively banned autonomous weapons in the U.S. military,

191
0:10:23.004,000 --> 0:10:26,000
but that directive needs to be made permanent.

192
0:10:26.757,000 --> 0:10:3,000
And it could set the stage for global action.

193
0:10:31.133,000 --> 0:10:34,000
Because we need an international legal framework

194
0:10:34.978,000 --> 0:10:36,000
for robotic weapons.

195
0:10:37.116,000 --> 0:10:39,000
And we need it now, before there's a devastating attack

196
0:10:40.044,000 --> 0:10:43,000
or a terrorist incident that causes nations of the world

197
0:10:43.196,000 --> 0:10:44,000
to rush to adopt these weapons

198
0:10:45.12,000 --> 0:10:48,000
before thinking through the consequences.

199
0:10:48.891,000 --> 0:10:5,000
Autonomous robotic weapons concentrate too much power

200
0:10:51.872,000 --> 0:10:57,000
in too few hands, and they would imperil democracy itself.

201
0:10:58.155,000 --> 0:11:,000
Now, don't get me wrong, I think there are tons

202
0:11:00.841,000 --> 0:11:02,000
of great uses for unarmed civilian drones:

203
0:11:03.459,000 --> 0:11:06,000
environmental monitoring, search and rescue, logistics.

204
0:11:07.398,000 --> 0:11:09,000
If we have an international treaty on robotic weapons,

205
0:11:10.224,000 --> 0:11:13,000
how do we gain the benefits of autonomous drones

206
0:11:13.811,000 --> 0:11:15,000
and vehicles while still protecting ourselves

207
0:11:16.459,000 --> 0:11:19,000
against illegal robotic weapons?

208
0:11:20.439,000 --> 0:11:24,000
I think the secret will be transparency.

209
0:11:25.18,000 --> 0:11:28,000
No robot should have an expectation of privacy

210
0:11:28.193,000 --> 0:11:31,000
in a public place.

211
0:11:31.644,000 --> 0:11:36,000
(Applause)

212
0:11:36.692,000 --> 0:11:38,000
Each robot and drone should have

213
0:11:38.737,000 --> 0:11:4,000
a cryptographically signed I.D. burned in at the factory

214
0:11:41.62,000 --> 0:11:43,000
that can be used to track its movement through public spaces.

215
0:11:44.543,000 --> 0:11:47,000
We have license plates on cars, tail numbers on aircraft.

216
0:11:47.924,000 --> 0:11:48,000
This is no different.

217
0:11:49.765,000 --> 0:11:51,000
And every citizen should be able to download an app

218
0:11:51.777,000 --> 0:11:54,000
that shows the population of drones and autonomous vehicles

219
0:11:54.902,000 --> 0:11:56,000
moving through public spaces around them,

220
0:11:57.331,000 --> 0:11:59,000
both right now and historically.

221
0:12:00.064,000 --> 0:12:03,000
And civic leaders should deploy sensors and civic drones

222
0:12:03.612,000 --> 0:12:05,000
to detect rogue drones,

223
0:12:05.956,000 --> 0:12:08,000
and instead of sending killer drones of their own up to shoot them down,

224
0:12:09.132,000 --> 0:12:11,000
they should notify humans to their presence.

225
0:12:12.124,000 --> 0:12:14,000
And in certain very high-security areas,

226
0:12:14.73,000 --> 0:12:15,000
perhaps civic drones would snare them

227
0:12:16.639,000 --> 0:12:18,000
and drag them off to a bomb disposal facility.

228
0:12:19.48,000 --> 0:12:22,000
But notice, this is more an immune system

229
0:12:22.507,000 --> 0:12:23,000
than a weapons system.

230
0:12:23.828,000 --> 0:12:25,000
It would allow us to avail ourselves of the use

231
0:12:26.42,000 --> 0:12:28,000
of autonomous vehicles and drones

232
0:12:28.452,000 --> 0:12:32,000
while still preserving our open, civil society.

233
0:12:32.747,000 --> 0:12:34,000
We must ban the deployment and development

234
0:12:35.746,000 --> 0:12:36,000
of killer robots.

235
0:12:37.608,000 --> 0:12:41,000
Let's not succumb to the temptation to automate war.

236
0:12:42.458,000 --> 0:12:44,000
Autocratic governments and criminal organizations

237
0:12:45.176,000 --> 0:12:47,000
undoubtedly will, but let's not join them.

238
0:12:48.132,000 --> 0:12:49,000
Autonomous robotic weapons

239
0:12:50.023,000 --> 0:12:52,000
would concentrate too much power

240
0:12:52.074,000 --> 0:12:54,000
in too few unseen hands,

241
0:12:54.556,000 --> 0:12:57,000
and that would be corrosive to representative government.

242
0:12:57.811,000 --> 0:12:59,000
Let's make sure, for democracies at least,

243
0:13:00.772,000 --> 0:13:02,000
killer robots remain fiction.

244
0:13:03.376,000 --> 0:13:04,000
Thank you.

245
0:13:04.486,000 --> 0:13:08,000
(Applause)

246
0:13:09.051,000 --> 0:13:13,000
Thank you. (Applause)

