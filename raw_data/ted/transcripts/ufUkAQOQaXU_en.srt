1
0:00:,000 --> 0:00:07,000
Translator: Joseph Geni Reviewer: Morton Bast

2
0:00:15.734,000 --> 0:00:17,000
Other people. Everyone is interested in other people.

3
0:00:18.543,000 --> 0:00:2,000
Everyone has relationships with other people,

4
0:00:20.666,000 --> 0:00:21,000
and they're interested in these relationships

5
0:00:22.258,000 --> 0:00:23,000
for a variety of reasons.

6
0:00:24.113,000 --> 0:00:26,000
Good relationships, bad relationships,

7
0:00:26.125,000 --> 0:00:29,000
annoying relationships, agnostic relationships,

8
0:00:29.271,000 --> 0:00:32,000
and what I'm going to do is focus on the central piece

9
0:00:32.695,000 --> 0:00:35,000
of an interaction that goes on in a relationship.

10
0:00:35.998,000 --> 0:00:37,000
So I'm going to take as inspiration the fact that we're all

11
0:00:38.334,000 --> 0:00:4,000
interested in interacting with other people,

12
0:00:40.759,000 --> 0:00:43,000
I'm going to completely strip it of all its complicating features,

13
0:00:44.591,000 --> 0:00:47,000
and I'm going to turn that object, that simplified object,

14
0:00:48.485,000 --> 0:00:52,000
into a scientific probe, and provide the early stages,

15
0:00:52.635,000 --> 0:00:54,000
embryonic stages of new insights into what happens

16
0:00:55.084,000 --> 0:00:58,000
in two brains while they simultaneously interact.

17
0:00:58.734,000 --> 0:01:,000
But before I do that, let me tell you a couple of things

18
0:01:01.027,000 --> 0:01:02,000
that made this possible.

19
0:01:02.726,000 --> 0:01:04,000
The first is we can now eavesdrop safely

20
0:01:05.507,000 --> 0:01:07,000
on healthy brain activity.

21
0:01:08.218,000 --> 0:01:1,000
Without needles and radioactivity,

22
0:01:10.795,000 --> 0:01:12,000
without any kind of clinical reason, we can go down the street

23
0:01:13.658,000 --> 0:01:16,000
and record from your friends' and neighbors' brains

24
0:01:16.785,000 --> 0:01:18,000
while they do a variety of cognitive tasks, and we use

25
0:01:19.323,000 --> 0:01:22,000
a method called functional magnetic resonance imaging.

26
0:01:23.057,000 --> 0:01:25,000
You've probably all read about it or heard about in some

27
0:01:25.382,000 --> 0:01:29,000
incarnation. Let me give you a two-sentence version of it.

28
0:01:29.76,000 --> 0:01:32,000
So we've all heard of MRIs. MRIs use magnetic fields

29
0:01:33.244,000 --> 0:01:35,000
and radio waves and they take snapshots of your brain

30
0:01:35.273,000 --> 0:01:37,000
or your knee or your stomach,

31
0:01:37.634,000 --> 0:01:39,000
grayscale images that are frozen in time.

32
0:01:39.679,000 --> 0:01:41,000
In the 1990s, it was discovered you could use

33
0:01:42,000 --> 0:01:44,000
the same machines in a different mode,

34
0:01:44.659,000 --> 0:01:46,000
and in that mode, you could make microscopic blood flow

35
0:01:47.005,000 --> 0:01:5,000
movies from hundreds of thousands of sites independently in the brain.

36
0:01:50.305,000 --> 0:01:53,000
Okay, so what? In fact, the so what is, in the brain,

37
0:01:53.505,000 --> 0:01:56,000
changes in neural activity, the things that make your brain work,

38
0:01:57.337,000 --> 0:01:59,000
the things that make your software work in your brain,

39
0:01:59.347,000 --> 0:02:01,000
are tightly correlated with changes in blood flow.

40
0:02:01.836,000 --> 0:02:02,000
You make a blood flow movie, you have an independent

41
0:02:03.809,000 --> 0:02:05,000
proxy of brain activity.

42
0:02:06.148,000 --> 0:02:09,000
This has literally revolutionized cognitive science.

43
0:02:09.182,000 --> 0:02:1,000
Take any cognitive domain you want, memory,

44
0:02:11.173,000 --> 0:02:13,000
motor planning, thinking about your mother-in-law,

45
0:02:13.314,000 --> 0:02:16,000
getting angry at people, emotional response, it goes on and on,

46
0:02:17.029,000 --> 0:02:2,000
put people into functional MRI devices, and

47
0:02:20.118,000 --> 0:02:23,000
image how these kinds of variables map onto brain activity.

48
0:02:23.501,000 --> 0:02:25,000
It's in its early stages, and it's crude by some measures,

49
0:02:26.35,000 --> 0:02:28,000
but in fact, 20 years ago, we were at nothing.

50
0:02:28.918,000 --> 0:02:3,000
You couldn't do people like this. You couldn't do healthy people.

51
0:02:31.277,000 --> 0:02:33,000
That's caused a literal revolution, and it's opened us up

52
0:02:33.765,000 --> 0:02:35,000
to a new experimental preparation. Neurobiologists,

53
0:02:36.583,000 --> 0:02:39,000
as you well know, have lots of experimental preps,

54
0:02:40.343,000 --> 0:02:43,000
worms and rodents and fruit flies and things like this.

55
0:02:43.484,000 --> 0:02:46,000
And now, we have a new experimental prep: human beings.

56
0:02:46.881,000 --> 0:02:49,000
We can now use human beings to study and model

57
0:02:50.642,000 --> 0:02:52,000
the software in human beings, and we have a few

58
0:02:53.592,000 --> 0:02:55,000
burgeoning biological measures.

59
0:02:56.427,000 --> 0:02:59,000
Okay, let me give you one example of the kinds of experiments that people do,

60
0:03:00.314,000 --> 0:03:02,000
and it's in the area of what you'd call valuation.

61
0:03:02.991,000 --> 0:03:04,000
Valuation is just what you think it is, you know?

62
0:03:05.126,000 --> 0:03:07,000
If you went and you were valuing two companies against

63
0:03:07.93,000 --> 0:03:09,000
one another, you'd want to know which was more valuable.

64
0:03:10.666,000 --> 0:03:13,000
Cultures discovered the key feature of valuation thousands of years ago.

65
0:03:14.545,000 --> 0:03:16,000
If you want to compare oranges to windshields, what do you do?

66
0:03:17.235,000 --> 0:03:19,000
Well, you can't compare oranges to windshields.

67
0:03:19.591,000 --> 0:03:21,000
They're immiscible. They don't mix with one another.

68
0:03:21.846,000 --> 0:03:23,000
So instead, you convert them to a common currency scale,

69
0:03:24.197,000 --> 0:03:26,000
put them on that scale, and value them accordingly.

70
0:03:26.903,000 --> 0:03:29,000
Well, your brain has to do something just like that as well,

71
0:03:30.339,000 --> 0:03:32,000
and we're now beginning to understand and identify

72
0:03:32.827,000 --> 0:03:34,000
brain systems involved in valuation,

73
0:03:34.964,000 --> 0:03:36,000
and one of them includes a neurotransmitter system

74
0:03:37.596,000 --> 0:03:39,000
whose cells are located in your brainstem

75
0:03:40.228,000 --> 0:03:43,000
and deliver the chemical dopamine to the rest of your brain.

76
0:03:43.403,000 --> 0:03:45,000
I won't go through the details of it, but that's an important

77
0:03:45.845,000 --> 0:03:47,000
discovery, and we know a good bit about that now,

78
0:03:48.002,000 --> 0:03:5,000
and it's just a small piece of it, but it's important because

79
0:03:50.232,000 --> 0:03:53,000
those are the neurons that you would lose if you had Parkinson's disease,

80
0:03:53.507,000 --> 0:03:55,000
and they're also the neurons that are hijacked by literally

81
0:03:55.523,000 --> 0:03:57,000
every drug of abuse, and that makes sense.

82
0:03:57.755,000 --> 0:03:59,000
Drugs of abuse would come in, and they would change

83
0:04:00.091,000 --> 0:04:01,000
the way you value the world. They change the way

84
0:04:01.88,000 --> 0:04:04,000
you value the symbols associated with your drug of choice,

85
0:04:05.079,000 --> 0:04:07,000
and they make you value that over everything else.

86
0:04:07.593,000 --> 0:04:1,000
Here's the key feature though. These neurons are also

87
0:04:10.614,000 --> 0:04:13,000
involved in the way you can assign value to literally abstract ideas,

88
0:04:14.115,000 --> 0:04:16,000
and I put some symbols up here that we assign value to

89
0:04:16.156,000 --> 0:04:18,000
for various reasons.

90
0:04:18.876,000 --> 0:04:2,000
We have a behavioral superpower in our brain,

91
0:04:21.565,000 --> 0:04:22,000
and it at least in part involves dopamine.

92
0:04:23.318,000 --> 0:04:27,000
We can deny every instinct we have for survival for an idea,

93
0:04:27.507,000 --> 0:04:31,000
for a mere idea. No other species can do that.

94
0:04:31.512,000 --> 0:04:34,000
In 1997, the cult Heaven's Gate committed mass suicide

95
0:04:35.118,000 --> 0:04:37,000
predicated on the idea that there was a spaceship

96
0:04:37.333,000 --> 0:04:4,000
hiding in the tail of the then-visible comet Hale-Bopp

97
0:04:41.118,000 --> 0:04:45,000
waiting to take them to the next level. It was an incredibly tragic event.

98
0:04:45.39,000 --> 0:04:48,000
More than two thirds of them had college degrees.

99
0:04:48.875,000 --> 0:04:51,000
But the point here is they were able to deny their instincts for survival

100
0:04:52.598,000 --> 0:04:54,000
using exactly the same systems that were put there

101
0:04:55.464,000 --> 0:04:59,000
to make them survive. That's a lot of control, okay?

102
0:04:59.506,000 --> 0:05:01,000
One thing that I've left out of this narrative

103
0:05:01.595,000 --> 0:05:03,000
is the obvious thing, which is the focus of the rest of my

104
0:05:03.829,000 --> 0:05:05,000
little talk, and that is other people.

105
0:05:05.988,000 --> 0:05:07,000
These same valuation systems are redeployed

106
0:05:08.984,000 --> 0:05:1,000
when we're valuing interactions with other people.

107
0:05:11.476,000 --> 0:05:14,000
So this same dopamine system that gets addicted to drugs,

108
0:05:14.747,000 --> 0:05:16,000
that makes you freeze when you get Parkinson's disease,

109
0:05:17.271,000 --> 0:05:2,000
that contributes to various forms of psychosis,

110
0:05:20.348,000 --> 0:05:23,000
is also redeployed to value interactions with other people

111
0:05:24.268,000 --> 0:05:26,000
and to assign value to gestures that you do

112
0:05:27.164,000 --> 0:05:29,000
when you're interacting with somebody else.

113
0:05:29.738,000 --> 0:05:31,000
Let me give you an example of this.

114
0:05:32.315,000 --> 0:05:34,000
You bring to the table such enormous processing power

115
0:05:35.282,000 --> 0:05:37,000
in this domain that you hardly even notice it.

116
0:05:37.906,000 --> 0:05:38,000
Let me just give you a few examples. So here's a baby.

117
0:05:39.373,000 --> 0:05:42,000
She's three months old. She still poops in her diapers and she can't do calculus.

118
0:05:43.103,000 --> 0:05:46,000
She's related to me. Somebody will be very glad that she's up here on the screen.

119
0:05:46.456,000 --> 0:05:48,000
You can cover up one of her eyes, and you can still read

120
0:05:48.832,000 --> 0:05:5,000
something in the other eye, and I see sort of curiosity

121
0:05:51.587,000 --> 0:05:54,000
in one eye, I see maybe a little bit of surprise in the other.

122
0:05:55.184,000 --> 0:05:58,000
Here's a couple. They're sharing a moment together,

123
0:05:58.363,000 --> 0:05:59,000
and we've even done an experiment where you can cut out

124
0:05:59.681,000 --> 0:06:02,000
different pieces of this frame and you can still see

125
0:06:02.688,000 --> 0:06:04,000
that they're sharing it. They're sharing it sort of in parallel.

126
0:06:05.192,000 --> 0:06:07,000
Now, the elements of the scene also communicate this

127
0:06:07.655,000 --> 0:06:09,000
to us, but you can read it straight off their faces,

128
0:06:09.89,000 --> 0:06:12,000
and if you compare their faces to normal faces, it would be a very subtle cue.

129
0:06:13.393,000 --> 0:06:16,000
Here's another couple. He's projecting out at us,

130
0:06:16.74,000 --> 0:06:18,000
and she's clearly projecting, you know,

131
0:06:19.628,000 --> 0:06:21,000
love and admiration at him.

132
0:06:21.891,000 --> 0:06:24,000
Here's another couple. (Laughter)

133
0:06:25.526,000 --> 0:06:3,000
And I'm thinking I'm not seeing love and admiration on the left. (Laughter)

134
0:06:30.676,000 --> 0:06:32,000
In fact, I know this is his sister, and you can just see

135
0:06:33.236,000 --> 0:06:35,000
him saying, "Okay, we're doing this for the camera,

136
0:06:35.749,000 --> 0:06:4,000
and then afterwards you steal my candy and you punch me in the face." (Laughter)

137
0:06:41.451,000 --> 0:06:43,000
He'll kill me for showing that.

138
0:06:43.557,000 --> 0:06:45,000
All right, so what does this mean?

139
0:06:46.354,000 --> 0:06:49,000
It means we bring an enormous amount of processing power to the problem.

140
0:06:49.704,000 --> 0:06:52,000
It engages deep systems in our brain, in dopaminergic

141
0:06:53.352,000 --> 0:06:55,000
systems that are there to make you chase sex, food and salt.

142
0:06:56.17,000 --> 0:06:58,000
They keep you alive. It gives them the pie, it gives

143
0:06:59.064,000 --> 0:07:01,000
that kind of a behavioral punch which we've called a superpower.

144
0:07:01.968,000 --> 0:07:04,000
So how can we take that and arrange a kind of staged

145
0:07:05.622,000 --> 0:07:07,000
social interaction and turn that into a scientific probe?

146
0:07:08.32,000 --> 0:07:1,000
And the short answer is games.

147
0:07:11.011,000 --> 0:07:15,000
Economic games. So what we do is we go into two areas.

148
0:07:15.415,000 --> 0:07:18,000
One area is called experimental economics. The other area is called behavioral economics.

149
0:07:18.751,000 --> 0:07:22,000
And we steal their games. And we contrive them to our own purposes.

150
0:07:22.829,000 --> 0:07:24,000
So this shows you one particular game called an ultimatum game.

151
0:07:25.796,000 --> 0:07:26,000
Red person is given a hundred dollars and can offer

152
0:07:27.641,000 --> 0:07:3,000
a split to blue. Let's say red wants to keep 70,

153
0:07:31.364,000 --> 0:07:35,000
and offers blue 30. So he offers a 70-30 split with blue.

154
0:07:35.45,000 --> 0:07:37,000
Control passes to blue, and blue says, "I accept it,"

155
0:07:38.301,000 --> 0:07:39,000
in which case he'd get the money, or blue says,

156
0:07:40.257,000 --> 0:07:44,000
"I reject it," in which case no one gets anything. Okay?

157
0:07:44.564,000 --> 0:07:47,000
So a rational choice economist would say, well,

158
0:07:47.956,000 --> 0:07:49,000
you should take all non-zero offers.

159
0:07:50.012,000 --> 0:07:53,000
What do people do? People are indifferent at an 80-20 split.

160
0:07:53.774,000 --> 0:07:56,000
At 80-20, it's a coin flip whether you accept that or not.

161
0:07:57.298,000 --> 0:07:59,000
Why is that? You know, because you're pissed off.

162
0:08:00.189,000 --> 0:08:03,000
You're mad. That's an unfair offer, and you know what an unfair offer is.

163
0:08:03.798,000 --> 0:08:05,000
This is the kind of game done by my lab and many around the world.

164
0:08:06.502,000 --> 0:08:08,000
That just gives you an example of the kind of thing that

165
0:08:09.046,000 --> 0:08:12,000
these games probe. The interesting thing is, these games

166
0:08:12.784,000 --> 0:08:15,000
require that you have a lot of cognitive apparatus on line.

167
0:08:16.491,000 --> 0:08:18,000
You have to be able to come to the table with a proper model of another person.

168
0:08:19.419,000 --> 0:08:22,000
You have to be able to remember what you've done.

169
0:08:22.632,000 --> 0:08:23,000
You have to stand up in the moment to do that.

170
0:08:24.052,000 --> 0:08:27,000
Then you have to update your model based on the signals coming back,

171
0:08:27.402,000 --> 0:08:29,000
and you have to do something that is interesting,

172
0:08:30.374,000 --> 0:08:32,000
which is you have to do a kind of depth of thought assay.

173
0:08:32.971,000 --> 0:08:35,000
That is, you have to decide what that other person expects of you.

174
0:08:36.304,000 --> 0:08:38,000
You have to send signals to manage your image in their mind.

175
0:08:39.258,000 --> 0:08:41,000
Like a job interview. You sit across the desk from somebody,

176
0:08:42.111,000 --> 0:08:43,000
they have some prior image of you,

177
0:08:43.48,000 --> 0:08:45,000
you send signals across the desk to move their image

178
0:08:46.231,000 --> 0:08:49,000
of you from one place to a place where you want it to be.

179
0:08:50.151,000 --> 0:08:53,000
We're so good at this we don't really even notice it.

180
0:08:53.536,000 --> 0:08:56,000
These kinds of probes exploit it. Okay?

181
0:08:57.303,000 --> 0:08:58,000
In doing this, what we've discovered is that humans

182
0:08:59.11,000 --> 0:09:01,000
are literal canaries in social exchanges.

183
0:09:01.441,000 --> 0:09:04,000
Canaries used to be used as kind of biosensors in mines.

184
0:09:04.838,000 --> 0:09:07,000
When methane built up, or carbon dioxide built up,

185
0:09:08.398,000 --> 0:09:12,000
or oxygen was diminished, the birds would swoon

186
0:09:12.584,000 --> 0:09:14,000
before people would -- so it acted as an early warning system:

187
0:09:14.91,000 --> 0:09:16,000
Hey, get out of the mine. Things aren't going so well.

188
0:09:17.89,000 --> 0:09:19,000
People come to the table, and even these very blunt,

189
0:09:20.844,000 --> 0:09:22,000
staged social interactions, and they, and there's just

190
0:09:23.834,000 --> 0:09:26,000
numbers going back and forth between the people,

191
0:09:26.85,000 --> 0:09:28,000
and they bring enormous sensitivities to it.

192
0:09:29.049,000 --> 0:09:31,000
So we realized we could exploit this, and in fact,

193
0:09:31.738,000 --> 0:09:33,000
as we've done that, and we've done this now in

194
0:09:34.294,000 --> 0:09:36,000
many thousands of people, I think on the order of

195
0:09:36.988,000 --> 0:09:38,000
five or six thousand. We actually, to make this

196
0:09:39.153,000 --> 0:09:41,000
a biological probe, need bigger numbers than that,

197
0:09:41.377,000 --> 0:09:44,000
remarkably so. But anyway,

198
0:09:45.051,000 --> 0:09:47,000
patterns have emerged, and we've been able to take

199
0:09:47.055,000 --> 0:09:5,000
those patterns, convert them into mathematical models,

200
0:09:50.891,000 --> 0:09:52,000
and use those mathematical models to gain new insights

201
0:09:53.58,000 --> 0:09:55,000
into these exchanges. Okay, so what?

202
0:09:55.711,000 --> 0:09:58,000
Well, the so what is, that's a really nice behavioral measure,

203
0:09:59.024,000 --> 0:10:02,000
the economic games bring to us notions of optimal play.

204
0:10:02.343,000 --> 0:10:04,000
We can compute that during the game.

205
0:10:04.827,000 --> 0:10:06,000
And we can use that to sort of carve up the behavior.

206
0:10:07.78,000 --> 0:10:11,000
Here's the cool thing. Six or seven years ago,

207
0:10:12.11,000 --> 0:10:14,000
we developed a team. It was at the time in Houston, Texas.

208
0:10:14.66,000 --> 0:10:17,000
It's now in Virginia and London. And we built software

209
0:10:18.054,000 --> 0:10:21,000
that'll link functional magnetic resonance imaging devices

210
0:10:21.261,000 --> 0:10:25,000
up over the Internet. I guess we've done up to six machines

211
0:10:25.296,000 --> 0:10:26,000
at a time, but let's just focus on two.

212
0:10:27.277,000 --> 0:10:3,000
So it synchronizes machines anywhere in the world.

213
0:10:30.335,000 --> 0:10:33,000
We synchronize the machines, set them into these

214
0:10:33.504,000 --> 0:10:34,000
staged social interactions, and we eavesdrop on both

215
0:10:35.487,000 --> 0:10:36,000
of the interacting brains. So for the first time,

216
0:10:37.153,000 --> 0:10:4,000
we don't have to look at just averages over single individuals,

217
0:10:40.76,000 --> 0:10:42,000
or have individuals playing computers, or try to make

218
0:10:43.657,000 --> 0:10:45,000
inferences that way. We can study individual dyads.

219
0:10:46.42,000 --> 0:10:48,000
We can study the way that one person interacts with another person,

220
0:10:49.205,000 --> 0:10:51,000
turn the numbers up, and start to gain new insights

221
0:10:51.769,000 --> 0:10:53,000
into the boundaries of normal cognition,

222
0:10:54.284,000 --> 0:10:56,000
but more importantly, we can put people with

223
0:10:57.016,000 --> 0:11:,000
classically defined mental illnesses, or brain damage,

224
0:11:00.353,000 --> 0:11:03,000
into these social interactions, and use these as probes of that.

225
0:11:03.904,000 --> 0:11:05,000
So we've started this effort. We've made a few hits,

226
0:11:06.254,000 --> 0:11:08,000
a few, I think, embryonic discoveries.

227
0:11:08.703,000 --> 0:11:1,000
We think there's a future to this. But it's our way

228
0:11:11.515,000 --> 0:11:13,000
of going in and redefining, with a new lexicon,

229
0:11:14.075,000 --> 0:11:18,000
a mathematical one actually, as opposed to the standard

230
0:11:18.097,000 --> 0:11:2,000
ways that we think about mental illness,

231
0:11:20.675,000 --> 0:11:22,000
characterizing these diseases, by using the people

232
0:11:22.742,000 --> 0:11:25,000
as birds in the exchanges. That is, we exploit the fact

233
0:11:25.749,000 --> 0:11:29,000
that the healthy partner, playing somebody with major depression,

234
0:11:29.993,000 --> 0:11:31,000
or playing somebody with autism spectrum disorder,

235
0:11:32.903,000 --> 0:11:35,000
or playing somebody with attention deficit hyperactivity disorder,

236
0:11:36.753,000 --> 0:11:39,000
we use that as a kind of biosensor, and then we use

237
0:11:39.972,000 --> 0:11:41,000
computer programs to model that person, and it gives us

238
0:11:42.616,000 --> 0:11:44,000
a kind of assay of this.

239
0:11:45.086,000 --> 0:11:47,000
Early days, and we're just beginning, we're setting up sites

240
0:11:47.217,000 --> 0:11:5,000
around the world. Here are a few of our collaborating sites.

241
0:11:50.627,000 --> 0:11:52,000
The hub, ironically enough,

242
0:11:52.936,000 --> 0:11:54,000
is centered in little Roanoke, Virginia.

243
0:11:55.825,000 --> 0:11:57,000
There's another hub in London, now, and the rest

244
0:11:58.094,000 --> 0:12:02,000
are getting set up. We hope to give the data away

245
0:12:02.103,000 --> 0:12:05,000
at some stage. That's a complicated issue

246
0:12:05.776,000 --> 0:12:07,000
about making it available to the rest of the world.

247
0:12:08.77,000 --> 0:12:09,000
But we're also studying just a small part

248
0:12:10.617,000 --> 0:12:12,000
of what makes us interesting as human beings, and so

249
0:12:12.884,000 --> 0:12:14,000
I would invite other people who are interested in this

250
0:12:14.925,000 --> 0:12:16,000
to ask us for the software, or even for guidance

251
0:12:17.494,000 --> 0:12:19,000
on how to move forward with that.

252
0:12:19.713,000 --> 0:12:21,000
Let me leave you with one thought in closing.

253
0:12:22.054,000 --> 0:12:23,000
The interesting thing about studying cognition

254
0:12:23.996,000 --> 0:12:26,000
has been that we've been limited, in a way.

255
0:12:27.728,000 --> 0:12:29,000
We just haven't had the tools to look at interacting brains

256
0:12:30.671,000 --> 0:12:31,000
simultaneously.

257
0:12:31.871,000 --> 0:12:33,000
The fact is, though, that even when we're alone,

258
0:12:34.341,000 --> 0:12:38,000
we're a profoundly social creature. We're not a solitary mind

259
0:12:38.452,000 --> 0:12:42,000
built out of properties that kept it alive in the world

260
0:12:42.825,000 --> 0:12:45,000
independent of other people. In fact, our minds

261
0:12:46.773,000 --> 0:12:48,000
depend on other people. They depend on other people,

262
0:12:49.643,000 --> 0:12:5,000
and they're expressed in other people,

263
0:12:51.184,000 --> 0:12:54,000
so the notion of who you are, you often don't know

264
0:12:54.836,000 --> 0:12:56,000
who you are until you see yourself in interaction with people

265
0:12:57.524,000 --> 0:12:59,000
that are close to you, people that are enemies of you,

266
0:12:59.93,000 --> 0:13:01,000
people that are agnostic to you.

267
0:13:02.475,000 --> 0:13:05,000
So this is the first sort of step into using that insight

268
0:13:06.251,000 --> 0:13:09,000
into what makes us human beings, turning it into a tool,

269
0:13:09.546,000 --> 0:13:1,000
and trying to gain new insights into mental illness.

270
0:13:11.524,000 --> 0:13:14,000
Thanks for having me. (Applause)

271
0:13:14.645,000 --> 0:13:17,000
(Applause)

