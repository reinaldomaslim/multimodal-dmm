1
0:00:,000 --> 0:00:07,000
Translator: Ivana Korom Reviewer: Joanna Pietrulewicz

2
0:00:13.76,000 --> 0:00:17,000
I consider myself one part artist and one part designer.

3
0:00:18.48,000 --> 0:00:21,000
And I work at an artificial intelligence research lab.

4
0:00:22.72,000 --> 0:00:23,000
We're trying to create technology

5
0:00:24.44,000 --> 0:00:27,000
that you'll want to interact with in the far future.

6
0:00:27.76,000 --> 0:00:31,000
Not just six months from now, but try years and decades from now.

7
0:00:33.12,000 --> 0:00:34,000
And we're taking a moonshot

8
0:00:34.76,000 --> 0:00:36,000
that we'll want to be interacting with computers

9
0:00:37.24,000 --> 0:00:39,000
in deeply emotional ways.

10
0:00:40.28,000 --> 0:00:41,000
So in order to do that,

11
0:00:41.76,000 --> 0:00:45,000
the technology has to be just as much human as it is artificial.

12
0:00:46.92,000 --> 0:00:48,000
It has to get you.

13
0:00:49.2,000 --> 0:00:52,000
You know, like that inside joke that'll have you and your best friend

14
0:00:52.56,000 --> 0:00:53,000
on the floor, cracking up.

15
0:00:54.52,000 --> 0:00:58,000
Or that look of disappointment that you can just smell from miles away.

16
0:01:00.56,000 --> 0:01:06,000
I view art as the gateway to help us bridge this gap between human and machine:

17
0:01:07.28,000 --> 0:01:1,000
to figure out what it means to get each other

18
0:01:10.44,000 --> 0:01:12,000
so that we can train AI to get us.

19
0:01:13.92,000 --> 0:01:16,000
See, to me, art is a way to put tangible experiences

20
0:01:17.76,000 --> 0:01:2,000
to intangible ideas, feelings and emotions.

21
0:01:21.8,000 --> 0:01:23,000
And I think it's one of the most human things about us.

22
0:01:25.48,000 --> 0:01:27,000
See, we're a complicated and complex bunch.

23
0:01:28.44,000 --> 0:01:31,000
We have what feels like an infinite range of emotions,

24
0:01:31.6,000 --> 0:01:33,000
and to top it off, we're all different.

25
0:01:34.12,000 --> 0:01:36,000
We have different family backgrounds,

26
0:01:36.44,000 --> 0:01:39,000
different experiences and different psychologies.

27
0:01:40.24,000 --> 0:01:42,000
And this is what makes life really interesting.

28
0:01:43.44,000 --> 0:01:46,000
But this is also what makes working on intelligent technology

29
0:01:46.96,000 --> 0:01:47,000
extremely difficult.

30
0:01:49.64,000 --> 0:01:52,000
And right now, AI research, well,

31
0:01:53.12,000 --> 0:01:55,000
it's a bit lopsided on the tech side.

32
0:01:55.16,000 --> 0:01:57,000
And that makes a lot of sense.

33
0:01:57.32,000 --> 0:01:59,000
See, for every qualitative thing about us --

34
0:01:59.8,000 --> 0:02:03,000
you know, those parts of us that are emotional, dynamic and subjective --

35
0:02:04.28,000 --> 0:02:07,000
we have to convert it to a quantitative metric:

36
0:02:07.44,000 --> 0:02:11,000
something that can be represented with facts, figures and computer code.

37
0:02:13,000 --> 0:02:16,000
The issue is, there are many qualitative things

38
0:02:16.4,000 --> 0:02:17,000
that we just can't put our finger on.

39
0:02:20.4,000 --> 0:02:23,000
So, think about hearing your favorite song for the first time.

40
0:02:25.2,000 --> 0:02:26,000
What were you doing?

41
0:02:28,000 --> 0:02:29,000
How did you feel?

42
0:02:30.72,000 --> 0:02:31,000
Did you get goosebumps?

43
0:02:33.24,000 --> 0:02:34,000
Or did you get fired up?

44
0:02:36.4,000 --> 0:02:37,000
Hard to describe, right?

45
0:02:38.8,000 --> 0:02:4,000
See, parts of us feel so simple,

46
0:02:40.92,000 --> 0:02:43,000
but under the surface, there's really a ton of complexity.

47
0:02:44.6,000 --> 0:02:46,000
And translating that complexity to machines

48
0:02:47.56,000 --> 0:02:49,000
is what makes them modern-day moonshots.

49
0:02:50.44,000 --> 0:02:54,000
And I'm not convinced that we can answer these deeper questions

50
0:02:54.64,000 --> 0:02:55,000
with just ones and zeros alone.

51
0:02:57.12,000 --> 0:02:58,000
So, in the lab, I've been creating art

52
0:02:59.08,000 --> 0:03:01,000
as a way to help me design better experiences

53
0:03:01.56,000 --> 0:03:03,000
for bleeding-edge technology.

54
0:03:03.68,000 --> 0:03:04,000
And it's been serving as a catalyst

55
0:03:05.44,000 --> 0:03:08,000
to beef up the more human ways that computers can relate to us.

56
0:03:1,000 --> 0:03:12,000
Through art, we're tacking some of the hardest questions,

57
0:03:12.72,000 --> 0:03:14,000
like what does it really mean to feel?

58
0:03:16.12,000 --> 0:03:2,000
Or how do we engage and know how to be present with each other?

59
0:03:20.8,000 --> 0:03:24,000
And how does intuition affect the way that we interact?

60
0:03:26.44,000 --> 0:03:28,000
So, take for example human emotion.

61
0:03:28.52,000 --> 0:03:31,000
Right now, computers can make sense of our most basic ones,

62
0:03:31.8,000 --> 0:03:34,000
like joy, sadness, anger, fear and disgust,

63
0:03:35.52,000 --> 0:03:38,000
by converting those characteristics to math.

64
0:03:39.4,000 --> 0:03:41,000
But what about the more complex emotions?

65
0:03:41.96,000 --> 0:03:42,000
You know, those emotions

66
0:03:43.2,000 --> 0:03:45,000
that we have a hard time describing to each other?

67
0:03:45.6,000 --> 0:03:46,000
Like nostalgia.

68
0:03:47.64,000 --> 0:03:5,000
So, to explore this, I created a piece of art, an experience,

69
0:03:51.6,000 --> 0:03:53,000
that asked people to share a memory,

70
0:03:53.72,000 --> 0:03:55,000
and I teamed up with some data scientists

71
0:03:55.88,000 --> 0:03:58,000
to figure out how to take an emotion that's so highly subjective

72
0:03:59.48,000 --> 0:04:02,000
and convert it into something mathematically precise.

73
0:04:03.84,000 --> 0:04:05,000
So, we created what we call a nostalgia score

74
0:04:06,000 --> 0:04:08,000
and it's the heart of this installation.

75
0:04:08.24,000 --> 0:04:11,000
To do that, the installation asks you to share a story,

76
0:04:11.32,000 --> 0:04:14,000
the computer then analyzes it for its simpler emotions,

77
0:04:14.6,000 --> 0:04:16,000
it checks for your tendency to use past-tense wording

78
0:04:17.28,000 --> 0:04:2,000
and also looks for words that we tend to associate with nostalgia,

79
0:04:20.64,000 --> 0:04:23,000
like "home," "childhood" and "the past."

80
0:04:24.76,000 --> 0:04:26,000
It then creates a nostalgia score

81
0:04:26.84,000 --> 0:04:28,000
to indicate how nostalgic your story is.

82
0:04:29.6,000 --> 0:04:33,000
And that score is the driving force behind these light-based sculptures

83
0:04:33.76,000 --> 0:04:36,000
that serve as physical embodiments of your contribution.

84
0:04:37.68,000 --> 0:04:4,000
And the higher the score, the rosier the hue.

85
0:04:40.92,000 --> 0:04:43,000
You know, like looking at the world through rose-colored glasses.

86
0:04:44.88,000 --> 0:04:46,000
So, when you see your score

87
0:04:47.52,000 --> 0:04:49,000
and the physical representation of it,

88
0:04:50.2,000 --> 0:04:52,000
sometimes you'd agree and sometimes you wouldn't.

89
0:04:53.16,000 --> 0:04:56,000
It's as if it really understood how that experience made you feel.

90
0:04:57.4,000 --> 0:04:59,000
But other times it gets tripped up

91
0:04:59.64,000 --> 0:05:01,000
and has you thinking it doesn't understand you at all.

92
0:05:02.68,000 --> 0:05:03,000
But the piece really serves to show

93
0:05:04.6,000 --> 0:05:08,000
that if we have a hard time explaining the emotions that we have to each other,

94
0:05:08.68,000 --> 0:05:1,000
how can we teach a computer to make sense of them?

95
0:05:12.36,000 --> 0:05:15,000
So, even the more objective parts about being human are hard to describe.

96
0:05:15.96,000 --> 0:05:16,000
Like, conversation.

97
0:05:17.88,000 --> 0:05:19,000
Have you ever really tried to break down the steps?

98
0:05:20.64,000 --> 0:05:22,000
So think about sitting with your friend at a coffee shop

99
0:05:23.32,000 --> 0:05:24,000
and just having small talk.

100
0:05:25.16,000 --> 0:05:26,000
How do you know when to take a turn?

101
0:05:27.44,000 --> 0:05:28,000
How do you know when to shift topics?

102
0:05:29.96,000 --> 0:05:31,000
And how do you even know what topics to discuss?

103
0:05:33.56,000 --> 0:05:35,000
See, most of us don't really think about it,

104
0:05:35.68,000 --> 0:05:36,000
because it's almost second nature.

105
0:05:37.36,000 --> 0:05:4,000
And when we get to know someone, we learn more about what makes them tick,

106
0:05:40.88,000 --> 0:05:42,000
and then we learn what topics we can discuss.

107
0:05:43.28,000 --> 0:05:46,000
But when it comes to teaching AI systems how to interact with people,

108
0:05:46.96,000 --> 0:05:48,000
we have to teach them step by step what to do.

109
0:05:49.84,000 --> 0:05:52,000
And right now, it feels clunky.

110
0:05:53.36,000 --> 0:05:57,000
If you've ever tried to talk with Alexa, Siri or Google Assistant,

111
0:05:57.52,000 --> 0:06:01,000
you can tell that it or they can still sound cold.

112
0:06:02.44,000 --> 0:06:03,000
And have you ever gotten annoyed

113
0:06:04.12,000 --> 0:06:06,000
when they didn't understand what you were saying

114
0:06:06.4,000 --> 0:06:09,000
and you had to rephrase what you wanted 20 times just to play a song?

115
0:06:11.44,000 --> 0:06:15,000
Alright, to the credit of the designers, realistic communication is really hard.

116
0:06:16.36,000 --> 0:06:18,000
And there's a whole branch of sociology,

117
0:06:18.52,000 --> 0:06:19,000
called conversation analysis,

118
0:06:20.48,000 --> 0:06:23,000
that tries to make blueprints for different types of conversation.

119
0:06:23.64,000 --> 0:06:27,000
Types like customer service or counseling, teaching and others.

120
0:06:28.88,000 --> 0:06:3,000
I've been collaborating with a conversation analyst at the lab

121
0:06:31.84,000 --> 0:06:35,000
to try to help our AI systems hold more human-sounding conversations.

122
0:06:36.56,000 --> 0:06:39,000
This way, when you have an interaction with a chatbot on your phone

123
0:06:39.76,000 --> 0:06:4,000
or a voice-based system in the car,

124
0:06:41.64,000 --> 0:06:44,000
it sounds a little more human and less cold and disjointed.

125
0:06:46.36,000 --> 0:06:47,000
So I created a piece of art

126
0:06:47.72,000 --> 0:06:49,000
that tries to highlight the robotic, clunky interaction

127
0:06:50.56,000 --> 0:06:51,000
to help us understand, as designers,

128
0:06:52.56,000 --> 0:06:56,000
why it doesn't sound human yet and, well, what we can do about it.

129
0:06:57.16,000 --> 0:06:58,000
The piece is called Bot to Bot

130
0:06:58.64,000 --> 0:07:,000
and it puts one conversational system against another

131
0:07:01.6,000 --> 0:07:03,000
and then exposes it to the general public.

132
0:07:04.16,000 --> 0:07:06,000
And what ends up happening is that you get something

133
0:07:06.68,000 --> 0:07:07,000
that tries to mimic human conversation,

134
0:07:08.6,000 --> 0:07:09,000
but falls short.

135
0:07:10.52,000 --> 0:07:12,000
Sometimes it works and sometimes it gets into these, well,

136
0:07:13.28,000 --> 0:07:14,000
loops of misunderstanding.

137
0:07:14.84,000 --> 0:07:17,000
So even though the machine-to-machine conversation can make sense,

138
0:07:17.96,000 --> 0:07:19,000
grammatically and colloquially,

139
0:07:2,000 --> 0:07:23,000
it can still end up feeling cold and robotic.

140
0:07:23.24,000 --> 0:07:27,000
And despite checking all the boxes, the dialogue lacks soul

141
0:07:27.28,000 --> 0:07:3,000
and those one-off quirks that make each of us who we are.

142
0:07:30.44,000 --> 0:07:32,000
So while it might be grammatically correct

143
0:07:32.52,000 --> 0:07:34,000
and uses all the right hashtags and emojis,

144
0:07:35.2,000 --> 0:07:39,000
it can end up sounding mechanical and, well, a little creepy.

145
0:07:39.36,000 --> 0:07:41,000
And we call this the uncanny valley.

146
0:07:41.72,000 --> 0:07:42,000
You know, that creepiness factor of tech

147
0:07:43.68,000 --> 0:07:45,000
where it's close to human but just slightly off.

148
0:07:46.56,000 --> 0:07:47,000
And the piece will start being

149
0:07:48.04,000 --> 0:07:51,000
one way that we test for the humanness of a conversation

150
0:07:51.28,000 --> 0:07:53,000
and the parts that get lost in translation.

151
0:07:54.56,000 --> 0:07:56,000
So there are other things that get lost in translation, too,

152
0:07:57.44,000 --> 0:07:58,000
like human intuition.

153
0:07:59.08,000 --> 0:08:01,000
Right now, computers are gaining more autonomy.

154
0:08:01.88,000 --> 0:08:02,000
They can take care of things for us,

155
0:08:03.64,000 --> 0:08:06,000
like change the temperature of our houses based on our preferences

156
0:08:06.84,000 --> 0:08:08,000
and even help us drive on the freeway.

157
0:08:09.56,000 --> 0:08:11,000
But there are things that you and I do in person

158
0:08:12.08,000 --> 0:08:14,000
that are really difficult to translate to AI.

159
0:08:15.44,000 --> 0:08:19,000
So think about the last time that you saw an old classmate or coworker.

160
0:08:21.08,000 --> 0:08:23,000
Did you give them a hug or go in for a handshake?

161
0:08:24.8,000 --> 0:08:25,000
You probably didn't think twice

162
0:08:26.32,000 --> 0:08:28,000
because you've had so many built up experiences

163
0:08:28.68,000 --> 0:08:3,000
that had you do one or the other.

164
0:08:31.44,000 --> 0:08:34,000
And as an artist, I feel that access to one's intuition,

165
0:08:34.92,000 --> 0:08:35,000
your unconscious knowing,

166
0:08:36.36,000 --> 0:08:39,000
is what helps us create amazing things.

167
0:08:39.44,000 --> 0:08:43,000
Big ideas, from that abstract, nonlinear place in our consciousness

168
0:08:43.52,000 --> 0:08:45,000
that is the culmination of all of our experiences.

169
0:08:47.84,000 --> 0:08:51,000
And if we want computers to relate to us and help amplify our creative abilities,

170
0:08:52.52,000 --> 0:08:55,000
I feel that we'll need to start thinking about how to make computers be intuitive.

171
0:08:56.44,000 --> 0:08:59,000
So I wanted to explore how something like human intuition

172
0:08:59.56,000 --> 0:09:02,000
could be directly translated to artificial intelligence.

173
0:09:03.04,000 --> 0:09:06,000
And I created a piece that explores computer-based intuition

174
0:09:06.28,000 --> 0:09:07,000
in a physical space.

175
0:09:08.48,000 --> 0:09:09,000
The piece is called Wayfinding,

176
0:09:10.2,000 --> 0:09:13,000
and it's set up as a symbolic compass that has four kinetic sculptures.

177
0:09:14.16,000 --> 0:09:16,000
Each one represents a direction,

178
0:09:16.24,000 --> 0:09:18,000
north, east, south and west.

179
0:09:19.08,000 --> 0:09:21,000
And there are sensors set up on the top of each sculpture

180
0:09:21.8,000 --> 0:09:23,000
that capture how far away you are from them.

181
0:09:24.08,000 --> 0:09:25,000
And the data that gets collected

182
0:09:25.92,000 --> 0:09:27,000
ends up changing the way that sculptures move

183
0:09:28.08,000 --> 0:09:3,000
and the direction of the compass.

184
0:09:31.36,000 --> 0:09:34,000
The thing is, the piece doesn't work like the automatic door sensor

185
0:09:35.04,000 --> 0:09:37,000
that just opens when you walk in front of it.

186
0:09:37.72,000 --> 0:09:42,000
See, your contribution is only a part of its collection of lived experiences.

187
0:09:42.8,000 --> 0:09:46,000
And all of those experiences affect the way that it moves.

188
0:09:46.88,000 --> 0:09:47,000
So when you walk in front of it,

189
0:09:48.64,000 --> 0:09:49,000
it starts to use all of the data

190
0:09:50.64,000 --> 0:09:52,000
that it's captured throughout its exhibition history --

191
0:09:53.28,000 --> 0:09:54,000
or its intuition --

192
0:09:55.12,000 --> 0:09:58,000
to mechanically respond to you based on what it's learned from others.

193
0:09:59.48,000 --> 0:10:01,000
And what ends up happening is that as participants

194
0:10:02.04,000 --> 0:10:04,000
we start to learn the level of detail that we need

195
0:10:04.88,000 --> 0:10:06,000
in order to manage expectations

196
0:10:06.92,000 --> 0:10:08,000
from both humans and machines.

197
0:10:09.72,000 --> 0:10:12,000
We can almost see our intuition being played out on the computer,

198
0:10:13.36,000 --> 0:10:16,000
picturing all of that data being processed in our mind's eye.

199
0:10:17.56,000 --> 0:10:18,000
My hope is that this type of art

200
0:10:19.24,000 --> 0:10:21,000
will help us think differently about intuition

201
0:10:21.68,000 --> 0:10:23,000
and how to apply that to AI in the future.

202
0:10:24.48,000 --> 0:10:27,000
So these are just a few examples of how I'm using art to feed into my work

203
0:10:28.44,000 --> 0:10:31,000
as a designer and researcher of artificial intelligence.

204
0:10:31.56,000 --> 0:10:34,000
And I see it as a crucial way to move innovation forward.

205
0:10:35.08,000 --> 0:10:39,000
Because right now, there are a lot of extremes when it comes to AI.

206
0:10:39.48,000 --> 0:10:41,000
Popular movies show it as this destructive force

207
0:10:42.32,000 --> 0:10:45,000
while commercials are showing it as a savior

208
0:10:45.4,000 --> 0:10:47,000
to solve some of the world's most complex problems.

209
0:10:48.36,000 --> 0:10:5,000
But regardless of where you stand,

210
0:10:50.92,000 --> 0:10:52,000
it's hard to deny that we're living in a world

211
0:10:53.12,000 --> 0:10:55,000
that's becoming more and more digital by the second.

212
0:10:55.72,000 --> 0:10:59,000
Our lives revolve around our devices, smart appliances and more.

213
0:11:01.4,000 --> 0:11:03,000
And I don't think this will let up any time soon.

214
0:11:04.4,000 --> 0:11:07,000
So, I'm trying to embed more humanness from the start.

215
0:11:08.16,000 --> 0:11:13,000
And I have a hunch that bringing art into an AI research process

216
0:11:13.32,000 --> 0:11:14,000
is a way to do just that.

217
0:11:15.24,000 --> 0:11:16,000
Thank you.

218
0:11:16.48,000 --> 0:11:18,000
(Applause)

