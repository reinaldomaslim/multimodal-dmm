1
0:00:,000 --> 0:00:07,000
Traducteur: Claire Ghyselen Relecteur: Morgane Quilfen

2
0:00:13.52,000 --> 0:00:16,000
On m'a invité dans un centre de villégiature luxueux

3
0:00:17.4,000 --> 0:00:19,000
pour réaliser une intervention sur l'avenir numérique.

4
0:00:19.926,000 --> 0:00:22,000
Je pensais trouver dans l'audience quelques centaines de dirigeants.

5
0:00:23.52,000 --> 0:00:25,000
Je patientais dans ma loge, prêt,

6
0:00:26.24,000 --> 0:00:31,000
mais au lieu de m'emmener sur une scène, on a invité cinq hommes dans ma loge

7
0:00:31.416,000 --> 0:00:33,000
et ils se sont mis à l'aise dans cet espace confiné.

8
0:00:33.862,000 --> 0:00:34,000
Cinq milliardaires de la high-tech.

9
0:00:35.64,000 --> 0:00:39,000
Ils ont ouvert le débat en m'assaillant des questions binaires

10
0:00:40.2,000 --> 0:00:42,000
comme : Bitcoin ou Etherium ?

11
0:00:43.12,000 --> 0:00:45,000
Réalité virtuelle ou réalité augmentée ?

12
0:00:45.8,000 --> 0:00:47,000
Je me demande s'ils avaient parié sur les réponses.

13
0:00:48.32,000 --> 0:00:5,000
Au fur et à mesure qu'ils se sentaient plus à l'aise avec moi,

14
0:00:51.16,000 --> 0:00:54,000
ils ont abordé le sujet qui les intéressait vraiment :

15
0:00:54.4,000 --> 0:00:56,000
l'Alaska ou la Nouvelle Zélande ?

16
0:00:57.76,000 --> 0:00:58,000
Exact.

17
0:00:58.976,000 --> 0:01:01,000
Ces milliardaires demandaient conseil à un théoricien des médias

18
0:01:02.042,000 --> 0:01:04,000
sur quel lieu choisir pour établir leur bunker de survie.

19
0:01:04.72,000 --> 0:01:07,000
On a tergiversé une heure sur la seule question :

20
0:01:07.76,000 --> 0:01:1,000
« Comment garder le contrôle de mon personnel de sécurité

21
0:01:11.4,000 --> 0:01:12,000
après l'apocalypse ? »

22
0:01:13.92,000 --> 0:01:15,000
L'« apocalypse », c'était la guerre thermonucléaire,

23
0:01:16.596,000 --> 0:01:17,000
la catastrophe climatique,

24
0:01:18.4,000 --> 0:01:2,000
l'instabilité sociale qui va anéantir le monde

25
0:01:20.55,000 --> 0:01:21,000
tel que nous le connaissons.

26
0:01:21.9,000 --> 0:01:24,000
Et plus crucial, rendre leur argent sans valeur.

27
0:01:26.2,000 --> 0:01:28,000
Ce que je pensais en réalité, c'est que,

28
0:01:28.44,000 --> 0:01:32,000
ces personnes étaient les plus riches et les plus puissantes au monde,

29
0:01:33.2,000 --> 0:01:37,000
mais elles se sentaient totalement démunies pour influer sur l'avenir.

30
0:01:37.88,000 --> 0:01:41,000
Leur meilleure idée est de se préparer à l'inévitable catastrophe

31
0:01:42.336,000 --> 0:01:46,000
et ensuite utiliser leur technologie, leur argent pour s'isoler du reste du monde.

32
0:01:47.52,000 --> 0:01:49,000
On parle des grands gagnants de l'économie numérique.

33
0:01:50.08,000 --> 0:01:53,000
(Rires)

34
0:01:53.52,000 --> 0:01:55,000
La renaissance numérique

35
0:01:56.32,000 --> 0:02:,000
a rapport au potentiel infini

36
0:02:00.6,000 --> 0:02:02,000
de l'imagination collective de l'Homme.

37
0:02:03.04,000 --> 0:02:08,000
Elle s'étend des mathématiques du chaos et de la physique quantique

38
0:02:08.2,000 --> 0:02:12,000
aux jeux de rôle et à l'hypothèse Gaïa.

39
0:02:12.4,000 --> 0:02:15,000
Nous étions convaincus que les êtres humains connectés

40
0:02:15.87,000 --> 0:02:19,000
pourraient créer l'avenir qu'ils imagineraient.

41
0:02:20.84,000 --> 0:02:22,000
Et Les boites de technologie ont pris leur essor.

42
0:02:24.6,000 --> 0:02:27,000
L'avenir numérique s'est transformé en contrats à terme d'actions.

43
0:02:28.24,000 --> 0:02:31,000
On a employé toute cette énergie de l'ère numérique

44
0:02:31.28,000 --> 0:02:35,000
pour injecter des stéroïdes dans le marché NASDAQ, pourtant moribond.

45
0:02:35.56,000 --> 0:02:38,000
Les magazines spécialisés en technologie nous annonçaient un tsunami.

46
0:02:39.2,000 --> 0:02:43,000
Seuls les investisseurs qui recrutaient les meilleurs planificateurs et futuristes

47
0:02:43.68,000 --> 0:02:45,000
allaient survivre à cette vague.

48
0:02:47.16,000 --> 0:02:53,000
L'avenir est passé d'un projet que nous créons ensemble et maintenant

49
0:02:53.206,000 --> 0:02:54,000
à un objet de paris,

50
0:02:54.662,000 --> 0:02:57,000
dans une concurrence à somme nulle où le gagnant rafle toute la mise.

51
0:03:00.12,000 --> 0:03:03,000
Quand l'avenir devient l'objet de telles spéculations,

52
0:03:03.28,000 --> 0:03:06,000
les hommes ne sont plus valorisés pour leur créativité.

53
0:03:06.6,000 --> 0:03:09,000
Notre valeur est celle de nos données.

54
0:03:09.736,000 --> 0:03:11,000
Car ils utilisent les données pour faire des prédictions.

55
0:03:12.422,000 --> 0:03:14,000
La créativité est source de perturbations.

56
0:03:14.76,000 --> 0:03:16,000
Elle rend toute prédiction complexe.

57
0:03:17,000 --> 0:03:19,000
Nous avons donc abouti à un paysage numérique

58
0:03:19.44,000 --> 0:03:22,000
qui réprime la créativité, la nouveauté

59
0:03:22.72,000 --> 0:03:24,000
et ce qui fait de nous des êtres humains.

60
0:03:26.76,000 --> 0:03:27,000
Les médias sociaux sont nés.

61
0:03:28.236,000 --> 0:03:31,000
Permettent-ils aux gens de tisser des liens entre eux de manière neuve ?

62
0:03:31.72,000 --> 0:03:34,000
Non, les médias sociaux utilisent nos données

63
0:03:34.846,000 --> 0:03:35,000
pour prédire nos comportements.

64
0:03:36.736,000 --> 0:03:38,000
Ou, si ça s'avère nécessaire, pour influencer nos comportements

65
0:03:39.722,000 --> 0:03:42,000
et nous pousser à agir en concordance avec nos profils statistiques.

66
0:03:45.2,000 --> 0:03:47,000
L'économie numérique aime-t-elle les gens ?

67
0:03:47.416,000 --> 0:03:49,000
Non, si vous élaborez un plan d'affaires, que devez-vous faire ?

68
0:03:50.412,000 --> 0:03:51,000
Éliminer tous les hommes.

69
0:03:51.64,000 --> 0:03:54,000
Les humains veulent des soins de santé, un salaire, du sens.

70
0:03:56.36,000 --> 0:03:58,000
Impossible de travailler à grande échelle.

71
0:03:59.36,000 --> 0:04:,000
(Rires)

72
0:04:00.84,000 --> 0:04:01,000
Mêmes nos applis

73
0:04:02.08,000 --> 0:04:05,000
ne nous sont d'aucun recours pour créer des liens de solidarité.

74
0:04:05.296,000 --> 0:04:07,000
Sur quel bouton appuie-t-on dans l'appli de transport partagé

75
0:04:08.172,000 --> 0:04:11,000
pour permettre aux conducteurs de parler de leurs conditions de travail

76
0:04:11.596,000 --> 0:04:12,000
ou de se syndiquer ?

77
0:04:13.6,000 --> 0:04:15,000
Même les outils de vidéo-conférence

78
0:04:15.64,000 --> 0:04:17,000
ne permettent l'établissement d'aucun rapport réel.

79
0:04:18.04,000 --> 0:04:21,000
Quelle que soit la qualité de la résolution,

80
0:04:21.4,000 --> 0:04:25,000
on ne peut pas observer si l'iris de notre interlocuteur est dilaté.

81
0:04:25.44,000 --> 0:04:28,000
Tous ces mécanismes que nous avons développés pour créer des liens,

82
0:04:28.59,000 --> 0:04:3,000
pendant des centaines de milliers d'années d'évolution,

83
0:04:31.399,000 --> 0:04:32,000
ne sont plus efficaces.

84
0:04:32.62,000 --> 0:04:35,000
On ne sait pas si la respiration de l'autre se synchronise à la nôtre.

85
0:04:35.916,000 --> 0:04:38,000
Les neurones miroirs ne réagissent pas, l'ocytocine ne vous traverse pas

86
0:04:39.336,000 --> 0:04:42,000
et on ne sait plus ce que signifie créer des liens avec d'autres humains.

87
0:04:43.36,000 --> 0:04:44,000
Maintenant, la situation est :

88
0:04:44.84,000 --> 0:04:46,000
« Ils étaient d'accord avec moi, mais m'ont-ils vraiment,

89
0:04:47.566,000 --> 0:04:48,000
vraiment compris ? »

90
0:04:48.84,000 --> 0:04:51,000
On ne pense pas que c'est la technologie qui est défaillante.

91
0:04:52.216,000 --> 0:04:54,000
On pense que c'est l'autre personne.

92
0:04:55.32,000 --> 0:04:59,000
Même les technologies et les initiatives numériques qui existent

93
0:04:59.4,000 --> 0:05:01,000
pour promouvoir l'humain,

94
0:05:01.6,000 --> 0:05:03,000
sont fondamentalement anti-humanistes.

95
0:05:05.6,000 --> 0:05:07,000
Songez à la blockchain.

96
0:05:08.52,000 --> 0:05:11,000
La blockchain existe-t-il pour développer une économie humaniste ?

97
0:05:11.63,000 --> 0:05:14,000
Non, elle ne crée aucune confiance entre les utilisateurs.

98
0:05:14.88,000 --> 0:05:17,000
La blockchain remplace la confiance d'une manière neuve

99
0:05:18.44,000 --> 0:05:2,000
et moins transparente.

100
0:05:21.6,000 --> 0:05:22,000
Et l'enseignement de la programmation ?

101
0:05:23.456,000 --> 0:05:25,000
L'éducation, c'est très bien, on est pour.

102
0:05:25.616,000 --> 0:05:26,000
C'est aussi une très bonne idée

103
0:05:27.132,000 --> 0:05:3,000
de vouloir que les enfants puissent avoir un travail dans un avenir numérique,

104
0:05:30.806,000 --> 0:05:32,000
et donc, enseignons-leur la programmation.

105
0:05:32.82,000 --> 0:05:34,000
Mais depuis quand l'éducation vise-t-elle l'emploi ?

106
0:05:35.92,000 --> 0:05:36,000
L'éducation n'a rien à voir avec ça.

107
0:05:37.68,000 --> 0:05:4,000
L'éducation vient en récompense d'un travail bien fait.

108
0:05:41.68,000 --> 0:05:42,000
Le principe d'éducation publique

109
0:05:43.256,000 --> 0:05:46,000
est fondé sur l'idée que les mineurs, travaillant dans la mine la journée,

110
0:05:46.752,000 --> 0:05:48,000
pourraient rentrer à la maison et jouir de la dignité

111
0:05:49.28,000 --> 0:05:51,000
de pouvoir lire un roman et le comprendre.

112
0:05:51.416,000 --> 0:05:53,000
Ou de l'intelligence pour pouvoir participer à la démocratie.

113
0:05:55.2,000 --> 0:05:58,000
Quand on en fait un préalable au travail, que faisons-nous en réalité ?

114
0:05:58.546,000 --> 0:06:,000
On permet simplement aux entreprises

115
0:06:01,000 --> 0:06:04,000
d'externaliser le coût de formation de leurs salariés.

116
0:06:05.52,000 --> 0:06:09,000
Le pire de tout est le mouvement pour une technologie humaniste.

117
0:06:09.64,000 --> 0:06:1,000
J'adore ces gens-là, des repentis,

118
0:06:11.62,000 --> 0:06:14,000
qui ont extrait les algorithmes des machines à sous de Las Vegas

119
0:06:15.44,000 --> 0:06:17,000
et encodé dans les médias sociaux pour nous rendre accros.

120
0:06:18.4,000 --> 0:06:19,000
Ils ont reconnus leurs péchés

121
0:06:20.36,000 --> 0:06:22,000
et souhaitent rendre la technologie plus humaine.

122
0:06:22.816,000 --> 0:06:24,000
Le son même de l'expression « technologie humaine »

123
0:06:25.342,000 --> 0:06:27,000
évoque un poulet fermier, par exemple.

124
0:06:28.16,000 --> 0:06:3,000
On va essayer d'être aussi humain que possible,

125
0:06:30.416,000 --> 0:06:32,000
jusqu'au moment de les amener à l'abattoir.

126
0:06:33.2,000 --> 0:06:36,000
On va rendre ces technologies aussi humaines que possible

127
0:06:36.64,000 --> 0:06:39,000
tant qu'elles exploitent suffisamment de nos données et d'argent

128
0:06:39.856,000 --> 0:06:4,000
pour satisfaire les actionnaires.

129
0:06:42.52,000 --> 0:06:44,000
Entretemps, les actionnaires pensent ceci :

130
0:06:45.15,000 --> 0:06:48,000
« Je dois gagner autant d'argent que possible pour me protéger

131
0:06:48.696,000 --> 0:06:51,000
du monde à venir que je suis en train de créer en gagnant cet argent ainsi ».

132
0:06:52.332,000 --> 0:06:53,000
(Rires)

133
0:06:54.2,000 --> 0:06:58,000
Ils peuvent porter autant de lunettes de réalité virtuelle qu'ils souhaitent,

134
0:06:58.256,000 --> 0:07:,000
peu importe le monde féérique auquel ils accèdent,

135
0:07:00.612,000 --> 0:07:03,000
ils ne peuvent pas externaliser l'esclavagisme et la pollution causés

136
0:07:04.12,000 --> 0:07:06,000
par la production des équipements posés sur leurs yeux.

137
0:07:07.12,000 --> 0:07:1,000
Ça me rappelle le monte-plats de Thomas Jefferson.

138
0:07:10.32,000 --> 0:07:12,000
On pense souvent qu'il a inventé le monte-plats

139
0:07:12.68,000 --> 0:07:15,000
pour épargner ses esclaves le labeur de monter les escaliers

140
0:07:16.36,000 --> 0:07:18,000
pour servir les plats à ses invités.

141
0:07:19.16,000 --> 0:07:21,000
À tort, car ce n'était pas pour les esclaves.

142
0:07:21.276,000 --> 0:07:23,000
Il s'agissait d'épargner à Jefferson et ses convives

143
0:07:24.102,000 --> 0:07:27,000
la vue des esclaves qui apportent les plats.

144
0:07:27.136,000 --> 0:07:28,000
Les mets arrivaient comme par magie,

145
0:07:28.902,000 --> 0:07:3,000
comme matérialisés par un réplicateur dans Star Trek.

146
0:07:32.72,000 --> 0:07:34,000
Ça fait partie du principe qui affirme

147
0:07:34.84,000 --> 0:07:38,000
que les humains sont le problème et la technologie la solution.

148
0:07:40.68,000 --> 0:07:42,000
Cette philosophie est caduque.

149
0:07:42.76,000 --> 0:07:44,000
Arrêtons d'utiliser la technologie

150
0:07:45.05,000 --> 0:07:48,000
pour optimiser l'humain par rapport au marché

151
0:07:48.08,000 --> 0:07:53,000
et optimisons la technologie par rapport à l'avenir de l'humanité.

152
0:07:55.08,000 --> 0:07:57,000
Ces jours-ci, c'est une proposition audacieuse

153
0:07:57.76,000 --> 0:08:01,000
car les humains ne sont guère populaires.

154
0:08:01.84,000 --> 0:08:03,000
J'ai tenu les mêmes propos récemment à une environnementaliste

155
0:08:04.766,000 --> 0:08:06,000
et elle m'a demandé pourquoi je défendais les humains.

156
0:08:07.312,000 --> 0:08:1,000
« L'homme a anéanti la planète. Il mérite de disparaître. »

157
0:08:11.216,000 --> 0:08:13,000
(Rires)

158
0:08:13.56,000 --> 0:08:15,000
Même les médias populaires détestent les hommes.

159
0:08:16.16,000 --> 0:08:17,000
Regardez la télévision :

160
0:08:17.416,000 --> 0:08:19,000
toutes les émissions de SF montrent les robots

161
0:08:19.572,000 --> 0:08:2,000
sous un jour meilleur que l'homme.

162
0:08:21.232,000 --> 0:08:23,000
Les films de zombies ? De quoi s'agit-il en fait ?

163
0:08:24.2,000 --> 0:08:27,000
Un type observe l'horizon, un zombie traverse son champ de vision.

164
0:08:27.48,000 --> 0:08:29,000
Zoom sur le visage du type

165
0:08:30.4,000 --> 0:08:31,000
et vous savez ce qu'il pense :

166
0:08:32.16,000 --> 0:08:34,000
« Quelle différence entre moi et le zombie ?

167
0:08:34.92,000 --> 0:08:35,000
Il marche, je marche.

168
0:08:36.48,000 --> 0:08:38,000
Il mange, moi aussi.

169
0:08:38.52,000 --> 0:08:4,000
Il tue, moi aussi, je tue. »

170
0:08:42.36,000 --> 0:08:43,000
Mais c'est un zombie.

171
0:08:43.92,000 --> 0:08:44,000
Vous en êtes conscient.

172
0:08:45.36,000 --> 0:08:48,000
Quand on n'arrive plus à distinguer un zombie de nous-mêmes,

173
0:08:49.08,000 --> 0:08:51,000
on a un souci, et pas un petit.

174
0:08:51.28,000 --> 0:08:52,000
(Rires)

175
0:08:52.52,000 --> 0:08:54,000
N'évoquons même pas le transhumanisme.

176
0:08:55.48,000 --> 0:08:58,000
J'ai participé à un panel sur le sujet et un type parlait de la singularité :

177
0:08:59.32,000 --> 0:09:02,000
« Le jour est proche où les machines seront plus intelligentes que l'Homme.

178
0:09:03.2,000 --> 0:09:05,000
Il ne restera qu'un seul choix à l'Homme :

179
0:09:05.36,000 --> 0:09:08,000
transmettre le relai de l'évolution à notre successeur

180
0:09:08.72,000 --> 0:09:09,000
et disparaître à l'horizon.

181
0:09:10.36,000 --> 0:09:13,000
Au mieux, on pourra peut-être télécharger notre conscience sur une puce

182
0:09:13.84,000 --> 0:09:14,000
et accepter notre extinction. »

183
0:09:16.64,000 --> 0:09:17,000
(Rires)

184
0:09:18.12,000 --> 0:09:21,000
J'ai répondu ceci : « Non, l'homme est particulier.

185
0:09:21.52,000 --> 0:09:24,000
On accueille l'ambiguïté, on comprend le paradoxe,

186
0:09:25.08,000 --> 0:09:27,000
on est conscient, bizarre et excentrique.

187
0:09:27.72,000 --> 0:09:3,000
Il devrait y avoir une place pour l'homme dans l'avenir numérique. »

188
0:09:31.056,000 --> 0:09:32,000
Le type m'a dit : « Oh, Rushkoff,

189
0:09:32.682,000 --> 0:09:34,000
tu dis ça parce que tu es un homme. »

190
0:09:34.96,000 --> 0:09:35,000
(Rires)

191
0:09:36.736,000 --> 0:09:37,000
Comme s'il s'agissait d'arrogance.

192
0:09:39.28,000 --> 0:09:41,000
OK, j'appartiens à « l'équipe humaine ».

193
0:09:43.2,000 --> 0:09:46,000
C'est l'intuition première de l'ère numérique.

194
0:09:47.08,000 --> 0:09:49,000
Être humain est un sport d'équipe

195
0:09:49.32,000 --> 0:09:51,000
et l'évolution est un acte collaboratif.

196
0:09:52.08,000 --> 0:09:53,000
Même les arbres d'une forêt,

197
0:09:53.52,000 --> 0:09:54,000
n'entrent pas en compétition,

198
0:09:54.97,000 --> 0:09:58,000
ils sont reliés par un vaste réseau de racines et de champignons

199
0:09:59,000 --> 0:10:03,000
qui leur permet de communiquer et d'échanger des nutriments.

200
0:10:03.56,000 --> 0:10:05,000
L'humanité est l'espèce la plus évoluée

201
0:10:05.696,000 --> 0:10:07,000
car notre évolution principale fut dans la collaboration

202
0:10:08.666,000 --> 0:10:09,000
et de la communication.

203
0:10:09.88,000 --> 0:10:1,000
Nous avons le langage verbal.

204
0:10:11.4,000 --> 0:10:12,000
Nous avons les technologies.

205
0:10:14.12,000 --> 0:10:18,000
C'est étrange car auparavant, je parlais de l'avenir numérique

206
0:10:18.72,000 --> 0:10:2,000
aux gens qui ne s'y connaissaient pas.

207
0:10:22.2,000 --> 0:10:24,000
Maintenant, j'ai l'impression d'être le dernier survivant

208
0:10:24.906,000 --> 0:10:27,000
qui se souvient ce à quoi la vie ressemblait avant le numérique.

209
0:10:28.68,000 --> 0:10:32,000
Il ne s'agit pas de rejeter le numérique ou les technologies.

210
0:10:32.92,000 --> 0:10:36,000
Il s'agit de conserver les valeurs que nous risquons d'abandonner

211
0:10:37.04,000 --> 0:10:38,000
et de les intégrer

212
0:10:38.5,000 --> 0:10:4,000
au sein des infrastructures numériques du futur.

213
0:10:41.88,000 --> 0:10:43,000
Ce n'est pas de la physique nucléaire.

214
0:10:44.176,000 --> 0:10:46,000
C'est aussi simple que de faire en sorte que les média sociaux

215
0:10:47.112,000 --> 0:10:49,000
ne nous montrent pas comment voir l'autre comme un adversaire

216
0:10:50.016,000 --> 0:10:53,000
mais qu'ils nous enseignent comment considérer l'adversaire comme un homme.

217
0:10:54.24,000 --> 0:10:55,000
Ça signifie façonner une économie

218
0:10:55.95,000 --> 0:10:57,000
qui ne favorise pas le monopole d'une plateforme

219
0:10:58.56,000 --> 0:11:01,000
en extrayant de la valeur des gens et des lieux

220
0:11:01.92,000 --> 0:11:04,000
mais qui promeut la circulation des valeurs à travers une communauté

221
0:11:05.856,000 --> 0:11:07,000
et nous permet d'établir des plateformes coopératives

222
0:11:08.342,000 --> 0:11:11,000
qui redistribue la propriété aussi largement que possible.

223
0:11:12.136,000 --> 0:11:13,000
Ça signifie la création de plateformes

224
0:11:13.962,000 --> 0:11:17,000
qui ne répriment pas créativité et innovation au nom de la prédiction

225
0:11:18.52,000 --> 0:11:2,000
mais qui les promeuvent,

226
0:11:21.12,000 --> 0:11:23,000
pour nous encourager à trouver des solutions

227
0:11:23.456,000 --> 0:11:26,000
pour nous extraire des sables mouvants où nous nous sommes mis.

228
0:11:27.44,000 --> 0:11:3,000
Plutôt que de mettre suffisamment d'argent de côté pour nous protéger

229
0:11:30.706,000 --> 0:11:31,000
du monde que nous avons créé,

230
0:11:32.096,000 --> 0:11:35,000
pourquoi ne pas consacrer notre temps et notre énergie à créer un monde

231
0:11:35.486,000 --> 0:11:37,000
dont nous n'éprouvons pas le besoin de nous échapper.

232
0:11:38.02,000 --> 0:11:41,000
Il n'y a pas d'issue de secours, il n'y a qu'un seul acte.

233
0:11:42.68,000 --> 0:11:44,000
Ne quittez pas le navire.

234
0:11:45.64,000 --> 0:11:46,000
Rejoignez-nous.

235
0:11:47.8,000 --> 0:11:48,000
Nous ne sommes pas parfaits

236
0:11:49.12,000 --> 0:11:51,000
mais quoi qu'il arrive, vous ne serez pas seul.

237
0:11:52.64,000 --> 0:11:53,000
Rejoignez « l'équipe humaine » !

238
0:11:55.16,000 --> 0:11:57,000
Trouvez l'autre.

239
0:11:57.28,000 --> 0:11:59,000
Ensemble, façonnons l'avenir que nous avons toujours souhaité.

240
0:12:01.56,000 --> 0:12:04,000
Voici ce que j'ai répondu aux milliardaires qui voulaient savoir

241
0:12:04.596,000 --> 0:12:07,000
comment maintenir le contrôle de leur personnel de sécurité

242
0:12:07.656,000 --> 0:12:08,000
après l'apocalypse :

243
0:12:09.28,000 --> 0:12:13,000
« Commencez par traiter votre personnel avec bienveillance et respect.

244
0:12:13.496,000 --> 0:12:15,000
Votre inquiétude sur l'apocalypse pourrait être vaine. »

245
0:12:16.84,000 --> 0:12:17,000
Merci.

246
0:12:18.08,000 --> 0:12:22,000
(Applaudissements)

