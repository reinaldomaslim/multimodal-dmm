1
0:00:12.653,000 --> 0:00:15,000
So in 2011, I altered my name

2
0:00:16.075,000 --> 0:00:19,000
so that I could participate in Far Right youth camp in Hungary.

3
0:00:20.614,000 --> 0:00:24,000
I was doing a PhD looking at youth political socialization --

4
0:00:25.004,000 --> 0:00:28,000
why young people were developing political ideologies

5
0:00:28.099,000 --> 0:00:3,000
in a post-communist setting,

6
0:00:30.133,000 --> 0:00:33,000
and I saw that a lot of young people I was talking to

7
0:00:33.39,000 --> 0:00:34,000
were joining the Far Right,

8
0:00:35.014,000 --> 0:00:37,000
and this was astounding to me.

9
0:00:37.194,000 --> 0:00:39,000
So I wanted to enroll in this youth camp

10
0:00:39.513,000 --> 0:00:42,000
to get a better understanding of why people were joining.

11
0:00:42.673,000 --> 0:00:43,000
So a colleague enrolled me,

12
0:00:44.254,000 --> 0:00:46,000
and my last name sounds a little bit too Jewish.

13
0:00:47.5,000 --> 0:00:49,000
So Erin got turned into Iréna,

14
0:00:50.269,000 --> 0:00:52,000
and Saltman got turned into Sós,

15
0:00:52.493,000 --> 0:00:54,000
which means "salty" in Hungarian.

16
0:00:55.438,000 --> 0:00:57,000
And in Hungarian, your last name goes first,

17
0:00:57.772,000 --> 0:01:01,000
so my James Bond name turned into "Salty Irena,"

18
0:01:02.21,000 --> 0:01:05,000
which is not something I would have naturally chosen for myself.

19
0:01:06.1,000 --> 0:01:07,000
But going to this camp,

20
0:01:08.031,000 --> 0:01:12,000
I was further shocked to realize that it was actually really fun.

21
0:01:13,000 --> 0:01:15,000
They talked very little about politics.

22
0:01:15.239,000 --> 0:01:18,000
It was mostly learning how to ride horses,

23
0:01:18.276,000 --> 0:01:19,000
shooting a bow and arrow,

24
0:01:20.168,000 --> 0:01:21,000
live music at night,

25
0:01:21.879,000 --> 0:01:22,000
free food and alcohol,

26
0:01:23.872,000 --> 0:01:25,000
also some air-gun target practice

27
0:01:26.762,000 --> 0:01:29,000
using mainstream politicians' faces as targets.

28
0:01:30.44,000 --> 0:01:33,000
And this seemed like a very, actually, friendly, inclusive group

29
0:01:34.191,000 --> 0:01:39,000
until you started talking or mentioning anything to do with the Roma population,

30
0:01:39.628,000 --> 0:01:41,000
Jewish people or immigrants,

31
0:01:41.914,000 --> 0:01:45,000
and then the discourse would become very hate-based very quickly.

32
0:01:46.663,000 --> 0:01:48,000
So it led me into my work now,

33
0:01:49.497,000 --> 0:01:51,000
where we pose the question,

34
0:01:51.902,000 --> 0:01:54,000
"Why do people join violent extremist movements,

35
0:01:54.966,000 --> 0:01:57,000
and how do we effectively counter these processes?"

36
0:01:58.393,000 --> 0:02:01,000
In the aftermath of horrible atrocities and attacks

37
0:02:01.708,000 --> 0:02:04,000
in places like Belgium, France, but all over the world,

38
0:02:05.095,000 --> 0:02:06,000
sometimes it's easier for us to think,

39
0:02:06.952,000 --> 0:02:07,000
"Well, these must be sociopaths,

40
0:02:08.921,000 --> 0:02:11,000
these must be naturally violent individuals.

41
0:02:12.009,000 --> 0:02:14,000
They must have something wrong with their upbringing."

42
0:02:14.629,000 --> 0:02:16,000
And what's really tragic

43
0:02:16.74,000 --> 0:02:18,000
is that oftentimes there's no one profile.

44
0:02:18.955,000 --> 0:02:21,000
Many people come from educated backgrounds,

45
0:02:22.233,000 --> 0:02:24,000
different socioeconomic backgrounds,

46
0:02:24.353,000 --> 0:02:26,000
men and women, different ages,

47
0:02:27.225,000 --> 0:02:29,000
some with families, some single.

48
0:02:29.527,000 --> 0:02:31,000
So why? What is this allure?

49
0:02:32.206,000 --> 0:02:34,000
And this is what I want to talk you through,

50
0:02:34.279,000 --> 0:02:36,000
as well as how do we challenge this in a modern era?

51
0:02:38.531,000 --> 0:02:39,000
We do know, through research,

52
0:02:40.038,000 --> 0:02:42,000
that there are quite a number of different things

53
0:02:42.418,000 --> 0:02:45,000
that affect somebody's process of radicalization,

54
0:02:45.793,000 --> 0:02:47,000
and we categorize these into push and pull factors.

55
0:02:48.587,000 --> 0:02:51,000
And these are pretty much similar for Far Right, neo-Nazi groups

56
0:02:52.024,000 --> 0:02:54,000
all the way to Islamist extremist and terrorist groups.

57
0:02:55.483,000 --> 0:02:58,000
And push factors are basically what makes you vulnerable

58
0:02:59.365,000 --> 0:03:,000
to a process of radicalization,

59
0:03:01.247,000 --> 0:03:03,000
to joining a violent extremist group.

60
0:03:03.477,000 --> 0:03:05,000
And these can be a lot of different things,

61
0:03:05.627,000 --> 0:03:08,000
but roughly, a sense of alienation, a sense of isolation,

62
0:03:09.564,000 --> 0:03:11,000
questioning your own identity,

63
0:03:11.739,000 --> 0:03:13,000
but also feeling that your in-group is under attack,

64
0:03:14.589,000 --> 0:03:17,000
and your in group might be based on a nationality or an ethnicity

65
0:03:18.406,000 --> 0:03:19,000
or a religion,

66
0:03:19.756,000 --> 0:03:22,000
and feeling that larger powers around you are doing nothing to help.

67
0:03:23.895,000 --> 0:03:26,000
Now, push factors alone do not make you a violent extremist,

68
0:03:27.34,000 --> 0:03:28,000
because if that were the fact,

69
0:03:28.794,000 --> 0:03:31,000
those same factors would go towards a group like the Roma population,

70
0:03:32.088,000 --> 0:03:34,000
and they're not a violently mobilized group.

71
0:03:34.893,000 --> 0:03:36,000
So we have to look at the pull factors.

72
0:03:37.204,000 --> 0:03:4,000
What are these violent extremist organizations offering

73
0:03:40.538,000 --> 0:03:41,000
that other groups are not offering?

74
0:03:42.507,000 --> 0:03:44,000
And actually, this is usually very positive things,

75
0:03:45.094,000 --> 0:03:47,000
very seemingly empowering things,

76
0:03:47.135,000 --> 0:03:49,000
such as brotherhood and sisterhood

77
0:03:49.622,000 --> 0:03:5,000
and a sense of belonging,

78
0:03:50.98,000 --> 0:03:52,000
as well as giving somebody a spiritual purpose,

79
0:03:53.878,000 --> 0:03:56,000
a divine purpose to build a utopian society

80
0:03:57.617,000 --> 0:03:58,000
if their goals can be met,

81
0:03:59.562,000 --> 0:04:01,000
but also a sense of empowerment and adventure.

82
0:04:02.337,000 --> 0:04:04,000
When we look at foreign terrorist fighters,

83
0:04:04.404,000 --> 0:04:06,000
we see young men with the wind in their hair

84
0:04:07.119,000 --> 0:04:09,000
out in the desert and women going to join them

85
0:04:09.689,000 --> 0:04:11,000
to have nuptials out in the sunset.

86
0:04:12.354,000 --> 0:04:15,000
It's very romantic, and you become a hero.

87
0:04:16.198,000 --> 0:04:18,000
For both men and women, that's the propaganda being given.

88
0:04:19.487,000 --> 0:04:21,000
So what extremist groups are very good at

89
0:04:22.153,000 --> 0:04:26,000
is taking a very complicated, confusing, nuanced world

90
0:04:27.003,000 --> 0:04:3,000
and simplifying that world into black and white,

91
0:04:30.27,000 --> 0:04:31,000
good and evil.

92
0:04:31.504,000 --> 0:04:32,000
And you become what is good,

93
0:04:33.409,000 --> 0:04:34,000
challenging what is evil.

94
0:04:36.361,000 --> 0:04:39,000
So I want to talk a little bit about ISIS, Daesh,

95
0:04:40.249,000 --> 0:04:44,000
because they have been a game changer in how we look at these processes,

96
0:04:44.651,000 --> 0:04:47,000
and through a lot of the material and their tactics.

97
0:04:47.881,000 --> 0:04:49,000
They're very much a modern movement.

98
0:04:50.745,000 --> 0:04:54,000
One of the aspects is the internet and the usage of social media,

99
0:04:55.254,000 --> 0:04:59,000
as we've all seen in headlines tweeting and videos of beheadings.

100
0:04:59.66,000 --> 0:05:01,000
But the internet alone does not radicalize you.

101
0:05:02.159,000 --> 0:05:03,000
The internet is a tool.

102
0:05:03.39,000 --> 0:05:04,000
You don't go online shopping for shoes

103
0:05:05.27,000 --> 0:05:06,000
and accidentally become a jihadist.

104
0:05:07.613,000 --> 0:05:1,000
However, what the Internet does do is it is a catalyst.

105
0:05:11.026,000 --> 0:05:15,000
It provides tools and scale and rapidity

106
0:05:15.169,000 --> 0:05:16,000
that doesn't exist elsewhere.

107
0:05:16.701,000 --> 0:05:18,000
And with ISIS, all of a sudden,

108
0:05:19.186,000 --> 0:05:24,000
this idea of a cloaked, dark figure of a jihadist changed for us.

109
0:05:24.528,000 --> 0:05:26,000
All of a sudden, we were in their kitchens.

110
0:05:26.607,000 --> 0:05:27,000
We saw what they were eating for dinner.

111
0:05:28.63,000 --> 0:05:29,000
They were tweeting.

112
0:05:29.805,000 --> 0:05:32,000
We had foreign terrorist fighters tweeting in their own languages.

113
0:05:32.987,000 --> 0:05:34,000
We had women going out there talking about their wedding day,

114
0:05:35.963,000 --> 0:05:36,000
about the births of their children.

115
0:05:37.734,000 --> 0:05:38,000
We had gaming culture, all of a sudden,

116
0:05:39.655,000 --> 0:05:42,000
and references to Grand Theft Auto being made.

117
0:05:43.291,000 --> 0:05:45,000
So all of a sudden, they were homey.

118
0:05:45.776,000 --> 0:05:46,000
They became human.

119
0:05:46.951,000 --> 0:05:48,000
And the problem is that trying to counter it,

120
0:05:49.189,000 --> 0:05:51,000
lots of governments and social media companies

121
0:05:51.523,000 --> 0:05:52,000
just tried to censor.

122
0:05:52.698,000 --> 0:05:53,000
How do we get rid of terrorist content?

123
0:05:54.713,000 --> 0:05:55,000
And it became a cat-and-mouse game

124
0:05:56.392,000 --> 0:05:59,000
where we would see accounts taken down and they'd just come back up,

125
0:05:59.62,000 --> 0:06:02,000
and an arrogance around somebody having a 25th account

126
0:06:02.757,000 --> 0:06:05,000
and material that was disseminated everywhere.

127
0:06:05.875,000 --> 0:06:07,000
But we also saw a dangerous trend --

128
0:06:07.92,000 --> 0:06:12,000
violent extremists know the rules and regulations of social media, too.

129
0:06:12.952,000 --> 0:06:16,000
So we would see a banal conversation with a recruiter

130
0:06:16.976,000 --> 0:06:17,000
start on a mainstream platform,

131
0:06:18.973,000 --> 0:06:2,000
and at the point at which that conversation

132
0:06:21.078,000 --> 0:06:22,000
was going to become illegal,

133
0:06:22.442,000 --> 0:06:24,000
they would jump to a smaller, less regulated,

134
0:06:24.967,000 --> 0:06:25,000
more encrypted platform.

135
0:06:26.614,000 --> 0:06:29,000
So all of a sudden, we couldn't track where that conversation went.

136
0:06:30.171,000 --> 0:06:31,000
So this is a problem with censorship,

137
0:06:32.057,000 --> 0:06:35,000
which is why we need to develop alternatives to censorship.

138
0:06:35.855,000 --> 0:06:38,000
ISIS is also a game-changer because it's state-building.

139
0:06:39.229,000 --> 0:06:41,000
It's not just recruiting combatants;

140
0:06:41.365,000 --> 0:06:42,000
it's trying to build a state.

141
0:06:43.251,000 --> 0:06:44,000
And what that means is all of a sudden,

142
0:06:45.215,000 --> 0:06:47,000
your recruitment model is much more broad.

143
0:06:47.239,000 --> 0:06:49,000
You're not just trying to get fighters --

144
0:06:49.312,000 --> 0:06:53,000
now you need architects, engineers, accountants, hackers and women.

145
0:06:53.602,000 --> 0:06:55,000
We've actually seen a huge increase of women going

146
0:06:56.016,000 --> 0:06:59,000
in the last 24, but especially 12 months.

147
0:06:59.539,000 --> 0:07:01,000
Some countries, one in four of the people going over to join

148
0:07:02.452,000 --> 0:07:03,000
are now women.

149
0:07:03.715,000 --> 0:07:04,000
And so, this really changes

150
0:07:05.107,000 --> 0:07:07,000
who we're trying to counter this process with.

151
0:07:08.499,000 --> 0:07:09,000
Now, not all doom and gloom.

152
0:07:10.174,000 --> 0:07:12,000
So the rest I'd like to talk about some of the positive things

153
0:07:13.158,000 --> 0:07:16,000
and the new innovation in trying to prevent and counter violent extremism.

154
0:07:17.026,000 --> 0:07:19,000
Preventing is very different than countering,

155
0:07:19.323,000 --> 0:07:21,000
and actually, you can think of it in medical terms.

156
0:07:21.903,000 --> 0:07:23,000
So preventative medicine is,

157
0:07:24.149,000 --> 0:07:27,000
how do we make it so you are naturally resilient

158
0:07:27.347,000 --> 0:07:29,000
to this process of radicalization,

159
0:07:29.871,000 --> 0:07:3,000
whereas that is going to be different

160
0:07:31.757,000 --> 0:07:33,000
if somebody is already showing a symptom or a sign

161
0:07:34.44,000 --> 0:07:36,000
of belonging to a violent extremist ideology.

162
0:07:37.345,000 --> 0:07:38,000
And so in preventative measures,

163
0:07:38.916,000 --> 0:07:4,000
we're talking more about really broad groups of people

164
0:07:41.631,000 --> 0:07:42,000
and exposure to ideas

165
0:07:43.472,000 --> 0:07:44,000
to make them resilient.

166
0:07:45.263,000 --> 0:07:46,000
Whereas it's very different

167
0:07:46.803,000 --> 0:07:49,000
if somebody is starting to question and agree with certain things online,

168
0:07:50.652,000 --> 0:07:53,000
and it's also very different if somebody already has a swastika tattoo

169
0:07:54.525,000 --> 0:07:56,000
and is very much embedded within a group.

170
0:07:56.597,000 --> 0:07:57,000
How do you reach them?

171
0:07:58.605,000 --> 0:08:01,000
So I'd like to go through three examples of each one of those levels

172
0:08:02.311,000 --> 0:08:03,000
and talk you through

173
0:08:03.55,000 --> 0:08:06,000
what some of the new ways of engaging with people are becoming.

174
0:08:07.194,000 --> 0:08:08,000
One is "Extreme Dialogue,"

175
0:08:08.631,000 --> 0:08:11,000
and it's an educational program that we helped develop.

176
0:08:11.735,000 --> 0:08:13,000
This one is from Canada,

177
0:08:14.14,000 --> 0:08:18,000
and it's meant to create dialogues within a classroom setting,

178
0:08:18.259,000 --> 0:08:19,000
using storytelling,

179
0:08:19.815,000 --> 0:08:22,000
because violent extremism can be very hard to try to explain,

180
0:08:22.99,000 --> 0:08:23,000
especially to younger individuals.

181
0:08:25.125,000 --> 0:08:28,000
So we have a network of former extremists and survivors of extremism

182
0:08:29.062,000 --> 0:08:32,000
that tell their stories through video and create question-giving to classrooms,

183
0:08:33.023,000 --> 0:08:35,000
to start a conversation about the topic.

184
0:08:35.35,000 --> 0:08:37,000
These two examples show Christianne,

185
0:08:37.906,000 --> 0:08:38,000
who lost her son,

186
0:08:39.081,000 --> 0:08:41,000
who radicalized and died fighting for ISIS,

187
0:08:41.598,000 --> 0:08:42,000
and Daniel is a former neo-Nazi

188
0:08:43.289,000 --> 0:08:45,000
who was an extremely violent neo-Nazi,

189
0:08:45.671,000 --> 0:08:49,000
and they pose questions about their lives and where they're at and regret,

190
0:08:49.853,000 --> 0:08:51,000
and force a classroom to have a dialogue around it.

191
0:08:52.995,000 --> 0:08:54,000
Now, looking at that middle range of individuals,

192
0:08:56.004,000 --> 0:08:58,000
actually, we need a lot of civil society voices.

193
0:08:58.727,000 --> 0:09:01,000
How do you interact with people that are looking for information online,

194
0:09:02.196,000 --> 0:09:04,000
that are starting to toy with an ideology,

195
0:09:04.562,000 --> 0:09:07,000
that are doing those searching identity questions?

196
0:09:07.65,000 --> 0:09:09,000
How do we provide alternatives for that?

197
0:09:09.816,000 --> 0:09:12,000
And that's when we combine large groups of civil society voices

198
0:09:13.23,000 --> 0:09:17,000
with creatives, techies, app developers, artists, comedians,

199
0:09:17.785,000 --> 0:09:19,000
and we can create really specified content

200
0:09:20.492,000 --> 0:09:24,000
and actually, online, disseminate it to very strategic audiences.

201
0:09:24.81,000 --> 0:09:26,000
So one example would be creating a satirical video

202
0:09:27.637,000 --> 0:09:29,000
which makes fun of Islamophobia,

203
0:09:30.16,000 --> 0:09:33,000
and targeting it to 15- to 20-year-olds online

204
0:09:34.12,000 --> 0:09:36,000
that have an interest in white power music

205
0:09:36.391,000 --> 0:09:38,000
and live specifically in Manchester.

206
0:09:38.814,000 --> 0:09:41,000
We can use these marketing tools to be very specific,

207
0:09:41.869,000 --> 0:09:43,000
so that we know when somebody's viewing, watching

208
0:09:44.616,000 --> 0:09:45,000
and engaging with that content,

209
0:09:46.129,000 --> 0:09:48,000
it's not just the average person, it's not me or you --

210
0:09:48.783,000 --> 0:09:51,000
it's a very specific audience that we are looking to engage with.

211
0:09:52.524,000 --> 0:09:55,000
Even more downstream, we developed a pilot program called "One to One,"

212
0:09:56.247,000 --> 0:09:57,000
where we took former extremists

213
0:09:57.82,000 --> 0:10:01,000
and we had them reach out directly to a group of labeled neofascists

214
0:10:02.708,000 --> 0:10:03,000
as well as Islamist extremists,

215
0:10:04.356,000 --> 0:10:07,000
and put direct messages through Facebook Messenger into their inbox, saying,

216
0:10:08.195,000 --> 0:10:1,000
"Hey, I see where you're going. I've been there.

217
0:10:10.505,000 --> 0:10:11,000
If you want to talk, I'm here."

218
0:10:12.071,000 --> 0:10:15,000
Now, we kind of expected death threats from this sort of interaction.

219
0:10:15.349,000 --> 0:10:19,000
It's a little alarming to have a former neo-Nazi say, "Hey, how are you?"

220
0:10:19.793,000 --> 0:10:21,000
But actually, we found that around 60 percent

221
0:10:22.024,000 --> 0:10:24,000
of the people reached out to responded,

222
0:10:24.602,000 --> 0:10:28,000
and of that, around another 60 percent had sustained engagement,

223
0:10:28.711,000 --> 0:10:3,000
meaning that they were having conversations

224
0:10:30.791,000 --> 0:10:33,000
with the hardest people to reach about what they were going through,

225
0:10:34.031,000 --> 0:10:35,000
planting seeds of doubt

226
0:10:35.206,000 --> 0:10:37,000
and giving them alternatives for talking about these subjects,

227
0:10:38.222,000 --> 0:10:39,000
and that's really important.

228
0:10:40.881,000 --> 0:10:42,000
So what we're trying to do

229
0:10:43.128,000 --> 0:10:45,000
is actually bring unlikely sectors to the table.

230
0:10:46.057,000 --> 0:10:48,000
We have amazing activists all over the world,

231
0:10:48.407,000 --> 0:10:5,000
but oftentimes, their messages are not strategic

232
0:10:50.797,000 --> 0:10:52,000
or they don't actually reach the audiences they want to reach.

233
0:10:53.727,000 --> 0:10:55,000
So we work with networks of former extremists.

234
0:10:55.99,000 --> 0:10:58,000
We work with networks of young people in different parts of the world.

235
0:10:59.443,000 --> 0:11:01,000
And we work with them to bring the tech sector to the table

236
0:11:02.237,000 --> 0:11:04,000
with artists and creatives and marketing expertise

237
0:11:05.079,000 --> 0:11:1,000
so that we can actually have a more robust and challenging of extremism

238
0:11:10.104,000 --> 0:11:11,000
that works together.

239
0:11:11.894,000 --> 0:11:13,000
So I would say that if you are in the audience

240
0:11:14.498,000 --> 0:11:16,000
and you happen to be a graphic designer,

241
0:11:17.221,000 --> 0:11:19,000
a poet, a marketing expert,

242
0:11:19.427,000 --> 0:11:2,000
somebody that works in PR,

243
0:11:21.36,000 --> 0:11:22,000
a comedian --

244
0:11:22.737,000 --> 0:11:24,000
you might not think that this is your sector,

245
0:11:24.912,000 --> 0:11:26,000
but actually, the skills that you have right now

246
0:11:27.675,000 --> 0:11:29,000
might be exactly what is needed

247
0:11:29.702,000 --> 0:11:31,000
to help challenge extremism effectively.

248
0:11:32.035,000 --> 0:11:33,000
Thank you.

249
0:11:33.21,000 --> 0:11:37,000
(Applause)

