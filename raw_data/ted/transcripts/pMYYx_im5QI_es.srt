1
0:00:,000 --> 0:00:07,000
Traductor: Máximo Hdez Revisor: Katherine Belloso

2
0:00:12.691,000 --> 0:00:15,000
Escribo novelas de suspenso de ciencia ficción,

3
0:00:15.849,000 --> 0:00:17,000
así que si digo "robots asesinos",

4
0:00:18.042,000 --> 0:00:2,000
probablemente podrían pensar en algo así.

5
0:00:20.403,000 --> 0:00:22,000
Pero en realidad no estoy aquí para hablar de ficción.

6
0:00:22.958,000 --> 0:00:24,000
Estoy aquí para hablar de robots asesinos muy reales,

7
0:00:25.906,000 --> 0:00:28,000
"drones" de combate autónomos.

8
0:00:29.028,000 --> 0:00:32,000
Y no me refiero a robots depredadores ni exterminadores,

9
0:00:32.655,000 --> 0:00:35,000
que tienen a un humano tomando decisiones de sus objetivos.

10
0:00:35.915,000 --> 0:00:38,000
Estoy hablando de armas robóticas totalmente autónomas

11
0:00:39.044,000 --> 0:00:41,000
que toman decisiones letales sobre seres humanos

12
0:00:41.698,000 --> 0:00:43,000
por su propia cuenta.

13
0:00:44.115,000 --> 0:00:48,000
De hecho existe un término técnico para esto: autonomía letal.

14
0:00:48.115,000 --> 0:00:5,000
Ahora, los robots asesinos letales autónomos

15
0:00:50.971,000 --> 0:00:53,000
pueden actuar de muchas formas: volando, conduciendo,

16
0:00:54.04,000 --> 0:00:56,000
o simplemente esperando al acecho.

17
0:00:56.786,000 --> 0:00:59,000
Y la verdad es que se están convirtiendo rápidamente en una realidad.

18
0:00:59.895,000 --> 0:01:01,000
Estas son dos estaciones automáticas de disparo

19
0:01:02.379,000 --> 0:01:06,000
desplegadas actualmente en la zona desmilitarizada entre Corea del Norte y del Sur

20
0:01:06.516,000 --> 0:01:08,000
Ambas máquinas son capaces de identificar

21
0:01:08.687,000 --> 0:01:11,000
automáticamente un objetivo humano y disparar contra él,

22
0:01:12.211,000 --> 0:01:16,000
la de la izquierda a una distancia de más de un kilómetro.

23
0:01:16.535,000 --> 0:01:19,000
En ambos casos, todavía hay un ser humano en el proceso

24
0:01:20.124,000 --> 0:01:22,000
para tomar esa decisión de disparo letal

25
0:01:22.496,000 --> 0:01:27,000
pero no es un requisito tecnológico, es una opción.

26
0:01:27.909,000 --> 0:01:3,000
Y es en esa opción en la que quiero centrarme,

27
0:01:31.002,000 --> 0:01:33,000
porque cuando desplazamos la toma de decisiones letales

28
0:01:33.643,000 --> 0:01:36,000
de los humanos al software,

29
0:01:36.752,000 --> 0:01:39,000
corremos el riesgo no sólo de sacar a la humanidad de la guerra,

30
0:01:40.228,000 --> 0:01:43,000
sino también el de cambiar nuestro panorama social completamente,

31
0:01:43.754,000 --> 0:01:45,000
lejos del campo de batalla.

32
0:01:45.978,000 --> 0:01:49,000
Eso es porque la manera en que los humanos resolvemos los conflictos

33
0:01:50.487,000 --> 0:01:51,000
moldea nuestro panorama social.

34
0:01:52.22,000 --> 0:01:54,000
Y así ha sido siempre a lo largo de la historia.

35
0:01:54.853,000 --> 0:01:56,000
Por ejemplo, estos eran los sistemas de armamento más avanzados

36
0:01:57.514,000 --> 0:01:59,000
en 1400 D.C.

37
0:01:59.593,000 --> 0:02:02,000
El costo de la construcción y el mantenimiento de ambos era muy elevados,

38
0:02:02.737,000 --> 0:02:05,000
pero con ellos se podía dominar a la población,

39
0:02:05.977,000 --> 0:02:08,000
y eso se reflejaba en la distribución del poder político en la sociedad feudal.

40
0:02:09.866,000 --> 0:02:11,000
El poder ocupó un lugar primordial.

41
0:02:12.553,000 --> 0:02:15,000
Y ¿qué cambió? La innovación tecnológica.

42
0:02:16.081,000 --> 0:02:17,000
Pólvora, cañón.

43
0:02:17.952,000 --> 0:02:2,000
Y muy pronto, la armadura y los castillos fueron obsoletos,

44
0:02:21.769,000 --> 0:02:23,000
e importó menos a quién se traía al campo de batalla

45
0:02:24.302,000 --> 0:02:27,000
versus cuánta gente se traía al campo de batalla.

46
0:02:28.081,000 --> 0:02:31,000
Y conforme los ejércitos crecieron en tamaño, los Estado-naciones surgieron

47
0:02:31.719,000 --> 0:02:34,000
como un requisito político y logístico de defensa.

48
0:02:35.399,000 --> 0:02:37,000
Y conforme los líderes tuvieron que depender más de su población,

49
0:02:37.775,000 --> 0:02:38,000
empezaron a compartir el poder.

50
0:02:39.608,000 --> 0:02:41,000
Se comenzó a formar el gobierno representativo.

51
0:02:42.207,000 --> 0:02:45,000
Repito, las herramientas que utilizamos para resolver conflictos

52
0:02:45.495,000 --> 0:02:48,000
dan forma a nuestro panorama social.

53
0:02:48.799,000 --> 0:02:52,000
Las armas robóticas autónomas son esas herramientas,

54
0:02:52.863,000 --> 0:02:57,000
salvo que, al exigir que muy pocas personas vayan a la guerra,

55
0:02:58.031,000 --> 0:03:02,000
se corre el riesgo de re-centralizar el poder en muy pocas manos,

56
0:03:02.871,000 --> 0:03:08,000
posiblemente revirtiendo una tendencia de cinco siglos hacia la democracia.

57
0:03:09.386,000 --> 0:03:1,000
Creo que, sabiendo esto,

58
0:03:11.143,000 --> 0:03:15,000
podemos tomar medidas decisivas para preservar nuestras instituciones democráticas,

59
0:03:15.495,000 --> 0:03:18,000
para hacer lo que los seres humanos saben hacer mejor, que es adaptarse.

60
0:03:19.474,000 --> 0:03:21,000
Pero el tiempo es un factor.

61
0:03:21.479,000 --> 0:03:23,000
Setenta naciones están desarrollando sus propios robots

62
0:03:24.33,000 --> 0:03:26,000
de combate controlados a distancia

63
0:03:26.487,000 --> 0:03:28,000
y como veremos, los drones de combate controlados remotamente

64
0:03:29.08,000 --> 0:03:33,000
son los precursores de las armas robóticas autónomas.

65
0:03:33.552,000 --> 0:03:35,000
Eso es porque una vez se han desplegado drones piloteados remotamente

66
0:03:36.319,000 --> 0:03:39,000
hay tres factores poderosos que influyen en la toma de decisiones

67
0:03:39.703,000 --> 0:03:43,000
lejos de los humanos y en la misma plataforma del arma.

68
0:03:44.303,000 --> 0:03:49,000
El primero de ellos es el diluvio de vídeos que producen los robots.

69
0:03:49.562,000 --> 0:03:52,000
Por ejemplo, en 2004, la flota de drones de los Estados Unidos produjo

70
0:03:53.415,000 --> 0:03:58,000
un total de 71 horas de vigilancia con video para el análisis.

71
0:03:58.727,000 --> 0:04:02,000
En el 2011, ésta se había elevado a 300 mil horas,

72
0:04:03.226,000 --> 0:04:06,000
superando la capacidad humana para revisarla toda,

73
0:04:06.375,000 --> 0:04:09,000
y aun ese número está a punto de subir drásticamente.

74
0:04:10.039,000 --> 0:04:12,000
El Gorgon Stare y los programas Argus del Pentágono

75
0:04:12.614,000 --> 0:04:15,000
pondrán hasta 65 cámaras que operan independientemente

76
0:04:15.778,000 --> 0:04:17,000
en cada plataforma de los drones,

77
0:04:17.816,000 --> 0:04:2,000
y esto superaría enormemente la capacidad humana para revisarlas.

78
0:04:21.119,000 --> 0:04:23,000
Y eso significa que se necesitará software de inteligencia visual

79
0:04:23.279,000 --> 0:04:27,000
para escanear elementos de interés.

80
0:04:27.327,000 --> 0:04:28,000
Y eso significa que muy pronto

81
0:04:28.675,000 --> 0:04:3,000
los drones dirán a los humanos qué mirar,

82
0:04:31.422,000 --> 0:04:33,000
y no al revés.

83
0:04:33.919,000 --> 0:04:35,000
Pero hay un segundo incentivo poderoso que aleja

84
0:04:36.392,000 --> 0:04:39,000
la toma de decisiones de los humanos y la acerca a las máquinas,

85
0:04:39.775,000 --> 0:04:41,000
y es la interferencia electromagnética,

86
0:04:42.647,000 --> 0:04:44,000
cortando la conexión entre el robot

87
0:04:44.883,000 --> 0:04:46,000
y su operador.

88
0:04:47.697,000 --> 0:04:49,000
Vimos un ejemplo de esto en 2011

89
0:04:50.315,000 --> 0:04:52,000
Cuando un dron RQ-170 Sentinel norteamericano

90
0:04:53.271,000 --> 0:04:57,000
se confundió en Irán debido a un ataque de "suplantación" de GPS,

91
0:04:57.578,000 --> 0:05:02,000
pero cualquier robot controlado remotamente es susceptible a este tipo de ataques,

92
0:05:02.692,000 --> 0:05:04,000
y eso significa que los drones

93
0:05:04.744,000 --> 0:05:07,000
tendrán que asumir más la toma de decisiones.

94
0:05:08.364,000 --> 0:05:11,000
Sabrán el objetivo de la misión,

95
0:05:11.407,000 --> 0:05:15,000
y reaccionarán a nuevas circunstancias sin ayuda humana.

96
0:05:16.252,000 --> 0:05:18,000
Ignorarán las señales de radio externas

97
0:05:18.833,000 --> 0:05:2,000
y enviarán muy pocas suyas.

98
0:05:21.163,000 --> 0:05:23,000
Lo que nos lleva, realmente, al tercer

99
0:05:23.169,000 --> 0:05:26,000
y más poderoso incentivo de llevar la toma de decisiones

100
0:05:27.031,000 --> 0:05:3,000
de los seres humanos a las armas:

101
0:05:30.373,000 --> 0:05:33,000
negación plausible.

102
0:05:33.666,000 --> 0:05:35,000
Vivimos en una economía global.

103
0:05:36.553,000 --> 0:05:4,000
La fabricación de alta tecnología ocurre en la mayoría de los continentes.

104
0:05:40.887,000 --> 0:05:42,000
El ciberespionaje está impulsando diseños muy avanzados

105
0:05:43.801,000 --> 0:05:44,000
a lugares desconocidos,

106
0:05:45.687,000 --> 0:05:47,000
y en ese ambiente, es muy probable

107
0:05:47.701,000 --> 0:05:51,000
que un diseño exitoso de drones se reproduzca en fábricas contratadas,

108
0:05:52.435,000 --> 0:05:54,000
y prolifere en el mercado negro.

109
0:05:54.605,000 --> 0:05:56,000
Y en esa situación, al investigar en los restos

110
0:05:57.065,000 --> 0:05:59,000
de un ataque suicida de drone, será muy difícil decir

111
0:06:00.025,000 --> 0:06:04,000
quién envió esa arma.

112
0:06:04.425,000 --> 0:06:06,000
Esto plantea la posibilidad muy real

113
0:06:07.225,000 --> 0:06:09,000
de una guerra anónima.

114
0:06:10.16,000 --> 0:06:12,000
Esto podría poner el equilibrio geopolítico de cabeza,

115
0:06:12.774,000 --> 0:06:15,000
y que a una nación le resulte muy difícil activar su potencia de ataque

116
0:06:16.265,000 --> 0:06:18,000
contra un atacante, lo cual podría inclinar la balanza

117
0:06:19.113,000 --> 0:06:22,000
en el siglo XXI de la defensa hacia la ofensiva.

118
0:06:22.877,000 --> 0:06:25,000
Podría hacer de la acción militar una opción viable

119
0:06:26.001,000 --> 0:06:28,000
no sólo para las naciones pequeñas,

120
0:06:28.289,000 --> 0:06:3,000
sino para las organizaciones criminales, las empresas privadas,

121
0:06:30.834,000 --> 0:06:32,000
e incluso para individuos poderosos.

122
0:06:33.313,000 --> 0:06:36,000
Podría crear un paisaje de caudillos rivales

123
0:06:36.641,000 --> 0:06:39,000
socavando el estado de derecho y la sociedad civil.

124
0:06:40.321,000 --> 0:06:43,000
Si la responsabilidad y la transparencia

125
0:06:43.937,000 --> 0:06:45,000
son dos de los pilares del gobierno representativo,

126
0:06:46.321,000 --> 0:06:5,000
las armas robóticas autónomas podrían socavar a ambos.

127
0:06:50.641,000 --> 0:06:51,000
Pueden estar pensando que

128
0:06:52.187,000 --> 0:06:54,000
los ciudadanos de naciones con alta tecnología

129
0:06:54.433,000 --> 0:06:56,000
tendrían la ventaja en cualquier guerra robótica,

130
0:06:57.136,000 --> 0:07:,000
que los ciudadanos de esas naciones serían menos vulnerables,

131
0:07:00.769,000 --> 0:07:04,000
particularmente contra los países en desarrollo.

132
0:07:05.057,000 --> 0:07:08,000
Pero creo que en realidad es exactamente lo contrario.

133
0:07:08.581,000 --> 0:07:1,000
Creo que los ciudadanos de las sociedades de alta tecnología

134
0:07:10.832,000 --> 0:07:13,000
son más vulnerables a las armas robóticas,

135
0:07:14.561,000 --> 0:07:18,000
y la razón puede resumirse en una palabra: datos.

136
0:07:19.026,000 --> 0:07:22,000
Los datos empoderan a las sociedades de alta tecnología.

137
0:07:22.507,000 --> 0:07:25,000
Geolocalización por teléfono celular, metadatos de telecomunicaciones,

138
0:07:25.697,000 --> 0:07:28,000
redes sociales, correo electrónico, mensajes de texto, datos de transacciones financieras,

139
0:07:29.169,000 --> 0:07:32,000
datos de transporte, es una riqueza de datos en tiempo real

140
0:07:32.701,000 --> 0:07:35,000
sobre los movimientos y las interacciones sociales de las personas.

141
0:07:36.074,000 --> 0:07:39,000
En resumen, somos más visibles para las máquinas

142
0:07:39.849,000 --> 0:07:41,000
que ninguna otra persona en la historia, y esto se adapta

143
0:07:42.091,000 --> 0:07:47,000
perfectamente a las necesidades de selección de las armas autónomas.

144
0:07:47.707,000 --> 0:07:48,000
Lo que están viendo aquí

145
0:07:49.445,000 --> 0:07:52,000
es un mapa de análisis de los vínculos de un grupo social.

146
0:07:52.691,000 --> 0:07:55,000
Las líneas indican la conectividad social entre individuos.

147
0:07:56.325,000 --> 0:07:58,000
Y estos tipos de mapas se pueden generar automáticamente

148
0:07:59.205,000 --> 0:08:03,000
basados en la la estela de datos que la gente moderna deja.

149
0:08:03.92,000 --> 0:08:05,000
Esto se utiliza normalmente para el mercadeo de bienes y servicios

150
0:08:06.397,000 --> 0:08:1,000
a un grupo objetivo específico, pero esta es una tecnología de doble uso,

151
0:08:10.813,000 --> 0:08:13,000
porque se define un grupo objetivo en otro contexto.

152
0:08:14.173,000 --> 0:08:16,000
Tenga en cuenta que ciertos individuos sobresalen.

153
0:08:16.733,000 --> 0:08:19,000
Estos son los ejes de las redes sociales.

154
0:08:20.013,000 --> 0:08:23,000
Estos son los organizadores, los creadores de opinión, los líderes,

155
0:08:23.603,000 --> 0:08:25,000
y a estas personas también se les puede identificar automáticamente

156
0:08:26.285,000 --> 0:08:28,000
por sus patrones de comunicación.

157
0:08:28.667,000 --> 0:08:3,000
En el caso de un vendedor, este podría seleccionarlos

158
0:08:30.813,000 --> 0:08:32,000
con muestras de productos, intentando difundir su marca

159
0:08:33.356,000 --> 0:08:35,000
a través de su grupo social.

160
0:08:36.185,000 --> 0:08:37,000
Pero un gobierno represivo

161
0:08:38.138,000 --> 0:08:42,000
buscando enemigos políticos podría en cambio removerlos,

162
0:08:42.948,000 --> 0:08:44,000
eliminarlos, destruir su grupo social,

163
0:08:45.708,000 --> 0:08:48,000
y aquellos que queden perderían cohesión social

164
0:08:48.877,000 --> 0:08:5,000
y organización.

165
0:08:51.498,000 --> 0:08:54,000
En un mundo en que proliferan las armas robóticas baratas,

166
0:08:54.822,000 --> 0:08:56,000
las fronteras ofrecerían muy poca protección

167
0:08:57.457,000 --> 0:08:58,000
a los críticos de los gobiernos distantes

168
0:08:59.403,000 --> 0:09:02,000
o de organizaciones criminales transnacionales.

169
0:09:03.049,000 --> 0:09:06,000
Los movimientos populares que buscan el cambio

170
0:09:06.542,000 --> 0:09:09,000
puede detectarse tempranamente para eliminar a sus líderes

171
0:09:10.151,000 --> 0:09:12,000
antes de que sus ideas adquieran masa crítica.

172
0:09:13.062,000 --> 0:09:15,000
Y de lo que se trata en un gobierno popular es

173
0:09:15.653,000 --> 0:09:18,000
que las ideas alcancen masa critica.

174
0:09:19.589,000 --> 0:09:22,000
Las armas letales anónimas podrían hacer de la acción letal

175
0:09:23.586,000 --> 0:09:26,000
una opción fácil para todo tipo de intereses en juego.

176
0:09:27.368,000 --> 0:09:3,000
Y esto pondría en jaque a la libertad de expresión

177
0:09:31.102,000 --> 0:09:36,000
y a la acción política popular, la esencia de la democracia.

178
0:09:36.41,000 --> 0:09:38,000
Y por esta razón necesitamos un tratado internacional

179
0:09:39.324,000 --> 0:09:42,000
sobre las armas robóticas y en particular una prohibición mundial

180
0:09:42.864,000 --> 0:09:45,000
sobre el desarrollo y el despliegue de robots asesinos.

181
0:09:46.772,000 --> 0:09:49,000
Ya tenemos tratados internacionales

182
0:09:50.026,000 --> 0:09:53,000
sobre armas nucleares y biológicas, que aunque imperfectos,

183
0:09:53.412,000 --> 0:09:55,000
han funcionado en gran medida.

184
0:09:55.7,000 --> 0:09:58,000
Pero las armas robóticas pueden ser igual de peligrosas,

185
0:09:59.468,000 --> 0:10:02,000
porque muy seguramente se utilizarán,

186
0:10:02.756,000 --> 0:10:07,000
y también serían dañinas para nuestras instituciones democráticas.

187
0:10:07.783,000 --> 0:10:1,000
En noviembre de 2012, el Departamento de Defensa de los Estados Unidos

188
0:10:11.251,000 --> 0:10:13,000
emitió una directiva que exige

189
0:10:13.709,000 --> 0:10:17,000
que un ser humano esté presente en todas las decisiones letales.

190
0:10:18.228,000 --> 0:10:22,000
Esto prohibió efectiva aunque temporalmente las armas autónomas en el ejército estadounidense,

191
0:10:23.004,000 --> 0:10:26,000
pero dicha directiva debe hacerse permanente.

192
0:10:26.757,000 --> 0:10:3,000
Y podría sentar las bases para la acción global.

193
0:10:31.133,000 --> 0:10:34,000
Porque necesitamos un marco jurídico internacional

194
0:10:34.978,000 --> 0:10:36,000
sobre armas robóticas.

195
0:10:37.116,000 --> 0:10:39,000
Y lo necesitamos ahora, antes de un ataque devastador

196
0:10:40.044,000 --> 0:10:43,000
o un incidente terrorista que haga que las naciones del mundo

197
0:10:43.196,000 --> 0:10:44,000
se vean obligadas a adoptar estas armas

198
0:10:45.12,000 --> 0:10:48,000
antes de pensar en las consecuencias.

199
0:10:48.891,000 --> 0:10:5,000
Las armas robóticas autónomas concentran demasiado poder

200
0:10:51.872,000 --> 0:10:57,000
en muy pocas manos y pondría en peligro la propia democracia.

201
0:10:58.155,000 --> 0:11:,000
No me malinterpreten, creo que hay toneladas

202
0:11:00.841,000 --> 0:11:02,000
de aplicaciones geniales para los drones civiles desarmados:

203
0:11:03.459,000 --> 0:11:06,000
control ambiental, búsqueda y rescate, logística.

204
0:11:07.398,000 --> 0:11:09,000
Si tenemos un tratado internacional sobre armas robóticas,

205
0:11:10.224,000 --> 0:11:13,000
¿cómo obtenemos los beneficios de los drones y vehículos

206
0:11:13.811,000 --> 0:11:15,000
autónomos y al mismo tiempo nos protegernos

207
0:11:16.459,000 --> 0:11:19,000
contra las armas robóticas ilegales?

208
0:11:20.439,000 --> 0:11:24,000
Creo que el secreto será la transparencia.

209
0:11:25.18,000 --> 0:11:28,000
No debería existir una expectativa de privacidad de un robot

210
0:11:28.193,000 --> 0:11:31,000
en un lugar público.

211
0:11:31.644,000 --> 0:11:36,000
(Aplausos)

212
0:11:36.692,000 --> 0:11:38,000
Cada robot y drone deben tener

213
0:11:38.737,000 --> 0:11:4,000
una identificación de fábrica firmada criptográficamente

214
0:11:41.62,000 --> 0:11:43,000
que pueda utilizarse para seguir sus movimientos en los espacios públicos.

215
0:11:44.543,000 --> 0:11:47,000
Tenemos placas en los coches, números de matricula en los aviones.

216
0:11:47.924,000 --> 0:11:48,000
Esto no es diferente.

217
0:11:49.765,000 --> 0:11:51,000
Y todos los ciudadanos deberían poder descargar una aplicación

218
0:11:51.777,000 --> 0:11:54,000
que muestre la población de drones y vehículos autónomos

219
0:11:54.902,000 --> 0:11:56,000
moviéndose a través de espacios públicos alrededor de ellos,

220
0:11:57.331,000 --> 0:11:59,000
tanto en ese momento como en un histórico.

221
0:12:00.064,000 --> 0:12:03,000
Y los líderes civiles deben desplegar sensores y drones civiles

222
0:12:03.612,000 --> 0:12:05,000
para detectar los drones no autorizados,

223
0:12:05.956,000 --> 0:12:08,000
y en lugar de enviar drones asesinos propios para derribarlos,

224
0:12:09.132,000 --> 0:12:11,000
deben notificar a los humanos de su presencia.

225
0:12:12.124,000 --> 0:12:14,000
Y en ciertas áreas de muy alta seguridad,

226
0:12:14.73,000 --> 0:12:15,000
tal vez los drones civiles deban capturarlos

227
0:12:16.639,000 --> 0:12:18,000
y arrastrarlos a una instalación de eliminación de explosivos.

228
0:12:19.48,000 --> 0:12:22,000
Pero tengan en cuenta que esto es más un sistema inmunológico

229
0:12:22.507,000 --> 0:12:23,000
que un sistema de armas.

230
0:12:23.828,000 --> 0:12:25,000
Esto nos permitiría valernos del uso

231
0:12:26.42,000 --> 0:12:28,000
de drones y vehículos autónomos

232
0:12:28.452,000 --> 0:12:32,000
y al mismo tiempo salvaguardar nuestra abierta sociedad civil.

233
0:12:32.747,000 --> 0:12:34,000
Hay que prohibir el despliegue y desarrollo

234
0:12:35.746,000 --> 0:12:36,000
de robots asesinos.

235
0:12:37.608,000 --> 0:12:41,000
No caigamos en la tentación de automatizar la guerra.

236
0:12:42.458,000 --> 0:12:44,000
Los gobiernos autocráticos y las organizaciones criminales

237
0:12:45.176,000 --> 0:12:47,000
sin duda lo harán, pero nosotros no.

238
0:12:48.132,000 --> 0:12:49,000
Las armas robóticas autónomas

239
0:12:50.023,000 --> 0:12:52,000
concentrarían demasiado poder

240
0:12:52.074,000 --> 0:12:54,000
en muy pocas manos invisibles,

241
0:12:54.556,000 --> 0:12:57,000
y eso sería corrosivo para un gobierno representativo.

242
0:12:57.811,000 --> 0:12:59,000
Asegurémonos de que al menos para las democracias,

243
0:13:00.772,000 --> 0:13:02,000
los robots asesinos sigan siendo ficción.

244
0:13:03.376,000 --> 0:13:04,000
Gracias.

245
0:13:04.486,000 --> 0:13:08,000
(Aplausos)

246
0:13:09.051,000 --> 0:13:13,000
Gracias. (Aplausos)

