1
0:00:,000 --> 0:00:07,000
Traducteur: Chiara Pecoraro Relecteur: Elisabeth Buffard

2
0:00:12.988,000 --> 0:00:14,000
Laissez-moi vous raconter une histoire,

3
0:00:15.304,000 --> 0:00:17,000
qui se passe il y a 200 millions d'années.

4
0:00:17.563,000 --> 0:00:18,000
C'est l'histoire du néocortex.

5
0:00:19.087,000 --> 0:00:2,000
Ce qui signifie « nouvelle écorce ».

6
0:00:21.061,000 --> 0:00:23,000
Chez les mammifères primitifs,

7
0:00:23.492,000 --> 0:00:25,000
car seuls les mammifères ont un néocortex,

8
0:00:25.547,000 --> 0:00:26,000
des créatures proches des rongeurs,

9
0:00:27.211,000 --> 0:00:29,000
il était de la taille et de l'épaisseur d'un timbre poste

10
0:00:30.17,000 --> 0:00:32,000
et formait une fine pellicule autour

11
0:00:32.229,000 --> 0:00:34,000
de leur cerveau pas plus gros qu'une noix,

12
0:00:34.493,000 --> 0:00:37,000
mais il était capable d'une nouvelle façon de réfléchir.

13
0:00:38.194,000 --> 0:00:42,000
Plutôt que les comportements prédéfinis des animaux autres que les mammifères,

14
0:00:42.303,000 --> 0:00:44,000
il pouvait inventer de nouveaux comportements.

15
0:00:44.735,000 --> 0:00:46,000
Par exemple, une souris fuit un prédateur,

16
0:00:47.138,000 --> 0:00:5,000
sa voie est bloquée, elle va essayer d'inventer une nouvelle solution.

17
0:00:50.868,000 --> 0:00:52,000
Ça peut marcher ou pas, mais si c'est le cas,

18
0:00:53.267,000 --> 0:00:55,000
elle s'en souviendra et adoptera un nouveau comportement,

19
0:00:55.502,000 --> 0:00:58,000
qui pourra alors se propager tel un virus au reste de la communauté.

20
0:00:58.647,000 --> 0:01:,000
Une autre souris en l'observant pourrait se dire,

21
0:01:01.026,000 --> 0:01:03,000
« Contourner cette pierre, c'était assez futé. »

22
0:01:03.69,000 --> 0:01:06,000
et pourrait adopter un nouveau comportement elle aussi.

23
0:01:06.825,000 --> 0:01:09,000
Les animaux autres que les mammifères ne pouvaient pas faire ce genre de choses.

24
0:01:10.682,000 --> 0:01:13,000
Ils avaient des comportements prédéfinis. Ils pourraient en apprendre un nouveau,

25
0:01:13.87,000 --> 0:01:14,000
mais leur vie est trop courte pour ça.

26
0:01:15.802,000 --> 0:01:16,000
Au cours d'un millier de vies,

27
0:01:17.754,000 --> 0:01:19,000
il pourrait développer un nouveau comportement prédéfini.

28
0:01:20.734,000 --> 0:01:23,000
Ça fonctionnait bien il y a 200 millions d'années,

29
0:01:23.851,000 --> 0:01:24,000
l'environnement changeait très lentement.

30
0:01:25.832,000 --> 0:01:26,000
Ça pouvait prendre 10 000 ans

31
0:01:27.386,000 --> 0:01:29,000
pour qu'un important changement environnemental ait lieu,

32
0:01:30.14,000 --> 0:01:33,000
pendant ce temps-là, l'animal aurait évolué vers un nouveau comportement.

33
0:01:33.789,000 --> 0:01:34,000
Ça fonctionnait bien,

34
0:01:35.31,000 --> 0:01:36,000
mais alors quelque chose arriva.

35
0:01:37.014,000 --> 0:01:39,000
Il y a 65 millions d'années,

36
0:01:39.15,000 --> 0:01:41,000
il y eut un changement soudain et violent de l'environnement.

37
0:01:42.035,000 --> 0:01:45,000
On l'appelle l'extinction du Crétacé-Tertiaire.

38
0:01:45.38,000 --> 0:01:47,000
C'est à ce moment que les dinosaures ont disparu,

39
0:01:48.213,000 --> 0:01:53,000
où 75% des espèces d'animaux et de plantes ont disparu

40
0:01:53.872,000 --> 0:01:54,000
et c'est aussi là que les mammifères

41
0:01:55.613,000 --> 0:01:57,000
ont dépassé leur niche écologique,

42
0:01:57.765,000 --> 0:02:,000
et si j'anthropomorphise, l'évolution biologique se dit alors :

43
0:02:01.419,000 --> 0:02:03,000
« Le néocortex, c'est assez chouette. »

44
0:02:03.444,000 --> 0:02:04,000
et commença alors à le faire grossir.

45
0:02:05.237,000 --> 0:02:06,000
Alors les mammifères ont grandi

46
0:02:07.109,000 --> 0:02:09,000
leurs cerveaux ont grossi à un rythme encore plus rapide,

47
0:02:09.904,000 --> 0:02:12,000
et le néocortex a grossi encore plus vite

48
0:02:13.301,000 --> 0:02:15,000
et a développé ces stries et ces plis qui lui sont propres

49
0:02:16.23,000 --> 0:02:18,000
pour étendre sa surface essentiellement.

50
0:02:19.111,000 --> 0:02:2,000
Si vous preniez un néocortex humain

51
0:02:20.93,000 --> 0:02:23,000
et l'étiriez au maximum, il est environ de la taille d'une serviette de table

52
0:02:23.951,000 --> 0:02:26,000
tout en restant fin. Environ de l'épaisseur d'une serviette de table.

53
0:02:27.53,000 --> 0:02:29,000
Mais il a tant de circonvolutions et de stries

54
0:02:29.727,000 --> 0:02:32,000
qu'il représente à présent 80% de notre cerveau,

55
0:02:32.802,000 --> 0:02:34,000
et c'est dans cette partie que nous réfléchissons,

56
0:02:35.263,000 --> 0:02:36,000
c'est le grand transcendeur.

57
0:02:37.024,000 --> 0:02:38,000
On a toujours notre vieux cerveau

58
0:02:38.878,000 --> 0:02:4,000
qui nous fournit nos pulsions et nos motivations primitifs,

59
0:02:41.182,000 --> 0:02:43,000
mais si j'ai une volonté de conquête,

60
0:02:43.618,000 --> 0:02:45,000
cette dernière va être exprimée par le néocortex

61
0:02:46.333,000 --> 0:02:48,000
dans la rédaction d'un poème ou l'invention d'une application

62
0:02:49.242,000 --> 0:02:51,000
ou encore dans la réalisation d'un TED Talk,

63
0:02:51.751,000 --> 0:02:53,000
et c'est vraiment là, dans le néocortex,

64
0:02:54.373,000 --> 0:02:55,000
que l'action se passe.

65
0:02:56.341,000 --> 0:02:57,000
Il y a 50 ans, j'ai écrit un article

66
0:02:58.268,000 --> 0:03:,000
décrivant comment je pensais que le cerveau fonctionnait,

67
0:03:00.316,000 --> 0:03:02,000
et je le décrivais comme une série de modules.

68
0:03:03.175,000 --> 0:03:05,000
Chaque module pouvait faire des choses selon un modèle,

69
0:03:05.693,000 --> 0:03:08,000
et aussi apprendre un modèle, s'en rappeler, et l'implémenter.

70
0:03:09.456,000 --> 0:03:11,000
Et ces modules s'organisaient selon une hiérarchie,

71
0:03:12.135,000 --> 0:03:14,000
nous créions cette hiérarchie avec notre réflexion.

72
0:03:15.089,000 --> 0:03:19,000
on n'en savait peu là-dessus il y a 50 ans.

73
0:03:19.984,000 --> 0:03:21,000
Ça m'a conduit à rencontrer le président Johnson.

74
0:03:22.099,000 --> 0:03:24,000
J'y ai réfléchi depuis 50 ans,

75
0:03:24.272,000 --> 0:03:26,000
et il y a un an et demi je publiais le livre

76
0:03:27.1,000 --> 0:03:28,000
"How to Create a Mind" (Comment créer un esprit)

77
0:03:28.365,000 --> 0:03:29,000
qui soutient la même théorie,

78
0:03:30.005,000 --> 0:03:32,000
mais à l'heure actuelle il y a pléthore de preuves.

79
0:03:32.79,000 --> 0:03:33,000
La quantité de données concernant le cerveau

80
0:03:34.604,000 --> 0:03:36,000
qui nous vient des neurosiences double chaque année.

81
0:03:37.087,000 --> 0:03:39,000
La résolution du scanner cérébral

82
0:03:39.461,000 --> 0:03:41,000
double elle aussi chaque année.

83
0:03:41.746,000 --> 0:03:43,000
Nous pouvons observer l'intérieur d'un cerveau vivant

84
0:03:43.923,000 --> 0:03:45,000
et ainsi voir ses connections neurologiques

85
0:03:46.333,000 --> 0:03:48,000
se faire et s'activer en temps réel.

86
0:03:49.036,000 --> 0:03:51,000
Nous pouvons voir votre cerveau créer vos pensées.

87
0:03:51.455,000 --> 0:03:52,000
Nous pouvons voir vos pensées créer votre cerveau,

88
0:03:53.39,000 --> 0:03:54,000
ce qui est essentiel pour expliquer son fonctionnement.

89
0:03:55.029,000 --> 0:03:57,000
Laissez-moi vous le décrire simplement.

90
0:03:57.248,000 --> 0:03:59,000
J'ai en réalité compté ces modules.

91
0:03:59.523,000 --> 0:04:01,000
Nous en avons environ 300 millions,

92
0:04:01.569,000 --> 0:04:03,000
et nous les créons en hiérarchies.

93
0:04:03.798,000 --> 0:04:05,000
Je vais vous donner un exemple simple.

94
0:04:05.88,000 --> 0:04:07,000
J'ai un ensemble de modules

95
0:04:08.685,000 --> 0:04:11,000
qui reconnaisse la barre horizontale de la lettre A,

96
0:04:12.088,000 --> 0:04:13,000
et c'est tout ce dont ils s'occupent.

97
0:04:14.002,000 --> 0:04:17,000
On peut diffuser une jolie chanson, une jolie fille peut passer devant vous,

98
0:04:17.03,000 --> 0:04:19,000
ils n'en ont rien à faire, mais s'ils rencontrent la barre de la A

99
0:04:19.98,000 --> 0:04:21,000
ils deviennent alors très actifs et disent 'barre',

100
0:04:22.881,000 --> 0:04:24,000
et placent alors une importante probabilité

101
0:04:24.993,000 --> 0:04:25,000
sur leur axone de sortie.

102
0:04:26.627,000 --> 0:04:27,000
On passe au niveau suivant,

103
0:04:28.2,000 --> 0:04:3,000
et ces couches sont organisées en différents niveaux conceptuels,

104
0:04:31.09,000 --> 0:04:34,000
chacun plus abstrait que le suivant. Le suivant pourrait alors dire "A",

105
0:04:34.986,000 --> 0:04:37,000
le message va au niveau supérieur qui pourrait dire "Apple" (pomme)

106
0:04:38.045,000 --> 0:04:39,000
L'information va aussi dans le sens inverse.

107
0:04:40.042,000 --> 0:04:44,000
Si le détecteur d'APPLE voit A-P-P-L, il va alors se dire :

108
0:04:44.298,000 --> 0:04:46,000
« Je pense que la prochaine lettre sera probablement un E »

109
0:04:46.957,000 --> 0:04:48,000
et enverra alors signal aux détecteurs de E, leur disant :

110
0:04:49.371,000 --> 0:04:51,000
« soyez prêts à trouver un E, je pense qu'il y en a un qui arrive. »

111
0:04:52.26,000 --> 0:04:54,000
Les détecteurs de E vont alors baisser leur seuil

112
0:04:54.779,000 --> 0:04:56,000
et même si le symbole est approximatif, le prendront pour un E.

113
0:04:57.464,000 --> 0:04:59,000
« D'ordinaire ce n'est pas le cas, mais ici on attend un E,

114
0:04:59.864,000 --> 0:05:01,000
donc c'est bon. Oui, je vois un E. », ensuite le détecteur d'APPLE dit :

115
0:05:02.3,000 --> 0:05:03,000
« Oui, j'ai bien vu APPLE ».

116
0:05:04.038,000 --> 0:05:05,000
L'information monte encore de cinq niveaux,

117
0:05:05.924,000 --> 0:05:07,000
et là on est assez haut dans la hiérarchie,

118
0:05:08.447,000 --> 0:05:1,000
et tiraillé entre les différents sens.

119
0:05:10.789,000 --> 0:05:12,000
Vous avez un module qui reconnaît un tissu

120
0:05:13.444,000 --> 0:05:15,000
est réceptif à une voix, sent un parfum,

121
0:05:16.288,000 --> 0:05:18,000
et va alors dire : « ma femme est entrée dans la pièce ».

122
0:05:18.801,000 --> 0:05:19,000
Dix niveaux plus hauts,

123
0:05:20.696,000 --> 0:05:23,000
et là vous êtes à un très haut niveau. probablement dans le cortex frontal,

124
0:05:24.316,000 --> 0:05:27,000
et vous aurez des modules qui disent : « C'était ironique.

125
0:05:27.56,000 --> 0:05:29,000
C'est drôle. Elle est jolie. »

126
0:05:29.93,000 --> 0:05:31,000
Vous pourriez penser que c'est plus sophistiqué,

127
0:05:32.035,000 --> 0:05:36,000
mais en fait, le plus compliqué, c'est la hiérarchie sous-jacente.

128
0:05:36.211,000 --> 0:05:38,000
Une jeune fille de 16 ans qui était opérée du cerveau,

129
0:05:38.83,000 --> 0:05:4,000
elle restait consciente car le chirurgien

130
0:05:40.881,000 --> 0:05:42,000
voulait maintenir le dialogue avec elle.

131
0:05:42.918,000 --> 0:05:44,000
C'est possible car il n'y a pas de récepteur de douleur dans le cerveau.

132
0:05:45.278,000 --> 0:05:49,000
Et lorsqu'ils stimulaient des points très particuliers dans son néocortex,

133
0:05:49.541,000 --> 0:05:51,000
représentés ici en rouge, elle se mettait à rire.

134
0:05:52.096,000 --> 0:05:55,000
Au début, ils pensaient qu'ils déclenchaient un réflexe du rire,

135
0:05:55.386,000 --> 0:05:57,000
mais ils ont vite découvert qu'ils avaient trouvé

136
0:05:57.885,000 --> 0:06:,000
le point de son néocortex qui détecte l'humour,

137
0:06:00.929,000 --> 0:06:01,000
et elle trouvait alors absolument tout hilarant

138
0:06:02.898,000 --> 0:06:04,000
dès qu'ils stimulaient ces points.

139
0:06:05.335,000 --> 0:06:06,000
Elle répétait :

140
0:06:06.56,000 --> 0:06:08,000
« Vous êtes tellement drôles tous debout autour de moi »

141
0:06:09.398,000 --> 0:06:1,000
alors qu'ils n'étaient pas drôles,

142
0:06:11.3,000 --> 0:06:14,000
du moins pas pendant l'opération.

143
0:06:14.547,000 --> 0:06:18,000
Alors, où en sommes-nous ajourd'hui ?

144
0:06:19.377,000 --> 0:06:22,000
Eh bien, les ordinateurs commencent à maîtriser

145
0:06:22.431,000 --> 0:06:26,000
les langues grâce à des techniques similaires à celles du néocortex.

146
0:06:27.322,000 --> 0:06:28,000
J'ai décrit l'algorithme,

147
0:06:28.813,000 --> 0:06:3,000
qui est similaire à un système appelé

148
0:06:30.867,000 --> 0:06:32,000
modèle hiérarchique de Markov caché,

149
0:06:33.1,000 --> 0:06:36,000
ce sur quoi je travaille depuis les années 90.

150
0:06:36.341,000 --> 0:06:39,000
Jeopardy est un jeu télévisé portant sur le langage,

151
0:06:39.579,000 --> 0:06:42,000
et Watson a obtenu un score plus important que les deux autres réunis.

152
0:06:43.421,000 --> 0:06:45,000
Il a répondu correctement à cette question :

153
0:06:45.97,000 --> 0:06:47,000
« Un long et ennuyeux discours énoncé

154
0:06:48.525,000 --> 0:06:51,000
par un mousseux nappage de tarte », et il répondit rapidement :

155
0:06:51.593,000 --> 0:06:53,000
« Comment nomme-t-on une diatribe de meringue ? »

156
0:06:53.843,000 --> 0:06:55,000
Jennings et l'autre joueur n'ont pas compris.

157
0:06:56.198,000 --> 0:06:58,000
C'est un exemple précis de la façon

158
0:06:58.234,000 --> 0:07:,000
dont les ordinateurs comprennent le langage humain,

159
0:07:00.298,000 --> 0:07:02,000
et ils l'apprennent en fait en lisant Wikipedia

160
0:07:02.85,000 --> 0:07:04,000
et de plusieurs autres encyclopédies.

161
0:07:04.915,000 --> 0:07:06,000
D'ici 5 à 10 ans,

162
0:07:07.048,000 --> 0:07:09,000
les moteurs de recherche se baseront non seulement

163
0:07:09.506,000 --> 0:07:11,000
sur les combinaisons de mots et de liens,

164
0:07:12.026,000 --> 0:07:13,000
mais bien sur leur compréhension.

165
0:07:13.94,000 --> 0:07:15,000
D'où la lecture de milliards de pages

166
0:07:16.351,000 --> 0:07:18,000
sur internet comme dans des livres.

167
0:07:19.084,000 --> 0:07:22,000
Donc vous vous baladerez et alors Google s'affichera et vous dira :

168
0:07:22.63,000 --> 0:07:25,000
« Mary, il y a un mois vous m'avez exprimé votre préoccupation

169
0:07:25.871,000 --> 0:07:27,000
concernant votre complément en glutathion

170
0:07:28.21,000 --> 0:07:3,000
qui ne passait pas la barrière hématoméningée.

171
0:07:30.441,000 --> 0:07:32,000
Eh bien une nouvelle recherche vient d'être publiée il y a 13 secondes

172
0:07:32.974,000 --> 0:07:33,000
décrivant une toute nouvelle approche,

173
0:07:34.946,000 --> 0:07:36,000
une nouvelle façon d'assimiler le gluthation.

174
0:07:37.118,000 --> 0:07:38,000
Lassez-moi vous en faire un résumé."

175
0:07:38.89,000 --> 0:07:41,000
D'ici 20 ans, nous aurons des nano-robots,

176
0:07:42.574,000 --> 0:07:43,000
car une des nouvelles tendances à forte évolution

177
0:07:44.381,000 --> 0:07:45,000
est la miniaturisation de la technologie.

178
0:07:46.316,000 --> 0:07:47,000
Ils entreront dans notre cerveau

179
0:07:48.186,000 --> 0:07:49,000
à travers nos vaisseaux capillaires

180
0:07:49.889,000 --> 0:07:51,000
et connecteront simplement notre néocortex

181
0:07:52.366,000 --> 0:07:55,000
à un néocortex synthétique dans le cloud,

182
0:07:55.551,000 --> 0:07:58,000
nous en fournissant ainsi une extension.

183
0:07:59.142,000 --> 0:08:,000
A l'heure actuelle,

184
0:08:00.72,000 --> 0:08:01,000
vous avez un ordinateur dans votre téléphone,

185
0:08:02.53,000 --> 0:08:04,000
mais si vous avez besoin de 10 000 ordinateurs pour quelques secondes

186
0:08:05.274,000 --> 0:08:09,000
pour faire une recherche complexe, vous pouvez y avoir accès dans le cloud.

187
0:08:09.895,000 --> 0:08:12,000
Dans les années 2030, si vous avez besoin d'une extension de néocortex,

188
0:08:12.99,000 --> 0:08:14,000
vous pourrez vous y connecter via le cloud

189
0:08:15.263,000 --> 0:08:16,000
directement depuis votre cerveau.

190
0:08:16.911,000 --> 0:08:17,000
Imaginons que je me balade et je me dis,

191
0:08:18.454,000 --> 0:08:2,000
« Oh, je vais croiser Chris Anderson, il vient vers moi.

192
0:08:21.377,000 --> 0:08:23,000
Il faut que je trouve quelque chose d'intelligent à dire...

193
0:08:24.037,000 --> 0:08:25,000
J'ai trois secondes pour ça.

194
0:08:25.551,000 --> 0:08:27,000
Les 300 millions de modules de mon néocortex

195
0:08:28.298,000 --> 0:08:29,000
ne seront pas suffisants.

196
0:08:29.538,000 --> 0:08:3,000
J'en ai besoin d'un milliard de plus. »

197
0:08:30.784,000 --> 0:08:33,000
Je serai alors capable d'y accéder via le cloud.

198
0:08:34.107,000 --> 0:08:36,000
Alors nous disposerons d'un système de pensée hybride

199
0:08:36.919,000 --> 0:08:39,000
fonctionnant sur des composants biologiques et non biologiques,

200
0:08:40.441,000 --> 0:08:41,000
mais la partie non-biologique

201
0:08:42.339,000 --> 0:08:44,000
est sujette à ma loi du retour accéléré.

202
0:08:45.021,000 --> 0:08:47,000
Elle va grandir de manière exponentielle.

203
0:08:47.26,000 --> 0:08:5,000
Souvenez-vous alors ce qu'il s'est passé il y a deux millions d'années

204
0:08:50.346,000 --> 0:08:52,000
la dernière fois que nous avons agrandi notre néocortex,

205
0:08:53.347,000 --> 0:08:55,000
lorsque nous sommes devenus des humanoïdes et reçu ce grand front.

206
0:08:56.183,000 --> 0:08:58,000
Les autres primates ont des sourcils inclinés.

207
0:08:58.76,000 --> 0:08:59,000
Ils n'ont pas de cortex frontal.

208
0:09:00.505,000 --> 0:09:03,000
Mais le cortex frontal n'est pas vraiment différent qualitativement parlant.

209
0:09:04.19,000 --> 0:09:06,000
C'est une expansion en taille du néocortex,

210
0:09:06.933,000 --> 0:09:08,000
mais cette quantité additionnelle de capacité de réflexion

211
0:09:09.636,000 --> 0:09:1,000
nous a permis alors de prendre

212
0:09:11.415,000 --> 0:09:14,000
une longueur d'avance et de créer le langage

213
0:09:14.761,000 --> 0:09:15,000
ainsi que l'art et la technologie

214
0:09:16.728,000 --> 0:09:17,000
et les conférences TED.

215
0:09:18.182,000 --> 0:09:2,000
Aucune autre espèce n'a fait ça.

216
0:09:20.313,000 --> 0:09:22,000
Par conséquent, au cours des prochaines décénnies,

217
0:09:22.658,000 --> 0:09:23,000
nous allons répéter ça.

218
0:09:24.148,000 --> 0:09:26,000
Nous allons à nouveau agrandir notre néocortex,

219
0:09:26.422,000 --> 0:09:28,000
seulement cette fois, nous ne serons pas limités

220
0:09:29.108,000 --> 0:09:32,000
à un contenu fixe.

221
0:09:32.458,000 --> 0:09:35,000
Il pourra grossir sans limite.

222
0:09:35.762,000 --> 0:09:37,000
Cette quantité additionnelle sera à nouveau

223
0:09:38.055,000 --> 0:09:4,000
le facteur nous permettant un gigantesque progrès

224
0:09:41.01,000 --> 0:09:42,000
dans les domaines de la culture et de la technologie.

225
0:09:42.645,000 --> 0:09:44,000
Merci beaucoup.

226
0:09:44.699,000 --> 0:09:47,000
(Applaudissements)

