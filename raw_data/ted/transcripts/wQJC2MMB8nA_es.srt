1
0:00:,000 --> 0:00:07,000
Traductor: Carlo Dezerega Revisor: Veronica Vera

2
0:00:15.26,000 --> 0:00:17,000
La seguridad es dos cosas diferentes:

3
0:00:17.26,000 --> 0:00:19,000
es una sensación, y es una realidad.

4
0:00:19.26,000 --> 0:00:21,000
Y son diferentes.

5
0:00:21.26,000 --> 0:00:23,000
Podrían sentirse seguros

6
0:00:23.26,000 --> 0:00:25,000
aun cuando no lo estén.

7
0:00:25.26,000 --> 0:00:27,000
Y pueden estar seguros

8
0:00:27.26,000 --> 0:00:29,000
aun cuando no se sientan seguros.

9
0:00:29.26,000 --> 0:00:31,000
En realidad, tenemos dos conceptos distintos

10
0:00:31.26,000 --> 0:00:33,000
asignados a la misma palabra.

11
0:00:33.26,000 --> 0:00:35,000
Y lo que quiero hacer en esta charla

12
0:00:35.26,000 --> 0:00:37,000
es separar el uno del otro

13
0:00:37.26,000 --> 0:00:39,000
y darnos cuenta de cuándo divergen

14
0:00:39.26,000 --> 0:00:41,000
y de cómo convergen.

15
0:00:41.26,000 --> 0:00:43,000
Y en realidad el lenguaje es un problema para esto.

16
0:00:43.26,000 --> 0:00:45,000
No hay muchas palabras útiles

17
0:00:45.26,000 --> 0:00:48,000
para los conceptos que vamos a describir.

18
0:00:48.26,000 --> 0:00:5,000
Así que si miran la seguridad

19
0:00:50.26,000 --> 0:00:52,000
del punto de vista económico,

20
0:00:52.26,000 --> 0:00:54,000
se trata de intercambiar una cosa por otra.

21
0:00:54.26,000 --> 0:00:56,000
Cada vez que obtienen un poco de seguridad,

22
0:00:56.26,000 --> 0:00:58,000
siempre están intercambiándola por otra cosa.

23
0:00:58.26,000 --> 0:01:,000
Sea esta es una decisión personal

24
0:01:00.26,000 --> 0:01:02,000
-si van a instalar una alarma antirrobo en su hogar-

25
0:01:02.26,000 --> 0:01:05,000
o una decisión nacional -si van a invadir otro país-

26
0:01:05.26,000 --> 0:01:07,000
van a sacrificar algo,

27
0:01:07.26,000 --> 0:01:1,000
ya sea dinero o tiempo, comodidad, capacidad,

28
0:01:10.26,000 --> 0:01:13,000
quizás libertades fundamentales.

29
0:01:13.26,000 --> 0:01:16,000
Y lo que deben preguntarse cuando miran algo de seguridad

30
0:01:16.26,000 --> 0:01:19,000
no es si esto nos hace más seguros,

31
0:01:19.26,000 --> 0:01:22,000
sino que si vale la pena el sacrificio.

32
0:01:22.26,000 --> 0:01:24,000
Han escuchado durante los últimos años que

33
0:01:24.26,000 --> 0:01:26,000
el mundo es más seguro porque Saddam Hussein no gobierna Irak.

34
0:01:26.26,000 --> 0:01:29,000
Eso puede ser cierto, pero no es terriblemente relevante.

35
0:01:29.26,000 --> 0:01:32,000
La pregunta es: ¿Valió la pena?

36
0:01:32.26,000 --> 0:01:35,000
Y pueden tomar su propia decisión

37
0:01:35.26,000 --> 0:01:37,000
y con eso decidir si la invasión valió la pena.

38
0:01:37.26,000 --> 0:01:39,000
Así se piensa acerca de la seguridad;

39
0:01:39.26,000 --> 0:01:41,000
en términos de decidirse por algo en desmedro de otra cosa.

40
0:01:41.26,000 --> 0:01:44,000
A menudo no hay buenas o malas decisiones en esto.

41
0:01:44.26,000 --> 0:01:46,000
Algunos de nosotros tenemos alarmas antirrobo en la casa

42
0:01:46.26,000 --> 0:01:48,000
y otros no lo tenemos.

43
0:01:48.26,000 --> 0:01:5,000
Y dependerá de donde vivimos,

44
0:01:50.26,000 --> 0:01:52,000
si es que vivimos solos o tenemos familia,

45
0:01:52.26,000 --> 0:01:54,000
la cantidad de cosas preciadas que tengamos,

46
0:01:54.26,000 --> 0:01:56,000
cuánto riesgo de robo

47
0:01:56.26,000 --> 0:01:58,000
estemos dispuestos a aceptar.

48
0:01:58.26,000 --> 0:02:,000
En la política también

49
0:02:00.26,000 --> 0:02:02,000
hay diferentes opiniones.

50
0:02:02.26,000 --> 0:02:04,000
Muchas veces, estos sacrificios

51
0:02:04.26,000 --> 0:02:06,000
son sobre más que sólo seguridad,

52
0:02:06.26,000 --> 0:02:08,000
y creo que eso es muy importante.

53
0:02:08.26,000 --> 0:02:1,000
Ahora, la gente tiene una intuición natural

54
0:02:10.26,000 --> 0:02:12,000
sobre estos sacrificios.

55
0:02:12.26,000 --> 0:02:14,000
Los hacemos todos los días;

56
0:02:14.26,000 --> 0:02:16,000
anoche en mi habitación de hotel,

57
0:02:16.26,000 --> 0:02:18,000
cuando decidí cerrar la puerta con doble llave,

58
0:02:18.26,000 --> 0:02:2,000
o cuando ustedes conducían para acá en su automóvil,

59
0:02:20.26,000 --> 0:02:22,000
cuando vamos a almorzar

60
0:02:22.26,000 --> 0:02:25,000
y decidimos que la comida no tiene veneno y la comemos.

61
0:02:25.26,000 --> 0:02:27,000
Tomamos estas decisiones una y otra vez

62
0:02:27.26,000 --> 0:02:29,000
muchas veces al día.

63
0:02:29.26,000 --> 0:02:31,000
A menudo ni siquiera nos damos cuenta.

64
0:02:31.26,000 --> 0:02:33,000
Son parte de estar vivo, todos lo hacemos.

65
0:02:33.26,000 --> 0:02:36,000
Todas las especies lo hacen.

66
0:02:36.26,000 --> 0:02:38,000
Imaginen un conejo en un campo, comiendo pasto,

67
0:02:38.26,000 --> 0:02:41,000
y el conejo repentinamente ve un zorro.

68
0:02:41.26,000 --> 0:02:43,000
Ese conejo tomará una decisión para su seguridad:

69
0:02:43.26,000 --> 0:02:45,000
"¿Debo quedarme o debo huir?"

70
0:02:45.26,000 --> 0:02:47,000
Y si lo piensan,

71
0:02:47.26,000 --> 0:02:5,000
los conejos que toman la decisión apropiada

72
0:02:50.26,000 --> 0:02:52,000
tienden a vivir y reproducirse,

73
0:02:52.26,000 --> 0:02:54,000
y los conejos que no lo hacen bien

74
0:02:54.26,000 --> 0:02:56,000
son comidos o se mueren de hambre.

75
0:02:56.26,000 --> 0:02:58,000
Así que uno pensaría

76
0:02:58.26,000 --> 0:03:01,000
que nosotros, como una especie exitosa en el planeta

77
0:03:01.26,000 --> 0:03:03,000
-ustedes, yo, todos nosotros-

78
0:03:03.26,000 --> 0:03:06,000
seríamos muy buenos para elegir una cosa en vez de otra.

79
0:03:06.26,000 --> 0:03:08,000
Y sin embargo observamos que, una y otra vez,

80
0:03:08.26,000 --> 0:03:11,000
somos irremediablemente malos para esto.

81
0:03:11.26,000 --> 0:03:14,000
Y creo que eso es una pregunta fundamentalmente interesante.

82
0:03:14.26,000 --> 0:03:16,000
Les daré la respuesta corta.

83
0:03:16.26,000 --> 0:03:18,000
La respuesta es que respondemos a la sensación de seguridad

84
0:03:18.26,000 --> 0:03:21,000
y no a la realidad.

85
0:03:21.26,000 --> 0:03:24,000
Ahora, la mayoría de las veces, eso funciona.

86
0:03:25.26,000 --> 0:03:27,000
La mayor parte del tiempo

87
0:03:27.26,000 --> 0:03:3,000
la sensación y la realidad son iguales.

88
0:03:30.26,000 --> 0:03:32,000
Sin duda eso es cierto

89
0:03:32.26,000 --> 0:03:35,000
para casi toda la prehistoria humana.

90
0:03:35.26,000 --> 0:03:38,000
Hemos desarrollado esta habilidad

91
0:03:38.26,000 --> 0:03:4,000
porque obedece la lógica evolutiva.

92
0:03:40.26,000 --> 0:03:42,000
Una manera de pensarlo

93
0:03:42.26,000 --> 0:03:44,000
es que estamos altamente optimizados

94
0:03:44.26,000 --> 0:03:46,000
para tomar decisiones sobre riesgos endémicos

95
0:03:46.26,000 --> 0:03:49,000
a los que viven en pequeños grupos familiares

96
0:03:49.26,000 --> 0:03:52,000
en las tierras altas de África oriental 100 mil años a. C.,

97
0:03:52.26,000 --> 0:03:55,000
y no tanto para Nueva York el 2010.

98
0:03:56.26,000 --> 0:03:59,000
Ahora bien, hay varios sesgos en la percepción del riesgo.

99
0:03:59.26,000 --> 0:04:01,000
Hay muchos experimentos buenos sobre esto.

100
0:04:01.26,000 --> 0:04:04,000
Y pueden ver ciertos sesgos que surgen una y otra vez.

101
0:04:04.26,000 --> 0:04:06,000
Y les voy a dar cuatro.

102
0:04:06.26,000 --> 0:04:09,000
Tendemos a exagerar los riesgos espectaculares e inusuales

103
0:04:09.26,000 --> 0:04:11,000
y minimizar los riesgos comunes;

104
0:04:11.26,000 --> 0:04:14,000
por eso la diferencia entre volar y manejar.

105
0:04:14.26,000 --> 0:04:16,000
Lo desconocido es percibido

106
0:04:16.26,000 --> 0:04:19,000
como más riesgoso que lo familiar.

107
0:04:20.26,000 --> 0:04:22,000
Un ejemplo sería que

108
0:04:22.26,000 --> 0:04:25,000
la gente teme ser secuestrada por desconocidos

109
0:04:25.26,000 --> 0:04:28,000
y los datos muestran que ser secuestrado por familiares es mucho más común.

110
0:04:28.26,000 --> 0:04:3,000
Esto se aplica para niños.

111
0:04:30.26,000 --> 0:04:33,000
En tercer lugar, los riesgos personificados

112
0:04:33.26,000 --> 0:04:36,000
son percibidos como mayores que los riesgos anónimos;

113
0:04:36.26,000 --> 0:04:39,000
por eso Bin Laden da más miedo porque tiene nombre.

114
0:04:39.26,000 --> 0:04:41,000
Y el cuarto es que

115
0:04:41.26,000 --> 0:04:43,000
la gente subestima los riesgos

116
0:04:43.26,000 --> 0:04:45,000
en situaciones donde tienen el control

117
0:04:45.26,000 --> 0:04:49,000
y los sobreestiman en situaciones que no controlan.

118
0:04:49.26,000 --> 0:04:52,000
Así que cuando practicas paracaidismo o fumas

119
0:04:52.26,000 --> 0:04:54,000
minimizas los riesgos de estos.

120
0:04:54.26,000 --> 0:04:57,000
Si te fuerzan a aceptar un riesgo -el terrorismo es un buen ejemplo-

121
0:04:57.26,000 --> 0:05:,000
lo exagerarás, porque no sientes como si lo controlaras.

122
0:05:02.26,000 --> 0:05:05,000
Hay un montón de sesgos más, de estos sesgos cognitivos,

123
0:05:05.26,000 --> 0:05:08,000
que afectan nuestras decisiones sobre riesgos.

124
0:05:08.26,000 --> 0:05:1,000
Está la heurística de disponibilidad,

125
0:05:10.26,000 --> 0:05:12,000
que significa básicamente

126
0:05:12.26,000 --> 0:05:15,000
que estimamos la probabilidad de cualquier cosa

127
0:05:15.26,000 --> 0:05:19,000
por lo fácil que es pensar en instancias de esto.

128
0:05:19.26,000 --> 0:05:21,000
Y se pueden imaginar cómo funciona eso.

129
0:05:21.26,000 --> 0:05:24,000
Si escuchas mucho sobre ataques de tigre deben haber muchos tigres alrededor.

130
0:05:24.26,000 --> 0:05:27,000
No escuchas hablar de ataques de león así que no hay muchos leones alrededor.

131
0:05:27.26,000 --> 0:05:3,000
Esto funciona hasta que inventas los periódicos.

132
0:05:30.26,000 --> 0:05:32,000
Porque lo que los periódicos hacen

133
0:05:32.26,000 --> 0:05:34,000
es repetir una y otra vez

134
0:05:34.26,000 --> 0:05:36,000
los riesgos inusuales.

135
0:05:36.26,000 --> 0:05:38,000
Le digo a la gente: "si está en las noticias, no te preocupes por eso".

136
0:05:38.26,000 --> 0:05:4,000
Porque, por definición,

137
0:05:40.26,000 --> 0:05:43,000
las noticias son algo que casi nunca sucede.

138
0:05:43.26,000 --> 0:05:45,000
(Risas)

139
0:05:45.26,000 --> 0:05:48,000
Cuando algo es tan común que deja de ser noticia

140
0:05:48.26,000 --> 0:05:5,000
(accidentes automovilísticos, violencia familiar);

141
0:05:50.26,000 --> 0:05:53,000
esos son los riesgos que hay que tener presentes.

142
0:05:53.26,000 --> 0:05:55,000
También somos una especie que contamos historias.

143
0:05:55.26,000 --> 0:05:58,000
Respondemos ante las historias más que a los datos.

144
0:05:58.26,000 --> 0:06:,000
Y tenemos algo de incapacidad aritmética básica.

145
0:06:00.26,000 --> 0:06:03,000
Es decir, el chiste de "Uno, dos, tres, muchos" no se equivoca mucho.

146
0:06:03.26,000 --> 0:06:06,000
Somos muy buenos para los números pequeños.

147
0:06:06.26,000 --> 0:06:08,000
Un mango, dos mangos, tres mangos;

148
0:06:08.26,000 --> 0:06:1,000
diez mil mangos, cien mil mangos:

149
0:06:10.26,000 --> 0:06:13,000
son más mangos de los que puedas comer antes que se pudran.

150
0:06:13.26,000 --> 0:06:16,000
Así que la mitad, un cuarto, un quinto; somos buenos para eso.

151
0:06:16.26,000 --> 0:06:18,000
Uno en un millón, uno en un billón;

152
0:06:18.26,000 --> 0:06:21,000
los dos son casi nunca.

153
0:06:21.26,000 --> 0:06:23,000
Así que tenemos problemas con los riesgos

154
0:06:23.26,000 --> 0:06:25,000
que no son muy frecuentes.

155
0:06:25.26,000 --> 0:06:27,000
Y lo que estos sesgos cognitivos hacen

156
0:06:27.26,000 --> 0:06:3,000
es que actúan como filtros entre nosotros y la realidad.

157
0:06:30.26,000 --> 0:06:32,000
Y el resultado es que

158
0:06:32.26,000 --> 0:06:34,000
la sensación y la realidad se desequilibran,

159
0:06:34.26,000 --> 0:06:37,000
se tornan diferentes.

160
0:06:37.26,000 --> 0:06:4,000
Así que puedes tener la sensación; sentirte más seguro de lo que estás.

161
0:06:40.26,000 --> 0:06:42,000
Hay una sensación irreal de seguridad.

162
0:06:42.26,000 --> 0:06:44,000
O al contrario,

163
0:06:44.26,000 --> 0:06:46,000
y esa es una sensación irreal de inseguridad.

164
0:06:46.26,000 --> 0:06:49,000
Escribo mucho sobre "teatro de seguridad",

165
0:06:49.26,000 --> 0:06:52,000
que son productos que hacen que la gente se sienta segura

166
0:06:52.26,000 --> 0:06:54,000
pero que en realidad no hacen nada.

167
0:06:54.26,000 --> 0:06:56,000
No hay una palabra apropiada para cosas que nos den seguridad,

168
0:06:56.26,000 --> 0:06:58,000
pero que no nos hagan sentir seguros.

169
0:06:58.26,000 --> 0:07:01,000
Quizás esto es lo que se supone que la CIA debería lograr.

170
0:07:03.26,000 --> 0:07:05,000
Y volvamos a la economía.

171
0:07:05.26,000 --> 0:07:09,000
Si la economía, si el mercado, son lo que impulsan a la seguridad

172
0:07:09.26,000 --> 0:07:11,000
y si la gente hace concesiones

173
0:07:11.26,000 --> 0:07:14,000
basadas en su sensación de seguridad,

174
0:07:14.26,000 --> 0:07:16,000
entonces lo más inteligente que las empresas pueden hacer

175
0:07:16.26,000 --> 0:07:18,000
por sus propios incentivos económicos

176
0:07:18.26,000 --> 0:07:21,000
es lograr la gente se sienta segura.

177
0:07:21.26,000 --> 0:07:24,000
Y hay dos maneras de hacer esto.

178
0:07:24.26,000 --> 0:07:26,000
Uno, pueden hacer que la gente realmente esté segura

179
0:07:26.26,000 --> 0:07:28,000
y esperar que se den cuenta.

180
0:07:28.26,000 --> 0:07:31,000
O dos, pueden hacer que la gente se sienta segura

181
0:07:31.26,000 --> 0:07:34,000
y esperar que no se den cuenta.

182
0:07:35.26,000 --> 0:07:38,000
Entonces, ¿qué hace que la gente se dé cuenta?

183
0:07:38.26,000 --> 0:07:4,000
Bueno, un par de cosas:

184
0:07:40.26,000 --> 0:07:42,000
entender qué es la seguridad,

185
0:07:42.26,000 --> 0:07:44,000
los riesgos, las amenazas,

186
0:07:44.26,000 --> 0:07:47,000
las medidas previas, cómo funcionan.

187
0:07:47.26,000 --> 0:07:49,000
Pero si sabes esas cosas,

188
0:07:49.26,000 --> 0:07:52,000
es más probable que tus sensaciones calcen con la realidad.

189
0:07:52.26,000 --> 0:07:55,000
Ayuda tener suficientes ejemplos del mundo real.

190
0:07:55.26,000 --> 0:07:58,000
Ahora todos sabemos la tasa de crímenes en nuestro vecindario,

191
0:07:58.26,000 --> 0:08:01,000
porque vivimos allí y tenemos una sensación al respecto

192
0:08:01.26,000 --> 0:08:04,000
que esencialmente calza con la realidad.

193
0:08:04.26,000 --> 0:08:07,000
El teatro de seguridad queda expuesto

194
0:08:07.26,000 --> 0:08:1,000
cuando es obvio que no está funcionando correctamente.

195
0:08:10.26,000 --> 0:08:14,000
Y entonces, ¿qué hace que la gente no se dé cuenta?

196
0:08:14.26,000 --> 0:08:16,000
Bueno, una mala comprensión.

197
0:08:16.26,000 --> 0:08:19,000
Si no entiendes los riesgos, no entiendes los costos,

198
0:08:19.26,000 --> 0:08:21,000
es probable que tomes una mala decisión,

199
0:08:21.26,000 --> 0:08:24,000
y que tu sensación no corresponda con la realidad.

200
0:08:24.26,000 --> 0:08:26,000
Ejemplos insuficientes:

201
0:08:26.26,000 --> 0:08:28,000
Hay un problema intrínseco

202
0:08:28.26,000 --> 0:08:3,000
con eventos de baja probabilidad.

203
0:08:30.26,000 --> 0:08:32,000
Si, por ejemplo, casi nunca hay

204
0:08:32.26,000 --> 0:08:34,000
actos terroristas,

205
0:08:34.26,000 --> 0:08:36,000
es muy difícil medir cuan eficientes

206
0:08:36.26,000 --> 0:08:39,000
son las medidas en la lucha contra el terrorismo.

207
0:08:40.26,000 --> 0:08:43,000
Por eso sigues sacrificando vírgenes,

208
0:08:43.26,000 --> 0:08:46,000
y la razón que tus defensas de unicornio estén funcionando de maravilla.

209
0:08:46.26,000 --> 0:08:49,000
No hay suficientes ejemplos de fracasos.

210
0:08:50.26,000 --> 0:08:53,000
Además, las sensaciones que nublan los temas;

211
0:08:53.26,000 --> 0:08:55,000
los sesgos cognitivos que mencioné antes,

212
0:08:55.26,000 --> 0:08:58,000
los miedos, las creencias populares,

213
0:08:58.26,000 --> 0:09:01,000
son básicamente un modelo inadecuado de la realidad.

214
0:09:02.26,000 --> 0:09:05,000
Y déjenme complicar las cosas.

215
0:09:05.26,000 --> 0:09:07,000
Está la sensación y la realidad.

216
0:09:07.26,000 --> 0:09:1,000
Quiero añadir un tercer elemento. Quiero añadir el modelo.

217
0:09:10.26,000 --> 0:09:12,000
Sensación y modelo dentro de nuestra cabeza,

218
0:09:12.26,000 --> 0:09:14,000
la realidad es el mundo exterior.

219
0:09:14.26,000 --> 0:09:17,000
No cambia, es real.

220
0:09:17.26,000 --> 0:09:19,000
Y la sensación se basa en la intuición.

221
0:09:19.26,000 --> 0:09:21,000
El modelamiento se basa en la razón.

222
0:09:21.26,000 --> 0:09:24,000
Eso es básicamente la diferencia.

223
0:09:24.26,000 --> 0:09:26,000
En un mundo primitivo y simple,

224
0:09:26.26,000 --> 0:09:29,000
no hay ninguna razón real para un modelo.

225
0:09:29.26,000 --> 0:09:32,000
Porque la sensación es muy similar a la realidad.

226
0:09:32.26,000 --> 0:09:34,000
No necesitas un modelo.

227
0:09:34.26,000 --> 0:09:36,000
Pero en un mundo moderno y complejo,

228
0:09:36.26,000 --> 0:09:38,000
necesitas modelos para

229
0:09:38.26,000 --> 0:09:41,000
comprender muchos de los riesgos que enfrentamos.

230
0:09:42.26,000 --> 0:09:44,000
Los gérmenes no nos generan una sensación.

231
0:09:44.26,000 --> 0:09:47,000
Se necesita un modelo para entenderlos.

232
0:09:47.26,000 --> 0:09:49,000
Así que este modelo es una

233
0:09:49.26,000 --> 0:09:52,000
representación inteligente de la realidad.

234
0:09:52.26,000 --> 0:09:55,000
Está, por supuesto, limitado por la ciencia,

235
0:09:55.26,000 --> 0:09:57,000
por la tecnología.

236
0:09:57.26,000 --> 0:10:,000
No podríamos tener una teoría de los gérmenes en enfermedades

237
0:10:00.26,000 --> 0:10:03,000
antes de que inventáramos el microscopio para verlos.

238
0:10:04.26,000 --> 0:10:07,000
Está limitado por nuestros prejuicios cognitivos.

239
0:10:07.26,000 --> 0:10:09,000
Pero tiene la capacidad de

240
0:10:09.26,000 --> 0:10:11,000
imponerse por sobre nuestras sensaciones.

241
0:10:11.26,000 --> 0:10:14,000
¿De dónde obtenemos estos modelos? De los demás.

242
0:10:14.26,000 --> 0:10:17,000
Los obtenemos de la religión, de la cultura,

243
0:10:17.26,000 --> 0:10:19,000
de los profesores, de los mayores.

244
0:10:19.26,000 --> 0:10:21,000
Hace un par de años

245
0:10:21.26,000 --> 0:10:23,000
estaba de safari en Sudáfrica.

246
0:10:23.26,000 --> 0:10:26,000
El guía con que estaba había crecido en el Parque Nacional Kruger.

247
0:10:26.26,000 --> 0:10:29,000
Tenía unos modelos de supervivencia muy complejos.

248
0:10:29.26,000 --> 0:10:31,000
Y dependía de si habías sido atacado

249
0:10:31.26,000 --> 0:10:33,000
por un león o un leopardo o un rinoceronte o un elefante

250
0:10:33.26,000 --> 0:10:36,000
-y cuando tenías que huir, y cuando tenías que subirte a un árbol,

251
0:10:36.26,000 --> 0:10:38,000
cuando no podías en ningún caso subirte a un árbol-.

252
0:10:38.26,000 --> 0:10:41,000
Me habría muerto en un día

253
0:10:41.26,000 --> 0:10:43,000
pero él nació allí

254
0:10:43.26,000 --> 0:10:45,000
y entendía cómo sobrevivir.

255
0:10:45.26,000 --> 0:10:47,000
Yo nací en Nueva York.

256
0:10:47.26,000 --> 0:10:5,000
Lo podría haber llevado a Nueva York y él se habría muerto en un día.

257
0:10:50.26,000 --> 0:10:52,000
(Risas)

258
0:10:52.26,000 --> 0:10:54,000
Porque teníamos modelos diferentes

259
0:10:54.26,000 --> 0:10:57,000
basados en nuestras experiencias diferentes.

260
0:10:58.26,000 --> 0:11:,000
Los modelos pueden provenir de los medios,

261
0:11:00.26,000 --> 0:11:03,000
de nuestros políticos electos.

262
0:11:03.26,000 --> 0:11:06,000
Piensen en los modelos de terrorismo,

263
0:11:06.26,000 --> 0:11:09,000
de secuestro infantil,

264
0:11:09.26,000 --> 0:11:11,000
de seguridad aérea, seguridad de los vehículos.

265
0:11:11.26,000 --> 0:11:14,000
Los modelos pueden provenir de la industria.

266
0:11:14.26,000 --> 0:11:16,000
Los dos que estoy siguiendo son las cámaras de vigilancia

267
0:11:16.26,000 --> 0:11:18,000
y las tarjetas de identificación,

268
0:11:18.26,000 --> 0:11:21,000
muchos de nuestros modelos de seguridad informática vienen de esto.

269
0:11:21.26,000 --> 0:11:24,000
Muchos de los modelos provienen de la ciencia.

270
0:11:24.26,000 --> 0:11:26,000
Un muy buen ejemplo son los modelos de salud.

271
0:11:26.26,000 --> 0:11:29,000
Piensen en cáncer, en gripe aviar, en gripe porcina, en SARS.

272
0:11:29.26,000 --> 0:11:32,000
Todas nuestras sensaciones de seguridad

273
0:11:32.26,000 --> 0:11:34,000
acerca de esas enfermedades

274
0:11:34.26,000 --> 0:11:36,000
provienen, en realidad, de los modelos

275
0:11:36.26,000 --> 0:11:39,000
entregados a nosotros por la ciencia filtrada a través de los medios.

276
0:11:40.26,000 --> 0:11:43,000
Y los modelos pueden cambiar.

277
0:11:43.26,000 --> 0:11:45,000
Los modelos no son estáticos.

278
0:11:45.26,000 --> 0:11:48,000
A medida que nos sentimos más cómodos en nuestros ambientes,

279
0:11:48.26,000 --> 0:11:52,000
nuestro modelo se va acercando a nuestra sensación.

280
0:11:53.26,000 --> 0:11:55,000
Así que un ejemplo podría ser,

281
0:11:55.26,000 --> 0:11:57,000
si nos remontamos 100 años atrás

282
0:11:57.26,000 --> 0:12:,000
cuando la electricidad se tornaba cada vez más común,

283
0:12:00.26,000 --> 0:12:02,000
había un montón de temores con respecto a esta.

284
0:12:02.26,000 --> 0:12:04,000
Quiero decir, había personas que tenían miedo de presionar un timbre

285
0:12:04.26,000 --> 0:12:07,000
ya que había electricidad dentro de él y eso era peligroso.

286
0:12:07.26,000 --> 0:12:1,000
Para nosotros no hay problemas cerca de la electricidad.

287
0:12:10.26,000 --> 0:12:12,000
Cambiamos las ampolletas

288
0:12:12.26,000 --> 0:12:14,000
sin siquiera pensar en ello.

289
0:12:14.26,000 --> 0:12:18,000
Nuestro modelo de seguridad con respecto a la electricidad

290
0:12:18.26,000 --> 0:12:21,000
es algo con lo cual nacemos.

291
0:12:21.26,000 --> 0:12:24,000
No ha cambiado mientras hemos ido creciendo.

292
0:12:24.26,000 --> 0:12:27,000
Y somos buenos para manejarlo.

293
0:12:27.26,000 --> 0:12:29,000
O piensen en los riesgos

294
0:12:29.26,000 --> 0:12:31,000
con respecto a Internet entre generaciones;

295
0:12:31.26,000 --> 0:12:33,000
cómo sus padres determinan la seguridad en Internet

296
0:12:33.26,000 --> 0:12:35,000
frente a cómo lo hacen ustedes

297
0:12:35.26,000 --> 0:12:38,000
frente a cómo lo harán nuestros hijos.

298
0:12:38.26,000 --> 0:12:41,000
Con el tiempo los modelos se van al inconsciente.

299
0:12:42.26,000 --> 0:12:45,000
Intuitivo es sólo otra palabra para familiar.

300
0:12:45.26,000 --> 0:12:47,000
Así que cuando el modelo se acerca a la realidad

301
0:12:47.26,000 --> 0:12:49,000
y converge con las sensaciones,

302
0:12:49.26,000 --> 0:12:52,000
a menudo no te das cuenta que está ahí.

303
0:12:52.26,000 --> 0:12:54,000
Y un buen ejemplo de esto

304
0:12:54.26,000 --> 0:12:57,000
apareció el año pasado con la gripe porcina.

305
0:12:57.26,000 --> 0:12:59,000
Cuando la gripe porcina apareció por primera vez

306
0:12:59.26,000 --> 0:13:03,000
la noticia inicial causó una reacción muy exagerada.

307
0:13:03.26,000 --> 0:13:05,000
Ahora tenía un nombre,

308
0:13:05.26,000 --> 0:13:07,000
lo que la hacía más atemorizante que la gripe común,

309
0:13:07.26,000 --> 0:13:09,000
a pesar de que era más letal.

310
0:13:09.26,000 --> 0:13:13,000
Y la gente pensó que los médicos debían ser capaces de manejarla.

311
0:13:13.26,000 --> 0:13:15,000
Así que estaba esa sensación de falta de control.

312
0:13:15.26,000 --> 0:13:17,000
Y esas dos cosas

313
0:13:17.26,000 --> 0:13:19,000
hacían que el riesgo pareciera más de lo que era.

314
0:13:19.26,000 --> 0:13:22,000
Mientras fue desapareciendo la novedad y pasando los meses,

315
0:13:22.26,000 --> 0:13:24,000
hubo una cantidad de tolerancia,

316
0:13:24.26,000 --> 0:13:26,000
la gente se acostumbró.

317
0:13:26.26,000 --> 0:13:29,000
No hubo datos nuevos, pero había menos temor.

318
0:13:29.26,000 --> 0:13:31,000
Para la llegada del otoño,

319
0:13:31.26,000 --> 0:13:33,000
la gente pensaba

320
0:13:33.26,000 --> 0:13:35,000
que los médicos ya deberían haberlo resuelto.

321
0:13:35.26,000 --> 0:13:37,000
Y hay una especie de bifurcación;

322
0:13:37.26,000 --> 0:13:39,000
la gente tuvo que elegir

323
0:13:39.26,000 --> 0:13:43,000
entre el miedo y la aceptación

324
0:13:43.26,000 --> 0:13:45,000
-en realidad entre el miedo y la indiferencia-

325
0:13:45.26,000 --> 0:13:48,000
y como que en realidad quedaron sospechosos.

326
0:13:48.26,000 --> 0:13:51,000
Y cuando el invierno pasado apareció la vacuna

327
0:13:51.26,000 --> 0:13:54,000
hubo una gran cantidad de personas -un número sorprendente-

328
0:13:54.26,000 --> 0:13:57,000
que se negó a ponérsela;

329
0:13:58.26,000 --> 0:14:,000
un buen ejemplo de

330
0:14:00.26,000 --> 0:14:03,000
cómo cambian las sensaciones de seguridad, cómo cambian sus modelos,

331
0:14:03.26,000 --> 0:14:05,000
un poco descontrolados

332
0:14:05.26,000 --> 0:14:07,000
sin nueva información,

333
0:14:07.26,000 --> 0:14:09,000
sin nuevos inputs.

334
0:14:09.26,000 --> 0:14:12,000
Este tipo de cosas sucede frecuentemente.

335
0:14:12.26,000 --> 0:14:15,000
Les voy a dar una complicación más.

336
0:14:15.26,000 --> 0:14:18,000
Tenemos la sensación, el modelo, la realidad.

337
0:14:18.26,000 --> 0:14:2,000
Tengo una visión muy relativista de la seguridad.

338
0:14:20.26,000 --> 0:14:23,000
Creo que depende del observador.

339
0:14:23.26,000 --> 0:14:25,000
Y la mayoría de las decisiones sobre seguridad

340
0:14:25.26,000 --> 0:14:29,000
involucran a varias personas.

341
0:14:29.26,000 --> 0:14:31,000
Y las partes interesadas,

342
0:14:31.26,000 --> 0:14:34,000
cada una con beneficios y perdidas propias,

343
0:14:34.26,000 --> 0:14:36,000
tratarán de influenciar la decisión.

344
0:14:36.26,000 --> 0:14:38,000
Yo llamo a eso su agenda.

345
0:14:38.26,000 --> 0:14:4,000
Y se pueden ver las agendas

346
0:14:40.26,000 --> 0:14:43,000
-en el marketing, en la política-

347
0:14:43.26,000 --> 0:14:46,000
tratando de convencerlos de elegir un modelo en vez de otro,

348
0:14:46.26,000 --> 0:14:48,000
tratando de convencerlos de ignorar un modelo

349
0:14:48.26,000 --> 0:14:51,000
y de confiar en sus sensaciones,

350
0:14:51.26,000 --> 0:14:54,000
dejando de lado a las personas con modelos que no les gustan.

351
0:14:54.26,000 --> 0:14:57,000
Esto es bastante frecuente.

352
0:14:57.26,000 --> 0:15:,000
Un ejemplo, un gran ejemplo, es el riesgo de fumar.

353
0:15:01.26,000 --> 0:15:04,000
Durante los últimos 50 años, el riesgo de fumar

354
0:15:04.26,000 --> 0:15:06,000
muestra cómo va cambiando un modelo

355
0:15:06.26,000 --> 0:15:09,000
y también muestra cómo una industria pelea contra

356
0:15:09.26,000 --> 0:15:11,000
un modelo que no le gusta.

357
0:15:11.26,000 --> 0:15:14,000
Comparen esto con el debate del humo de segunda mano;

358
0:15:14.26,000 --> 0:15:17,000
el mismo caso probablemente 20 años antes.

359
0:15:17.26,000 --> 0:15:19,000
Piensen acerca de los cinturones de seguridad.

360
0:15:19.26,000 --> 0:15:21,000
Cuando yo era niño, nadie se ponía el cinturón de seguridad.

361
0:15:21.26,000 --> 0:15:23,000
Hoy en día, ningún niño te permite manejar

362
0:15:23.26,000 --> 0:15:25,000
si no lo llevas puesto.

363
0:15:26.26,000 --> 0:15:28,000
Comparen esto con el debate del airbag;

364
0:15:28.26,000 --> 0:15:31,000
probablemente como 30 años atrasado.

365
0:15:31.26,000 --> 0:15:34,000
Todos son ejemplos de modelos que van cambiando.

366
0:15:36.26,000 --> 0:15:39,000
Lo que aprendemos es que cambiar los modelos es difícil.

367
0:15:39.26,000 --> 0:15:41,000
Los modelos son difíciles de desalojar.

368
0:15:41.26,000 --> 0:15:43,000
Si estos son iguales a sus sensaciones,

369
0:15:43.26,000 --> 0:15:46,000
ni siquiera se darán cuenta que tienen un modelo.

370
0:15:46.26,000 --> 0:15:48,000
Y hay otro sesgo cognitivo que

371
0:15:48.26,000 --> 0:15:5,000
llamaré sesgo de confirmación,

372
0:15:50.26,000 --> 0:15:53,000
donde tendemos a aceptar los datos

373
0:15:53.26,000 --> 0:15:55,000
que confirman nuestras creencias

374
0:15:55.26,000 --> 0:15:58,000
y rechazar los datos que las contradicen.

375
0:15:59.26,000 --> 0:16:01,000
Y es probable que ignoremos

376
0:16:01.26,000 --> 0:16:04,000
la evidencia en contra de nuestro modelo, incluso si es convincente.

377
0:16:04.26,000 --> 0:16:07,000
Debe ser súper convincente antes de que le prestemos atención.

378
0:16:08.26,000 --> 0:16:1,000
Aún más complejos son los nuevos modelos que se extenderán por mucho tiempo.

379
0:16:10.26,000 --> 0:16:12,000
El calentamiento global es un gran ejemplo.

380
0:16:12.26,000 --> 0:16:14,000
Somos terribles

381
0:16:14.26,000 --> 0:16:16,000
para modelos que abarcan 80 años.

382
0:16:16.26,000 --> 0:16:18,000
Podemos modelar la próxima cosecha.

383
0:16:18.26,000 --> 0:16:21,000
De repente podemos modelar hasta que nuestros hijos crezcan.

384
0:16:21.26,000 --> 0:16:24,000
Pero simplemente no somos buenos para 80 años.

385
0:16:24.26,000 --> 0:16:27,000
Y entonces es un modelo muy difícil de aceptar.

386
0:16:27.26,000 --> 0:16:31,000
Podemos tener ambos modelos en nuestra cabeza al mismo tiempo,

387
0:16:31.26,000 --> 0:16:34,000
ese tipo de problema

388
0:16:34.26,000 --> 0:16:37,000
donde tenemos ambas creencias al mismo tiempo;

389
0:16:37.26,000 --> 0:16:39,000
la disonancia cognitiva.

390
0:16:39.26,000 --> 0:16:41,000
Con el tiempo,

391
0:16:41.26,000 --> 0:16:44,000
el nuevo modelo reemplazará al antiguo.

392
0:16:44.26,000 --> 0:16:47,000
Las sensaciones fuertes pueden crear un modelo.

393
0:16:47.26,000 --> 0:16:5,000
El 11 de septiembre creó un modelo de seguridad

394
0:16:50.26,000 --> 0:16:52,000
en las mentes de mucha gente.

395
0:16:52.26,000 --> 0:16:55,000
También se pueden crear a través de experiencias personales con crímenes,

396
0:16:55.26,000 --> 0:16:57,000
a través de sustos de salud personales,

397
0:16:57.26,000 --> 0:16:59,000
de problemas de salud en las noticias.

398
0:16:59.26,000 --> 0:17:01,000
Verán estos eventos llamados "flash de luz"

399
0:17:01.26,000 --> 0:17:03,000
por los psiquiatras.

400
0:17:03.26,000 --> 0:17:06,000
Pueden crear un modelo de forma instantánea,

401
0:17:06.26,000 --> 0:17:09,000
porque son muy emotivos.

402
0:17:09.26,000 --> 0:17:11,000
Y en el mundo tecnológico

403
0:17:11.26,000 --> 0:17:13,000
no tenemos experiencia

404
0:17:13.26,000 --> 0:17:15,000
para elegir los modelos.

405
0:17:15.26,000 --> 0:17:17,000
Y dependemos de otros. Dependemos de representantes.

406
0:17:17.26,000 --> 0:17:21,000
Quiero decir, esto funciona mientras sea para corregir a otros.

407
0:17:21.26,000 --> 0:17:23,000
Dependemos de los organismos gubernamentales para

408
0:17:23.26,000 --> 0:17:28,000
que nos digan qué medicamentos son seguros.

409
0:17:28.26,000 --> 0:17:3,000
Volé ayer para acá.

410
0:17:30.26,000 --> 0:17:32,000
No revisé el avión.

411
0:17:32.26,000 --> 0:17:34,000
Confié en algún otro grupo

412
0:17:34.26,000 --> 0:17:37,000
para determinar si mi avión era seguro para volar.

413
0:17:37.26,000 --> 0:17:4,000
Estamos aquí, nadie teme que el techo se vaya a caer sobre nosotros,

414
0:17:40.26,000 --> 0:17:43,000
no porque lo comprobamos,

415
0:17:43.26,000 --> 0:17:45,000
sino porque tenemos bastante confianza que

416
0:17:45.26,000 --> 0:17:48,000
los códigos de construcción son buenos.

417
0:17:48.26,000 --> 0:17:5,000
Es un modelo que simplemente aceptamos

418
0:17:50.26,000 --> 0:17:52,000
sólo por fe.

419
0:17:52.26,000 --> 0:17:55,000
Y eso está bien.

420
0:17:57.26,000 --> 0:17:59,000
Ahora, lo que queremos

421
0:17:59.26,000 --> 0:18:01,000
es que la gente se familiarice lo suficiente

422
0:18:01.26,000 --> 0:18:03,000
con modelos buenos

423
0:18:03.26,000 --> 0:18:05,000
-y que se reflejen en lo que sienten-

424
0:18:05.26,000 --> 0:18:09,000
para que puedan tomar buenas decisiones de seguridad.

425
0:18:09.26,000 --> 0:18:11,000
Y entonces cuando estos se desalinean

426
0:18:11.26,000 --> 0:18:13,000
se tienen dos opciones.

427
0:18:13.26,000 --> 0:18:15,000
Una es arreglar las sensaciones de la gente,

428
0:18:15.26,000 --> 0:18:17,000
apelar directamente a las sensaciones y sentimientos.

429
0:18:17.26,000 --> 0:18:2,000
Es manipulativo, pero puede funcionar.

430
0:18:20.26,000 --> 0:18:22,000
La segunda manera, que es más honesta,

431
0:18:22.26,000 --> 0:18:25,000
es realmente solucionar el modelo.

432
0:18:26.26,000 --> 0:18:28,000
El cambio se produce lentamente.

433
0:18:28.26,000 --> 0:18:31,000
El debate del cigarrillo tomó 40 años,

434
0:18:31.26,000 --> 0:18:34,000
y ese era uno simple.

435
0:18:34.26,000 --> 0:18:36,000
Algunos de estos son difíciles.

436
0:18:36.26,000 --> 0:18:38,000
Quiero decir, sin embargo,

437
0:18:38.26,000 --> 0:18:4,000
que la información parece ser nuestra mejor esperanza.

438
0:18:40.26,000 --> 0:18:42,000
Y les mentí.

439
0:18:42.26,000 --> 0:18:44,000
Recuerdan cuando dije lo de la sensación, el modelo, la realidad.

440
0:18:44.26,000 --> 0:18:47,000
Dije que la realidad no cambia. Pero en verdad sí cambia.

441
0:18:47.26,000 --> 0:18:49,000
Vivimos en un mundo tecnológico;

442
0:18:49.26,000 --> 0:18:52,000
la realidad cambia todo el tiempo.

443
0:18:52.26,000 --> 0:18:55,000
Así que podríamos tener -por primera vez para nuestra especie-

444
0:18:55.26,000 --> 0:18:58,000
la sensación persiguiendo al modelo, el modelo persiguiendo la realidad,

445
0:18:58.26,000 --> 0:19:01,000
la realidad va cambiando; y puede que jamás se vayan a alcanzar.

446
0:19:02.26,000 --> 0:19:04,000
No lo sabemos.

447
0:19:04.26,000 --> 0:19:06,000
Pero en el largo plazo,

448
0:19:06.26,000 --> 0:19:09,000
tanto la sensación como la realidad son importantes.

449
0:19:09.26,000 --> 0:19:12,000
Y quiero cerrar con dos historias rápidas para ilustrar esto.

450
0:19:12.26,000 --> 0:19:14,000
En 1982 -no sé si la gente recordará esto-

451
0:19:14.26,000 --> 0:19:17,000
hubo una epidemia de corta duración

452
0:19:17.26,000 --> 0:19:19,000
de envenenamientos con Tylenol en los Estados Unidos.

453
0:19:19.26,000 --> 0:19:22,000
Es una historia horrible. Alguien tomó una botella de Tylenol,

454
0:19:22.26,000 --> 0:19:25,000
puso veneno en ella, la cerró y volvió a ponerla en el estante.

455
0:19:25.26,000 --> 0:19:27,000
Otra persona la compró y murió.

456
0:19:27.26,000 --> 0:19:29,000
Esto aterrorizó a todo el mundo.

457
0:19:29.26,000 --> 0:19:31,000
Hubo un par de ataques que imitaron esto.

458
0:19:31.26,000 --> 0:19:34,000
No había riesgo real, pero la gente estaba asustada.

459
0:19:34.26,000 --> 0:19:36,000
Y así es como

460
0:19:36.26,000 --> 0:19:38,000
se inventó la industria farmacéutica a prueba de manipulaciones.

461
0:19:38.26,000 --> 0:19:4,000
Esas tapas difíciles de abrir surgieron de esto.

462
0:19:40.26,000 --> 0:19:42,000
Es totalmente teatro de seguridad.

463
0:19:42.26,000 --> 0:19:44,000
Como tarea para la casa piensen en 10 maneras de vulnerarlas.

464
0:19:44.26,000 --> 0:19:47,000
Les daré una; una jeringa.

465
0:19:47.26,000 --> 0:19:5,000
Sin embargo hizo que la gente se sintiera mejor.

466
0:19:50.26,000 --> 0:19:52,000
Hizo que su sensación de seguridad

467
0:19:52.26,000 --> 0:19:54,000
se pareciera más a la realidad.

468
0:19:54.26,000 --> 0:19:57,000
Última historia; hace unos años una amiga mía dio a luz.

469
0:19:57.26,000 --> 0:19:59,000
La visité en el hospital.

470
0:19:59.26,000 --> 0:20:01,000
Resulta que ahora cuando un bebé nace

471
0:20:01.26,000 --> 0:20:03,000
le ponen al bebé una pulsera RFID,

472
0:20:03.26,000 --> 0:20:05,000
le ponen una pulsera relacionada a la madre

473
0:20:05.26,000 --> 0:20:07,000
y si otra persona retira al bebé de la sala de maternidad

474
0:20:07.26,000 --> 0:20:09,000
suena una alarma.

475
0:20:09.26,000 --> 0:20:11,000
Me dije: "Bueno, eso está bien bueno.

476
0:20:11.26,000 --> 0:20:13,000
Me pregunto cuán comunes son los robos de bebé

477
0:20:13.26,000 --> 0:20:15,000
desde los hospitales."

478
0:20:15.26,000 --> 0:20:17,000
Me voy a casa y lo busco.

479
0:20:17.26,000 --> 0:20:19,000
Básicamente no sucede jamás.

480
0:20:19.26,000 --> 0:20:21,000
Pero si lo piensas,

481
0:20:21.26,000 --> 0:20:23,000
si eres un hospital

482
0:20:23.26,000 --> 0:20:25,000
y tienes que alejar al bebé de su madre,

483
0:20:25.26,000 --> 0:20:27,000
fuera de la pieza para tomar algunos exámenes,

484
0:20:27.26,000 --> 0:20:29,000
mejor que tengas un buen teatro de seguridad

485
0:20:29.26,000 --> 0:20:31,000
o te va a arrancar el brazo entero.

486
0:20:31.26,000 --> 0:20:33,000
(Risas)

487
0:20:33.26,000 --> 0:20:35,000
Así que es importante para nosotros,

488
0:20:35.26,000 --> 0:20:37,000
aquellos de nosotros que diseñamos seguridad,

489
0:20:37.26,000 --> 0:20:4,000
que observamos las políticas de seguridad,

490
0:20:40.26,000 --> 0:20:42,000
o incluso miramos a las políticas públicas

491
0:20:42.26,000 --> 0:20:44,000
y las maneras que estas afectan a la seguridad.

492
0:20:44.26,000 --> 0:20:47,000
No es sólo la realidad, es sensación y la realidad.

493
0:20:47.26,000 --> 0:20:49,000
Lo que es importante

494
0:20:49.26,000 --> 0:20:51,000
es que sean más o menos iguales.

495
0:20:51.26,000 --> 0:20:53,000
Es importante que -si nuestras sensaciones calzan con la realidad-

496
0:20:53.26,000 --> 0:20:55,000
tomemos mejores decisiones de seguridad.

497
0:20:55.26,000 --> 0:20:57,000
Gracias.

498
0:20:57.26,000 --> 0:20:59,000
(Aplausos)

