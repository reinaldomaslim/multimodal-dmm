1
0:00:,000 --> 0:00:07,000
Traductor: Paula Motter Revisor: Analia Padin

2
0:00:12.8,000 --> 0:00:15,000
¿Por qué pensamos que los ricos deben pagar más impuestos?

3
0:00:16.4,000 --> 0:00:17,000
¿Por qué compramos el último iPhone?

4
0:00:18.8,000 --> 0:00:2,000
¿Por qué elegimos a nuestra actual pareja?

5
0:00:21.28,000 --> 0:00:23,000
¿Y por qué tanta gente votó por Donald Trump?

6
0:00:24.68,000 --> 0:00:26,000
¿Cuáles fueron los motivos? ¿Por qué lo hicieron?

7
0:00:28.01,000 --> 0:00:29,000
Hacemos estas preguntas todo el tiempo

8
0:00:30.026,000 --> 0:00:31,000
y esperamos que nos den una respuesta.

9
0:00:31.876,000 --> 0:00:34,000
Y cuando nos preguntan a nosotros esperamos poder responder;

10
0:00:35.046,000 --> 0:00:37,000
poder explicar, simplemente, por qué hicimos lo que hicimos.

11
0:00:38.44,000 --> 0:00:39,000
Pero ¿lo sabemos realmente?

12
0:00:41,000 --> 0:00:44,000
Cuando decimos que preferimos a George Clooney sobre Tom Hanks

13
0:00:44.479,000 --> 0:00:45,000
por su compromiso con el medio ambiente,

14
0:00:46.56,000 --> 0:00:47,000
¿es realmente cierto?

15
0:00:48.56,000 --> 0:00:5,000
Se puede ser totalmente sincero y creer genuinamente

16
0:00:51.08,000 --> 0:00:53,000
en el motivo que explica nuestra elección,

17
0:00:54.04,000 --> 0:00:56,000
pero yo creo que algo está faltando.

18
0:00:57.28,000 --> 0:01:,000
Tal como están las cosas, y dada la naturaleza de la subjetividad,

19
0:01:00.766,000 --> 0:01:04,000
resulta muy difícil poder demostrarle a alguien que se ha equivocado.

20
0:01:06.6,000 --> 0:01:08,000
Soy psicólogo experimental,

21
0:01:08.76,000 --> 0:01:11,000
y en el laboratorio hemos estado tratando de resolver este problema.

22
0:01:12.32,000 --> 0:01:14,000
Queríamos diseñar un experimento

23
0:01:14.52,000 --> 0:01:17,000
que nos permitiera cuestionar lo que la gente dice de sí misma,

24
0:01:18.08,000 --> 0:01:2,000
independientemente de cuán segura parezca.

25
0:01:21.7,000 --> 0:01:23,000
Pero engañar a las personas sobre lo que piensan no es fácil,

26
0:01:24.72,000 --> 0:01:25,000
por eso recurrimos a los profesionales:

27
0:01:27.12,000 --> 0:01:28,000
los magos.

28
0:01:29.12,000 --> 0:01:31,000
Son expertos en crear la ilusión de una libre elección.

29
0:01:31.79,000 --> 0:01:33,000
Cuando dicen "Elige cualquier naipe",

30
0:01:34.36,000 --> 0:01:36,000
lo único que sabemos es que esa elección ya no es libre.

31
0:01:38.19,000 --> 0:01:4,000
Pues bien, luego de intercambiar ideas

32
0:01:40.606,000 --> 0:01:41,000
con un grupo de magos suecos,

33
0:01:42.526,000 --> 0:01:43,000
creamos un método

34
0:01:44.147,000 --> 0:01:47,000
para poder manipular el resultado de las decisiones de la gente.

35
0:01:48.76,000 --> 0:01:5,000
De esta manera, podríamos saber cuándo la gente se equivoca,

36
0:01:51.736,000 --> 0:01:53,000
aun sin saberlo.

37
0:01:54.48,000 --> 0:01:58,000
Les mostraré ahora un breve video sobre esta manipulación.

38
0:01:59.16,000 --> 0:02:,000
Es muy simple.

39
0:02:00.6,000 --> 0:02:02,000
Los participantes deben elegir una opción,

40
0:02:02.76,000 --> 0:02:04,000
pero yo les doy la opción que descartaron.

41
0:02:05.04,000 --> 0:02:08,000
Y luego veremos cómo reaccionaron y qué dijeron.

42
0:02:09.24,000 --> 0:02:12,000
Es sencillo, pero traten de detectar dónde está el truco.

43
0:02:13.44,000 --> 0:02:14,000
Esto fue filmado con participantes

44
0:02:15.31,000 --> 0:02:16,000
que no sabían cómo era la prueba.

45
0:02:17.95,000 --> 0:02:18,000
(Video)

46
0:02:19,000 --> 0:02:21,000
P. Johansson: Hola. Soy Petter. Mujer: Hola, soy Becka.

47
0:02:21.62,000 --> 0:02:23,000
PJ: Te mostraré unas fotografías

48
0:02:24.02,000 --> 0:02:27,000
y debes decidir cuál de estas personas te parece más atractiva.

49
0:02:27.19,000 --> 0:02:28,000
Becka: Muy bien.

50
0:02:28.23,000 --> 0:02:31,000
PJ: Y a veces te preguntaré también por qué la elegiste.

51
0:02:32,000 --> 0:02:33,000
Becka: Perfecto.

52
0:02:33.03,000 --> 0:02:34,000
PJ: ¿Lista? Becka: Sí.

53
0:02:43.12,000 --> 0:02:44,000
PJ: ¿Por qué elegiste esa?

54
0:02:44.96,000 --> 0:02:45,000
Becka: Por la sonrisa, creo.

55
0:02:46.48,000 --> 0:02:47,000
PJ: La sonrisa.

56
0:02:52.4,000 --> 0:02:53,000
Hombre: La de la izquierda.

57
0:02:57.52,000 --> 0:02:58,000
De nuevo, simplemente me gusta.

58
0:02:59.76,000 --> 0:03:,000
Una foto interesante.

59
0:03:01.4,000 --> 0:03:04,000
Soy fotógrafo. Me gusta la iluminación y la toma.

60
0:03:06.28,000 --> 0:03:08,000
Petter Johansson: Pero este es el truco.

61
0:03:10.12,000 --> 0:03:11,000
(Video) Mujer 1: Esta.

62
0:03:16.24,000 --> 0:03:18,000
PJ: Les doy la otra foto, no la que eligieron.

63
0:03:20.52,000 --> 0:03:21,000
Y veamos qué ocurre.

64
0:03:28.24,000 --> 0:03:29,000
Mujer 2: Mm...

65
0:03:35.76,000 --> 0:03:37,000
Lo veo más inocente que el hombre de la otra foto.

66
0:03:45.36,000 --> 0:03:46,000
Hombre: La de la izquierda.

67
0:03:49.28,000 --> 0:03:52,000
Me gusta la sonrisa, la forma de la nariz y de la cara.

68
0:03:53,000 --> 0:03:55,000
La veo más interesante; me gusta el peinado.

69
0:04:00.04,000 --> 0:04:01,000
Mujer 3: Esta.

70
0:04:03.52,000 --> 0:04:04,000
Me gusta esa sonrisa afectada.

71
0:04:05.12,000 --> 0:04:07,000
PJ: Te gusta más esa sonrisa.

72
0:04:09.68,000 --> 0:04:12,000
(Risas)

73
0:04:12.88,000 --> 0:04:13,000
Mujer 3: Este.

74
0:04:15.28,000 --> 0:04:16,000
PJ: ¿Por qué lo elegiste?

75
0:04:17.52,000 --> 0:04:19,000
Mujer 3: No sé, se parece un poco al Hobbit.

76
0:04:20.19,000 --> 0:04:21,000
(Risas)

77
0:04:22.52,000 --> 0:04:25,000
PJ: ¿Y qué ocurre cuando al final les digo cómo es el experimento de verdad?

78
0:04:27.16,000 --> 0:04:29,000
Es todo. Ahora te haré unas preguntas.

79
0:04:29.46,000 --> 0:04:3,000
Hombre: Seguro

80
0:04:30.49,000 --> 0:04:32,000
PJ: ¿Qué te pareció? ¿Fácil o difícil?

81
0:04:33.28,000 --> 0:04:34,000
Hombre: Fácil.

82
0:04:36.04,000 --> 0:04:37,000
PJ: Durante el experimento,

83
0:04:37.4,000 --> 0:04:4,000
cambié las fotografías tres veces.

84
0:04:40.76,000 --> 0:04:41,000
¿Lo notaste?

85
0:04:42.36,000 --> 0:04:43,000
Hombre: No, en absoluto.

86
0:04:44.2,000 --> 0:04:45,000
PJ: ¿Para nada? Hombre: No.

87
0:04:45.72,000 --> 0:04:47,000
Cambiar las fotos... ¿en qué sentido?

88
0:04:47.84,000 --> 0:04:5,000
PJ: Claro, tú elegías una, pero yo te daba la otra.

89
0:04:51.43,000 --> 0:04:53,000
Hombre: La otra ... No.

90
0:04:53.51,000 --> 0:04:55,000
Bueno, esto demuestra cuán concentrado estaba.

91
0:04:55.8,000 --> 0:04:56,000
(Risas)

92
0:04:58.88,000 --> 0:05:03,000
PJ: ¿Notaste que durante el experimento a veces yo cambiaba las fotografías?

93
0:05:04.08,000 --> 0:05:06,000
Mujer 2: No, no me di cuenta.

94
0:05:06.12,000 --> 0:05:09,000
PJ: Tú elegías una, pero yo te daba la otra.

95
0:05:09.92,000 --> 0:05:1,000
¿Ninguna sospecha de lo que ocurría?

96
0:05:11.736,000 --> 0:05:12,000
Mujer 2: No.

97
0:05:13.16,000 --> 0:05:14,000
No me di cuenta.

98
0:05:14.44,000 --> 0:05:15,000
(Risas)

99
0:05:16.4,000 --> 0:05:17,000
PJ: Gracias.

100
0:05:17.64,000 --> 0:05:18,000
Mujer 2: Gracias a ti.

101
0:05:19.04,000 --> 0:05:21,000
Petter Johansson: Como habrán notado,

102
0:05:21.116,000 --> 0:05:23,000
el truco es que tengo dos fotos en cada mano

103
0:05:23.256,000 --> 0:05:24,000
y, cuando les entrego una de ellas,

104
0:05:25.046,000 --> 0:05:29,000
la foto negra se confunde con el color negro de la mesa.

105
0:05:30.64,000 --> 0:05:31,000
En este tipo de experimentos,

106
0:05:32.4,000 --> 0:05:36,000
menos del 20 % de los participantes suele detectar el truco.

107
0:05:36.8,000 --> 0:05:37,000
Y como vieron en el video,

108
0:05:38.24,000 --> 0:05:4,000
cuando al final se les cuenta la verdad,

109
0:05:41.44,000 --> 0:05:42,000
se muestran muy sorprendidos

110
0:05:42.85,000 --> 0:05:44,000
y a menudo se resisten a creer que ha habido un truco.

111
0:05:45.84,000 --> 0:05:49,000
Esto demuestra que el efecto es bastante contundente y genuino.

112
0:05:50.49,000 --> 0:05:52,000
Pero si a Uds. les interesa el autoconocimiento, como a mí,

113
0:05:53.32,000 --> 0:05:57,000
la parte más interesante es cómo justificaron sus decisiones.

114
0:05:58.64,000 --> 0:06:01,000
Analizamos las explicaciones que dan los participantes.

115
0:06:03.36,000 --> 0:06:05,000
Este gráfico muestra

116
0:06:06.71,000 --> 0:06:09,000
que si comparamos lo que dicen en un experimento manipulado

117
0:06:10.55,000 --> 0:06:11,000
respecto de uno no manipulado, es decir,

118
0:06:12.546,000 --> 0:06:16,000
cuando explican una decisión real y una donde el resultado es manipulado,

119
0:06:17.36,000 --> 0:06:19,000
vemos que las explicaciones son increíblemente parecidas.

120
0:06:20.106,000 --> 0:06:22,000
Son igual de emocionales, igual de específicas,

121
0:06:22.92,000 --> 0:06:25,000
expresadas con el mismo nivel de certeza.

122
0:06:27.12,000 --> 0:06:29,000
Entonces, la firme conclusión

123
0:06:30.37,000 --> 0:06:31,000
es que si no hay diferencias

124
0:06:31.79,000 --> 0:06:34,000
entre una elección real y una elección manipulada,

125
0:06:35.44,000 --> 0:06:37,000
quizá estemos inventando cosas todo el tiempo.

126
0:06:38.52,000 --> 0:06:39,000
Pero también hicimos estudios

127
0:06:39.976,000 --> 0:06:42,000
donde tratamos de relacionar lo que dicen con la cara que eligen.

128
0:06:43.08,000 --> 0:06:44,000
Y descubrimos esto.

129
0:06:45.76,000 --> 0:06:5,000
Este participante eligió la chica de la izquierda,

130
0:06:50.84,000 --> 0:06:51,000
pero le dimos la foto de la derecha.

131
0:06:52.72,000 --> 0:06:54,000
Y justificó su elección diciendo:

132
0:06:55.56,000 --> 0:06:56,000
"Es radiante.

133
0:06:56.88,000 --> 0:06:58,000
Preferiría acercarme a ella en un bar y no a la otra chica.

134
0:06:59.71,000 --> 0:07:,000
Y me gustan los pendientes".

135
0:07:01.64,000 --> 0:07:04,000
Lo que inicialmente lo llevó a elegir la chica de la izquierda

136
0:07:05.13,000 --> 0:07:08,000
no fueron precisamente los pendientes, pues quien los tenía puestos era la otra.

137
0:07:09.56,000 --> 0:07:12,000
Este es un claro ejemplo de una construcción 'a posteriori':

138
0:07:13.5,000 --> 0:07:15,000
justificaron la decisión después.

139
0:07:17.32,000 --> 0:07:19,000
Este experimento muestra

140
0:07:19.62,000 --> 0:07:22,000
que si no logramos detectar que nuestra elección fue cambiada,

141
0:07:23.32,000 --> 0:07:26,000
inmediatamente intentaremos explicarla de alguna manera.

142
0:07:27.52,000 --> 0:07:29,000
Y descubrimos también que muchas veces los participantes

143
0:07:30.42,000 --> 0:07:33,000
terminan prefiriendo la alternativa que habían elegido bajo un engaño.

144
0:07:34.32,000 --> 0:07:36,000
O sea que, si les damos a elegir de nuevo,

145
0:07:36.36,000 --> 0:07:39,000
eligen la imagen que antes habían rechazado.

146
0:07:41.59,000 --> 0:07:43,000
Este efecto se llama "ceguera a la elección".

147
0:07:43.84,000 --> 0:07:45,000
Hemos hecho una variedad de estudios

148
0:07:46.08,000 --> 0:07:48,000
sobre la elección del consumidor,

149
0:07:48.64,000 --> 0:07:5,000
elecciones realizadas con base en el sabor y el olor

150
0:07:51,000 --> 0:07:53,000
e incluso problemas de razonamiento.

151
0:07:53.08,000 --> 0:07:54,000
Pero lo que queremos saber

152
0:07:54.5,000 --> 0:07:58,000
es si esta conducta también rige decisiones más complejas e importantes.

153
0:07:59.12,000 --> 0:08:02,000
Por ejemplo, las relacionadas con cuestiones morales y políticas.

154
0:08:04.4,000 --> 0:08:07,000
El siguiente experimento requiere cierto contexto.

155
0:08:08.64,000 --> 0:08:12,000
En Suecia, el panorama político

156
0:08:12.92,000 --> 0:08:15,000
está dominado por dos coaliciones: una de derecha y una de izquierda.

157
0:08:17.72,000 --> 0:08:21,000
Y los votantes pueden fluctuar entre partidos dentro de cada coalición,

158
0:08:22.17,000 --> 0:08:24,000
pero hay muy poco movimiento entre una coalición y la otra.

159
0:08:25.68,000 --> 0:08:26,000
Y, antes de cada elección,

160
0:08:27.68,000 --> 0:08:31,000
los periódicos y los institutos de sondeo

161
0:08:31.92,000 --> 0:08:33,000
crearon lo que ellos llaman "una brújula electoral",

162
0:08:34.56,000 --> 0:08:37,000
que consiste en una serie de temas polémicos

163
0:08:37.92,000 --> 0:08:39,000
que dividen a ambas coaliciones.

164
0:08:40.28,000 --> 0:08:43,000
Por ejemplo: si el impuesto a la gasolina debería incrementarse.

165
0:08:44.039,000 --> 0:08:48,000
O si los 13 meses de licencia pagada por paternidad o maternidad

166
0:08:48.249,000 --> 0:08:5,000
deberían dividirse equitativamente entre ambos padres

167
0:08:50.955,000 --> 0:08:52,000
para fomentar la igualdad de género.

168
0:08:54.84,000 --> 0:08:56,000
Pues bien, antes de las últimas elecciones en Suecia,

169
0:08:57.376,000 --> 0:08:59,000
creamos nuestra propia brújula electoral.

170
0:09:00.48,000 --> 0:09:02,000
Salimos a la calle y le preguntamos a la gente

171
0:09:02.79,000 --> 0:09:04,000
si quería participar de una rápida encuesta política.

172
0:09:06,000 --> 0:09:07,000
Primero les pedimos que manifestaran

173
0:09:07.786,000 --> 0:09:09,000
su intención de voto entre las dos coaliciones.

174
0:09:10.56,000 --> 0:09:13,000
Luego les pedimos que respondieran estas 12 preguntas.

175
0:09:14.36,000 --> 0:09:15,000
Completaban con sus respuestas,

176
0:09:16.34,000 --> 0:09:18,000
y luego les pedíamos que explicaran, por ejemplo:

177
0:09:18.66,000 --> 0:09:22,000
¿Por qué considera que el impuesto a la gasolina debería incrementarse?

178
0:09:23.52,000 --> 0:09:25,000
Y así seguimos con las otras preguntas.

179
0:09:25.64,000 --> 0:09:28,000
Luego, usando una plantilla con códigos en colores,

180
0:09:29.56,000 --> 0:09:31,000
calculamos el puntaje total.

181
0:09:32.52,000 --> 0:09:35,000
Así, esta persona tendría uno, dos, tres, cuatro ...

182
0:09:36,000 --> 0:09:39,000
cinco, seis, siete, ocho ... nueve puntos a la izquierda,

183
0:09:39.32,000 --> 0:09:41,000
lo cual indica su tendencia a la izquierda, básicamente.

184
0:09:42.8,000 --> 0:09:46,000
Y finalmente, debían expresar nuevamente su intención de voto.

185
0:09:48.16,000 --> 0:09:5,000
Pero, claro, también aquí había un truco.

186
0:09:51.36,000 --> 0:09:53,000
Primero nos acercábamos a las personas,

187
0:09:53.56,000 --> 0:09:55,000
les preguntábamos su intención de voto

188
0:09:55.64,000 --> 0:09:57,000
y, mientras completaban las respuestas,

189
0:09:57.92,000 --> 0:10:01,000
nosotros escribíamos las respuestas que iban en dirección opuesta.

190
0:10:03.4,000 --> 0:10:05,000
Poníamos esas repuestas debajo del bloc de notas.

191
0:10:06,000 --> 0:10:08,000
Y cuando nos devolvían el cuestionario,

192
0:10:08.8,000 --> 0:10:11,000
simplemente las pegábamos encima de las respuestas del participante.

193
0:10:12.89,000 --> 0:10:13,000
(Risas)

194
0:10:16,000 --> 0:10:17,000
Y allí está.

195
0:10:23.88,000 --> 0:10:25,000
Y luego preguntábamos por cada una de las respuestas:

196
0:10:26.68,000 --> 0:10:28,000
"¿Cuál fue su razonamiento en este punto?".

197
0:10:28.746,000 --> 0:10:29,000
Exponían sus razones,

198
0:10:3,000 --> 0:10:32,000
juntos calculábamos el puntaje total.

199
0:10:34.8,000 --> 0:10:38,000
Y al final escribían nuevamente su intención de voto.

200
0:10:41.96,000 --> 0:10:42,000
Lo primero que descubrimos

201
0:10:43.64,000 --> 0:10:46,000
es que estas manipulaciones son detectadas muy pocas veces.

202
0:10:47.84,000 --> 0:10:49,000
Con 'detectar' no me refiero a que digan:

203
0:10:50.14,000 --> 0:10:52,000
"Tendrás que haber cambiado mi respuesta",

204
0:10:52.286,000 --> 0:10:53,000
sino más bien:

205
0:10:53.49,000 --> 0:10:55,000
"Está bien, debo haber malinterpretado la pregunta.

206
0:10:56.406,000 --> 0:10:57,000
¿Puedo cambiarla?".

207
0:10:59.08,000 --> 0:11:04,000
Y aunque hayamos corregido algunas de estas manipulaciones,

208
0:11:04.24,000 --> 0:11:06,000
la gran mayoría pasó desapercibida.

209
0:11:06.48,000 --> 0:11:09,000
Así que logramos cambiar el 90 % de las respuestas de los participantes

210
0:11:10.27,000 --> 0:11:13,000
de izquierda a derecha, de derecha a izquierda; su perfil general.

211
0:11:14.8,000 --> 0:11:18,000
¿Y qué sucede cuando se les pide justificar esas decisiones?

212
0:11:20.16,000 --> 0:11:23,000
En este punto, las explicaciones son mucho más interesantes

213
0:11:23.24,000 --> 0:11:25,000
en comparación con la prueba de las caras.

214
0:11:25.28,000 --> 0:11:28,000
La gente dijo cosas como estas. Las leeré:

215
0:11:29.72,000 --> 0:11:32,000
"El control gubernamental a gran escala de correos electrónicos e Internet

216
0:11:33.37,000 --> 0:11:36,000
debería estar permitido para combatir el delito y el terrorismo internacional".

217
0:11:37.71,000 --> 0:11:39,000
"¿Está de acuerdo en cierto modo con esta afirmación?". "Sí".

218
0:11:40.64,000 --> 0:11:42,000
"¿Cómo justifica su postura?".

219
0:11:43.6,000 --> 0:11:44,000
"Bueno...

220
0:11:45.19,000 --> 0:11:48,000
es tan difícil luchar contra el delito y el terrorismo internacional

221
0:11:48.61,000 --> 0:11:5,000
que creo que deberían existir herramientas de este tipo".

222
0:11:51.36,000 --> 0:11:54,000
Y luego la persona recuerda un artículo publicado en el periódico matutino,

223
0:11:55.006,000 --> 0:11:56,000
"En el periódico de hoy

224
0:11:56.596,000 --> 0:11:59,000
dicen que pueden escuchar los móviles de la prisión

225
0:12:00.04,000 --> 0:12:03,000
si el líder de una banda quiere seguir delinquiendo desde adentro.

226
0:12:03.71,000 --> 0:12:05,000
Es una locura no tener el poder suficiente

227
0:12:06.44,000 --> 0:12:08,000
parar poner freno a estas cosas

228
0:12:08.576,000 --> 0:12:1,000
cuando en realidad existe la posibilidad de hacerlo".

229
0:12:11.08,000 --> 0:12:13,000
Y luego se ve una vacilación sobre el final:

230
0:12:13.29,000 --> 0:12:15,000
"No me gusta que tengan acceso a todo lo que uno hace,

231
0:12:15.98,000 --> 0:12:17,000
pero creo que a la larga vale la pena".

232
0:12:19,000 --> 0:12:21,000
Si ignoráramos que esta persona

233
0:12:21.56,000 --> 0:12:23,000
participó de un experimento de ceguera a la elección,

234
0:12:24.106,000 --> 0:12:28,000
no cuestionaríamos su sinceridad.

235
0:12:29.8,000 --> 0:12:31,000
¿Y qué pasa después con la intención de voto?

236
0:12:32.68,000 --> 0:12:36,000
Lo que descubrimos también está influenciado por el cuestionario.

237
0:12:37.4,000 --> 0:12:38,000
Hay 10 participantes

238
0:12:39.16,000 --> 0:12:41,000
que fluctúan de la izquierda a la derecha, y viceversa.

239
0:12:42.16,000 --> 0:12:44,000
Hay otros 19 que fluctúan de una intención de voto segura

240
0:12:44.996,000 --> 0:12:45,000
a otra incierta.

241
0:12:46.2,000 --> 0:12:49,000
Otros van de la incertidumbre a la intención segura.

242
0:12:49.32,000 --> 0:12:53,000
Y después están los que manifiestan incertidumbre en todo el cuestionario.

243
0:12:54.08,000 --> 0:12:56,000
Y este grupo es interesante porque,

244
0:12:56.846,000 --> 0:12:59,000
según los institutos de sondeo,

245
0:13:00.32,000 --> 0:13:01,000
cuanto más cerca está la elección

246
0:13:02,000 --> 0:13:04,000
los únicos votos que están en juego

247
0:13:04.16,000 --> 0:13:06,000
son los de la gente que está en la franja de indecisos.

248
0:13:06.84,000 --> 0:13:09,000
Pero nosotros demostramos que hay un número mucho mayor de personas

249
0:13:10.08,000 --> 0:13:12,000
que consideran la posibilidad de cambiar de opinión.

250
0:13:13.64,000 --> 0:13:16,000
Y en este punto aclaro que no está permitido usar este método

251
0:13:17.16,000 --> 0:13:19,000
para alterar el voto de la gente

252
0:13:19.8,000 --> 0:13:2,000
antes de una elección;

253
0:13:21.32,000 --> 0:13:24,000
nosotros les explicamos después

254
0:13:24.984,000 --> 0:13:26,000
y les dimos la oportunidad de retroceder y decidirse

255
0:13:27.66,000 --> 0:13:29,000
por la elección inicial.

256
0:13:30.6,000 --> 0:13:34,000
Esto demuestra que si podemos hacer que la gente vea la postura opuesta

257
0:13:34.89,000 --> 0:13:37,000
y se haga sus propios cuestionamientos,

258
0:13:38.52,000 --> 0:13:4,000
podría cambiar de opinión.

259
0:13:42.4,000 --> 0:13:43,000
Bien.

260
0:13:44.76,000 --> 0:13:45,000
¿Qué significa todo esto?

261
0:13:46.44,000 --> 0:13:48,000
¿Qué les parece que está sucediendo aquí?

262
0:13:48.88,000 --> 0:13:51,000
En primer lugar, gran parte de lo que llamamos autoconocimiento,

263
0:13:52.33,000 --> 0:13:54,000
es en realidad interpretación subjetiva.

264
0:13:55.06,000 --> 0:14:,000
Hago una elección y, cuando debo justificarla,

265
0:14:00.32,000 --> 0:14:02,000
simplemente intento explicarla

266
0:14:02.88,000 --> 0:14:03,000
de la manera más racional posible.

267
0:14:04.84,000 --> 0:14:07,000
Pero lo hacemos tan rápido y con tanta facilidad

268
0:14:07.88,000 --> 0:14:11,000
que creemos saber la respuesta cuando explicamos el porqué.

269
0:14:13.04,000 --> 0:14:16,000
Y como es una interpretación,

270
0:14:16.16,000 --> 0:14:18,000
a veces cometemos errores,

271
0:14:18.48,000 --> 0:14:2,000
de la misma manera en que cometemos errores

272
0:14:20.59,000 --> 0:14:21,000
al intentar entender a otras personas.

273
0:14:23.16,000 --> 0:14:26,000
Por eso debemos tener cuidado al preguntar "¿por qué?".

274
0:14:26.96,000 --> 0:14:3,000
Porque lo que puede pasar si preguntamos

275
0:14:31.8,000 --> 0:14:35,000
"¿Por qué tienes esta postura?".

276
0:14:35.84,000 --> 0:14:38,000
"¿Por qué sigues en este trabajo o en esta relación?",

277
0:14:39.08,000 --> 0:14:42,000
es que estemos creando una actitud

278
0:14:42.52,000 --> 0:14:44,000
que no existía antes de hacer la pregunta.

279
0:14:45.44,000 --> 0:14:48,000
Y esto es importante también en nuestra vida profesional,

280
0:14:48.64,000 --> 0:14:49,000
o podría serlo.

281
0:14:49.88,000 --> 0:14:51,000
Si diseñas algo y luego preguntas,

282
0:14:52.44,000 --> 0:14:54,000
"¿Por qué piensa Ud. que esto es bueno o malo?".

283
0:14:54.726,000 --> 0:14:57,000
O si eres un periodista que entrevista a un político,

284
0:14:57.82,000 --> 0:14:59,000
"¿Por qué tomó Ud. esta decisión?".

285
0:15:00.2,000 --> 0:15:01,000
O si eres un político

286
0:15:02.16,000 --> 0:15:04,000
e intentas explicar por qué tomaste una determinada decisión.

287
0:15:06.08,000 --> 0:15:09,000
Puede resultar inquietante,

288
0:15:09.68,000 --> 0:15:12,000
pero si vemos el lado positivo,

289
0:15:13.2,000 --> 0:15:14,000
se lo puede interpretar

290
0:15:14.96,000 --> 0:15:17,000
como que somos más flexibles de lo que creemos,

291
0:15:18.36,000 --> 0:15:19,000
que podemos cambiar de opinión,

292
0:15:20.28,000 --> 0:15:22,000
que nuestras opiniones no son inamovibles.

293
0:15:22.76,000 --> 0:15:25,000
Y también podemos cambiar la opinión de otros,

294
0:15:25.96,000 --> 0:15:29,000
con solo hacerlos razonar para que vean la postura opuesta.

295
0:15:31.43,000 --> 0:15:34,000
Y en mi vida personal, desde que empecé con esta investigación,

296
0:15:35.36,000 --> 0:15:37,000
con mi pareja acordamos

297
0:15:37.96,000 --> 0:15:39,000
que está permitido retractarse.

298
0:15:40.28,000 --> 0:15:42,000
Si dije que algo me gustaba el año pasado

299
0:15:42.64,000 --> 0:15:44,000
no significa que me deba seguir gustando.

300
0:15:45.48,000 --> 0:15:47,000
Liberarse de la necesidad de mantenerse en una posición

301
0:15:48.32,000 --> 0:15:52,000
representa un gran alivio y facilita las relaciones.

302
0:15:53.72,000 --> 0:15:55,000
La conclusión, entonces, es:

303
0:15:57.32,000 --> 0:15:59,000
Debes saber que no te conoces...

304
0:15:59.84,000 --> 0:16:01,000
o al menos no tan bien como crees.

305
0:16:03.48,000 --> 0:16:04,000
Gracias.

306
0:16:04.72,000 --> 0:16:08,000
(Aplausos)

