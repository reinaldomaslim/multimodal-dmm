1
0:00:,000 --> 0:00:07,000
Traductor: Enrique Palomares Revisor: Natalia Alvarado

2
0:00:12.836,000 --> 0:00:14,000
[Esta charla contiene contenido para adultos]

3
0:00:17.741,000 --> 0:00:18,000
Hace cinco años

4
0:00:19.385,000 --> 0:00:22,000
recibí una llamada que cambiaría mi vida.

5
0:00:23.795,000 --> 0:00:25,000
Recuerdo ese día muy claramente.

6
0:00:27.245,000 --> 0:00:28,000
Fue en esta época del año,

7
0:00:29.17,000 --> 0:00:3,000
y yo estaba sentada en mi oficina.

8
0:00:31.692,000 --> 0:00:34,000
Recuerdo el sol entrando por la ventana.

9
0:00:35.592,000 --> 0:00:36,000
Y mi teléfono sonó.

10
0:00:37.565,000 --> 0:00:38,000
Yo contesté,

11
0:00:39.594,000 --> 0:00:42,000
y eran dos agentes federales pidiendo mi ayuda

12
0:00:43.596,000 --> 0:00:45,000
para identificar a una pequeña niña

13
0:00:46.326,000 --> 0:00:51,000
que aparecía en cientos de imágenes de abuso sexual infantil en internet.

14
0:00:53.145,000 --> 0:00:55,000
Ellos apenas habían comenzado a trabajar en el caso,

15
0:00:55.745,000 --> 0:00:57,000
pero sí sabían que

16
0:00:58.639,000 --> 0:01:02,000
su abuso había sido difundido al mundo durante años

17
0:01:03.486,000 --> 0:01:08,000
en sitios web del internet oscuro dedicados al abuso sexual infantil.

18
0:01:09.605,000 --> 0:01:13,000
Y su agresor era muy sofisticado tecnológicamente:

19
0:01:14.014,000 --> 0:01:18,000
nuevas imágenes y videos cada par de semanas,

20
0:01:18.626,000 --> 0:01:22,000
pero muy pocas pistas sobre quién era ella

21
0:01:22.699,000 --> 0:01:23,000
o dónde estaba.

22
0:01:24.744,000 --> 0:01:25,000
Así que, los agentes nos llamaron,

23
0:01:26.734,000 --> 0:01:28,000
porque se enteraron de nuestra organización no lucrativa

24
0:01:29.448,000 --> 0:01:32,000
que crea tecnología para combatir el abuso sexual infantil.

25
0:01:33.596,000 --> 0:01:35,000
Pero solo hacía dos años que funcionábamos

26
0:01:35.907,000 --> 0:01:38,000
y solo habíamos trabajado en tráfico sexual infantil.

27
0:01:39.944,000 --> 0:01:41,000
Tuve que decirles

28
0:01:42.091,000 --> 0:01:43,000
que no teníamos nada.

29
0:01:44.28,000 --> 0:01:47,000
No teníamos nada que pudiera ayudarles a detener este abuso.

30
0:01:49.263,000 --> 0:01:52,000
Les tomó a los agentes otro año más

31
0:01:52.861,000 --> 0:01:55,000
hasta finalmente encontrar a la niña.

32
0:01:56.853,000 --> 0:01:58,000
Y para cuando ella fue rescatada,

33
0:01:59.152,000 --> 0:02:04,000
cientos de imágenes y videos mostrando su violación

34
0:02:04.394,000 --> 0:02:06,000
se habían hecho virales en el internet oscuro

35
0:02:07.379,000 --> 0:02:1,000
en redes de pares, en salas de chat privadas

36
0:02:10.42,000 --> 0:02:13,000
hasta en sitios web que Uds. y yo usamos

37
0:02:13.664,000 --> 0:02:15,000
todos los días.

38
0:02:17.216,000 --> 0:02:2,000
Y hoy, mientras ella lucha por recuperarse,

39
0:02:21.055,000 --> 0:02:25,000
vive con el hecho de que miles en todo el mundo

40
0:02:25.218,000 --> 0:02:28,000
siguen viendo su abuso.

41
0:02:29.994,000 --> 0:02:31,000
He aprendido en los últimos cinco años

42
0:02:32.446,000 --> 0:02:34,000
que este caso está lejos de ser único.

43
0:02:36.119,000 --> 0:02:39,000
¿Cómo llegamos aquí como sociedad?

44
0:02:41.49,000 --> 0:02:44,000
A finales de los 80, la pornografía infantil

45
0:02:45.273,000 --> 0:02:5,000
o lo que realmente es, el contenido de abuso sexual infantil

46
0:02:50.55,000 --> 0:02:51,000
llegó a ser casi eliminado.

47
0:02:53.209,000 --> 0:02:57,000
Nuevas leyes y más acciones judiciales lo hicieron simplemente demasiado arriesgado

48
0:02:57.737,000 --> 0:02:58,000
para enviarlo por correo.

49
0:03:00.233,000 --> 0:03:04,000
Entonces internet llegó y el mercado explotó.

50
0:03:05.31,000 --> 0:03:08,000
Hoy en día, la cantidad de contenido en circulación

51
0:03:08.69,000 --> 0:03:1,000
es enorme y sigue creciendo.

52
0:03:12.421,000 --> 0:03:15,000
Este es un verdadero problema global,

53
0:03:15.689,000 --> 0:03:16,000
pero si solo consideramos EE. UU.,

54
0:03:17.546,000 --> 0:03:19,000
solo el año pasado en EE. UU.

55
0:03:20.281,000 --> 0:03:25,000
más de 45 millones de imágenes y videos de contenido de abuso sexual infantil

56
0:03:25.579,000 --> 0:03:28,000
fueron reportados al Centro Nacional para Niños Desaparecidos y Explotados,

57
0:03:29.281,000 --> 0:03:33,000
y eso es casi el doble de la cantidad del año anterior,

58
0:03:34.627,000 --> 0:03:39,000
Y los detalles detrás de estos números son difíciles de contemplar,

59
0:03:39.937,000 --> 0:03:44,000
con más del 60 % mostrando a niños menores de 12 años,

60
0:03:45.681,000 --> 0:03:49,000
y la mayoría de ellos incluyen actos de extrema violencia sexual.

61
0:03:50.85,000 --> 0:03:55,000
Los violadores son aclamados en salas de chat dedicadas al abuso de niños,

62
0:03:56.174,000 --> 0:03:58,000
donde ganan rango y notoriedad

63
0:03:58.681,000 --> 0:04:,000
con más violaciones y más víctimas.

64
0:04:02.243,000 --> 0:04:04,000
En este mercado,

65
0:04:04.862,000 --> 0:04:07,000
la moneda de cambio se ha vuelto el mismo contenido.

66
0:04:10.023,000 --> 0:04:13,000
Los violadores han sido rápidos en aprovecharse de las nuevas tecnologías,

67
0:04:13.853,000 --> 0:04:16,000
pero nuestra respuesta como sociedad no lo ha sido.

68
0:04:17.671,000 --> 0:04:21,000
Los violadores no leen los términos de uso de los sitios web,

69
0:04:21.866,000 --> 0:04:24,000
y el contenido no respeta fronteras geográficas.

70
0:04:26.656,000 --> 0:04:32,000
Y ellos ganan cada vez que nosotros buscamos en una pieza del rompecabezas,

71
0:04:32.793,000 --> 0:04:36,000
lo cual es exactamente la forma en que está diseñada nuestra repuesta hoy en día.

72
0:04:36.834,000 --> 0:04:39,000
La fuerza de la ley funciona en una jurisdicción.

73
0:04:40.345,000 --> 0:04:43,000
Las compañías solo buscan en su plataforma.

74
0:04:43.783,000 --> 0:04:45,000
Y cualquier dato que descubren sobre la marcha

75
0:04:46.511,000 --> 0:04:48,000
es rara vez compartido.

76
0:04:49.402,000 --> 0:04:54,000
Es muy obvio que este enfoque no está funcionando.

77
0:04:55.64,000 --> 0:04:58,000
Debemos rediseñar la respuesta a esta epidemia

78
0:04:59.777,000 --> 0:05:,000
de la era digital.

79
0:05:01.702,000 --> 0:05:03,000
Y eso es exactamente lo que estamos haciendo en Thron.

80
0:05:05.311,000 --> 0:05:08,000
Estamos creando tecnología para conectar estos puntos,

81
0:05:08.952,000 --> 0:05:1,000
para armar a quienes libran esta batalla:

82
0:05:11.298,000 --> 0:05:13,000
fuerzas judiciales, ONGs y compañías,

83
0:05:14.146,000 --> 0:05:17,000
con las herramientas necesarias para por fin eliminar del internet

84
0:05:17.679,000 --> 0:05:19,000
el contenido de abuso sexual infantil.

85
0:05:21.571,000 --> 0:05:22,000
Hablemos por un momento...

86
0:05:22.866,000 --> 0:05:23,000
(Aplausos)

87
0:05:24.409,000 --> 0:05:25,000
Gracias.

88
0:05:25.737,000 --> 0:05:27,000
(Aplausos)

89
0:05:29.8,000 --> 0:05:31,000
Hablemos por un momento sobre los puntos que mencioné

90
0:05:33.323,000 --> 0:05:36,000
Como se pueden imaginar, el contenido es terrible.

91
0:05:36.558,000 --> 0:05:39,000
Si no tienen por qué verlo, no querrán verlo.

92
0:05:40.43,000 --> 0:05:44,000
Y así, la mayoría de compañías o agencias de fuerza judicial

93
0:05:45.423,000 --> 0:05:46,000
que tienen este contenido

94
0:05:47.11,000 --> 0:05:5,000
pueden transformar cada archivo en una serie única de números.

95
0:05:50.586,000 --> 0:05:51,000
Esto es llamado "hash".

96
0:05:52.084,000 --> 0:05:54,000
Es básicamente una huella digital

97
0:05:54.251,000 --> 0:05:56,000
para cada archivo o cada video.

98
0:05:56.673,000 --> 0:06:,000
Esto permite usar la información en investigaciones

99
0:06:01.31,000 --> 0:06:04,000
o que una compañía pueda eliminar el contenido de su plataforma,

100
0:06:04.361,000 --> 0:06:09,000
sin tener que revisar uno a uno cada imagen y cada video

101
0:06:10.196,000 --> 0:06:12,000
Sin embargo, el problema de hoy en día

102
0:06:12.371,000 --> 0:06:15,000
es que hay cientos de millones de estos "hash"

103
0:06:16.146,000 --> 0:06:19,000
almacenados por todo el mundo.

104
0:06:20.214,000 --> 0:06:21,000
En un silo,

105
0:06:21.389,000 --> 0:06:24,000
podría funcionar para la agencia que tenga control sobre este,

106
0:06:24.489,000 --> 0:06:28,000
pero si no se conectan estos datos, no sabremos cuántos son únicos.

107
0:06:28.643,000 --> 0:06:31,000
No sabremos cuáles son de niños que ya han sido rescatados

108
0:06:32.183,000 --> 0:06:34,000
o cuáles son de quienes aún necesitan ser identificados.

109
0:06:35.096,000 --> 0:06:39,000
Por lo que nuestra primera y más básica premisa es que

110
0:06:39.29,000 --> 0:06:41,000
todos estos datos deben ser conectados.

111
0:06:42.318,000 --> 0:06:48,000
Hay dos formas en las que estos datos, combinados con software a escala global,

112
0:06:48.511,000 --> 0:06:51,000
pueden tener un impacto transformativo.

113
0:06:52.464,000 --> 0:06:54,000
La primera es con la fuerza de la ley:

114
0:06:55.11,000 --> 0:06:58,000
ayudándoles a identificar nuevas víctimas de forma más rápida,

115
0:06:58.765,000 --> 0:06:59,000
deteniendo su abuso

116
0:07:00.005,000 --> 0:07:02,000
y deteniendo a aquellos que producen este contenido.

117
0:07:03.441,000 --> 0:07:05,000
La segunda es con empresas:

118
0:07:06.131,000 --> 0:07:09,000
usándolos como pistas para identificar los cientos de millones de archivos

119
0:07:09.776,000 --> 0:07:1,000
en circulación a día de hoy,

120
0:07:11.394,000 --> 0:07:12,000
bajándolos

121
0:07:12.605,000 --> 0:07:18,000
y evitando la carga de contenido nuevo antes de que haga viral.

122
0:07:21.694,000 --> 0:07:22,000
Hace cuatro años,

123
0:07:23.364,000 --> 0:07:24,000
cuando ese caso terminó,

124
0:07:26.3,000 --> 0:07:29,000
nuestro equipo se sentó, y sentimos...

125
0:07:31.635,000 --> 0:07:34,000
un profundo sentimiento de fracaso, es como puedo describirlo,

126
0:07:34.997,000 --> 0:07:37,000
porque vigilamos ese año por completo

127
0:07:38.672,000 --> 0:07:39,000
mientras ellos la buscaban.

128
0:07:40.016,000 --> 0:07:43,000
Y vimos cada lugar en la investigación

129
0:07:44.007,000 --> 0:07:46,000
y si la tecnología hubiese existido,

130
0:07:46.419,000 --> 0:07:48,000
la habrían encontrado más rápido.

131
0:07:49.684,000 --> 0:07:5,000
Así que, avanzamos

132
0:07:51.644,000 --> 0:07:53,000
y terminamos haciendo lo que mejor sabemos hacer:

133
0:07:54.623,000 --> 0:07:56,000
empezamos a crear software.

134
0:07:57.689,000 --> 0:07:59,000
Hemos comenzado con la fuerza de la ley.

135
0:07:59.965,000 --> 0:08:03,000
Nuestro sueño fue una buena señal para los oficiales de todo el mundo

136
0:08:04.41,000 --> 0:08:08,000
porque si alguien se atreve a publicar en internet una nueva víctima,

137
0:08:08.978,000 --> 0:08:11,000
alguien comenzará a buscarla de inmediato.

138
0:08:13.324,000 --> 0:08:15,000
Obviamente no puedo dar detalles sobre este software,

139
0:08:16.305,000 --> 0:08:18,000
pero hoy en día está en uso en 38 países,

140
0:08:18.938,000 --> 0:08:2,000
reduciendo el tiempo necesario para identificar una víctima

141
0:08:21.936,000 --> 0:08:23,000
en más del 65 % de los casos.

142
0:08:24.29,000 --> 0:08:28,000
(Aplausos)

143
0:08:33.442,000 --> 0:08:36,000
Y ahora nos estamos centrando en el segundo punto:

144
0:08:36.481,000 --> 0:08:41,000
crear el software para identificar y eliminar este contenido.

145
0:08:43.193,000 --> 0:08:45,000
Hablemos por un momento sobre estas compañías.

146
0:08:46.27,000 --> 0:08:51,000
45 millones de imágenes y videos considerando solo el año pasado en EE. UU.

147
0:08:52.28,000 --> 0:08:55,000
Esto proviene de solo 12 empresas.

148
0:08:57.883,000 --> 0:09:03,000
Doce empresas, 45 millones de archivos sobre abuso sexual infantil.

149
0:09:04.335,000 --> 0:09:06,000
Esto viene de empresas que tienen el dinero

150
0:09:07.159,000 --> 0:09:11,000
para crear la infraestructura necesaria para eliminar este contenido.

151
0:09:11.74,000 --> 0:09:13,000
Pero hay cientos de otras empresas,

152
0:09:14.175,000 --> 0:09:16,000
desde pequeñas a medianas por todo el mundo,

153
0:09:16.865,000 --> 0:09:18,000
que necesitan hacer este trabajo,

154
0:09:18.943,000 --> 0:09:23,000
pero puede que ellos: 1) no sepan que sus plataformas se usan para el abuso

155
0:09:24.392,000 --> 0:09:29,000
o 2) no tienen el dinero para gastar en algo que no genera ganancias.

156
0:09:30.932,000 --> 0:09:33,000
Así que nos adelantamos y lo construimos por ellos,

157
0:09:34.245,000 --> 0:09:38,000
y este sistema ahora se vuelve más listo entre más empresas participen.

158
0:09:39.965,000 --> 0:09:4,000
Permítanme darles un ejemplo.

159
0:09:42.459,000 --> 0:09:45,000
Nuestro primero socio, Imgur, si no han oído hablar de esta empresas,

160
0:09:46.361,000 --> 0:09:49,000
es uno de los sitios web más visitados en EE. UU.

161
0:09:49.527,000 --> 0:09:54,000
Cada día se suben millones de piezas de contenido generado por los usuarios,

162
0:09:54.559,000 --> 0:09:56,000
en una misión de hacer del internet un lugar más divertido.

163
0:09:58.012,000 --> 0:09:59,000
Se asociaron con nosotros primero.

164
0:09:59.888,000 --> 0:10:02,000
En tan solo 20 minutos de haber subido nuestro sistema,

165
0:10:03.255,000 --> 0:10:06,000
alguien intentó subir una conocida pieza de material de abuso.

166
0:10:06.851,000 --> 0:10:08,000
Pudieron detenerlo, bajarlo,

167
0:10:08.983,000 --> 0:10:11,000
y reportarlo al Centro Nacional de Niños Desaparecidos y Explotados.

168
0:10:12.473,000 --> 0:10:13,000
Pero ellos fueron un paso más adelante,

169
0:10:14.405,000 --> 0:10:18,000
inspeccionaron la cuenta de la persona que había subido el contenido.

170
0:10:19.086,000 --> 0:10:23,000
Cientos de piezas de contenido de abuso sexual infantil

171
0:10:23.821,000 --> 0:10:24,000
del que habíamos visto.

172
0:10:26.152,000 --> 0:10:29,000
Y aquí fue donde comenzamos a ver un impacto exponencial.

173
0:10:29.708,000 --> 0:10:3,000
Bajamos ese contenido,

174
0:10:31.5,000 --> 0:10:34,000
se reporta al Centro Nacional de Niños Explotados y Desaparecidos

175
0:10:35.074,000 --> 0:10:37,000
y estos "hash" van de vuelta al sistema

176
0:10:37.609,000 --> 0:10:39,000
Y benefician a cualquier otra compañía que lo use.

177
0:10:40.097,000 --> 0:10:44,000
Y cuando los millones de "hash" que tenemos hayan dirigido a millones más en directo,

178
0:10:44.905,000 --> 0:10:48,000
las empresas alrededor del mundo identificarán y bajarán el contenido,

179
0:10:49.467,000 --> 0:10:53,000
aumentado drásticamente el tiempo en el que eliminamos

180
0:10:54.052,000 --> 0:10:58,000
el contenido de abuso sexual infantil del internet por todo el mundo.

181
0:10:58.37,000 --> 0:11:03,000
(Aplausos)

182
0:11:06.208,000 --> 0:11:09,000
Pero este es el por qué no solo se trata de software y datos,

183
0:11:09.452,000 --> 0:11:1,000
tiene que tratarse de escala,

184
0:11:11.248,000 --> 0:11:14,000
Tenemos que activar miles de agentes,

185
0:11:14.785,000 --> 0:11:16,000
cientos de empresas por todo el mundo

186
0:11:17.186,000 --> 0:11:2,000
así la tecnología nos permitirá superar a los perpetradores

187
0:11:20.818,000 --> 0:11:24,000
y desmantelar las comunidades que están normalizando el abuso sexual infantil

188
0:11:24.967,000 --> 0:11:25,000
a día de hoy por todo el mundo.

189
0:11:27.064,000 --> 0:11:29,000
Y el momento para hacer esto es ahora.

190
0:11:30.288,000 --> 0:11:35,000
No podemos decir más que no sabemos del impacto de esto en nuestros niños,

191
0:11:36.688,000 --> 0:11:4,000
La primera generación de niños cuyo abuso se hizo viral

192
0:11:41.17,000 --> 0:11:42,000
ya son ahora adultos jóvenes.

193
0:11:43.451,000 --> 0:11:45,000
El Centro Canadiense de Protección Infantil

194
0:11:46.06,000 --> 0:11:48,000
acaba de hacer un estudio sobre estos adultos jóvenes

195
0:11:48.78,000 --> 0:11:52,000
para entender el trauma particular del que tratan de recuperarse,

196
0:11:53.44,000 --> 0:11:55,000
sabiendo que su abuso aún existe.

197
0:11:57.213,000 --> 0:12:01,000
El 80 % de estos adultos jóvenes ha considerado el suicidio.

198
0:12:02.566,000 --> 0:12:06,000
Más del 60 % ha intentado suicidarse.

199
0:12:07.572,000 --> 0:12:12,000
Y la mayoría de ellos vive todos los días con el miedo

200
0:12:12.813,000 --> 0:12:16,000
de que mientras ellos caminan por la calle o van a una entrevista de trabajo

201
0:12:17.3,000 --> 0:12:19,000
o van a la escuela

202
0:12:19.614,000 --> 0:12:21,000
o cuando conocen a alguien por internet,

203
0:12:22.063,000 --> 0:12:25,000
que esta persona haya visto su abuso.

204
0:12:26.547,000 --> 0:12:3,000
Y esto se hace realidad para más del 30 % de ellos.

205
0:12:32.256,000 --> 0:12:36,000
Ellos han sido reconocidos debido al material sobre su abuso.

206
0:12:38.022,000 --> 0:12:41,000
Esto no va a ser fácil,

207
0:12:41.322,000 --> 0:12:43,000
pero no es imposible.

208
0:12:44.189,000 --> 0:12:46,000
Ahora se necesita la voluntad,

209
0:12:46.889,000 --> 0:12:47,000
la voluntad de nuestra sociedad

210
0:12:48.502,000 --> 0:12:51,000
de mirar algo que es realmente difícil de mirar,

211
0:12:52.08,000 --> 0:12:54,000
de sacar algo de la oscuridad

212
0:12:54.447,000 --> 0:12:56,000
para que estos niños tengan una voz;

213
0:12:58.11,000 --> 0:13:02,000
la voluntad de las empresas para actuar y asegurarse de que

214
0:13:03.08,000 --> 0:13:06,000
sus plataformas no sean cómplices del abuso infantil;

215
0:13:07.205,000 --> 0:13:1,000
la voluntad de los gobiernos de invertir en las herramientas necesarias

216
0:13:11.18,000 --> 0:13:16,000
para investigar y aplicar sus leyes en un crimen digital,

217
0:13:16.298,000 --> 0:13:2,000
incluso cuando las víctimas no pueden hablar por ellas mismas.

218
0:13:21.746,000 --> 0:13:24,000
Este compromiso audaz es parte de esa voluntad.

219
0:13:26.269,000 --> 0:13:31,000
Es la declaración de la guerra en contra de uno los peores males de la humanidad.

220
0:13:32.263,000 --> 0:13:33,000
Pero a lo que me aferro

221
0:13:34.227,000 --> 0:13:37,000
es que en realidad es una inversión en un futuro

222
0:13:37.7,000 --> 0:13:4,000
donde cada pequeño pueda ser simplemente un niño.

223
0:13:41.357,000 --> 0:13:42,000
Gracias.

224
0:13:42.896,000 --> 0:13:48,000
(Aplausos)

