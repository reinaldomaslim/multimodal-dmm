1
0:00:12.495,000 --> 0:00:15,000
There is an ancient proverb that says

2
0:00:16.053,000 --> 0:00:2,000
it's very difficult to find a black cat in a dark room,

3
0:00:20.115,000 --> 0:00:22,000
especially when there is no cat.

4
0:00:22.903,000 --> 0:00:25,000
I find this a particularly apt description of science

5
0:00:26.232,000 --> 0:00:28,000
and how science works --

6
0:00:28.368,000 --> 0:00:31,000
bumbling around in a dark room, bumping into things,

7
0:00:31.688,000 --> 0:00:33,000
trying to figure out what shape this might be,

8
0:00:33.99,000 --> 0:00:34,000
what that might be,

9
0:00:35.434,000 --> 0:00:37,000
there are reports of a cat somewhere around,

10
0:00:37.923,000 --> 0:00:38,000
they may not be reliable, they may be,

11
0:00:39.716,000 --> 0:00:4,000
and so forth and so on.

12
0:00:41.236,000 --> 0:00:42,000
Now I know this is different than the way most people

13
0:00:43.212,000 --> 0:00:44,000
think about science.

14
0:00:44.764,000 --> 0:00:45,000
Science, we generally are told,

15
0:00:46.318,000 --> 0:00:48,000
is a very well-ordered mechanism for

16
0:00:49.068,000 --> 0:00:5,000
understanding the world,

17
0:00:50.369,000 --> 0:00:52,000
for gaining facts, for gaining data,

18
0:00:52.655,000 --> 0:00:53,000
that it's rule-based,

19
0:00:54.208,000 --> 0:00:57,000
that scientists use this thing called the scientific method

20
0:00:57.449,000 --> 0:00:59,000
and we've been doing this for 14 generations or so now,

21
0:01:00.288,000 --> 0:01:02,000
and the scientific method is a set of rules

22
0:01:02.859,000 --> 0:01:06,000
for getting hard, cold facts out of the data.

23
0:01:07.051,000 --> 0:01:09,000
I'd like to tell you that's not the case.

24
0:01:09.146,000 --> 0:01:1,000
So there's the scientific method,

25
0:01:10.978,000 --> 0:01:12,000
but what's really going on is this. (Laughter)

26
0:01:13.297,000 --> 0:01:13,000
[The Scientific Method vs. Farting Around]

27
0:01:14.255,000 --> 0:01:17,000
And it's going on kind of like that.

28
0:01:17.359,000 --> 0:01:18,000
[... in the dark] (Laughter)

29
0:01:18.78,000 --> 0:01:22,000
So what is the difference, then,

30
0:01:23.321,000 --> 0:01:26,000
between the way I believe science is pursued

31
0:01:27.137,000 --> 0:01:29,000
and the way it seems to be perceived?

32
0:01:29.998,000 --> 0:01:31,000
So this difference first came to me in some ways

33
0:01:32.713,000 --> 0:01:34,000
in my dual role at Columbia University,

34
0:01:34.81,000 --> 0:01:38,000
where I'm both a professor and run a laboratory in neuroscience

35
0:01:38.965,000 --> 0:01:4,000
where we try to figure out how the brain works.

36
0:01:41.16,000 --> 0:01:43,000
We do this by studying the sense of smell,

37
0:01:43.531,000 --> 0:01:45,000
the sense of olfaction, and in the laboratory,

38
0:01:46.062,000 --> 0:01:48,000
it's a great pleasure and fascinating work

39
0:01:48.696,000 --> 0:01:5,000
and exciting to work with graduate students and post-docs

40
0:01:51.567,000 --> 0:01:53,000
and think up cool experiments to understand how this

41
0:01:54.178,000 --> 0:01:56,000
sense of smell works and how the brain might be working,

42
0:01:56.564,000 --> 0:01:58,000
and, well, frankly, it's kind of exhilarating.

43
0:01:59.366,000 --> 0:02:01,000
But at the same time, it's my responsibility

44
0:02:02.084,000 --> 0:02:04,000
to teach a large course to undergraduates on the brain,

45
0:02:05.033,000 --> 0:02:06,000
and that's a big subject,

46
0:02:06.108,000 --> 0:02:08,000
and it takes quite a while to organize that,

47
0:02:08.499,000 --> 0:02:1,000
and it's quite challenging and it's quite interesting,

48
0:02:11.31,000 --> 0:02:14,000
but I have to say, it's not so exhilarating.

49
0:02:14.867,000 --> 0:02:15,000
So what was the difference?

50
0:02:16.263,000 --> 0:02:18,000
Well, the course I was and am teaching

51
0:02:18.332,000 --> 0:02:24,000
is called Cellular and Molecular Neuroscience - I. (Laughs)

52
0:02:24.796,000 --> 0:02:28,000
It's 25 lectures full of all sorts of facts,

53
0:02:29.351,000 --> 0:02:33,000
it uses this giant book called "Principles of Neural Science"

54
0:02:33.668,000 --> 0:02:35,000
by three famous neuroscientists.

55
0:02:36.002,000 --> 0:02:39,000
This book comes in at 1,414 pages,

56
0:02:39.783,000 --> 0:02:41,000
it weighs a hefty seven and a half pounds.

57
0:02:42.519,000 --> 0:02:43,000
Just to put that in some perspective,

58
0:02:44.446,000 --> 0:02:47,000
that's the weight of two normal human brains.

59
0:02:47.901,000 --> 0:02:5,000
(Laughter)

60
0:02:51.184,000 --> 0:02:54,000
So I began to realize, by the end of this course,

61
0:02:54.451,000 --> 0:02:56,000
that the students maybe were getting the idea

62
0:02:56.699,000 --> 0:02:59,000
that we must know everything there is to know about the brain.

63
0:02:59.73,000 --> 0:03:,000
That's clearly not true.

64
0:03:01.492,000 --> 0:03:03,000
And they must also have this idea, I suppose,

65
0:03:04.19,000 --> 0:03:07,000
that what scientists do is collect data and collect facts

66
0:03:07.571,000 --> 0:03:09,000
and stick them in these big books.

67
0:03:09.66,000 --> 0:03:1,000
And that's not really the case either.

68
0:03:11.067,000 --> 0:03:14,000
When I go to a meeting, after the meeting day is over

69
0:03:14.37,000 --> 0:03:17,000
and we collect in the bar over a couple of beers with my colleagues,

70
0:03:17.467,000 --> 0:03:19,000
we never talk about what we know.

71
0:03:19.668,000 --> 0:03:21,000
We talk about what we don't know.

72
0:03:21.834,000 --> 0:03:23,000
We talk about what still has to get done,

73
0:03:24.119,000 --> 0:03:26,000
what's so critical to get done in the lab.

74
0:03:26.944,000 --> 0:03:28,000
Indeed, this was, I think, best said by Marie Curie

75
0:03:29.501,000 --> 0:03:31,000
who said that one never notices what has been done

76
0:03:31.92,000 --> 0:03:32,000
but only what remains to be done.

77
0:03:33.381,000 --> 0:03:35,000
This was in a letter to her brother after obtaining

78
0:03:35.606,000 --> 0:03:38,000
her second graduate degree, I should say.

79
0:03:39.324,000 --> 0:03:41,000
I have to point out this has always been one of my favorite pictures of Marie Curie,

80
0:03:42.137,000 --> 0:03:44,000
because I am convinced that that glow behind her

81
0:03:44.44,000 --> 0:03:46,000
is not a photographic effect. (Laughter)

82
0:03:47.178,000 --> 0:03:48,000
That's the real thing.

83
0:03:48.978,000 --> 0:03:52,000
It is true that her papers are, to this day,

84
0:03:53.358,000 --> 0:03:55,000
stored in a basement room in the Bibliothèque Française

85
0:03:56.237,000 --> 0:03:58,000
in a concrete room that's lead-lined,

86
0:03:58.434,000 --> 0:04:,000
and if you're a scholar and you want access to these notebooks,

87
0:04:01.086,000 --> 0:04:03,000
you have to put on a full radiation hazmat suit,

88
0:04:03.835,000 --> 0:04:05,000
so it's pretty scary business.

89
0:04:06.186,000 --> 0:04:08,000
Nonetheless, this is what I think we were leaving out

90
0:04:08.982,000 --> 0:04:09,000
of our courses

91
0:04:10.608,000 --> 0:04:12,000
and leaving out of the interaction that we have

92
0:04:13.134,000 --> 0:04:15,000
with the public as scientists, the what-remains-to-be-done.

93
0:04:16.107,000 --> 0:04:18,000
This is the stuff that's exhilarating and interesting.

94
0:04:18.741,000 --> 0:04:2,000
It is, if you will, the ignorance.

95
0:04:21.651,000 --> 0:04:21,000
That's what was missing.

96
0:04:22.63,000 --> 0:04:24,000
So I thought, well, maybe I should teach a course

97
0:04:25.49,000 --> 0:04:27,000
on ignorance,

98
0:04:27.59,000 --> 0:04:3,000
something I can finally excel at, perhaps, for example.

99
0:04:31.219,000 --> 0:04:32,000
So I did start teaching this course on ignorance,

100
0:04:33.097,000 --> 0:04:34,000
and it's been quite interesting

101
0:04:34.193,000 --> 0:04:36,000
and I'd like to tell you to go to the website.

102
0:04:36.279,000 --> 0:04:39,000
You can find all sorts of information there. It's wide open.

103
0:04:39.915,000 --> 0:04:42,000
And it's been really quite an interesting time for me

104
0:04:43.438,000 --> 0:04:44,000
to meet up with other scientists who come in and talk

105
0:04:45.279,000 --> 0:04:46,000
about what it is they don't know.

106
0:04:46.827,000 --> 0:04:47,000
Now I use this word "ignorance," of course,

107
0:04:48.812,000 --> 0:04:51,000
to be at least in part intentionally provocative,

108
0:04:51.97,000 --> 0:04:53,000
because ignorance has a lot of bad connotations

109
0:04:54.36,000 --> 0:04:56,000
and I clearly don't mean any of those.

110
0:04:56.365,000 --> 0:04:59,000
So I don't mean stupidity, I don't mean a callow indifference

111
0:04:59.87,000 --> 0:05:01,000
to fact or reason or data.

112
0:05:02.178,000 --> 0:05:05,000
The ignorant are clearly unenlightened, unaware,

113
0:05:05.449,000 --> 0:05:08,000
uninformed, and present company today excepted,

114
0:05:08.756,000 --> 0:05:1,000
often occupy elected offices, it seems to me.

115
0:05:11.664,000 --> 0:05:12,000
That's another story, perhaps.

116
0:05:13.47,000 --> 0:05:14,000
I mean a different kind of ignorance.

117
0:05:15.103,000 --> 0:05:17,000
I mean a kind of ignorance that's less pejorative,

118
0:05:17.371,000 --> 0:05:2,000
a kind of ignorance that comes from a communal gap in our knowledge,

119
0:05:20.858,000 --> 0:05:21,000
something that's just not there to be known

120
0:05:22.723,000 --> 0:05:24,000
or isn't known well enough yet or we can't make predictions from,

121
0:05:25.544,000 --> 0:05:27,000
the kind of ignorance that's maybe best summed up

122
0:05:27.862,000 --> 0:05:28,000
in a statement by James Clerk Maxwell,

123
0:05:29.707,000 --> 0:05:32,000
perhaps the greatest physicist between Newton and Einstein,

124
0:05:33.156,000 --> 0:05:35,000
who said, "Thoroughly conscious ignorance

125
0:05:35.457,000 --> 0:05:37,000
is the prelude to every real advance in science."

126
0:05:38.025,000 --> 0:05:39,000
I think it's a wonderful idea:

127
0:05:39.413,000 --> 0:05:42,000
thoroughly conscious ignorance.

128
0:05:42.56,000 --> 0:05:44,000
So that's the kind of ignorance that I want to talk about today,

129
0:05:44.981,000 --> 0:05:45,000
but of course the first thing we have to clear up

130
0:05:46.5,000 --> 0:05:48,000
is what are we going to do with all those facts?

131
0:05:48.603,000 --> 0:05:51,000
So it is true that science piles up at an alarming rate.

132
0:05:52.277,000 --> 0:05:54,000
We all have this sense that science is this mountain of facts,

133
0:05:55.087,000 --> 0:05:59,000
this accumulation model of science, as many have called it,

134
0:05:59.123,000 --> 0:06:01,000
and it seems impregnable, it seems impossible.

135
0:06:01.574,000 --> 0:06:02,000
How can you ever know all of this?

136
0:06:02.888,000 --> 0:06:05,000
And indeed, the scientific literature grows at an alarming rate.

137
0:06:06.469,000 --> 0:06:09,000
In 2006, there were 1.3 million papers published.

138
0:06:10.123,000 --> 0:06:12,000
There's about a two-and-a-half-percent yearly growth rate,

139
0:06:12.755,000 --> 0:06:16,000
and so last year we saw over one and a half million papers being published.

140
0:06:17.145,000 --> 0:06:19,000
Divide that by the number of minutes in a year,

141
0:06:19.375,000 --> 0:06:22,000
and you wind up with three new papers per minute.

142
0:06:22.513,000 --> 0:06:23,000
So I've been up here a little over 10 minutes,

143
0:06:23.995,000 --> 0:06:24,000
I've already lost three papers.

144
0:06:25.771,000 --> 0:06:27,000
I have to get out of here actually. I have to go read.

145
0:06:28.611,000 --> 0:06:31,000
So what do we do about this? Well, the fact is

146
0:06:32.057,000 --> 0:06:36,000
that what scientists do about it is a kind of a controlled neglect, if you will.

147
0:06:36.566,000 --> 0:06:38,000
We just don't worry about it, in a way.

148
0:06:39.23,000 --> 0:06:41,000
The facts are important. You have to know a lot of stuff

149
0:06:41.473,000 --> 0:06:42,000
to be a scientist. That's true.

150
0:06:43.283,000 --> 0:06:45,000
But knowing a lot of stuff doesn't make you a scientist.

151
0:06:46.21,000 --> 0:06:48,000
You need to know a lot of stuff to be a lawyer

152
0:06:48.875,000 --> 0:06:51,000
or an accountant or an electrician or a carpenter.

153
0:06:52.767,000 --> 0:06:55,000
But in science, knowing a lot of stuff is not the point.

154
0:06:56.377,000 --> 0:06:59,000
Knowing a lot of stuff is there to help you get

155
0:06:59.933,000 --> 0:07:,000
to more ignorance.

156
0:07:01.321,000 --> 0:07:03,000
So knowledge is a big subject, but I would say

157
0:07:03.831,000 --> 0:07:05,000
ignorance is a bigger one.

158
0:07:06.318,000 --> 0:07:08,000
So this leads us to maybe think about, a little bit

159
0:07:08.528,000 --> 0:07:1,000
about, some of the models of science that we tend to use,

160
0:07:11.411,000 --> 0:07:12,000
and I'd like to disabuse you of some of them.

161
0:07:13.236,000 --> 0:07:15,000
So one of them, a popular one, is that scientists

162
0:07:15.549,000 --> 0:07:17,000
are patiently putting the pieces of a puzzle together

163
0:07:18.177,000 --> 0:07:2,000
to reveal some grand scheme or another.

164
0:07:20.95,000 --> 0:07:22,000
This is clearly not true. For one, with puzzles,

165
0:07:23.508,000 --> 0:07:26,000
the manufacturer has guaranteed that there's a solution.

166
0:07:27.007,000 --> 0:07:28,000
We don't have any such guarantee.

167
0:07:28.756,000 --> 0:07:31,000
Indeed, there are many of us who aren't so sure about the manufacturer.

168
0:07:31.911,000 --> 0:07:34,000
(Laughter)

169
0:07:34.974,000 --> 0:07:35,000
So I think the puzzle model doesn't work.

170
0:07:36.731,000 --> 0:07:39,000
Another popular model is that science is busy unraveling things

171
0:07:40.245,000 --> 0:07:42,000
the way you unravel the peels of an onion.

172
0:07:42.441,000 --> 0:07:44,000
So peel by peel, you take away the layers of the onion

173
0:07:45.43,000 --> 0:07:47,000
to get at some fundamental kernel of truth.

174
0:07:47.749,000 --> 0:07:49,000
I don't think that's the way it works either.

175
0:07:49.936,000 --> 0:07:51,000
Another one, a kind of popular one, is the iceberg idea,

176
0:07:52.87,000 --> 0:07:54,000
that we only see the tip of the iceberg but underneath

177
0:07:55.33,000 --> 0:07:57,000
is where most of the iceberg is hidden.

178
0:07:57.515,000 --> 0:08:,000
But all of these models are based on the idea of a large body of facts

179
0:08:01.069,000 --> 0:08:03,000
that we can somehow or another get completed.

180
0:08:03.489,000 --> 0:08:06,000
We can chip away at this iceberg and figure out what it is,

181
0:08:06.832,000 --> 0:08:08,000
or we could just wait for it to melt, I suppose, these days,

182
0:08:09.437,000 --> 0:08:12,000
but one way or another we could get to the whole iceberg. Right?

183
0:08:12.664,000 --> 0:08:14,000
Or make it manageable. But I don't think that's the case.

184
0:08:15.131,000 --> 0:08:17,000
I think what really happens in science

185
0:08:17.53,000 --> 0:08:18,000
is a model more like the magic well,

186
0:08:19.36,000 --> 0:08:2,000
where no matter how many buckets you take out,

187
0:08:21.197,000 --> 0:08:23,000
there's always another bucket of water to be had,

188
0:08:23.309,000 --> 0:08:25,000
or my particularly favorite one,

189
0:08:25.436,000 --> 0:08:27,000
with the effect and everything, the ripples on a pond.

190
0:08:28.375,000 --> 0:08:31,000
So if you think of knowledge being this ever-expanding ripple on a pond,

191
0:08:31.502,000 --> 0:08:34,000
the important thing to realize is that our ignorance,

192
0:08:34.884,000 --> 0:08:37,000
the circumference of this knowledge, also grows with knowledge.

193
0:08:38.266,000 --> 0:08:4,000
So the knowledge generates ignorance.

194
0:08:41.029,000 --> 0:08:43,000
This is really well said, I thought, by George Bernard Shaw.

195
0:08:43.944,000 --> 0:08:45,000
This is actually part of a toast that he delivered

196
0:08:46.621,000 --> 0:08:49,000
to celebrate Einstein at a dinner celebrating Einstein's work,

197
0:08:50.298,000 --> 0:08:51,000
in which he claims that science

198
0:08:51.712,000 --> 0:08:53,000
just creates more questions than it answers. ["Science is always wrong. It never solves a problem without creating 10 more."]

199
0:08:53.977,000 --> 0:08:56,000
I find that kind of glorious, and I think he's precisely right,

200
0:08:57.519,000 --> 0:08:59,000
plus it's a kind of job security.

201
0:09:00.045,000 --> 0:09:02,000
As it turns out, he kind of cribbed that

202
0:09:02.771,000 --> 0:09:03,000
from the philosopher Immanuel Kant

203
0:09:04.623,000 --> 0:09:06,000
who a hundred years earlier had come up with this idea

204
0:09:07.268,000 --> 0:09:1,000
of question propagation, that every answer begets more questions.

205
0:09:11.076,000 --> 0:09:13,000
I love that term, "question propagation,"

206
0:09:13.275,000 --> 0:09:15,000
this idea of questions propagating out there.

207
0:09:16.014,000 --> 0:09:17,000
So I'd say the model we want to take is not

208
0:09:17.901,000 --> 0:09:2,000
that we start out kind of ignorant and we get some facts together

209
0:09:21.41,000 --> 0:09:23,000
and then we gain knowledge.

210
0:09:23.553,000 --> 0:09:25,000
It's rather kind of the other way around, really.

211
0:09:25.932,000 --> 0:09:26,000
What do we use this knowledge for?

212
0:09:27.839,000 --> 0:09:29,000
What are we using this collection of facts for?

213
0:09:30.367,000 --> 0:09:32,000
We're using it to make better ignorance,

214
0:09:33.224,000 --> 0:09:36,000
to come up with, if you will, higher-quality ignorance.

215
0:09:36.303,000 --> 0:09:37,000
Because, you know, there's low-quality ignorance

216
0:09:38.175,000 --> 0:09:4,000
and there's high-quality ignorance. It's not all the same.

217
0:09:40.588,000 --> 0:09:42,000
Scientists argue about this all the time.

218
0:09:42.958,000 --> 0:09:43,000
Sometimes we call them bull sessions.

219
0:09:44.923,000 --> 0:09:45,000
Sometimes we call them grant proposals.

220
0:09:46.841,000 --> 0:09:49,000
But nonetheless, it's what the argument is about.

221
0:09:50.349,000 --> 0:09:51,000
It's the ignorance. It's the what we don't know.

222
0:09:52.193,000 --> 0:09:54,000
It's what makes a good question.

223
0:09:54.883,000 --> 0:09:55,000
So how do we think about these questions?

224
0:09:56.513,000 --> 0:09:57,000
I'm going to show you a graph that shows up

225
0:09:58.465,000 --> 0:10:01,000
quite a bit on happy hour posters in various science departments.

226
0:10:02.332,000 --> 0:10:06,000
This graph asks the relationship between what you know

227
0:10:06.553,000 --> 0:10:08,000
and how much you know about it.

228
0:10:08.743,000 --> 0:10:11,000
So what you know, you can know anywhere from nothing to everything, of course,

229
0:10:12.258,000 --> 0:10:13,000
and how much you know about it can be anywhere

230
0:10:13.941,000 --> 0:10:15,000
from a little to a lot.

231
0:10:16.364,000 --> 0:10:2,000
So let's put a point on the graph. There's an undergraduate.

232
0:10:20.596,000 --> 0:10:22,000
Doesn't know much but they have a lot of interest.

233
0:10:22.96,000 --> 0:10:23,000
They're interested in almost everything.

234
0:10:24.651,000 --> 0:10:27,000
Now you look at a master's student, a little further along in their education,

235
0:10:28.105,000 --> 0:10:29,000
and you see they know a bit more,

236
0:10:29.456,000 --> 0:10:3,000
but it's been narrowed somewhat.

237
0:10:31.346,000 --> 0:10:33,000
And finally you get your Ph.D., where it turns out

238
0:10:34.065,000 --> 0:10:39,000
you know a tremendous amount about almost nothing. (Laughter)

239
0:10:39.17,000 --> 0:10:42,000
What's really disturbing is the trend line that goes through that

240
0:10:42.951,000 --> 0:10:45,000
because, of course, when it dips below the zero axis, there,

241
0:10:46.726,000 --> 0:10:48,000
it gets into a negative area.

242
0:10:48.988,000 --> 0:10:5,000
That's where you find people like me, I'm afraid.

243
0:10:51.903,000 --> 0:10:54,000
So the important thing here is that this can all be changed.

244
0:10:55.271,000 --> 0:10:56,000
This whole view can be changed

245
0:10:57.075,000 --> 0:11:,000
by just changing the label on the x-axis.

246
0:11:00.236,000 --> 0:11:01,000
So instead of how much you know about it,

247
0:11:02.153,000 --> 0:11:05,000
we could say, "What can you ask about it?"

248
0:11:05.694,000 --> 0:11:07,000
So yes, you do need to know a lot of stuff as a scientist,

249
0:11:08.561,000 --> 0:11:1,000
but the purpose of knowing a lot of stuff

250
0:11:11.19,000 --> 0:11:13,000
is not just to know a lot of stuff. That just makes you a geek, right?

251
0:11:13.777,000 --> 0:11:15,000
Knowing a lot of stuff, the purpose is

252
0:11:15.915,000 --> 0:11:16,000
to be able to ask lots of questions,

253
0:11:17.591,000 --> 0:11:2,000
to be able to frame thoughtful, interesting questions,

254
0:11:20.679,000 --> 0:11:21,000
because that's where the real work is.

255
0:11:22.404,000 --> 0:11:24,000
Let me give you a quick idea of a couple of these sorts of questions.

256
0:11:24.956,000 --> 0:11:26,000
I'm a neuroscientist, so how would we come up

257
0:11:27.119,000 --> 0:11:28,000
with a question in neuroscience?

258
0:11:28.55,000 --> 0:11:3,000
Because it's not always quite so straightforward.

259
0:11:31.219,000 --> 0:11:33,000
So, for example, we could say, well what is it that the brain does?

260
0:11:33.778,000 --> 0:11:34,000
Well, one thing the brain does, it moves us around.

261
0:11:35.592,000 --> 0:11:37,000
We walk around on two legs.

262
0:11:37.597,000 --> 0:11:38,000
That seems kind of simple, somehow or another.

263
0:11:39.448,000 --> 0:11:41,000
I mean, virtually everybody over 10 months of age

264
0:11:42.173,000 --> 0:11:44,000
walks around on two legs, right?

265
0:11:44.345,000 --> 0:11:45,000
So that maybe is not that interesting.

266
0:11:45.736,000 --> 0:11:48,000
So instead maybe we want to choose something a little more complicated to look at.

267
0:11:48.884,000 --> 0:11:5,000
How about the visual system?

268
0:11:51.659,000 --> 0:11:52,000
There it is, the visual system.

269
0:11:53.286,000 --> 0:11:56,000
I mean, we love our visual systems. We do all kinds of cool stuff.

270
0:11:56.534,000 --> 0:11:59,000
Indeed, there are over 12,000 neuroscientists

271
0:11:59.925,000 --> 0:12:,000
who work on the visual system,

272
0:12:01.505,000 --> 0:12:03,000
from the retina to the visual cortex,

273
0:12:03.586,000 --> 0:12:05,000
in an attempt to understand not just the visual system

274
0:12:06.151,000 --> 0:12:09,000
but to also understand how general principles

275
0:12:09.175,000 --> 0:12:1,000
of how the brain might work.

276
0:12:11.126,000 --> 0:12:12,000
But now here's the thing:

277
0:12:12.786,000 --> 0:12:14,000
Our technology has actually been pretty good

278
0:12:15.266,000 --> 0:12:17,000
at replicating what the visual system does.

279
0:12:17.856,000 --> 0:12:2,000
We have TV, we have movies,

280
0:12:20.879,000 --> 0:12:22,000
we have animation, we have photography,

281
0:12:23.374,000 --> 0:12:26,000
we have pattern recognition, all of these sorts of things.

282
0:12:26.525,000 --> 0:12:28,000
They work differently than our visual systems in some cases,

283
0:12:29.171,000 --> 0:12:3,000
but nonetheless we've been pretty good at

284
0:12:30.762,000 --> 0:12:33,000
making a technology work like our visual system.

285
0:12:34.238,000 --> 0:12:36,000
Somehow or another, a hundred years of robotics,

286
0:12:37.174,000 --> 0:12:39,000
you never saw a robot walk on two legs,

287
0:12:39.44,000 --> 0:12:41,000
because robots don't walk on two legs

288
0:12:41.603,000 --> 0:12:43,000
because it's not such an easy thing to do.

289
0:12:43.993,000 --> 0:12:44,000
A hundred years of robotics,

290
0:12:45.521,000 --> 0:12:48,000
and we can't get a robot that can move more than a couple steps one way or the other.

291
0:12:48.888,000 --> 0:12:5,000
You ask them to go up an inclined plane, and they fall over.

292
0:12:51.46,000 --> 0:12:53,000
Turn around, and they fall over. It's a serious problem.

293
0:12:53.464,000 --> 0:12:56,000
So what is it that's the most difficult thing for a brain to do?

294
0:12:57.011,000 --> 0:12:58,000
What ought we to be studying?

295
0:12:58.634,000 --> 0:13:02,000
Perhaps it ought to be walking on two legs, or the motor system.

296
0:13:02.929,000 --> 0:13:03,000
I'll give you an example from my own lab,

297
0:13:04.664,000 --> 0:13:05,000
my own particularly smelly question,

298
0:13:06.389,000 --> 0:13:08,000
since we work on the sense of smell.

299
0:13:08.488,000 --> 0:13:11,000
But here's a diagram of five molecules

300
0:13:11.716,000 --> 0:13:12,000
and sort of a chemical notation.

301
0:13:13.226,000 --> 0:13:15,000
These are just plain old molecules, but if you sniff those molecules

302
0:13:16.222,000 --> 0:13:18,000
up these two little holes in the front of your face,

303
0:13:18.692,000 --> 0:13:21,000
you will have in your mind the distinct impression of a rose.

304
0:13:22.566,000 --> 0:13:24,000
If there's a real rose there, those molecules will be the ones,

305
0:13:24.724,000 --> 0:13:25,000
but even if there's no rose there,

306
0:13:26.284,000 --> 0:13:27,000
you'll have the memory of a molecule.

307
0:13:27.875,000 --> 0:13:3,000
How do we turn molecules into perceptions?

308
0:13:30.979,000 --> 0:13:31,000
What's the process by which that could happen?

309
0:13:32.836,000 --> 0:13:35,000
Here's another example: two very simple molecules, again in this kind of chemical notation.

310
0:13:36.796,000 --> 0:13:38,000
It might be easier to visualize them this way,

311
0:13:38.873,000 --> 0:13:4,000
so the gray circles are carbon atoms, the white ones

312
0:13:41.667,000 --> 0:13:43,000
are hydrogen atoms and the red ones are oxygen atoms.

313
0:13:44.442,000 --> 0:13:48,000
Now these two molecules differ by only one carbon atom

314
0:13:48.74,000 --> 0:13:5,000
and two little hydrogen atoms that ride along with it,

315
0:13:51.428,000 --> 0:13:52,000
and yet one of them, heptyl acetate,

316
0:13:53.414,000 --> 0:13:55,000
has the distinct odor of a pear,

317
0:13:55.725,000 --> 0:13:58,000
and hexyl acetate is unmistakably banana.

318
0:13:59.564,000 --> 0:14:01,000
So there are two really interesting questions here, it seems to me.

319
0:14:02.121,000 --> 0:14:05,000
One is, how can a simple little molecule like that

320
0:14:05.336,000 --> 0:14:07,000
create a perception in your brain that's so clear

321
0:14:07.804,000 --> 0:14:08,000
as a pear or a banana?

322
0:14:09.546,000 --> 0:14:12,000
And secondly, how the hell can we tell the difference

323
0:14:12.667,000 --> 0:14:16,000
between two molecules that differ by a single carbon atom?

324
0:14:16.982,000 --> 0:14:17,000
I mean, that's remarkable to me,

325
0:14:18.628,000 --> 0:14:21,000
clearly the best chemical detector on the face of the planet.

326
0:14:21.66,000 --> 0:14:23,000
And you don't even think about it, do you?

327
0:14:24.436,000 --> 0:14:26,000
So this is a favorite quote of mine that takes us

328
0:14:27.053,000 --> 0:14:28,000
back to the ignorance and the idea of questions.

329
0:14:28.799,000 --> 0:14:3,000
I like to quote because I think dead people

330
0:14:30.818,000 --> 0:14:32,000
shouldn't be excluded from the conversation.

331
0:14:33.361,000 --> 0:14:34,000
And I also think it's important to realize that

332
0:14:35.3,000 --> 0:14:37,000
the conversation's been going on for a while, by the way.

333
0:14:37.762,000 --> 0:14:39,000
So Erwin Schrodinger, a great quantum physicist

334
0:14:40.52,000 --> 0:14:42,000
and, I think, philosopher, points out how you have to

335
0:14:43.086,000 --> 0:14:46,000
"abide by ignorance for an indefinite period" of time.

336
0:14:46.551,000 --> 0:14:47,000
And it's this abiding by ignorance

337
0:14:48.538,000 --> 0:14:49,000
that I think we have to learn how to do.

338
0:14:50.204,000 --> 0:14:52,000
This is a tricky thing. This is not such an easy business.

339
0:14:53.181,000 --> 0:14:54,000
I guess it comes down to our education system,

340
0:14:55.14,000 --> 0:14:57,000
so I'm going to talk a little bit about ignorance and education,

341
0:14:57.597,000 --> 0:14:59,000
because I think that's where it really has to play out.

342
0:14:59.865,000 --> 0:15:01,000
So for one, let's face it,

343
0:15:02.132,000 --> 0:15:05,000
in the age of Google and Wikipedia,

344
0:15:05.484,000 --> 0:15:06,000
the business model of the university

345
0:15:07.277,000 --> 0:15:1,000
and probably secondary schools is simply going to have to change.

346
0:15:10.698,000 --> 0:15:11,000
We just can't sell facts for a living anymore.

347
0:15:12.599,000 --> 0:15:14,000
They're available with a click of the mouse,

348
0:15:14.649,000 --> 0:15:16,000
or if you want to, you could probably just ask the wall

349
0:15:17.145,000 --> 0:15:18,000
one of these days, wherever they're going to hide the things

350
0:15:18.857,000 --> 0:15:19,000
that tell us all this stuff.

351
0:15:20.274,000 --> 0:15:22,000
So what do we have to do? We have to give our students

352
0:15:23.157,000 --> 0:15:26,000
a taste for the boundaries, for what's outside that circumference,

353
0:15:27.053,000 --> 0:15:31,000
for what's outside the facts, what's just beyond the facts.

354
0:15:31.361,000 --> 0:15:33,000
How do we do that?

355
0:15:33.518,000 --> 0:15:34,000
Well, one of the problems, of course,

356
0:15:35.026,000 --> 0:15:37,000
turns out to be testing.

357
0:15:37.135,000 --> 0:15:39,000
We currently have an educational system

358
0:15:39.784,000 --> 0:15:42,000
which is very efficient but is very efficient at a rather bad thing.

359
0:15:43.493,000 --> 0:15:45,000
So in second grade, all the kids are interested in science,

360
0:15:46.467,000 --> 0:15:47,000
the girls and the boys.

361
0:15:47.73,000 --> 0:15:5,000
They like to take stuff apart. They have great curiosity.

362
0:15:51.704,000 --> 0:15:53,000
They like to investigate things. They go to science museums.

363
0:15:54.203,000 --> 0:16:,000
They like to play around. They're in second grade.

364
0:16:00.407,000 --> 0:16:01,000
They're interested.

365
0:16:01.901,000 --> 0:16:03,000
But by 11th or 12th grade, fewer than 10 percent

366
0:16:04.835,000 --> 0:16:07,000
of them have any interest in science whatsoever,

367
0:16:07.91,000 --> 0:16:09,000
let alone a desire to go into science as a career.

368
0:16:10.855,000 --> 0:16:12,000
So we have this remarkably efficient system

369
0:16:13.837,000 --> 0:16:16,000
for beating any interest in science out of everybody's head.

370
0:16:17.81,000 --> 0:16:18,000
Is this what we want?

371
0:16:19.724,000 --> 0:16:21,000
I think this comes from what a teacher colleague of mine

372
0:16:22.066,000 --> 0:16:24,000
calls "the bulimic method of education."

373
0:16:24.788,000 --> 0:16:25,000
You know. You can imagine what it is.

374
0:16:26.161,000 --> 0:16:28,000
We just jam a whole bunch of facts down their throats over here

375
0:16:29.109,000 --> 0:16:31,000
and then they puke it up on an exam over here

376
0:16:31.463,000 --> 0:16:35,000
and everybody goes home with no added intellectual heft whatsoever.

377
0:16:36.042,000 --> 0:16:38,000
This can't possibly continue to go on.

378
0:16:38.123,000 --> 0:16:4,000
So what do we do? Well the geneticists, I have to say,

379
0:16:40.457,000 --> 0:16:41,000
have an interesting maxim they live by.

380
0:16:42.44,000 --> 0:16:47,000
Geneticists always say, you always get what you screen for.

381
0:16:47.692,000 --> 0:16:49,000
And that's meant as a warning.

382
0:16:50.553,000 --> 0:16:52,000
So we always will get what we screen for,

383
0:16:52.872,000 --> 0:16:55,000
and part of what we screen for is in our testing methods.

384
0:16:56.327,000 --> 0:16:59,000
Well, we hear a lot about testing and evaluation,

385
0:16:59.57,000 --> 0:17:01,000
and we have to think carefully when we're testing

386
0:17:01.757,000 --> 0:17:04,000
whether we're evaluating or whether we're weeding,

387
0:17:04.844,000 --> 0:17:05,000
whether we're weeding people out,

388
0:17:06.303,000 --> 0:17:09,000
whether we're making some cut.

389
0:17:09.437,000 --> 0:17:11,000
Evaluation is one thing. You hear a lot about evaluation

390
0:17:12.078,000 --> 0:17:14,000
in the literature these days, in the educational literature,

391
0:17:14.988,000 --> 0:17:16,000
but evaluation really amounts to feedback and it amounts

392
0:17:17.946,000 --> 0:17:19,000
to an opportunity for trial and error.

393
0:17:20.1,000 --> 0:17:24,000
It amounts to a chance to work over a longer period of time

394
0:17:24.594,000 --> 0:17:25,000
with this kind of feedback.

395
0:17:26.504,000 --> 0:17:28,000
That's different than weeding, and usually, I have to tell you,

396
0:17:29.442,000 --> 0:17:31,000
when people talk about evaluation, evaluating students,

397
0:17:32.168,000 --> 0:17:34,000
evaluating teachers, evaluating schools,

398
0:17:34.955,000 --> 0:17:38,000
evaluating programs, that they're really talking about weeding.

399
0:17:39.116,000 --> 0:17:43,000
And that's a bad thing, because then you will get what you select for,

400
0:17:43.326,000 --> 0:17:44,000
which is what we've gotten so far.

401
0:17:45.284,000 --> 0:17:48,000
So I'd say what we need is a test that says, "What is x?"

402
0:17:48.725,000 --> 0:17:51,000
and the answers are "I don't know, because no one does,"

403
0:17:51.817,000 --> 0:17:52,000
or "What's the question?" Even better.

404
0:17:53.558,000 --> 0:17:55,000
Or, "You know what, I'll look it up, I'll ask someone,

405
0:17:55.964,000 --> 0:17:57,000
I'll phone someone. I'll find out."

406
0:17:58.664,000 --> 0:17:59,000
Because that's what we want people to do,

407
0:18:00.214,000 --> 0:18:01,000
and that's how you evaluate them.

408
0:18:01.585,000 --> 0:18:02,000
And maybe for the advanced placement classes,

409
0:18:03.528,000 --> 0:18:06,000
it could be, "Here's the answer. What's the next question?"

410
0:18:07.242,000 --> 0:18:08,000
That's the one I like in particular.

411
0:18:08.753,000 --> 0:18:1,000
So let me end with a quote from William Butler Yeats,

412
0:18:10.93,000 --> 0:18:13,000
who said "Education is not about filling buckets;

413
0:18:14.097,000 --> 0:18:16,000
it is lighting fires."

414
0:18:16.25,000 --> 0:18:19,000
So I'd say, let's get out the matches.

415
0:18:20.125,000 --> 0:18:21,000
Thank you.

416
0:18:21.333,000 --> 0:18:24,000
(Applause)

417
0:18:24.56,000 --> 0:18:27,000
Thank you. (Applause)

