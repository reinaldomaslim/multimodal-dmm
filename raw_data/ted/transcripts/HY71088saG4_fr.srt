1
0:00:,000 --> 0:00:07,000
Traducteur: Morgane Quilfen Relecteur: eric vautier

2
0:00:12.833,000 --> 0:00:15,000
En 2011, j'ai changé de nom

3
0:00:16.255,000 --> 0:00:19,000
afin de pouvoir participer à un camp de jeunes de l'extrême droite en Hongrie.

4
0:00:20.794,000 --> 0:00:24,000
J'étais en doctorat, étudiant la socialisation politique des jeunes --

5
0:00:25.184,000 --> 0:00:28,000
pourquoi les jeunes développaient des idéologies politiques

6
0:00:28.279,000 --> 0:00:3,000
dans un environnement post-communiste --

7
0:00:30.313,000 --> 0:00:33,000
j'ai vu que beaucoup des jeunes auxquels je parlais

8
0:00:33.57,000 --> 0:00:34,000
adhéraient à l'extrême-droite

9
0:00:35.194,000 --> 0:00:37,000
et j'ai trouvé cela stupéfiant.

10
0:00:37.374,000 --> 0:00:39,000
Alors j'ai voulu m'inscrire à ce camp de jeunes

11
0:00:39.693,000 --> 0:00:42,000
pour mieux comprendre pourquoi les gens y adhéraient.

12
0:00:42.853,000 --> 0:00:43,000
Un collègue m'a inscrite

13
0:00:44.434,000 --> 0:00:46,000
et mon nom de famille a une consonance trop juive.

14
0:00:47.68,000 --> 0:00:49,000
Erin s'est transformé en Iréna

15
0:00:50.449,000 --> 0:00:52,000
et Saltman en Sós,

16
0:00:52.673,000 --> 0:00:54,000
qui veut dire « salé » en hongrois.

17
0:00:55.618,000 --> 0:00:57,000
En hongrois, le nom de famille vient d'abord

18
0:00:57.952,000 --> 0:01:01,000
donc mon nom d'espionne s'est transformé en « Salée Irena »,

19
0:01:02.39,000 --> 0:01:05,000
ce qui n'est pas quelque chose que j'aurais naturellement choisi.

20
0:01:06.28,000 --> 0:01:07,000
Mais en allant à ce camp,

21
0:01:08.211,000 --> 0:01:12,000
j'ai été encore plus choquée de réaliser que c'était très amusant.

22
0:01:13.18,000 --> 0:01:15,000
Ils ont très peu parlé de politique.

23
0:01:15.419,000 --> 0:01:18,000
C'était principalement apprendre à monter à cheval,

24
0:01:18.456,000 --> 0:01:19,000
tirer avec un arc et des flèches,

25
0:01:20.348,000 --> 0:01:21,000
de la musique le soir,

26
0:01:22.059,000 --> 0:01:23,000
de la nourriture et de l'alcool gratuits,

27
0:01:24.052,000 --> 0:01:26,000
du tir sur cible avec des armes à air comprimé

28
0:01:26.942,000 --> 0:01:29,000
avec pour cible le visage des principaux politiciens.

29
0:01:30.62,000 --> 0:01:33,000
Cela semblait être un groupe très amical et ouvert

30
0:01:34.371,000 --> 0:01:39,000
jusqu'à ce que vous mentionniez quoi que ce soit en lien avec la population rom,

31
0:01:39.808,000 --> 0:01:41,000
les juifs ou les immigrants,

32
0:01:42.094,000 --> 0:01:46,000
alors le discours se basait très vite sur la haine.

33
0:01:46.843,000 --> 0:01:48,000
Cela m'a menée à mon travail actuel

34
0:01:49.677,000 --> 0:01:51,000
où nous posons la question :

35
0:01:52.082,000 --> 0:01:55,000
« Pourquoi les gens adhèrent-ils à des mouvements extrémistes violents

36
0:01:55.362,000 --> 0:01:57,000
et comment contrer efficacement ces processus ? »

37
0:01:58.573,000 --> 0:02:01,000
Dans le sillage d'horribles atrocités et attaques

38
0:02:01.888,000 --> 0:02:04,000
dans des endroits comme la Belgique, la France mais à travers le monde,

39
0:02:05.275,000 --> 0:02:06,000
il est parfois plus simple de penser :

40
0:02:07.132,000 --> 0:02:08,000
« Ce doit être des sociopathes,

41
0:02:09.101,000 --> 0:02:12,000
ce doit être des individus naturellement violents.

42
0:02:12.189,000 --> 0:02:14,000
Quelque chose doit clocher dans leur éducation. »

43
0:02:14.809,000 --> 0:02:16,000
Ce qui est tragique

44
0:02:16.92,000 --> 0:02:18,000
est que, souvent, il n'y a pas de profil unique.

45
0:02:19.171,000 --> 0:02:22,000
Beaucoup de gens sont éduqués,

46
0:02:22.413,000 --> 0:02:24,000
sont d'origines socio-économiques diverses,

47
0:02:24.533,000 --> 0:02:26,000
des hommes et des femmes, différents âges,

48
0:02:27.405,000 --> 0:02:29,000
certains ayant une famille, d'autres célibataires.

49
0:02:29.783,000 --> 0:02:31,000
Pourquoi ? Qu'est-ce qui les attire ?

50
0:02:32.386,000 --> 0:02:34,000
C'est de cela dont je veux vous parler,

51
0:02:34.459,000 --> 0:02:36,000
ainsi que comment remettre cela en question à l'ère moderne.

52
0:02:38.711,000 --> 0:02:39,000
Nous savons, grâce à des études,

53
0:02:40.234,000 --> 0:02:42,000
qu'il y a un certain nombre de choses différentes

54
0:02:42.598,000 --> 0:02:45,000
qui influencent le processus de radicalisation de quelqu'un

55
0:02:45.973,000 --> 0:02:47,000
catégorisées en facteurs d'attraction et de répulsion.

56
0:02:48.767,000 --> 0:02:51,000
Ces choses sont similaires pour les groupes d'extrême-droite, néo-nazis,

57
0:02:52.204,000 --> 0:02:54,000
jusqu'aux groupes islamistes extrémistes et terroristes.

58
0:02:55.663,000 --> 0:02:58,000
Les facteurs de répulsion sont ce qui vous rend vulnérable

59
0:02:59.545,000 --> 0:03:,000
à un processus de radicalisation,

60
0:03:01.427,000 --> 0:03:03,000
à l'adhésion à un groupe extrémiste violent.

61
0:03:03.657,000 --> 0:03:05,000
Cela peut être beaucoup de choses différentes,

62
0:03:05.823,000 --> 0:03:08,000
en général : un sentiment d'aliénation ; un sentiment d'isolement ;

63
0:03:09.744,000 --> 0:03:11,000
un questionnement de son identité ;

64
0:03:11.919,000 --> 0:03:13,000
mais également le sentiment que votre groupe est attaqué

65
0:03:14.769,000 --> 0:03:17,000
et votre groupe peut être basé sur une nationalité, une ethnie

66
0:03:18.586,000 --> 0:03:19,000
ou une religion ;

67
0:03:19.936,000 --> 0:03:22,000
un sentiment que les puissances autour de vous ne font rien pour aider.

68
0:03:24.075,000 --> 0:03:27,000
Les facteurs de répulsion seuls ne font pas de vous un extrémiste violent

69
0:03:27.52,000 --> 0:03:28,000
car si c'était le cas,

70
0:03:28.974,000 --> 0:03:31,000
les mêmes facteurs s'appliqueraient à un groupe tel que la population rom

71
0:03:32.434,000 --> 0:03:34,000
et ce n'est pas un groupe violemment mobilisé.

72
0:03:35.073,000 --> 0:03:37,000
Nous devons considérer les facteurs d'attraction.

73
0:03:37.384,000 --> 0:03:4,000
Qu'offrent ces organisations extrémistes violentes

74
0:03:40.718,000 --> 0:03:41,000
que d'autres groupes n'offrent pas ?

75
0:03:42.687,000 --> 0:03:44,000
Ce sont en général des choses très positives,

76
0:03:45.274,000 --> 0:03:47,000
très stimulantes,

77
0:03:47.315,000 --> 0:03:5,000
telles que la fraternité et un sentiment d'appartenance.

78
0:03:51.16,000 --> 0:03:53,000
Ils offrent également un objectif spirituel,

79
0:03:54.058,000 --> 0:03:57,000
un objectif divin de construction d'une société utopique

80
0:03:57.797,000 --> 0:03:58,000
si leurs buts sont atteints,

81
0:03:59.742,000 --> 0:04:01,000
mais aussi un sentiment d'émancipation et d'aventure.

82
0:04:02.517,000 --> 0:04:04,000
Les combattants terroristes étrangers

83
0:04:04.584,000 --> 0:04:06,000
sont des jeunes hommes avec les cheveux dans le vent,

84
0:04:07.299,000 --> 0:04:09,000
dans le désert et des femmes les rejoignent

85
0:04:09.869,000 --> 0:04:11,000
pour la nuit au coucher du soleil.

86
0:04:12.534,000 --> 0:04:15,000
C'est très romantique, vous devenez un héros.

87
0:04:16.378,000 --> 0:04:18,000
Pour les hommes et les femmes, c'est la propagande présentée.

88
0:04:19.667,000 --> 0:04:21,000
Les groupes extrémistes sont très bons

89
0:04:22.333,000 --> 0:04:26,000
pour prendre un monde très compliqué, déroutant et nuancé

90
0:04:27.183,000 --> 0:04:3,000
et simplifier ce monde en noir et blanc,

91
0:04:30.45,000 --> 0:04:31,000
en bien et mal.

92
0:04:31.684,000 --> 0:04:32,000
Vous devenez ce qui est bon

93
0:04:33.589,000 --> 0:04:34,000
et défiez ce qui est mal.

94
0:04:36.541,000 --> 0:04:39,000
J'aimerais parler un peu de Daech,

95
0:04:40.429,000 --> 0:04:44,000
car ils ont changé la donne concernant notre regard sur ces processus,

96
0:04:44.831,000 --> 0:04:47,000
via leur matériel et leurs tactiques.

97
0:04:48.061,000 --> 0:04:5,000
C'est un mouvement très moderne.

98
0:04:50.925,000 --> 0:04:54,000
L'un des aspects est internet et l'utilisation des réseaux sociaux,

99
0:04:55.434,000 --> 0:04:59,000
nous avons tous vu les gros titres, les tweets et les vidéos de décapitations.

100
0:04:59.84,000 --> 0:05:01,000
Mais internet seul ne vous radicalise pas.

101
0:05:02.339,000 --> 0:05:03,000
Internet est un outil.

102
0:05:03.57,000 --> 0:05:04,000
En achetant des chaussures en ligne,

103
0:05:05.45,000 --> 0:05:06,000
vous ne devenez pas un djihadiste.

104
0:05:07.793,000 --> 0:05:1,000
Cependant, internet est un catalyseur.

105
0:05:11.206,000 --> 0:05:15,000
Il fournit des outils, une échelle, une rapidité

106
0:05:15.349,000 --> 0:05:16,000
qui n'existent pas ailleurs.

107
0:05:16.881,000 --> 0:05:18,000
Avec l'EI, tout à coup,

108
0:05:19.366,000 --> 0:05:24,000
l'idée de ce visage sombre et masqué d'un djihadiste a changé.

109
0:05:24.708,000 --> 0:05:26,000
Tout à coup, nous étions dans leur cuisine.

110
0:05:26.787,000 --> 0:05:27,000
Nous avons vu ce qu'ils mangeaient le soir.

111
0:05:28.81,000 --> 0:05:29,000
Ils tweetaient.

112
0:05:29.985,000 --> 0:05:32,000
Des combattants terroristes étrangers tweetaient dans leur langue.

113
0:05:33.167,000 --> 0:05:35,000
Des femmes se manifestaient, parlant de leur mariage,

114
0:05:36.143,000 --> 0:05:37,000
de la naissance de leurs enfants.

115
0:05:37.914,000 --> 0:05:38,000
Il y avait une culture de jeux vidéo

116
0:05:39.835,000 --> 0:05:42,000
et des références à Grand Theft Auto.

117
0:05:43.471,000 --> 0:05:45,000
Tout à coup, ils étaient accueillants.

118
0:05:45.956,000 --> 0:05:46,000
Ils sont devenus humains.

119
0:05:47.147,000 --> 0:05:49,000
Le problème est qu'en essayant de contrer cela,

120
0:05:49.369,000 --> 0:05:51,000
beaucoup de gouvernements et de réseaux sociaux

121
0:05:51.703,000 --> 0:05:52,000
ont essayé la censure.

122
0:05:52.798,000 --> 0:05:54,000
Comment se débarrasser du contenu terroriste ?

123
0:05:54.949,000 --> 0:05:55,000
C'est un jeu du chat et de la souris

124
0:05:56.668,000 --> 0:05:59,000
où des comptes étaient supprimés et revenaient immédiatement,

125
0:05:59.8,000 --> 0:06:02,000
il y avait de l'arrogance pour quelqu'un ayant un 25ème compte

126
0:06:02.953,000 --> 0:06:05,000
et du contenu disséminé partout.

127
0:06:06.055,000 --> 0:06:08,000
Nous avons observé une tendance dangereuse --

128
0:06:08.146,000 --> 0:06:09,000
les extrémistes violents aussi

129
0:06:10.132,000 --> 0:06:13,000
connaissent les règles et règlements des réseaux sociaux.

130
0:06:13.132,000 --> 0:06:17,000
Nous voyions une conversation banale avec un recruteur

131
0:06:17.156,000 --> 0:06:18,000
sur une plateforme grand public

132
0:06:19.153,000 --> 0:06:22,000
et quand la conversation allait devenir illégale,

133
0:06:22.622,000 --> 0:06:25,000
ils passaient à une plateforme plus petite, moins réglementée,

134
0:06:25.633,000 --> 0:06:26,000
plus cryptée.

135
0:06:26.794,000 --> 0:06:29,000
Tout à coup, nous ne pouvions pas localiser où était cette conversation.

136
0:06:30.351,000 --> 0:06:31,000
C'est un problème avec la censure,

137
0:06:32.237,000 --> 0:06:35,000
c'est pourquoi nous devons développer des alternatives à la censure.

138
0:06:36.035,000 --> 0:06:39,000
Daech a aussi changé la donne car il vise à créer un État.

139
0:06:39.409,000 --> 0:06:41,000
Il n'y a pas que le recrutement de combattants,

140
0:06:41.601,000 --> 0:06:42,000
il vise à créer un État.

141
0:06:43.431,000 --> 0:06:44,000
Cela signifie que tout à coup,

142
0:06:45.395,000 --> 0:06:47,000
le modèle de recrutement est plus large.

143
0:06:47.419,000 --> 0:06:49,000
Il ne s'agit pas que d'avoir des combattants,

144
0:06:49.548,000 --> 0:06:53,000
il faut des architectes, des ingénieurs, des comptables, des pirates et des femmes.

145
0:06:53.782,000 --> 0:06:55,000
Nous avons vu une forte augmentation des femmes

146
0:06:56.196,000 --> 0:06:59,000
adhérant les 24 et surtout les 12 derniers mois.

147
0:06:59.719,000 --> 0:07:02,000
Dans certains pays, une personne sur quatre rejoignant le combat

148
0:07:02.748,000 --> 0:07:03,000
est une femme.

149
0:07:03.895,000 --> 0:07:04,000
Cela change vraiment

150
0:07:05.287,000 --> 0:07:07,000
pour qui nous essayons de contrer ce processus.

151
0:07:08.679,000 --> 0:07:09,000
Tout n'est pas sombre.

152
0:07:10.354,000 --> 0:07:12,000
J'aimerais parler de choses positives

153
0:07:13.338,000 --> 0:07:14,000
et de l'innovation pour essayer

154
0:07:14.868,000 --> 0:07:16,000
de prévenir et de contrer le terrorisme violent.

155
0:07:17.206,000 --> 0:07:19,000
Prévenir et contrer sont deux choses différentes

156
0:07:19.503,000 --> 0:07:21,000
et vous pouvez le voir comme des termes médicaux.

157
0:07:22.083,000 --> 0:07:24,000
La médecine préventive,

158
0:07:24.329,000 --> 0:07:27,000
c'est s'assurer que vous soyez naturellement résistants

159
0:07:27.527,000 --> 0:07:29,000
à ce processus de radicalisation

160
0:07:30.051,000 --> 0:07:31,000
tandis que cela sera différent

161
0:07:31.937,000 --> 0:07:33,000
si quelqu'un présente déjà des symptômes ou un signe

162
0:07:34.62,000 --> 0:07:36,000
d'appartenance à une idéologie extrémiste violente.

163
0:07:37.525,000 --> 0:07:38,000
Dans les mesures préventives,

164
0:07:39.096,000 --> 0:07:41,000
nous parlons plus de larges groupes de gens

165
0:07:41.811,000 --> 0:07:42,000
et de l'exposition à des idées

166
0:07:43.652,000 --> 0:07:44,000
pour les rendre résistants.

167
0:07:45.443,000 --> 0:07:46,000
Cela est très différent

168
0:07:46.983,000 --> 0:07:49,000
si quelqu'un se pose des questions et est d'accord avec des choses en ligne.

169
0:07:50.832,000 --> 0:07:53,000
C'est aussi très différent si quelqu'un a déjà un tatouage de croix gammée

170
0:07:54.705,000 --> 0:07:56,000
et est très intégré à un groupe.

171
0:07:56.777,000 --> 0:07:57,000
Comment établir le contact ?

172
0:07:58.785,000 --> 0:08:01,000
J'aimerais évoquer trois exemples de chacun de ces trois niveaux

173
0:08:02.491,000 --> 0:08:03,000
et vous expliquer

174
0:08:03.73,000 --> 0:08:06,000
certaines des nouvelles méthodes pour engager le dialogue avec les gens.

175
0:08:07.374,000 --> 0:08:08,000
Il y a « Dialogue extrême »,

176
0:08:08.811,000 --> 0:08:11,000
c'est un programme éducatif que nous avons aidé à développer.

177
0:08:11.915,000 --> 0:08:13,000
Il vient du Canada

178
0:08:14.32,000 --> 0:08:18,000
et il est censé créer des dialogues dans une salle de classe

179
0:08:18.439,000 --> 0:08:19,000
grâce à la narration,

180
0:08:19.995,000 --> 0:08:22,000
car l'extrémisme violent peut être très difficile à expliquer,

181
0:08:23.17,000 --> 0:08:24,000
en particulier aux plus jeunes.

182
0:08:25.305,000 --> 0:08:28,000
Nous avons un réseau d'anciens extrémistes et de survivants de l'extrémisme

183
0:08:29.242,000 --> 0:08:32,000
qui racontent leur histoire en vidéo et soulèvent des questions pour la classe

184
0:08:33.203,000 --> 0:08:35,000
afin de lancer une conversation sur ce sujet.

185
0:08:35.53,000 --> 0:08:37,000
Ces deux exemples montrent comment Christiane,

186
0:08:38.086,000 --> 0:08:39,000
qui a perdu son fils

187
0:08:39.261,000 --> 0:08:41,000
qui s'est radicalisé et est mort en se battant pour l'EI,

188
0:08:41.924,000 --> 0:08:42,000
et Daniel, ancien néo-nazi,

189
0:08:43.469,000 --> 0:08:45,000
qui était un néo-nazi extrêmement violent.

190
0:08:45.851,000 --> 0:08:49,000
Ils posent des questions sur leur vie, où ils en sont et ce qu'ils regrettent,

191
0:08:50.033,000 --> 0:08:52,000
poussant la classe à avoir un dialogue à ce sujet.

192
0:08:53.175,000 --> 0:08:55,000
En considérant cette plage moyenne d'individus,

193
0:08:56.184,000 --> 0:08:58,000
nous avons besoin de beaucoup de voix de la société civile.

194
0:08:58.973,000 --> 0:09:01,000
Comment interagir avec des gens cherchant des informations en ligne,

195
0:09:02.376,000 --> 0:09:04,000
commençant à jouer avec une idéologie,

196
0:09:04.742,000 --> 0:09:07,000
se posant ces questions à la recherche de leur identité ?

197
0:09:07.83,000 --> 0:09:09,000
Comment fournir des alternatives ?

198
0:09:09.996,000 --> 0:09:12,000
C'est là que nous combinons de grands groupes de voix de la société civile

199
0:09:13.466,000 --> 0:09:16,000
avec des créateurs, des technophiles, des développeurs d'applications,

200
0:09:16.765,000 --> 0:09:17,000
des artistes, des comédiens

201
0:09:18.055,000 --> 0:09:2,000
et nous pouvons créer du contenu spécifique

202
0:09:20.672,000 --> 0:09:24,000
et le disséminer en ligne aux publics stratégiques.

203
0:09:24.99,000 --> 0:09:26,000
Un exemple serait de créer une vidéo satirique

204
0:09:27.817,000 --> 0:09:29,000
qui se moque de l'islamophobie

205
0:09:30.34,000 --> 0:09:33,000
et de cibler en ligne les gens de 15 à 20 ans

206
0:09:34.3,000 --> 0:09:36,000
qui sont intéressés par la musique du pouvoir blanc

207
0:09:36.707,000 --> 0:09:38,000
et vivent à Manchester.

208
0:09:38.994,000 --> 0:09:41,000
Nous pouvons utiliser ces outils de marketing pour être spécifiques

209
0:09:42.145,000 --> 0:09:44,000
afin de savoir que, quand quelqu'un regarde

210
0:09:44.796,000 --> 0:09:45,000
et s'intéresse à ce contenu,

211
0:09:46.309,000 --> 0:09:48,000
ce n'est pas une personne ordinaire, ni moi ni vous,

212
0:09:49.029,000 --> 0:09:52,000
c'est un public spécifique avec lequel nous voulons interagir.

213
0:09:52.704,000 --> 0:09:55,000
Encore plus en aval, nous avons développé un programme, « Tête à tête »,

214
0:09:56.427,000 --> 0:09:57,000
où d'anciens extrémistes

215
0:09:58,000 --> 0:10:02,000
prenaient directement contact avec un groupe classifié comme néofasciste

216
0:10:02.888,000 --> 0:10:03,000
et des extrémistes islamistes

217
0:10:04.536,000 --> 0:10:07,000
en envoyant dans leur boîte de réception sur Facebook des messages disant :

218
0:10:08.375,000 --> 0:10:1,000
« Hé ! J'ai vu où tu allais. Je suis passé par là.

219
0:10:10.721,000 --> 0:10:11,000
Si tu veux parler, je suis là. »

220
0:10:12.267,000 --> 0:10:15,000
Nous nous attendions à des menaces de mort avec ces interactions.

221
0:10:15.529,000 --> 0:10:19,000
C'est alarmant qu'un ancien néo-nazi vous demande comment ça va.

222
0:10:19.973,000 --> 0:10:21,000
Nous avons découvert qu'environ 60%

223
0:10:22.204,000 --> 0:10:24,000
des personnes contactées répondaient

224
0:10:24.782,000 --> 0:10:28,000
et, parmi elles, environ 60% avaient une discussion pérenne,

225
0:10:28.891,000 --> 0:10:3,000
elles avaient des conversations

226
0:10:30.971,000 --> 0:10:33,000
avec des gens difficiles à atteindre quant à ce qu'ils traversaient,

227
0:10:34.211,000 --> 0:10:35,000
plantant des doutes

228
0:10:35.386,000 --> 0:10:37,000
et leur offrant des alternatives pour parler de ces sujets

229
0:10:38.402,000 --> 0:10:39,000
et c'est très important.

230
0:10:41.061,000 --> 0:10:43,000
Ce que nous essayons de faire,

231
0:10:43.308,000 --> 0:10:45,000
c'est de rassembler des gens de secteurs invraisemblables.

232
0:10:46.237,000 --> 0:10:48,000
Nous avons de super activistes à travers le monde

233
0:10:48.587,000 --> 0:10:5,000
mais souvent, leurs messages ne sont pas stratégiques

234
0:10:51.113,000 --> 0:10:53,000
ou n'atteignent pas les publics cibles.

235
0:10:53.907,000 --> 0:10:55,000
Nous travaillons avec ces réseaux d'anciens extrémistes,

236
0:10:56.536,000 --> 0:10:59,000
des réseaux de jeunes gens dans divers endroits du monde.

237
0:10:59.623,000 --> 0:11:01,000
Nous travaillons avec eux pour rassemble les technophiles,

238
0:11:02.417,000 --> 0:11:04,000
des artistes, des créatifs, des experts du marketing

239
0:11:05.259,000 --> 0:11:1,000
afin de contester de façon plus robuste l'extrémisme

240
0:11:10.284,000 --> 0:11:11,000
en travaillant ensemble.

241
0:11:12.074,000 --> 0:11:14,000
Je dirais que si vous êtes dans le public

242
0:11:14.678,000 --> 0:11:16,000
et que vous êtes graphiste,

243
0:11:17.401,000 --> 0:11:19,000
poète, expert en marketing,

244
0:11:19.607,000 --> 0:11:2,000
un attaché de presse,

245
0:11:21.54,000 --> 0:11:22,000
comédien --

246
0:11:22.917,000 --> 0:11:24,000
vous pensez peut-être que ce n'est pas votre secteur

247
0:11:25.388,000 --> 0:11:27,000
mais les compétences que vous avez

248
0:11:27.855,000 --> 0:11:29,000
pourraient être ce qu'il nous faut

249
0:11:29.882,000 --> 0:11:31,000
pour aider à contrer efficacement l'extrémisme.

250
0:11:32.215,000 --> 0:11:33,000
Merci.

251
0:11:33.39,000 --> 0:11:37,000
(Applaudissements)

