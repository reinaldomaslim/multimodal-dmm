1
0:00:,000 --> 0:00:07,000
Traducteur: Hélène Vernet Relecteur: TED Translators admin

2
0:00:12.885,000 --> 0:00:14,000
Dans la Grèce antique,

3
0:00:15.436,000 --> 0:00:18,000
quand un esclave, un soldat, un poète ou un politicien

4
0:00:19.213,000 --> 0:00:23,000
avait besoin de répondre aux questions importantes de leur vie

5
0:00:23.431,000 --> 0:00:26,000
telles que : « Devrais-je me marier ? Entreprendre ce voyage ? »

6
0:00:26.682,000 --> 0:00:29,000
ou « Est-ce que notre armée devrait avancer sur ce territoire ? »,

7
0:00:29.809,000 --> 0:00:31,000
tous consultaient l'oracle.

8
0:00:33,000 --> 0:00:34,000
Voici comment ça fonctionnait.

9
0:00:34.484,000 --> 0:00:36,000
Vous lui posiez une question en vous mettant à genoux.

10
0:00:37.07,000 --> 0:00:4,000
Ensuite, elle entrait en une transe qui pouvait prendre un ou deux jours.

11
0:00:40.538,000 --> 0:00:42,000
Puis, finalement, elle en sortait

12
0:00:43.165,000 --> 0:00:46,000
pour vous donner ses prédictions comme réponse.

13
0:00:46.81,000 --> 0:00:48,000
Depuis les os divinatoires de la Chine ancienne

14
0:00:49.5,000 --> 0:00:51,000
à la Grèce antique et les calendriers mayas,

15
0:00:51.869,000 --> 0:00:53,000
les gens ont cherché avec passion dans les prédictions

16
0:00:54.485,000 --> 0:00:57,000
le moyen de savoir ce qui allait se passer dans le futur.

17
0:00:58.386,000 --> 0:01:01,000
Et c'est parce que nous voulons tous prendre la bonne décision.

18
0:01:01.629,000 --> 0:01:03,000
Nous ne voulons pas manquer le coche.

19
0:01:03.892,000 --> 0:01:04,000
Le futur est effrayant

20
0:01:05.589,000 --> 0:01:07,000
mais devient plus engageant quand nous savons

21
0:01:07.7,000 --> 0:01:1,000
que nous pouvons prendre une décision avec une garantie du résultat.

22
0:01:11.052,000 --> 0:01:14,000
Hé bien, nous avons un nouvel oracle, et son nom, c'est « Big Data »,

23
0:01:14.9,000 --> 0:01:17,000
ou « Watson », « apprentissage profond » « réseau de neurones artificiel »...

24
0:01:19.34,000 --> 0:01:23,000
Voici le genre de questions posées aujourd'hui à notre oracle :

25
0:01:23.376,000 --> 0:01:25,000
« Quel est le moyen le plus efficace

26
0:01:25.822,000 --> 0:01:28,000
d'expédier ces téléphones de la Chine à la Suède ? »,

27
0:01:29.169,000 --> 0:01:3,000
ou « Quels sont les risques

28
0:01:31.049,000 --> 0:01:34,000
que mon enfant naisse avec une maladie génétique ? »

29
0:01:34.976,000 --> 0:01:37,000
ou « Quel volume de ventes pouvons-nous prévoir pour ce produit ? »

30
0:01:40.108,000 --> 0:01:43,000
J'ai un chien. Son nom est Elle et elle déteste la pluie.

31
0:01:43.969,000 --> 0:01:46,000
J'ai tout essayé pour tenter de changer son attitude.

32
0:01:47.509,000 --> 0:01:49,000
Mais vu que j'ai échoué,

33
0:01:50.304,000 --> 0:01:53,000
je suis obligée de consulter, moi aussi, un oracle appelé Dark Sky,

34
0:01:53.444,000 --> 0:01:55,000
chaque fois que nous allons sortir pour la promenade,

35
0:01:55.929,000 --> 0:01:58,000
pour les prévisions météo précises des prochaines dix minutes.

36
0:02:01.365,000 --> 0:02:02,000
Elle est si mignonne.

37
0:02:03.827,000 --> 0:02:08,000
À cause de tout cela, notre oracle est une industrie de 122 milliards de dollars.

38
0:02:10.006,000 --> 0:02:13,000
Mais malgré la taille de cette industrie,

39
0:02:13.406,000 --> 0:02:15,000
les retours sont étonnamment faibles.

40
0:02:16.342,000 --> 0:02:2,000
Il est facile d'investir dans big data, mais l'utiliser est difficile.

41
0:02:21.981,000 --> 0:02:25,000
Plus de 73 % des projets de big data ne sont pas rentables,

42
0:02:26.045,000 --> 0:02:28,000
et certains dirigeants viennent me voir en disant :

43
0:02:28.46,000 --> 0:02:29,000
« Il nous est arrivé la même chose.

44
0:02:30.133,000 --> 0:02:31,000
Nous avons investi dans le big data,

45
0:02:31.946,000 --> 0:02:34,000
mais nos employés ne prennent pas de meilleures décisions,

46
0:02:35.082,000 --> 0:02:38,000
et ils ne vont certainement pas trouver plus d'idées révolutionnaires. »

47
0:02:38.824,000 --> 0:02:41,000
Pour moi, tout ceci est vraiment intéressant

48
0:02:42.122,000 --> 0:02:44,000
parce que je suis un ethnographe de la technologie.

49
0:02:44.63,000 --> 0:02:46,000
J'étudie et je conseille les entreprises

50
0:02:47.218,000 --> 0:02:49,000
sur les modèles d'utilisation de la technologie,

51
0:02:49.725,000 --> 0:02:51,000
et un de mes centres d'intérêt est la data.

52
0:02:52.427,000 --> 0:02:57,000
Pourquoi plus de données ne nous aide pas à prendre de meilleures décisions,

53
0:02:57.644,000 --> 0:02:59,000
en particulier pour les sociétés qui ont les ressources

54
0:03:00.231,000 --> 0:03:02,000
pour investir dans ces systèmes de big data ?

55
0:03:02.337,000 --> 0:03:04,000
Pourquoi cela n'est-il pas plus facile pour eux?

56
0:03:05.88,000 --> 0:03:07,000
J'a moi-même fait l'expérience de ce problème.

57
0:03:09.374,000 --> 0:03:12,000
En 2009, j'ai commencé un travail de recherche à Nokia.

58
0:03:13.232,000 --> 0:03:15,000
À cette époque, Nokia était une des plus grandes compagnies

59
0:03:15.99,000 --> 0:03:16,000
de téléphones mobiles dans le monde,

60
0:03:17.754,000 --> 0:03:2,000
dominant les marchés naissants en Chine, au Mexique et en Inde,

61
0:03:20.822,000 --> 0:03:22,000
pays dans lesquels j'avais déjà fait des recherches

62
0:03:23.214,000 --> 0:03:26,000
sur la façon dont les gens à faible revenu utilisent la technologie.

63
0:03:26.424,000 --> 0:03:28,000
J'ai passé beaucoup de temps libre en Chine,

64
0:03:28.488,000 --> 0:03:3,000
ce qui m'a permis de découvrir l'économie parallèle.

65
0:03:31.018,000 --> 0:03:33,000
J'ai, par exemple, travaillé comme vendeuse de rue

66
0:03:33.443,000 --> 0:03:35,000
en vendant des raviolis chinois aux ouvriers du bâtiment.

67
0:03:36.147,000 --> 0:03:37,000
J'ai travaillé sur le terrain,

68
0:03:37.599,000 --> 0:03:39,000
passant des jours et des nuits dans les cybercafés,

69
0:03:40.405,000 --> 0:03:42,000
fréquentant la jeunesse chinoise pour comprendre

70
0:03:42.665,000 --> 0:03:44,000
la façon dont ils utilisent les jeux et les portables

71
0:03:45.283,000 --> 0:03:48,000
y compris dans leurs déplacements de la campagne à la ville.

72
0:03:50.335,000 --> 0:03:53,000
En compilant toutes ces expériences qualitatives,

73
0:03:54.286,000 --> 0:03:56,000
j'ai commencé à voir très clairement

74
0:03:57.134,000 --> 0:03:59,000
qu'un très grand changement allait se produire

75
0:03:59.81,000 --> 0:04:01,000
parmi les chinois à faible revenu.

76
0:04:03.02,000 --> 0:04:06,000
Bien que cernés par les publicités pour des produits de luxe

77
0:04:06.661,000 --> 0:04:1,000
tels que les toilettes chics - qui n'en voudrait pas ? -

78
0:04:10.93,000 --> 0:04:12,000
pour des appartements et des voitures,

79
0:04:13.844,000 --> 0:04:14,000
à travers mes conversations avec eux,

80
0:04:15.688,000 --> 0:04:18,000
j'ai découvert que les pubs qui les affectaient le plus

81
0:04:19.553,000 --> 0:04:2,000
étaient celles concernant les IPhones

82
0:04:21.573,000 --> 0:04:24,000
qui leur promettaient l'accès à une vie à la pointe de la technologie.

83
0:04:25.389,000 --> 0:04:28,000
Quand j'ai vécu avec eux dans des bidonvilles urbains comme celui-ci,

84
0:04:28.656,000 --> 0:04:3,000
j'ai vu des gens investir presque la moitié de leur revenu

85
0:04:31.676,000 --> 0:04:34,000
dans l'achat d'un téléphone, lequel devenait de plus en plus « shanzhaï »,

86
0:04:35.659,000 --> 0:04:38,000
une imitation bon marché d'iPhone et autres marques.

87
0:04:40.303,000 --> 0:04:42,000
Ils sont tout à fait utilisables.

88
0:04:42.89,000 --> 0:04:43,000
Ils font l'affaire.

89
0:04:44.75,000 --> 0:04:48,000
Après des années à vivre et travailler avec les ambulants,

90
0:04:49.023,000 --> 0:04:53,000
à travailler et faire tout ce qu'ils faisaient,

91
0:04:54.021,000 --> 0:04:57,000
j'ai commencé à joindre toutes ces données ensemble -

92
0:04:57.642,000 --> 0:05:,000
des choses à priori insignifiantes comme la vente de raviolis chinois

93
0:05:00.789,000 --> 0:05:04,000
aux choses plus consistantes comme le montant de leurs factures de téléphone.

94
0:05:05.723,000 --> 0:05:08,000
J'ai été capable de créer une image plus globale de ce qui se passait.

95
0:05:09.416,000 --> 0:05:11,000
Alors, je me suis rendue compte

96
0:05:11.462,000 --> 0:05:14,000
que même le plus pauvre, en Chine, souhaiterait avoir un smartphone

97
0:05:14.995,000 --> 0:05:18,000
et qu'il serait prêt à tout faire pour en avoir un.

98
0:05:21.073,000 --> 0:05:24,000
Rappelez-vous que les iPhone venaient juste de sortir.

99
0:05:24.783,000 --> 0:05:27,000
C'était en 2009, il y a huit ans,

100
0:05:28.295,000 --> 0:05:3,000
et les Androïde ressemblaient à peine aux iPhone.

101
0:05:31.068,000 --> 0:05:33,000
Beaucoup de gens intelligents et réalistes ont dit :

102
0:05:33.419,000 --> 0:05:35,000
« Ces smartphones sont juste une mode.

103
0:05:36.32,000 --> 0:05:38,000
Qui veut porter ces trucs lourds

104
0:05:38.897,000 --> 0:05:42,000
dont les batteries sont faciles à épuiser et qui se cassent en tombant ? »

105
0:05:44.753,000 --> 0:05:47,000
Mais j'avais beaucoup de données et confiance en mes intuitions.

106
0:05:48.254,000 --> 0:05:51,000
J'étais donc très impatiente de les partager avec Nokia.

107
0:05:53.332,000 --> 0:05:57,000
Mais Nokia n'a pas été convaincu parce que ce n'était pas du big data.

108
0:05:58.929,000 --> 0:06:,000
Ils ont dit : « Nous avons des millions de points de données

109
0:06:01.788,000 --> 0:06:04,000
et rien n'indique que quelqu'un veut acheter un smartphone.

110
0:06:05.606,000 --> 0:06:08,000
Vos données basées sur 100, bien que larges,

111
0:06:09.237,000 --> 0:06:12,000
sont trop faibles pour que nous les prenions réellement au sérieux. »

112
0:06:12.719,000 --> 0:06:13,000
J'ai dit : « Vous avez raison.

113
0:06:14.208,000 --> 0:06:17,000
Vous n'êtes pas capable de le voir car vos enquêtes assument

114
0:06:18.063,000 --> 0:06:2,000
que les gens ne connaissent pas les smartphones.

115
0:06:20.456,000 --> 0:06:22,000
Vous ne pouvez donc pas obtenir les données

116
0:06:22.475,000 --> 0:06:25,000
concernant le désir des gens d'acheter un smartphone dans deux ans.

117
0:06:25.785,000 --> 0:06:28,000
Vos méthodes ont été conçues pour optimiser un modèle commercial existant.

118
0:06:29.771,000 --> 0:06:31,000
Pour ma part, jobserve les nouvelles dynamiques humaines

119
0:06:32.471,000 --> 0:06:33,000
qui ne sont pas encore apparues.

120
0:06:34.023,000 --> 0:06:38,000
Nous explorons en dehors de la dynamique des marchés afin de la prédire. »

121
0:06:39.301,000 --> 0:06:41,000
Savez-vous ce qui est arrivé à Nokia ?

122
0:06:41.562,000 --> 0:06:43,000
Leur compagnie a subit un revers.

123
0:06:44.676,000 --> 0:06:48,000
Ceci est le prix à payer pour avoir raté le coche.

124
0:06:49.151,000 --> 0:06:5,000
C'était inconcevable!

125
0:06:51.962,000 --> 0:06:53,000
Mais Nokia nest pas la seule.

126
0:06:54.087,000 --> 0:06:56,000
Je vois sans arrêt des organisations rejeter des données

127
0:06:56.718,000 --> 0:06:58,000
quand elles ne viennent pas d'une analyse quantitative

128
0:06:59.269,000 --> 0:07:01,000
ou ne s'accordent pas avec une.

129
0:07:02.191,000 --> 0:07:04,000
Ce n'est pas la faute du big data.

130
0:07:04.899,000 --> 0:07:08,000
C'est la façon dont nous utilisons big data ; c'est notre responsabilité.

131
0:07:09.692,000 --> 0:07:1,000
La réputation de succès de big data

132
0:07:11.44,000 --> 0:07:14,000
vient de la quantification d'environnements bien spécifiques

133
0:07:15.351,000 --> 0:07:17,000
tels que les réseaux de distribution délectricité,

134
0:07:17.804,000 --> 0:07:19,000
la logistique de livraison ou le code génétique,

135
0:07:20.374,000 --> 0:07:23,000
où nous quantifions en systèmes plus ou moins indépendants.

136
0:07:24.381,000 --> 0:07:27,000
Mais tous les systèmes ne sont pas aussi indépendants.

137
0:07:27.583,000 --> 0:07:3,000
Lorsque les systèmes sont plus dynamiques,

138
0:07:30.756,000 --> 0:07:33,000
en particulier ceux impliquant des êtres humains,

139
0:07:34.628,000 --> 0:07:36,000
les forces sont complexes et imprévisibles,

140
0:07:37.131,000 --> 0:07:4,000
et nous ne savons pas bien les modéliser.

141
0:07:41.041,000 --> 0:07:43,000
Quand vous prédisez un comportement humain,

142
0:07:43.971,000 --> 0:07:47,000
de nouveaux facteurs entrent en jeu car les conditions changent constamment.

143
0:07:48.037,000 --> 0:07:49,000
Donc, ce cycle est infini.

144
0:07:49.655,000 --> 0:07:53,000
Quand vous pensez savoir, quelque chose d'inconnu apparaît.

145
0:07:53.862,000 --> 0:07:56,000
C'est pourquoi compter uniquement sur big data

146
0:07:57.076,000 --> 0:07:59,000
augmente nos risques de rater le coche

147
0:07:59.932,000 --> 0:08:03,000
tout en nous donnant l'illusion que nous savons déjà tout.

148
0:08:04.255,000 --> 0:08:07,000
Ce qui rend ce paradoxe si difficile à voir

149
0:08:08.246,000 --> 0:08:1,000
ou même à l'appréhender avec notre intellect,

150
0:08:11.072,000 --> 0:08:14,000
c'est ce que j'appelle « le préjugé de la quantification »,

151
0:08:14.685,000 --> 0:08:19,000
l'habitude inconsciente de privilégier le mesurable sur le non-mesurable -

152
0:08:21.148,000 --> 0:08:23,000
nous en faisons souvent l'expérience au travail ;

153
0:08:24.302,000 --> 0:08:26,000
certains de nos collèges peuvent être comme ça

154
0:08:27.026,000 --> 0:08:29,000
voir notre compagnie toute entière -

155
0:08:29.55,000 --> 0:08:31,000
où les gens deviennent si focalisés sur ce chiffre

156
0:08:32.022,000 --> 0:08:33,000
qu'ils ne peuvent rien voir en dehors,

157
0:08:33.982,000 --> 0:08:37,000
même si vous leur présentez les preuves sous les yeux.

158
0:08:39.103,000 --> 0:08:42,000
C'est un message intéressant

159
0:08:42.473,000 --> 0:08:44,000
parce qu'il n'y a rien de mal à quantifier.

160
0:08:44.624,000 --> 0:08:46,000
En fait, c'est très gratifiant.

161
0:08:47.231,000 --> 0:08:5,000
Regarder une feuille de calcul Excel me réconforte beaucoup,

162
0:08:50.585,000 --> 0:08:51,000
même les plus simples.

163
0:08:51.991,000 --> 0:08:52,000
(Rires)

164
0:08:53.086,000 --> 0:08:55,000
C'est un peu comme si oui, la formule marche,

165
0:08:55.294,000 --> 0:08:57,000
tout va bien, la situation est sous contrôle.

166
0:08:58.72,000 --> 0:09:03,000
Mais le problème, c'est que quantifier devient une addiction,

167
0:09:03.798,000 --> 0:09:07,000
et quand nous oublions cela et n'avons rien pour nous le rappeler,

168
0:09:07.967,000 --> 0:09:09,000
il est facile de rejeter les données

169
0:09:10.355,000 --> 0:09:12,000
qui ne peuvent être exprimées en valeurs numériques ;

170
0:09:12.997,000 --> 0:09:15,000
il est facile de déraper vers le raisonnement miracle

171
0:09:16.289,000 --> 0:09:18,000
comme s'il existait une solution simple.

172
0:09:19.464,000 --> 0:09:23,000
C'est un dangereux moment pour toute organisation

173
0:09:23.517,000 --> 0:09:25,000
car souvent, le futur que nous avons besoin de prédire

174
0:09:26.212,000 --> 0:09:28,000
n'est pas dans cette botte de foin, là,

175
0:09:28.42,000 --> 0:09:3,000
mais plutôt dans cette tornade qui se dirige sur nous,

176
0:09:31.02,000 --> 0:09:33,000
en dehors de la grange.

177
0:09:34.922,000 --> 0:09:37,000
Il n'y a pas de plus grand danger que d'être incapable de voir l'inconnu.

178
0:09:38.77,000 --> 0:09:4,000
Cela vous conduit à prendre de mauvaises décisions

179
0:09:41.116,000 --> 0:09:43,000
et à manquer quelque chose d'important.

180
0:09:43.646,000 --> 0:09:46,000
Néanmoins cette voie n'est pas une fatalité.

181
0:09:47.304,000 --> 0:09:5,000
Il s'avère que l'oracle de la Grèce antique

182
0:09:50.503,000 --> 0:09:54,000
contient la clé secrète qui montre la voie à suivre.

183
0:09:55.678,000 --> 0:09:57,000
Des recherches géologiques récentes ont montré

184
0:09:58.044,000 --> 0:10:01,000
que le Temple d'Apollon dans lequel était situé le fameux oracle

185
0:10:01.739,000 --> 0:10:03,000
a été construit entre deux failles sismiques.

186
0:10:04.717,000 --> 0:10:06,000
Ces failles libéraient des vapeurs pétrochimiques

187
0:10:07.575,000 --> 0:10:08,000
du dessous de l'écorce terrestre,

188
0:10:09.405,000 --> 0:10:12,000
et l'oracle était littéralement assise au-dessus de ces deux failles

189
0:10:13.304,000 --> 0:10:16,000
et inhalait des quantités énormes d'éthylène...

190
0:10:16.444,000 --> 0:10:17,000
(Rires)

191
0:10:17.626,000 --> 0:10:18,000
C'est vrai !

192
0:10:19.048,000 --> 0:10:2,000
(Rires)

193
0:10:20.255,000 --> 0:10:23,000
C'est vrai et c'est ce qui lui permettait de pérorer et halluciner

194
0:10:23.506,000 --> 0:10:25,000
et d'entrer dans un état similaire à la transe.

195
0:10:25.699,000 --> 0:10:26,000
Elle planait complètement !

196
0:10:27.437,000 --> 0:10:28,000
(Rires)

197
0:10:31.711,000 --> 0:10:33,000
Donc, comment se fait-il que les gens

198
0:10:34.686,000 --> 0:10:38,000
obtenaient des conseils utiles dans son état ?

199
0:10:39.483,000 --> 0:10:41,000
Eh bien, voyez-vous ces gens autour de l'oracle ?

200
0:10:41.787,000 --> 0:10:44,000
Ils la soutiennent car elle est un peu dans les vapes.

201
0:10:45.116,000 --> 0:10:49,000
Remarquez cet homme sur la gauche qui tient le carnet orange.

202
0:10:50.105,000 --> 0:10:51,000
Ce sont les guides du temple

203
0:10:51.859,000 --> 0:10:54,000
qui travaillent main dans la main avec l'oracle.

204
0:10:56.084,000 --> 0:10:58,000
Quand les questionneurs venaient et s'agenouillaient,

205
0:10:58.624,000 --> 0:11:,000
les guides du temple se mettaient au travail,

206
0:11:00.718,000 --> 0:11:03,000
car une fois les questions posées, ils observaient les états émotionnels

207
0:11:04.291,000 --> 0:11:05,000
et demandaient des infos complémentaires :

208
0:11:06.259,000 --> 0:11:09,000
« Pourquoi voulez-vous cette prédiction ? Qui êtes-vous ?

209
0:11:09.607,000 --> 0:11:11,000
Qu'allez-vous faire de cette information ? »

210
0:11:12.395,000 --> 0:11:13,000
Ensuite, les guides du temple,

211
0:11:13.791,000 --> 0:11:16,000
avec cette information plus ethnographique et qualitative,

212
0:11:17.781,000 --> 0:11:19,000
interprétaient les paroles de l'oracle.

213
0:11:21.308,000 --> 0:11:23,000
Donc, l'oracle n'était pas seule,

214
0:11:23.534,000 --> 0:11:26,000
de même, nos systèmes de big data ne devraient pas l'être.

215
0:11:26.642,000 --> 0:11:27,000
Pour clarifier, je ne dis pas

216
0:11:28.321,000 --> 0:11:3,000
que les systèmes de big data exhalent de l'éthylène

217
0:11:31.298,000 --> 0:11:33,000
ou qu'ils font des prévisions caduques.

218
0:11:33.55,000 --> 0:11:35,000
Exactement le contraire, ce que je veux dire

219
0:11:35.992,000 --> 0:11:39,000
c'est que tout comme l'oracle avait besoin des guides du temple,

220
0:11:40.488,000 --> 0:11:42,000
nos systèmes de big data ont aussi besoin d'eux.

221
0:11:43.12,000 --> 0:11:46,000
Ils ont besoin des ethnographes et des chercheurs sur les utilisateurs

222
0:11:47.073,000 --> 0:11:5,000
pour rassembler ce que j'appelle « les données denses ».

223
0:11:50.502,000 --> 0:11:52,000
Ce sont des données précieuses fournies par les hommes,

224
0:11:53.387,000 --> 0:11:57,000
les histoires, émotions et interactions non quantifiables.

225
0:11:57.643,000 --> 0:11:59,000
C'est le genre de données que j'ai recueillies pour Nokia

226
0:12:00.219,000 --> 0:12:02,000
sous la forme d'un échantillon très petit

227
0:12:02.682,000 --> 0:12:04,000
mais incroyablement profond quant au sens.

228
0:12:05.661,000 --> 0:12:09,000
Ce qui le rend si dense et consistant,

229
0:12:10.365,000 --> 0:12:14,000
c'est l'expérience et la compréhension du récit humain.

230
0:12:14.498,000 --> 0:12:17,000
C'est ce qui aide à percevoir ce qui manque dans nos modèles.

231
0:12:18.851,000 --> 0:12:2,000
Les données denses ancrent les questions commerciales

232
0:12:21.37,000 --> 0:12:22,000
dans les questions humaines.

233
0:12:22.92,000 --> 0:12:25,000
C'est pourquoi fusionner big data et données denses

234
0:12:26.406,000 --> 0:12:28,000
permet d'obtenir une image plus complète.

235
0:12:28.662,000 --> 0:12:3,000
Le big data peut offrir des aperçus à échelle

236
0:12:31.397,000 --> 0:12:33,000
et tirer le meilleur profit de l'intelligence artificielle,

237
0:12:34.348,000 --> 0:12:36,000
tandis que les données denses aident à minimiser

238
0:12:36.654,000 --> 0:12:39,000
la perte de contexte générée en rendant big data utilisable,

239
0:12:39.782,000 --> 0:12:41,000
et à tirer le meilleur de l'intelligence humaine.

240
0:12:42.277,000 --> 0:12:45,000
En fait, quand vous intégrez les deux, ça devient vraiment intéressant,

241
0:12:45.607,000 --> 0:12:48,000
car vous ne travaillez plus uniquement avec les données recueillies,

242
0:12:48.817,000 --> 0:12:5,000
vous travaillez avec des données non recueillies.

243
0:12:51.498,000 --> 0:12:53,000
Vous commencez à demander « pourquoi? » :

244
0:12:54.031,000 --> 0:12:55,000
Pourquoi cela se passe-t-il ?

245
0:12:55.778,000 --> 0:12:56,000
Quand Netflix a fait ça,

246
0:12:57.197,000 --> 0:13:,000
ils ont ouvert une nouvelle voie de transformation pour leur entreprise.

247
0:13:01.406,000 --> 0:13:04,000
Netflix est connue pour ses algorithmes de recommandation.

248
0:13:05.386,000 --> 0:13:09,000
Ils ont offert un million de dollars à quiconque pouvait les améliorer

249
0:13:10.207,000 --> 0:13:11,000
et il y a eu des gagnants.

250
0:13:12.255,000 --> 0:13:14,000
Mais Netflix a découvert que ces améliorations

251
0:13:14.834,000 --> 0:13:16,000
étaient seulement incrémentielles.

252
0:13:17.294,000 --> 0:13:18,000
Pour comprendre la situation,

253
0:13:18.942,000 --> 0:13:22,000
ils ont embauché un ethnographe, Grant McCracken,

254
0:13:23.157,000 --> 0:13:24,000
afin d'obtenir des données denses,

255
0:13:24.893,000 --> 0:13:27,000
et il a trouvé une chose qu'ils n'avaient pas vue à l'origine

256
0:13:28.675,000 --> 0:13:3,000
dans les données quantitatives.

257
0:13:31.072,000 --> 0:13:33,000
Il a découvert que les gens aimaient le « binge-watching ».

258
0:13:33.934,000 --> 0:13:36,000
En fait, ils ne s'en culpabilisaient pas mais en jouissaient.

259
0:13:38.16,000 --> 0:13:4,000
Netflix a réalisé : « Oh, c'est une nouvelle donnée ».

260
0:13:40.69,000 --> 0:13:42,000
Ils se sont tournés vers leur équipe de science des données

261
0:13:43.478,000 --> 0:13:47,000
qui a su comparer cette donnée avec leurs données quantitatives.

262
0:13:47.825,000 --> 0:13:5,000
Après l'avoir vérifiée et validée,

263
0:13:51.019,000 --> 0:13:55,000
Netflix a décidé d'agir de façon simple mais efficace.

264
0:13:56.834,000 --> 0:14:02,000
Au lieu d'offrir une même émission dans différents genres

265
0:14:03.2,000 --> 0:14:07,000
ou plus d'émissions différentes d'utilisateurs similaires,

266
0:14:07.262,000 --> 0:14:09,000
ils ont simplement offert plus de la même émission.

267
0:14:09.65,000 --> 0:14:11,000
« Nous vous rendons le Binge-watching plus facile! »

268
0:14:12.115,000 --> 0:14:15,000
Ils ne se sont pas arrêtés là mais ont fait toutes sortes de choses

269
0:14:15.255,000 --> 0:14:17,000
pour changer lentière expérience de leur spectateur

270
0:14:17.69,000 --> 0:14:19,000
pour l'encourager au binge-watching.

271
0:14:20.23,000 --> 0:14:23,000
Voilà pourquoi les gens et les amis disparaissent des weekends entiers

272
0:14:23.601,000 --> 0:14:25,000
pour regarder les « Master of None » manqués.

273
0:14:25.862,000 --> 0:14:29,000
En fusionnant big data et données denses, ils ont amélioré leurs services

274
0:14:30.059,000 --> 0:14:32,000
et transformé la façon dont nous consommons les médias.

275
0:14:32.895,000 --> 0:14:36,000
Maintenant, il est prévu que leurs stocks doublent dans les prochaines années.

276
0:14:38.28,000 --> 0:14:41,000
Mais il ne s'agit pas de regarder plus de vidéos,

277
0:14:42.134,000 --> 0:14:44,000
ou de vendre plus de smartphones.

278
0:14:44.144,000 --> 0:14:48,000
Pour certains, incorporer le résultat des données denses dans cet algorithme

279
0:14:48.217,000 --> 0:14:5,000
peut être une question de vie ou de mort,

280
0:14:50.504,000 --> 0:14:52,000
en particulier pour les marginalisés.

281
0:14:53.738,000 --> 0:14:55,000
Les services de Police, dans tout le pays,

282
0:14:55.976,000 --> 0:14:58,000
utilisent le big data dans la prévision policière,

283
0:14:59.183,000 --> 0:15:02,000
afin de définir les cautions et recommandations de sentences

284
0:15:02.291,000 --> 0:15:05,000
d'une manière qui renforce les préjugés existants.

285
0:15:06.296,000 --> 0:15:08,000
Skynet, l'algorithme d'apprentissage machine de la NASA

286
0:15:08.883,000 --> 0:15:13,000
a probablement aidé à tuer des milliers de civils au Pakistan

287
0:15:14.211,000 --> 0:15:18,000
en mal interprétant les métadonnées des appareils cellulaires.

288
0:15:19.131,000 --> 0:15:22,000
Quand nos vies deviennent de plus en plus automatisées,

289
0:15:22.558,000 --> 0:15:25,000
des automobiles aux assurances maladie et à l'emploi,

290
0:15:25.662,000 --> 0:15:27,000
il est probable que nous tous

291
0:15:28.036,000 --> 0:15:31,000
allons être affectés par les erreurs de quantification.

292
0:15:32.872,000 --> 0:15:34,000
Mais la bonne nouvelle, c'est que nous avons fait des progrès

293
0:15:35.763,000 --> 0:15:37,000
depuis les émanations d'éthylène de la prophétie.

294
0:15:38.187,000 --> 0:15:4,000
Nous avons de meilleurs outils, donc utilisons-les au mieux.

295
0:15:41.185,000 --> 0:15:43,000
Intégrons big data aux données denses.

296
0:15:43.532,000 --> 0:15:45,000
Amenons nos guides du temple avec les oracles.

297
0:15:45.817,000 --> 0:15:48,000
Et que ce soit dans les entreprises, les sociétés à but non lucratif,

298
0:15:49.217,000 --> 0:15:51,000
les gouvernements ou même les logiciels,

299
0:15:51.71,000 --> 0:15:52,000
tout ce travail compte,

300
0:15:53.526,000 --> 0:15:56,000
car il implique que tous ensemble, nous nous engageons

301
0:15:56.573,000 --> 0:15:58,000
à créer des données meilleures,

302
0:15:58.788,000 --> 0:16:01,000
de meilleurs algorithmes, résultats, et de meilleures décisions.

303
0:16:02.315,000 --> 0:16:05,000
C'est de cette façon que nous éviterons de manquer le coche.

304
0:16:07.222,000 --> 0:16:09,000
(Applaudissements)

