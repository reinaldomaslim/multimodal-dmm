1
0:00:12.76,000 --> 0:00:14,000
You only get one chance to make a first impression,

2
0:00:15.44,000 --> 0:00:18,000
and that's true if you're a robot as well as if you're a person.

3
0:00:18.64,000 --> 0:00:21,000
The first time that I met one of these robots

4
0:00:21.68,000 --> 0:00:23,000
was at a place called Willow Garage in 2008.

5
0:00:24.6,000 --> 0:00:27,000
When I went to visit there, my host walked me into the building

6
0:00:27.64,000 --> 0:00:28,000
and we met this little guy.

7
0:00:29.24,000 --> 0:00:3,000
He was rolling into the hallway,

8
0:00:30.92,000 --> 0:00:31,000
came up to me, sat there,

9
0:00:32.76,000 --> 0:00:34,000
stared blankly past me,

10
0:00:35.04,000 --> 0:00:36,000
did nothing for a while,

11
0:00:36.72,000 --> 0:00:37,000
rapidly spun his head around 180 degrees

12
0:00:38.68,000 --> 0:00:39,000
and then ran away.

13
0:00:40.24,000 --> 0:00:42,000
And that was not a great first impression.

14
0:00:42.44,000 --> 0:00:44,000
The thing that I learned about robots that day

15
0:00:44.64,000 --> 0:00:46,000
is that they kind of do their own thing,

16
0:00:46.84,000 --> 0:00:48,000
and they're not totally aware of us.

17
0:00:49,000 --> 0:00:52,000
And I think as we're experimenting with these possible robot futures,

18
0:00:52.263,000 --> 0:00:54,000
we actually end up learning a lot more about ourselves

19
0:00:54.96,000 --> 0:00:55,000
as opposed to just these machines.

20
0:00:56.64,000 --> 0:00:57,000
And what I learned that day

21
0:00:58,000 --> 0:01:01,000
was that I had pretty high expectations for this little dude.

22
0:01:01.44,000 --> 0:01:04,000
He was not only supposed to be able to navigate the physical world,

23
0:01:04.64,000 --> 0:01:06,000
but also be able to navigate my social world --

24
0:01:07.32,000 --> 0:01:09,000
he's in my space; it's a personal robot.

25
0:01:09.52,000 --> 0:01:11,000
wWhy didn't it understand me?

26
0:01:11.56,000 --> 0:01:12,000
My host explained to me,

27
0:01:12.84,000 --> 0:01:15,000
"Well, the robot is trying to get from point A to point B,

28
0:01:16.04,000 --> 0:01:17,000
and you were an obstacle in his way,

29
0:01:17.84,000 --> 0:01:19,000
so he had to replan his path,

30
0:01:19.88,000 --> 0:01:2,000
figure out where to go,

31
0:01:21.16,000 --> 0:01:22,000
and then get there some other way,"

32
0:01:22.88,000 --> 0:01:24,000
which was actually not a very efficient thing to do.

33
0:01:25.36,000 --> 0:01:28,000
If that robot had figured out that I was a person, not a chair,

34
0:01:28.64,000 --> 0:01:3,000
and that I was willing to get out of its way

35
0:01:30.76,000 --> 0:01:31,000
if it was trying to get somewhere,

36
0:01:32.44,000 --> 0:01:34,000
then it actually would have been more efficient

37
0:01:34.68,000 --> 0:01:35,000
at getting its job done

38
0:01:35.96,000 --> 0:01:37,000
if it had bothered to notice that I was a human

39
0:01:38.2,000 --> 0:01:41,000
and that I have different affordances than things like chairs and walls do.

40
0:01:41.8,000 --> 0:01:44,000
You know, we tend to think of these robots as being from outer space

41
0:01:45.04,000 --> 0:01:47,000
and from the future and from science fiction,

42
0:01:47.2,000 --> 0:01:48,000
and while that could be true,

43
0:01:48.64,000 --> 0:01:5,000
I'd actually like to argue that robots are here today,

44
0:01:51.32,000 --> 0:01:53,000
and they live and work amongst us right now.

45
0:01:54.12,000 --> 0:01:56,000
These are two robots that live in my home.

46
0:01:57,000 --> 0:01:59,000
They vacuum the floors and they cut the grass

47
0:01:59.52,000 --> 0:02:,000
every single day,

48
0:02:00.76,000 --> 0:02:03,000
which is more than I would do if I actually had time to do these tasks,

49
0:02:04.16,000 --> 0:02:06,000
and they probably do it better than I would, too.

50
0:02:06.52,000 --> 0:02:08,000
This one actually takes care of my kitty.

51
0:02:09.04,000 --> 0:02:11,000
Every single time he uses the box, it cleans it,

52
0:02:11.64,000 --> 0:02:12,000
which is not something I'm willing to do,

53
0:02:13.64,000 --> 0:02:15,000
and it actually makes his life better as well as mine.

54
0:02:16.24,000 --> 0:02:18,000
And while we call these robot products --

55
0:02:18.68,000 --> 0:02:2,000
it's a "robot vacuum cleaner, it's a robot lawnmower,

56
0:02:21.4,000 --> 0:02:22,000
it's a robot littler box,"

57
0:02:22.919,000 --> 0:02:26,000
I think there's actually a bunch of other robots hiding in plain sight

58
0:02:27.08,000 --> 0:02:28,000
that have just become so darn useful

59
0:02:28.96,000 --> 0:02:29,000
and so darn mundane

60
0:02:30.44,000 --> 0:02:32,000
that we call them things like, "dishwasher," right?

61
0:02:32.96,000 --> 0:02:33,000
They get new names.

62
0:02:34.2,000 --> 0:02:35,000
They don't get called robot anymore

63
0:02:35.92,000 --> 0:02:37,000
because they actually serve a purpose in our lives.

64
0:02:38.36,000 --> 0:02:39,000
Similarly, a thermostat, right?

65
0:02:39.88,000 --> 0:02:4,000
I know my robotics friends out there

66
0:02:41.68,000 --> 0:02:43,000
are probably cringing at me calling this a robot,

67
0:02:44.04,000 --> 0:02:45,000
but it has a goal.

68
0:02:45.32,000 --> 0:02:47,000
Its goal is to make my house 66 degrees Fahrenheit,

69
0:02:48.24,000 --> 0:02:49,000
and it senses the world.

70
0:02:49.52,000 --> 0:02:5,000
It knows it's a little bit cold,

71
0:02:51.12,000 --> 0:02:53,000
it makes a plan and then it acts on the physical world.

72
0:02:53.76,000 --> 0:02:54,000
It's robotics.

73
0:02:55.04,000 --> 0:02:57,000
Even if it might not look like Rosie the Robot,

74
0:02:57.64,000 --> 0:02:59,000
it's doing something that's really useful in my life

75
0:03:00.6,000 --> 0:03:01,000
so I don't have to take care

76
0:03:02,000 --> 0:03:04,000
of turning the temperature up and down myself.

77
0:03:04.6,000 --> 0:03:07,000
And I think these systems live and work amongst us now,

78
0:03:08.44,000 --> 0:03:1,000
and not only are these systems living amongst us

79
0:03:10.8,000 --> 0:03:12,000
but you are probably a robot operator, too.

80
0:03:13.48,000 --> 0:03:14,000
When you drive your car,

81
0:03:14.76,000 --> 0:03:16,000
it feels like you are operating machinery.

82
0:03:17,000 --> 0:03:19,000
You are also going from point A to point B,

83
0:03:19.84,000 --> 0:03:21,000
but your car probably has power steering,

84
0:03:22.08,000 --> 0:03:24,000
it probably has automatic braking systems,

85
0:03:24.8,000 --> 0:03:27,000
it might have an automatic transmission and maybe even adaptive cruise control.

86
0:03:28.56,000 --> 0:03:3,000
And while it might not be a fully autonomous car,

87
0:03:31.52,000 --> 0:03:32,000
it has bits of autonomy,

88
0:03:32.84,000 --> 0:03:33,000
and they're so useful

89
0:03:34.2,000 --> 0:03:35,000
and they make us drive safer,

90
0:03:36.04,000 --> 0:03:39,000
and we just sort of feel like they're invisible-in-use, right?

91
0:03:39.72,000 --> 0:03:4,000
So when you're driving your car,

92
0:03:41.32,000 --> 0:03:44,000
you should just feel like you're going from one place to another.

93
0:03:44.44,000 --> 0:03:47,000
It doesn't feel like it's this big thing that you have to deal with and operate

94
0:03:48.2,000 --> 0:03:49,000
and use these controls

95
0:03:49.48,000 --> 0:03:51,000
because we spent so long learning how to drive

96
0:03:51.68,000 --> 0:03:53,000
that they've become extensions of ourselves.

97
0:03:54.4,000 --> 0:03:56,000
When you park that car in that tight little garage space,

98
0:03:57.12,000 --> 0:03:58,000
you know where your corners are.

99
0:03:58.72,000 --> 0:04:01,000
And when you drive a rental car that maybe you haven't driven before,

100
0:04:02,000 --> 0:04:05,000
it takes some time to get used to your new robot body.

101
0:04:05.08,000 --> 0:04:08,000
And this is also true for people who operate other types of robots,

102
0:04:09.08,000 --> 0:04:11,000
so I'd like to share with you a few stories about that.

103
0:04:12.24,000 --> 0:04:14,000
Dealing with the problem of remote collaboration.

104
0:04:14.6,000 --> 0:04:16,000
So, at Willow Garage I had a coworker named Dallas,

105
0:04:17.2,000 --> 0:04:18,000
and Dallas looked like this.

106
0:04:18.8,000 --> 0:04:22,000
He worked from his home in Indiana in our company in California.

107
0:04:22.88,000 --> 0:04:24,000
He was a voice in a box on the table in most of our meetings,

108
0:04:25.84,000 --> 0:04:27,000
which was kind of OK except that, you know,

109
0:04:28.079,000 --> 0:04:31,000
if we had a really heated debate and we didn't like what he was saying,

110
0:04:31.48,000 --> 0:04:32,000
we might just hang up on him.

111
0:04:32.92,000 --> 0:04:33,000
(Laughter)

112
0:04:33.959,000 --> 0:04:35,000
Then we might have a meeting after that meeting

113
0:04:36.2,000 --> 0:04:38,000
and actually make the decisions in the hallway afterwards

114
0:04:38.92,000 --> 0:04:39,000
when he wasn't there anymore.

115
0:04:40.36,000 --> 0:04:41,000
So that wasn't so great for him.

116
0:04:41.96,000 --> 0:04:42,000
And as a robotics company at Willow,

117
0:04:43.72,000 --> 0:04:45,000
we had some extra robot body parts laying around,

118
0:04:46.08,000 --> 0:04:48,000
so Dallas and his buddy Curt put together this thing,

119
0:04:48.6,000 --> 0:04:5,000
which looks kind of like Skype on a stick on wheels,

120
0:04:51.56,000 --> 0:04:52,000
which seems like a techy, silly toy,

121
0:04:53.32,000 --> 0:04:55,000
but really it's probably one of the most powerful tools

122
0:04:56.12,000 --> 0:04:58,000
that I've seen ever made for remote collaboration.

123
0:04:59.16,000 --> 0:05:02,000
So now, if I didn't answer Dallas' email question,

124
0:05:02.68,000 --> 0:05:04,000
he could literally roll into my office,

125
0:05:04.92,000 --> 0:05:06,000
block my doorway and ask me the question again --

126
0:05:07.52,000 --> 0:05:08,000
(Laughter)

127
0:05:08.56,000 --> 0:05:09,000
until I answered it.

128
0:05:09.8,000 --> 0:05:11,000
And I'm not going to turn him off, right? That's kind of rude.

129
0:05:12.8,000 --> 0:05:14,000
Not only was it good for these one-on-one communications,

130
0:05:15.52,000 --> 0:05:17,000
but also for just showing up at the company all-hands meeting.

131
0:05:18.48,000 --> 0:05:19,000
Getting your butt in that chair

132
0:05:20.2,000 --> 0:05:23,000
and showing people that you're present and committed to your project

133
0:05:23.44,000 --> 0:05:24,000
is a big deal

134
0:05:24.72,000 --> 0:05:26,000
and can help remote collaboration a ton.

135
0:05:26.92,000 --> 0:05:28,000
We saw this over the period of months and then years,

136
0:05:29.8,000 --> 0:05:31,000
not only at our company but at others, too.

137
0:05:32.72,000 --> 0:05:34,000
The best thing that can happen with these systems

138
0:05:35.08,000 --> 0:05:37,000
is that it starts to feel like you're just there.

139
0:05:37.44,000 --> 0:05:38,000
It's just you, it's just your body,

140
0:05:39.16,000 --> 0:05:42,000
and so people actually start to give these things personal space.

141
0:05:42.28,000 --> 0:05:43,000
So when you're having a stand-up meeting,

142
0:05:44.28,000 --> 0:05:45,000
people will stand around the space

143
0:05:45.96,000 --> 0:05:47,000
just as they would if you were there in person.

144
0:05:48.2,000 --> 0:05:5,000
That's great until there's breakdowns and it's not.

145
0:05:50.8,000 --> 0:05:51,000
People, when they first see these robots,

146
0:05:52.8,000 --> 0:05:55,000
are like, "Wow, where's the components? There must be a camera over there,"

147
0:05:56.4,000 --> 0:05:57,000
and they start poking your face.

148
0:05:58,000 --> 0:06:,000
"You're talking too softly, I'm going to turn up your volume,"

149
0:06:00.96,000 --> 0:06:02,000
which is like having a coworker walk up to you and say,

150
0:06:03.6,000 --> 0:06:05,000
"You're speaking too softly, I'm going to turn up your face."

151
0:06:06.52,000 --> 0:06:07,000
That's awkward and not OK,

152
0:06:07.8,000 --> 0:06:09,000
and so we end up having to build these new social norms

153
0:06:10.44,000 --> 0:06:12,000
around using these systems.

154
0:06:12.68,000 --> 0:06:15,000
Similarly, as you start feeling like it's your body,

155
0:06:16.12,000 --> 0:06:19,000
you start noticing things like, "Oh, my robot is kind of short."

156
0:06:19.84,000 --> 0:06:21,000
Dallas would say things to me -- he was six-foot tall --

157
0:06:22.52,000 --> 0:06:25,000
and we would take him via robot to cocktail parties and things like that,

158
0:06:26,000 --> 0:06:27,000
as you do,

159
0:06:27.24,000 --> 0:06:3,000
and the robot was about five-foot-tall, which is close to my height.

160
0:06:30.6,000 --> 0:06:31,000
And he would tell me,

161
0:06:31.84,000 --> 0:06:33,000
"You know, people are not really looking at me.

162
0:06:34.4,000 --> 0:06:36,000
I feel like I'm just looking at this sea of shoulders,

163
0:06:37.12,000 --> 0:06:38,000
and it's just -- we need a taller robot."

164
0:06:39.12,000 --> 0:06:4,000
And I told him,

165
0:06:40.4,000 --> 0:06:41,000
"Um, no.

166
0:06:41.72,000 --> 0:06:42,000
You get to walk in my shoes for today.

167
0:06:43.68,000 --> 0:06:46,000
You get to see what it's like to be on the shorter end of the spectrum."

168
0:06:47.24,000 --> 0:06:5,000
And he actually ended up building a lot of empathy for that experience,

169
0:06:50.64,000 --> 0:06:51,000
which was kind of great.

170
0:06:51.92,000 --> 0:06:52,000
So when he'd come visit in person,

171
0:06:53.6,000 --> 0:06:55,000
he no longer stood over me as he was talking to me,

172
0:06:56.04,000 --> 0:06:58,000
he would sit down and talk to me eye to eye,

173
0:06:58.16,000 --> 0:06:59,000
which was kind of a beautiful thing.

174
0:06:59.92,000 --> 0:07:01,000
So we actually decided to look at this in the laboratory

175
0:07:02.6,000 --> 0:07:05,000
and see what others kinds of differences things like robot height would make.

176
0:07:06.28,000 --> 0:07:08,000
And so half of the people in our study used a shorter robot,

177
0:07:09.16,000 --> 0:07:11,000
half of the people in our study used a taller robot

178
0:07:11.6,000 --> 0:07:13,000
and we actually found that the exact same person

179
0:07:13.88,000 --> 0:07:16,000
who has the exact same body and says the exact same things as someone,

180
0:07:17.24,000 --> 0:07:19,000
is more persuasive and perceived as being more credible

181
0:07:19.88,000 --> 0:07:2,000
if they're in a taller robot form.

182
0:07:21.56,000 --> 0:07:22,000
It makes no rational sense,

183
0:07:23.4,000 --> 0:07:24,000
but that's why we study psychology.

184
0:07:25.12,000 --> 0:07:27,000
And really, you know, the way that Cliff Nass would put this

185
0:07:28,000 --> 0:07:31,000
is that we're having to deal with these new technologies

186
0:07:31.04,000 --> 0:07:33,000
despite the fact that we have very old brains.

187
0:07:33.8,000 --> 0:07:35,000
Human psychology is not changing at the same speed that tech is

188
0:07:36.8,000 --> 0:07:37,000
and so we're always playing catch-up,

189
0:07:38.64,000 --> 0:07:39,000
trying to make sense of this world

190
0:07:40.32,000 --> 0:07:42,000
where these autonomous things are running around.

191
0:07:42.68,000 --> 0:07:44,000
Usually, things that talk are people, not machines, right?

192
0:07:45.44,000 --> 0:07:49,000
And so we breathe a lot of meaning into things like just height of a machine,

193
0:07:50.04,000 --> 0:07:51,000
not a person,

194
0:07:51.32,000 --> 0:07:53,000
and attribute that to the person using the system.

195
0:07:55.12,000 --> 0:07:57,000
You know, this, I think, is really important

196
0:07:57.36,000 --> 0:07:58,000
when you're thinking about robotics.

197
0:07:59.12,000 --> 0:08:01,000
It's not so much about reinventing humans,

198
0:08:01.24,000 --> 0:08:04,000
it's more about figuring out how we extend ourselves, right?

199
0:08:04.4,000 --> 0:08:06,000
And we end up using things in ways that are sort of surprising.

200
0:08:07.4,000 --> 0:08:11,000
So these guys can't play pool because the robots don't have arms,

201
0:08:11.68,000 --> 0:08:13,000
but they can heckle the guys who are playing pool

202
0:08:14.04,000 --> 0:08:17,000
and that can be an important thing for team bonding,

203
0:08:17.24,000 --> 0:08:18,000
which is kind of neat.

204
0:08:18.56,000 --> 0:08:2,000
People who get really good at operating these systems

205
0:08:21.08,000 --> 0:08:23,000
will even do things like make up new games,

206
0:08:23.16,000 --> 0:08:25,000
like robot soccer in the middle of the night,

207
0:08:25.32,000 --> 0:08:26,000
pushing the trash cans around.

208
0:08:26.8,000 --> 0:08:27,000
But not everyone's good.

209
0:08:28.4,000 --> 0:08:3,000
A lot of people have trouble operating these systems.

210
0:08:30.92,000 --> 0:08:32,000
This is actually a guy who logged into the robot

211
0:08:33.2,000 --> 0:08:35,000
and his eyeball was turned 90 degrees to the left.

212
0:08:35.6,000 --> 0:08:36,000
He didn't know that,

213
0:08:36.88,000 --> 0:08:38,000
so he ended up just bashing around the office,

214
0:08:39.08,000 --> 0:08:41,000
running into people's desks, getting super embarrassed,

215
0:08:41.72,000 --> 0:08:43,000
laughing about it -- his volume was way too high.

216
0:08:44.08,000 --> 0:08:46,000
And this guy here in the image is telling me,

217
0:08:46.24,000 --> 0:08:48,000
"We need a robot mute button."

218
0:08:48.36,000 --> 0:08:51,000
And by that what he really meant was we don't want it to be so disruptive.

219
0:08:51.88,000 --> 0:08:52,000
So as a robotics company,

220
0:08:53.52,000 --> 0:08:55,000
we added some obstacle avoidance to the system.

221
0:08:56,000 --> 0:08:59,000
It got a little laser range finder that could see the obstacles,

222
0:08:59.08,000 --> 0:09:02,000
and if I as a robot operator try to say, run into a chair,

223
0:09:02.24,000 --> 0:09:04,000
it wouldn't let me, it would just plan a path around,

224
0:09:04.76,000 --> 0:09:05,000
which seems like a good idea.

225
0:09:06.64,000 --> 0:09:09,000
People did hit fewer obstacles using that system, obviously,

226
0:09:09.84,000 --> 0:09:11,000
but actually, for some of the people,

227
0:09:11.96,000 --> 0:09:13,000
it took them a lot longer to get through our obstacle course,

228
0:09:14.84,000 --> 0:09:15,000
and we wanted to know why.

229
0:09:17.08,000 --> 0:09:2,000
It turns out that there's this important human dimension --

230
0:09:20.16,000 --> 0:09:22,000
a personality dimension called locus of control,

231
0:09:22.48,000 --> 0:09:25,000
and people who have a strong internal locus of control,

232
0:09:25.64,000 --> 0:09:28,000
they need to be the masters of their own destiny --

233
0:09:28.72,000 --> 0:09:31,000
really don't like giving up control to an autonomous system --

234
0:09:31.84,000 --> 0:09:33,000
so much so that they will fight the autonomy;

235
0:09:34,000 --> 0:09:37,000
"If I want to hit that chair, I'm going to hit that chair."

236
0:09:37.12,000 --> 0:09:4,000
And so they would actually suffer from having that autonomous assistance,

237
0:09:40.76,000 --> 0:09:42,000
which is an important thing for us to know

238
0:09:43.36,000 --> 0:09:46,000
as we're building increasingly autonomous, say, cars, right?

239
0:09:46.68,000 --> 0:09:49,000
How are different people going to grapple with that loss of control?

240
0:09:50.88,000 --> 0:09:52,000
It's going to be different depending on human dimensions.

241
0:09:53.6,000 --> 0:09:56,000
We can't treat humans as if we're just one monolithic thing.

242
0:09:57.12,000 --> 0:09:59,000
We vary by personality, by culture,

243
0:09:59.56,000 --> 0:10:01,000
we even vary by emotional state moment to moment,

244
0:10:02.04,000 --> 0:10:03,000
and being able to design these systems,

245
0:10:04.04,000 --> 0:10:06,000
these human-robot interaction systems,

246
0:10:06.36,000 --> 0:10:08,000
we need to take into account the human dimensions,

247
0:10:09.12,000 --> 0:10:1,000
not just the technological ones.

248
0:10:11.64,000 --> 0:10:15,000
Along with a sense of control also comes a sense of responsibility.

249
0:10:15.96,000 --> 0:10:17,000
And if you were a robot operator using one of these systems,

250
0:10:18.84,000 --> 0:10:2,000
this is what the interface would look like.

251
0:10:20.92,000 --> 0:10:21,000
It looks a little bit like a video game,

252
0:10:22.88,000 --> 0:10:24,000
which can be good because that's very familiar to people,

253
0:10:25.88,000 --> 0:10:26,000
but it can also be bad

254
0:10:27.12,000 --> 0:10:29,000
because it makes people feel like it's a video game.

255
0:10:29.6,000 --> 0:10:31,000
We had a bunch of kids over at Stanford play with the system

256
0:10:32.48,000 --> 0:10:34,000
and drive the robot around our office in Menlo Park,

257
0:10:34.96,000 --> 0:10:35,000
and the kids started saying things like,

258
0:10:36.92,000 --> 0:10:39,000
"10 points if you hit that guy over there. 20 points for that one."

259
0:10:40.12,000 --> 0:10:42,000
And they would chase them down the hallway.

260
0:10:42.16,000 --> 0:10:43,000
(Laughter)

261
0:10:43.2,000 --> 0:10:44,000
I told them, "Um, those are real people.

262
0:10:45.16,000 --> 0:10:48,000
They're actually going to bleed and feel pain if you hit them."

263
0:10:48.48,000 --> 0:10:49,000
And they'd be like, "OK, got it."

264
0:10:50.12,000 --> 0:10:52,000
But five minutes later, they would be like,

265
0:10:52.2,000 --> 0:10:55,000
"20 points for that guy over there, he just looks like he needs to get hit."

266
0:10:55.84,000 --> 0:10:57,000
It's a little bit like "Ender's Game," right?

267
0:10:58,000 --> 0:10:59,000
There is a real world on that other side

268
0:10:59.96,000 --> 0:11:02,000
and I think it's our responsibility as people designing these interfaces

269
0:11:03.4,000 --> 0:11:04,000
to help people remember

270
0:11:04.68,000 --> 0:11:06,000
that there's real consequences to their actions

271
0:11:06.96,000 --> 0:11:08,000
and to feel a sense of responsibility

272
0:11:09.28,000 --> 0:11:12,000
when they're operating these increasingly autonomous things.

273
0:11:13.84,000 --> 0:11:15,000
These are kind of a great example

274
0:11:16.16,000 --> 0:11:19,000
of experimenting with one possible robotic future,

275
0:11:19.44,000 --> 0:11:22,000
and I think it's pretty cool that we can extend ourselves

276
0:11:23.32,000 --> 0:11:25,000
and learn about the ways that we extend ourselves

277
0:11:25.68,000 --> 0:11:26,000
into these machines

278
0:11:26.92,000 --> 0:11:28,000
while at the same time being able to express our humanity

279
0:11:29.64,000 --> 0:11:3,000
and our personality.

280
0:11:30.88,000 --> 0:11:31,000
We also build empathy for others

281
0:11:32.48,000 --> 0:11:35,000
in terms of being shorter, taller, faster, slower,

282
0:11:35.72,000 --> 0:11:36,000
and maybe even armless,

283
0:11:37.16,000 --> 0:11:38,000
which is kind of neat.

284
0:11:38.52,000 --> 0:11:4,000
We also build empathy for the robots themselves.

285
0:11:41.08,000 --> 0:11:42,000
This is one of my favorite robots.

286
0:11:42.76,000 --> 0:11:43,000
It's called the Tweenbot.

287
0:11:44.24,000 --> 0:11:45,000
And this guy has a little flag that says,

288
0:11:46.24,000 --> 0:11:48,000
"I'm trying to get to this intersection in Manhattan,"

289
0:11:48.84,000 --> 0:11:5,000
and it's cute and rolls forward, that's it.

290
0:11:51.64,000 --> 0:11:54,000
It doesn't know how to build a map, it doesn't know how to see the world,

291
0:11:55.12,000 --> 0:11:56,000
it just asks for help.

292
0:11:56.4,000 --> 0:11:57,000
The nice thing about people

293
0:11:57.76,000 --> 0:12:,000
is that it can actually depend upon the kindness of strangers.

294
0:12:00.88,000 --> 0:12:03,000
It did make it across the park to the other side of Manhattan --

295
0:12:04.8,000 --> 0:12:05,000
which is pretty great --

296
0:12:06.08,000 --> 0:12:09,000
just because people would pick it up and point it in the right direction.

297
0:12:09.56,000 --> 0:12:09,000
(Laughter)

298
0:12:10.52,000 --> 0:12:11,000
And that's great, right?

299
0:12:11.8,000 --> 0:12:13,000
We're trying to build this human-robot world

300
0:12:14.52,000 --> 0:12:17,000
in which we can coexist and collaborate with one another,

301
0:12:17.96,000 --> 0:12:2,000
and we don't need to be fully autonomous and just do things on our own.

302
0:12:21.36,000 --> 0:12:22,000
We actually do things together.

303
0:12:22.88,000 --> 0:12:23,000
And to make that happen,

304
0:12:24.16,000 --> 0:12:27,000
we actually need help from people like the artists and the designers,

305
0:12:27.44,000 --> 0:12:28,000
the policy makers, the legal scholars,

306
0:12:29.32,000 --> 0:12:31,000
psychologists, sociologists, anthropologists --

307
0:12:31.56,000 --> 0:12:32,000
we need more perspectives in the room

308
0:12:33.4,000 --> 0:12:35,000
if we're going to do the thing that Stu Card says we should do,

309
0:12:36.4,000 --> 0:12:39,000
which is invent the future that we actually want to live in.

310
0:12:40.36,000 --> 0:12:42,000
And I think we can continue to experiment

311
0:12:43.04,000 --> 0:12:45,000
with these different robotic futures together,

312
0:12:45.24,000 --> 0:12:49,000
and in doing so, we will end up learning a lot more about ourselves.

313
0:12:50.72,000 --> 0:12:51,000
Thank you.

314
0:12:51.96,000 --> 0:12:53,000
(Applause)

