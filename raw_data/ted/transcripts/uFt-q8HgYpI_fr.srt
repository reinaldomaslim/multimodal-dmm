1
0:00:,000 --> 0:00:07,000
Traducteur: Gwendolyne Ricaud Relecteur: eric vautier

2
0:00:12.836,000 --> 0:00:14,000
[Contient du contenu destiné aux adultes]

3
0:00:17.741,000 --> 0:00:18,000
Il y a cinq ans,

4
0:00:19.385,000 --> 0:00:22,000
J'ai reçu un appel qui allait changer ma vie.

5
0:00:23.795,000 --> 0:00:25,000
Je me rappelle très bien cette journée.

6
0:00:27.245,000 --> 0:00:28,000
C'était à cette période de l'année,

7
0:00:29.17,000 --> 0:00:3,000
j'étais dans mon bureau.

8
0:00:31.692,000 --> 0:00:34,000
Le soleil entrait par la fenêtre.

9
0:00:35.592,000 --> 0:00:36,000
Mon téléphone a sonné.

10
0:00:37.565,000 --> 0:00:38,000
J'ai décroché,

11
0:00:39.594,000 --> 0:00:42,000
c'était deux agents fédéraux, me demandant de les aider

12
0:00:43.596,000 --> 0:00:45,000
à identifier une petite fille

13
0:00:46.326,000 --> 0:00:51,000
dans des centaines d'images d'abus sexuels d'enfants trouvées en ligne.

14
0:00:53.145,000 --> 0:00:55,000
Ils venaient de commencer à travailler sur l'affaire,

15
0:00:55.745,000 --> 0:00:57,000
mais ils savaient

16
0:00:58.639,000 --> 0:01:02,000
que ses abus avaient été diffusés mondialement pendant des années

17
0:01:03.486,000 --> 0:01:08,000
sur des sites du dark web dédiés aux abus sexuels sur des enfants.

18
0:01:09.605,000 --> 0:01:13,000
Et son agresseur était incroyablement sophistiqué sur le plan technologique :

19
0:01:14.014,000 --> 0:01:18,000
de nouvelles images et vidéos toutes les semaines,

20
0:01:18.626,000 --> 0:01:22,000
mais très peu d'informations sur qui elle était

21
0:01:22.699,000 --> 0:01:23,000
ou sa localisation.

22
0:01:25.324,000 --> 0:01:26,000
Ils nous ont appelés,

23
0:01:26.734,000 --> 0:01:28,000
car nous étions une association

24
0:01:29.448,000 --> 0:01:32,000
créant des technologies pour lutter contre les abus d'enfants.

25
0:01:33.596,000 --> 0:01:35,000
Mais nous n'existions que depuis deux ans,

26
0:01:35.907,000 --> 0:01:38,000
et nous n'avions travaillé que sur le trafic d'enfants.

27
0:01:39.944,000 --> 0:01:41,000
Et j'ai dû leur dire

28
0:01:42.091,000 --> 0:01:43,000
que nous n'avions rien.

29
0:01:44.28,000 --> 0:01:47,000
Nous n'avions rien pour les aider à mettre fin à cet abus.

30
0:01:49.263,000 --> 0:01:52,000
Il leur a fallu un an de plus

31
0:01:52.861,000 --> 0:01:55,000
pour enfin trouver cette enfant.

32
0:01:56.853,000 --> 0:01:58,000
Lorsqu'elle a été sauvée,

33
0:01:59.152,000 --> 0:02:05,000
des centaines d'images et vidéos de son viol avaient circulé,

34
0:02:05.664,000 --> 0:02:06,000
du dark web

35
0:02:07.379,000 --> 0:02:1,000
vers des réseaux peer-to-peer, des salons de chat privés

36
0:02:10.42,000 --> 0:02:15,000
jusqu'aux sites Web que vous et moi consultons chaque jour.

37
0:02:17.216,000 --> 0:02:2,000
Elle doit lutter pour s'en remettre,

38
0:02:21.055,000 --> 0:02:25,000
sachant que des milliers de personnes dans le monde

39
0:02:25.218,000 --> 0:02:28,000
continuent de regarder son viol.

40
0:02:29.994,000 --> 0:02:31,000
Ces cinq dernières années, j'ai pu apprendre

41
0:02:32.446,000 --> 0:02:34,000
que ce cas était loin d'être le seul.

42
0:02:36.119,000 --> 0:02:39,000
Comment notre société en est-elle arrivée là ?

43
0:02:41.49,000 --> 0:02:44,000
Dans la fin des années 80, la pédopornographie -

44
0:02:45.273,000 --> 0:02:5,000
ou plutôt, l'exploitation sexuelle des enfants,

45
0:02:50.55,000 --> 0:02:51,000
a été presque éliminée.

46
0:02:53.209,000 --> 0:02:55,000
Les échanges par la poste étaient devenus trop risqués,

47
0:02:56.033,000 --> 0:02:59,000
suite aux nouvelles lois, et à l'augmentation des poursuites.

48
0:03:00.233,000 --> 0:03:04,000
L'arrivée d'internet a permis l'explosion du marché

49
0:03:05.31,000 --> 0:03:08,000
La quantité de contenu qui circule aujourd'hui

50
0:03:08.69,000 --> 0:03:1,000
est massive et en pleine croissance.

51
0:03:12.421,000 --> 0:03:15,000
C'est un problème mondial,

52
0:03:15.689,000 --> 0:03:16,000
mais en s'intéressant juste aux USA :

53
0:03:17.546,000 --> 0:03:19,000
rien qu'aux USA l'année dernière,

54
0:03:20.281,000 --> 0:03:25,000
plus de 45 millions d'images et vidéos pédopornographiques

55
0:03:25.579,000 --> 0:03:28,000
ont été signalées au National Center for Missing and Exploited Children,

56
0:03:29.281,000 --> 0:03:33,000
c'est presque le double de l'année précédente.

57
0:03:34.627,000 --> 0:03:39,000
La réalité derrière ces chiffres est dure à imaginer.

58
0:03:39.937,000 --> 0:03:44,000
Plus de 60% des images représentent des moins de 12 ans,

59
0:03:45.681,000 --> 0:03:49,000
la plupart d'entre eux incluent des actes de violence sexuelle extrêmes.

60
0:03:50.85,000 --> 0:03:55,000
Les agresseurs sont encouragés dans les chats dédiés à la maltraitance d'enfants,

61
0:03:56.174,000 --> 0:03:58,000
où ils gagnent en rang et en notoriété

62
0:03:58.681,000 --> 0:04:,000
faisant plus de victimes.

63
0:04:02.243,000 --> 0:04:04,000
Dans ce marché,

64
0:04:04.862,000 --> 0:04:07,000
la monnaie est le contenu.

65
0:04:10.023,000 --> 0:04:13,000
Les agresseurs ont rapidement tiré parti des nouvelles technologies,

66
0:04:13.853,000 --> 0:04:16,000
mais notre réponse en tant que société est lente.

67
0:04:17.671,000 --> 0:04:21,000
Les agresseurs ne lisent pas les CGU des sites Internet,

68
0:04:21.866,000 --> 0:04:24,000
et le contenu ne respecte pas les frontières géographiques.

69
0:04:26.656,000 --> 0:04:32,000
Ils gagnent quand nous regardons une chose à la fois,

70
0:04:32.793,000 --> 0:04:36,000
ce qui est exactement la façon dont notre réponse est conçue aujourd'hui.

71
0:04:36.834,000 --> 0:04:39,000
Les forces de l'ordre travaillent dans une seule juridiction.

72
0:04:40.345,000 --> 0:04:43,000
Les entreprises ne surveillent que leurs propres plateformes.

73
0:04:43.783,000 --> 0:04:45,000
Et quoi qu'ils apprennent,

74
0:04:46.511,000 --> 0:04:48,000
ils le partagent rarement.

75
0:04:49.402,000 --> 0:04:54,000
Il est évident que cette déconnexion ne fonctionne pas.

76
0:04:55.643,000 --> 0:04:59,000
Nous devons repenser notre réponse à cette épidémie

77
0:04:59.777,000 --> 0:05:,000
de l'ère numérique.

78
0:05:01.702,000 --> 0:05:03,000
Et c'est exactement ce que Thorn fait.

79
0:05:05.311,000 --> 0:05:08,000
Nous construisons la technologie pour connecter ces points,

80
0:05:08.952,000 --> 0:05:1,000
pour armer tous les acteurs -

81
0:05:11.298,000 --> 0:05:13,000
les forces de l'ordre, les ONG et les entreprises -

82
0:05:14.146,000 --> 0:05:17,000
avec les outils dont ils ont besoin pour éliminer définitivement

83
0:05:17.679,000 --> 0:05:19,000
le contenu pédopornographique d'Internet.

84
0:05:21.571,000 --> 0:05:22,000
Parlons un peu --

85
0:05:22.866,000 --> 0:05:23,000
(Applaudissements)

86
0:05:24.409,000 --> 0:05:25,000
Merci.

87
0:05:25.737,000 --> 0:05:27,000
(Applaudissements)

88
0:05:29.8,000 --> 0:05:31,000
Parlons un peu de ces points.

89
0:05:33.323,000 --> 0:05:36,000
Vous l'imaginez, le contenu est atroce.

90
0:05:36.558,000 --> 0:05:39,000
Si on n'y est pas obligé, on ne veut pas le voir.

91
0:05:40.43,000 --> 0:05:44,000
La plupart des entreprises ou forces de l'ordre

92
0:05:45.423,000 --> 0:05:46,000
qui ont accès à ce contenu

93
0:05:47.11,000 --> 0:05:5,000
peuvent traduire chaque fichier en une suite de chiffres.

94
0:05:50.586,000 --> 0:05:51,000
C'est un « hash ».

95
0:05:52.084,000 --> 0:05:54,000
C'est surtout une empreinte digitale

96
0:05:54.251,000 --> 0:05:56,000
par fichier ou vidéo.

97
0:05:56.673,000 --> 0:06:,000
Cela leur permet d'utiliser ces informations lors d'enquêtes,

98
0:06:01.31,000 --> 0:06:04,000
ou aux entreprises de supprimer le contenu de leurs plateformes

99
0:06:04.361,000 --> 0:06:09,000
sans avoir à revoir chaque image ou vidéo.

100
0:06:10.196,000 --> 0:06:12,000
Le problème actuel est que

101
0:06:12.371,000 --> 0:06:15,000
des centaines de millions de ces hash

102
0:06:16.146,000 --> 0:06:19,000
traînent dans des silos de données autour du monde.

103
0:06:20.214,000 --> 0:06:21,000
Dans ces silos,

104
0:06:21.389,000 --> 0:06:24,000
cela a beau fonctionner pour l'agence qui en a le contrôle,

105
0:06:24.489,000 --> 0:06:28,000
mais sans partager ces données, nous ne savons pas

106
0:06:28.643,000 --> 0:06:31,000
lesquelles montrent des enfants qui ont été sauvés

107
0:06:32.183,000 --> 0:06:34,000
ou ont toujours besoin d'être sauvés.

108
0:06:35.096,000 --> 0:06:39,000
Notre but premier est donc de connecter

109
0:06:39.29,000 --> 0:06:41,000
toutes ces données.

110
0:06:42.318,000 --> 0:06:48,000
Il y a deux façons dont elles peuvent transformer cet espace,

111
0:06:48.511,000 --> 0:06:51,000
combinées à des logiciels utilisés mondialement.

112
0:06:52.464,000 --> 0:06:54,000
La première est pour la police :

113
0:06:55.11,000 --> 0:06:58,000
identifier les victimes plus rapidement,

114
0:06:58.765,000 --> 0:06:59,000
arrêter les abus,

115
0:07:00.005,000 --> 0:07:02,000
et bloquer les créateurs de contenu.

116
0:07:03.441,000 --> 0:07:05,000
La deuxième est pour les entreprises :

117
0:07:06.131,000 --> 0:07:09,000
s'en servir comme indices pour identifier les millions de dossiers

118
0:07:09.776,000 --> 0:07:1,000
qui circulent actuellement,

119
0:07:11.394,000 --> 0:07:12,000
les retirer

120
0:07:12.605,000 --> 0:07:18,000
puis empêcher la mise en ligne de contenu avant qu'il devienne viral.

121
0:07:21.694,000 --> 0:07:22,000
Il y a quatre ans,

122
0:07:23.364,000 --> 0:07:24,000
à la fin de l'affaire

123
0:07:26.3,000 --> 0:07:29,000
notre équipe était là, ressentant un genre de...

124
0:07:31.635,000 --> 0:07:34,000
sentiment profond d'échec, je dirais,

125
0:07:34.997,000 --> 0:07:37,000
car nous avions observé toute cette année

126
0:07:38.672,000 --> 0:07:39,000
quand ils la cherchaient.

127
0:07:40.016,000 --> 0:07:43,000
Nous avons vu chaque étape de l'enquête

128
0:07:44.007,000 --> 0:07:46,000
où ils auraient pu la retrouver plus rapidement

129
0:07:46.419,000 --> 0:07:48,000
si la technologie avait existé.

130
0:07:49.684,000 --> 0:07:5,000
Nous sommes partis de ça

131
0:07:51.644,000 --> 0:07:53,000
pour commencer à faire la seule chose que nous savions faire :

132
0:07:54.623,000 --> 0:07:56,000
nous avons créé des logiciels.

133
0:07:57.689,000 --> 0:07:59,000
Nous avons commencé avec les forces de l'ordre.

134
0:07:59.965,000 --> 0:08:03,000
Nous rêvions d'une alarme sur le bureau des policiers

135
0:08:04.41,000 --> 0:08:08,000
pour que quelqu'un puisse commencer à mener l'enquête

136
0:08:08.978,000 --> 0:08:11,000
dès que quelqu'un osait poster une nouvelle victime.

137
0:08:13.324,000 --> 0:08:15,000
Je ne peux évidemment pas détailler ce logiciel,

138
0:08:16.305,000 --> 0:08:18,000
mais il est utilisé dans 38 pays,

139
0:08:18.938,000 --> 0:08:2,000
réduisant le temps de retrouver un enfant

140
0:08:21.936,000 --> 0:08:23,000
de plus de 65%.

141
0:08:24.29,000 --> 0:08:28,000
(Applaudissements)

142
0:08:33.442,000 --> 0:08:36,000
Nous travaillons actuellement sur le second point :

143
0:08:36.481,000 --> 0:08:41,000
créer le logiciel qui aide les entreprises à repérer et supprimer le contenu.

144
0:08:43.193,000 --> 0:08:45,000
Parlons un instant de ces entreprises.

145
0:08:46.27,000 --> 0:08:51,000
Je vous disais, 45 millions d'images et vidéos rien qu'aux US l'année dernière.

146
0:08:52.28,000 --> 0:08:55,000
Qui venaient uniquement de 12 entreprises.

147
0:08:57.883,000 --> 0:09:03,000
Douze entreprises, 45 millions de dossiers d'abus d'enfants.

148
0:09:04.335,000 --> 0:09:06,000
Venant de ces entreprises ayant les moyens financiers

149
0:09:07.159,000 --> 0:09:11,000
de créer les infrastructures nécessaires à la suppression de ce contenu.

150
0:09:11.74,000 --> 0:09:13,000
Il y a des centaines d'autres entreprises,

151
0:09:14.175,000 --> 0:09:16,000
petites à moyennes, tout autour du monde

152
0:09:16.865,000 --> 0:09:18,000
qui doivent faire ce travail, mais qui :

153
0:09:18.943,000 --> 0:09:23,000
1) soit n'imaginent pas leur plateforme utilisée pour ce contenu,

154
0:09:24.392,000 --> 0:09:29,000
2) soit n'ont pas d'argent à investir si cela ne leur rapporte pas de bénéfices.

155
0:09:30.932,000 --> 0:09:33,000
Nous avons pris l'initiative de le faire pour eux,

156
0:09:34.245,000 --> 0:09:38,000
et plus il y a d'entreprises, plus ce système est performant.

157
0:09:39.965,000 --> 0:09:4,000
Je vous donne un exemple.

158
0:09:42.459,000 --> 0:09:45,000
Notre premier partenaire, Imgur - l'un des sites

159
0:09:46.361,000 --> 0:09:49,000
les plus visités aux États-Unis - partage des millions

160
0:09:49.527,000 --> 0:09:54,000
de contenus crées par les utilisateurs chaque jour

161
0:09:54.559,000 --> 0:09:56,000
dans le but de faire d'Internet un endroit plus amusant.

162
0:09:58.012,000 --> 0:09:59,000
Ils se sont associés à nous.

163
0:09:59.888,000 --> 0:10:02,000
En 20 minutes d'utilisation de notre système,

164
0:10:03.255,000 --> 0:10:06,000
quelqu'un a essayé de publier du contenu abusif.

165
0:10:06.851,000 --> 0:10:08,000
Ils ont pu l'en empêcher, le supprimer,

166
0:10:08.983,000 --> 0:10:11,000
et l'ont signalé au National Center for Missing and Exploited Children.

167
0:10:12.473,000 --> 0:10:13,000
Mais ils sont allés plus loin,

168
0:10:14.405,000 --> 0:10:18,000
et ont inspecté le compte de l'utilisateur qui l'avait publié.

169
0:10:19.086,000 --> 0:10:23,000
Ils ont trouvé des centaines d'autres fichiers d'abus pédosexuels

170
0:10:23.821,000 --> 0:10:24,000
qu'ils n'avaient jamais vus.

171
0:10:26.152,000 --> 0:10:29,000
C'est là que nous commençons à voir l'impact exponentiel.

172
0:10:29.708,000 --> 0:10:3,000
Nous retirons le contenu,

173
0:10:31.5,000 --> 0:10:34,000
le signalons au National Center for Missing and Exploited Children

174
0:10:35.074,000 --> 0:10:37,000
et ces hash sont sauvegardés par le système

175
0:10:37.609,000 --> 0:10:39,000
et les autres entreprises en profitent.

176
0:10:40.097,000 --> 0:10:44,000
Quand les millions de hash en créent d'autres, et qu'en temps réel,

177
0:10:44.905,000 --> 0:10:48,000
les entreprises identifient et retirent le contenu,

178
0:10:49.467,000 --> 0:10:53,000
nous augmentons drastiquement la vitesse à laquelle nous retirons

179
0:10:54.052,000 --> 0:10:58,000
le contenu pédopornographique d'Internet autour du monde.

180
0:10:58.37,000 --> 0:11:03,000
(Applaudissements)

181
0:11:06.208,000 --> 0:11:09,000
Mais il ne peut pas s'agir que de logiciels et de données,

182
0:11:09.452,000 --> 0:11:1,000
il faut que ce soit massif.

183
0:11:11.248,000 --> 0:11:14,000
Nous devons engager des centaines de policiers,

184
0:11:14.785,000 --> 0:11:16,000
des centaines d'entreprises autour du monde

185
0:11:17.186,000 --> 0:11:2,000
lorsque la technologie nous permettra de distancer les agresseurs

186
0:11:20.818,000 --> 0:11:24,000
et de démanteler les réseaux qui normalisent les abus pédosexuels

187
0:11:24.967,000 --> 0:11:25,000
tout autour du monde.

188
0:11:27.064,000 --> 0:11:29,000
Il faut faire cela maintenant.

189
0:11:30.288,000 --> 0:11:35,000
Nous ne pouvons plus dire que nous n'en connaissons pas l'impact sur nos enfants.

190
0:11:36.688,000 --> 0:11:4,000
La première génération d'enfants dont les abus sont devenus viraux

191
0:11:41.17,000 --> 0:11:42,000
sont maintenant de jeunes adultes.

192
0:11:43.451,000 --> 0:11:45,000
Le Centre Canadien de Protection de l'Enfance

193
0:11:46.06,000 --> 0:11:48,000
a récemment étudié ces jeunes adultes

194
0:11:48.78,000 --> 0:11:52,000
afin de comprendre le trauma unique dont ils doivent se remettre,

195
0:11:53.44,000 --> 0:11:55,000
en sachant que leurs abus sont toujours en ligne.

196
0:11:57.213,000 --> 0:12:01,000
80% de ces jeunes adultes ont pensé au suicide.

197
0:12:02.566,000 --> 0:12:06,000
Plus de 60% ont tenté de se suicider.

198
0:12:07.572,000 --> 0:12:12,000
La plupart d'entre eux vivent chaque jour dans la peur

199
0:12:12.813,000 --> 0:12:16,000
de marcher dans la rue, de passer un entretien,

200
0:12:17.3,000 --> 0:12:19,000
d'aller à l'école

201
0:12:19.614,000 --> 0:12:21,000
ou de faire des rencontres en ligne,

202
0:12:22.063,000 --> 0:12:25,000
et que leurs interlocuteurs aient vu les abus qu'ils ont subis.

203
0:12:26.547,000 --> 0:12:3,000
C'est ce qui est arrivé à 30% d'entre eux.

204
0:12:32.256,000 --> 0:12:36,000
Ils ont été reconnus de ces abus en ligne.

205
0:12:38.022,000 --> 0:12:41,000
Cela ne va pas être facile,

206
0:12:41.322,000 --> 0:12:43,000
mais ce n'est pas impossible.

207
0:12:44.189,000 --> 0:12:46,000
Cela va nécessiter la volonté,

208
0:12:46.889,000 --> 0:12:47,000
la volonté de notre société

209
0:12:48.502,000 --> 0:12:51,000
de voir quelque chose qui est difficile à regarder,

210
0:12:52.08,000 --> 0:12:54,000
de sortir quelque chose de l'obscurité

211
0:12:54.447,000 --> 0:12:56,000
afin que ces enfants soient entendus ;

212
0:12:58.11,000 --> 0:13:02,000
la volonté des entreprises d'agir et de s'assurer que leurs plateformes

213
0:13:03.08,000 --> 0:13:06,000
ne sont pas complices de ces abus ;

214
0:13:07.205,000 --> 0:13:1,000
la volonté du gouvernement et des forces de l'ordre d'investir

215
0:13:11.18,000 --> 0:13:16,000
dans les outils nécessaires dans les premiers crimes numériques,

216
0:13:16.298,000 --> 0:13:2,000
même quand les victimes ne peuvent pas parler.

217
0:13:21.746,000 --> 0:13:24,000
Cet engagement audacieux s'inscrit dans cette volonté.

218
0:13:26.269,000 --> 0:13:31,000
C'est une déclaration de guerre contre l'un des pires démons de l'humanité.

219
0:13:32.263,000 --> 0:13:33,000
Ce à quoi je m'accroche,

220
0:13:34.227,000 --> 0:13:37,000
c'est que c'est un investissement pour un avenir

221
0:13:37.7,000 --> 0:13:4,000
où chaque enfant peut simplement être un enfant.

222
0:13:41.357,000 --> 0:13:42,000
Merci.

223
0:13:42.896,000 --> 0:13:48,000
(Applaudissements)

