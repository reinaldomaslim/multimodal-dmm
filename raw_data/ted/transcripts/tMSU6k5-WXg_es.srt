1
0:00:,000 --> 0:00:07,000
Traductor: Sebastian Betti Revisor: Ciro Gomez

2
0:00:12.485,000 --> 0:00:14,000
Hace 10 años escribí un libro que titulé:

3
0:00:14.707,000 --> 0:00:17,000
"¿Nuestro siglo final?" Signos de interrogación.

4
0:00:17.8,000 --> 0:00:2,000
Mis editores quitaron los signos de interrogación. (Risas)

5
0:00:21.377,000 --> 0:00:22,000
Los editores estadounidenses cambiaron el título por:

6
0:00:23.259,000 --> 0:00:26,000
"Nuestra hora final".

7
0:00:27.168,000 --> 0:00:3,000
A los estadounidenses les gusta la gratificación instantánea y lo contrario.

8
0:00:30.66,000 --> 0:00:31,000
(Risas)

9
0:00:32.368,000 --> 0:00:33,000
El tema era este:

10
0:00:34.118,000 --> 0:00:38,000
Nuestra Tierra ha existido durante 45 millones de siglos,

11
0:00:38.284,000 --> 0:00:4,000
pero este siglo es especial;

12
0:00:40.297,000 --> 0:00:43,000
es el primero en el que una especie, la nuestra,

13
0:00:43.313,000 --> 0:00:45,000
tiene el futuro del planeta en sus manos.

14
0:00:46.115,000 --> 0:00:47,000
Durante casi toda la historia de la Tierra,

15
0:00:48.105,000 --> 0:00:49,000
las amenazas provinieron de la Naturaleza:

16
0:00:50.041,000 --> 0:00:53,000
enfermedades, terremotos, asteroides, etc.;

17
0:00:53.537,000 --> 0:00:58,000
pero a partir de ahora, los peores peligros vienen de nosotros.

18
0:00:59.209,000 --> 0:01:02,000
Y ahora no solo está la amenaza nuclear;

19
0:01:02.48,000 --> 0:01:03,000
en nuestro mundo interconectado,

20
0:01:04.231,000 --> 0:01:07,000
las fallas de red pueden propagarse en cascada por el mundo;

21
0:01:07.394,000 --> 0:01:1,000
los viajes en avión pueden propagar pandemias por el mundo en cuestión de días;

22
0:01:11.35,000 --> 0:01:14,000
y los medios sociales pueden propagar pánico y rumores

23
0:01:14.677,000 --> 0:01:17,000
literalmente a la velocidad de la luz.

24
0:01:17.894,000 --> 0:01:2,000
Nos preocupamos demasiado por riesgos menores:

25
0:01:21.119,000 --> 0:01:25,000
accidentes aéreos improbables, sustancias cancerígenas en los alimentos,

26
0:01:25.15,000 --> 0:01:27,000
dosis bajas de radiación, etc.;

27
0:01:27.376,000 --> 0:01:29,000
pero nosotros y nuestros políticos

28
0:01:30.201,000 --> 0:01:34,000
negamos los escenarios catastróficos.

29
0:01:34.404,000 --> 0:01:37,000
Por suerte, aún no ha sucedido lo peor.

30
0:01:37.442,000 --> 0:01:39,000
De hecho, quizá no ocurrirá.

31
0:01:39.638,000 --> 0:01:42,000
Pero si un evento es potencialmente devastador,

32
0:01:42.823,000 --> 0:01:44,000
vale la pena pagar una prima sustancial

33
0:01:45.691,000 --> 0:01:48,000
para protegerse en contra de eso, aunque sea poco probable,

34
0:01:49.527,000 --> 0:01:53,000
así como tenemos un seguro de incendio en nuestra casa.

35
0:01:54.04,000 --> 0:01:58,000
Y así como la ciencia ofrece mayor poder y más promesas,

36
0:01:59.037,000 --> 0:02:02,000
el lado negativo da más miedo también.

37
0:02:02.903,000 --> 0:02:04,000
Somos cada vez más vulnerables.

38
0:02:05.142,000 --> 0:02:06,000
En unas pocas décadas,

39
0:02:06.98,000 --> 0:02:08,000
millones podrán

40
0:02:09.21,000 --> 0:02:12,000
usar mal los rápidos avances en biotecnología

41
0:02:12.331,000 --> 0:02:15,000
así como hoy usan mal la cibertecnología.

42
0:02:15.884,000 --> 0:02:18,000
Freeman Dyson, en una charla TED,

43
0:02:19.083,000 --> 0:02:22,000
previó que los niños diseñarán y crearán nuevos organismos

44
0:02:22.679,000 --> 0:02:26,000
tan rutinariamente como su generación jugaba con juegos de química.

45
0:02:27.19,000 --> 0:02:29,000
Bueno, esto puede ser de ciencia ficción,

46
0:02:29.718,000 --> 0:02:32,000
pero, de ocurrir ese escenario,

47
0:02:32.901,000 --> 0:02:34,000
nuestra ecología e incluso nuestra especie

48
0:02:35.638,000 --> 0:02:38,000
seguramente no sobreviviría mucho tiempo indemne.

49
0:02:39.627,000 --> 0:02:42,000
Por ejemplo, hay algunos eco-extremistas

50
0:02:43.49,000 --> 0:02:45,000
que piensan que sería mejor para el planeta,

51
0:02:45.999,000 --> 0:02:48,000
para Gaia, si hubiera muchos menos humanos.

52
0:02:49.402,000 --> 0:02:51,000
¿Qué sucederá cuando estas personas dominen

53
0:02:52.119,000 --> 0:02:54,000
técnicas de biología sintética

54
0:02:54.256,000 --> 0:02:56,000
comunes en el 2050?

55
0:02:57.108,000 --> 0:03:,000
Para entonces, otras pesadillas de ciencia ficción

56
0:03:00.15,000 --> 0:03:01,000
pueden hacerse realidad:

57
0:03:01.86,000 --> 0:03:03,000
robots tontos que se vuelven hostiles,

58
0:03:03.93,000 --> 0:03:05,000
o una red desarrolla una mente propia

59
0:03:06.347,000 --> 0:03:08,000
y nos amenaza a todos.

60
0:03:08.936,000 --> 0:03:11,000
Bueno, ¿podemos protegernos de tales riesgos con regulación?

61
0:03:12.206,000 --> 0:03:14,000
Sin duda hay que probar, pero estas empresas

62
0:03:14.613,000 --> 0:03:17,000
son tan competitivas, tan globalizadas,

63
0:03:18.142,000 --> 0:03:19,000
impulsadas por tanta presión comercial,

64
0:03:20.122,000 --> 0:03:23,000
que cualquier cosa posible de hacer se hará en alguna parte,

65
0:03:23.407,000 --> 0:03:25,000
sin importar lo que digan las regulaciones.

66
0:03:25.443,000 --> 0:03:28,000
Es como las leyes antinarcóticos, tratamos de regular, pero no podemos.

67
0:03:28.93,000 --> 0:03:31,000
Y la aldea global tendrá sus tontos de aldea,

68
0:03:31.974,000 --> 0:03:34,000
que tendrán un rango global.

69
0:03:35.47,000 --> 0:03:37,000
Por eso, como dije en mi libro,

70
0:03:37.761,000 --> 0:03:39,000
tendremos un viaje lleno de baches en este siglo.

71
0:03:40.65,000 --> 0:03:43,000
Puede haber retrocesos en nuestra sociedad;

72
0:03:44.14,000 --> 0:03:48,000
de hecho, existe una probabilidad del 50 % de un severo revés.

73
0:03:48.255,000 --> 0:03:5,000
Pero ¿hay eventos concebibles

74
0:03:51.169,000 --> 0:03:53,000
que puedan ser incluso peores,

75
0:03:53.33,000 --> 0:03:56,000
que puedan extinguir la vida?

76
0:03:56.76,000 --> 0:03:58,000
Cuando aparece un nuevo acelerador de partículas,

77
0:03:59.686,000 --> 0:04:,000
algunos preguntan con inquietud:

78
0:04:01.475,000 --> 0:04:03,000
¿Podría destruir la Tierra, o incluso peor,

79
0:04:03.725,000 --> 0:04:05,000
desintegrar por completo el tejido del espacio?

80
0:04:06.384,000 --> 0:04:09,000
Bueno por suerte hay consuelo.

81
0:04:09.927,000 --> 0:04:11,000
Junto con otra gente señalo que la Naturaleza

82
0:04:11.971,000 --> 0:04:12,000
ya ha hecho los mismos experimentos

83
0:04:13.904,000 --> 0:04:15,000
millones y millones de veces

84
0:04:16.09,000 --> 0:04:17,000
vía colisiones de rayos cósmicos.

85
0:04:17.855,000 --> 0:04:2,000
Pero los científicos deberían tener precauciones

86
0:04:20.909,000 --> 0:04:22,000
con experimentos que generen condiciones

87
0:04:23.489,000 --> 0:04:25,000
sin precedentes en el mundo natural.

88
0:04:25.972,000 --> 0:04:28,000
Los biólogos deben evitar la liberación potencialmente devastadora

89
0:04:29.394,000 --> 0:04:31,000
de patógenos genéticamente modificados.

90
0:04:32.11,000 --> 0:04:35,000
Y, por cierto, nuestra aversión especial

91
0:04:35.627,000 --> 0:04:38,000
al riesgo de desastres verdaderamente existenciales

92
0:04:39.088,000 --> 0:04:42,000
depende de una cuestión filosófica y ética,

93
0:04:42.363,000 --> 0:04:43,000
y es esta:

94
0:04:44.033,000 --> 0:04:46,000
Consideren 2 escenarios.

95
0:04:46.341,000 --> 0:04:51,000
El Escenario A arrasa al 90 % de la humanidad.

96
0:04:51.577,000 --> 0:04:54,000
El Escenario B arrasa al 100 %.

97
0:04:55.473,000 --> 0:04:57,000
¿Cuánto peor es B que A?

98
0:04:58.391,000 --> 0:05:01,000
Algunos dirían 10 % peor.

99
0:05:01.414,000 --> 0:05:04,000
El conteo de cuerpos es 10 % más alto.

100
0:05:04.564,000 --> 0:05:06,000
Pero yo sostengo que B es incomparablemente peor.

101
0:05:07.47,000 --> 0:05:09,000
Como astrónomo no puedo creer

102
0:05:10.099,000 --> 0:05:12,000
que los humanos seamos el fin de la historia.

103
0:05:12.566,000 --> 0:05:15,000
Faltan 5000 millones de años para que estalle el Sol,

104
0:05:15.889,000 --> 0:05:17,000
y el universo puede seguir para siempre,

105
0:05:18.6,000 --> 0:05:2,000
por eso la evolución post-humana

106
0:05:20.892,000 --> 0:05:22,000
aquí en la Tierra y mucho más allá,

107
0:05:23.082,000 --> 0:05:25,000
podría prolongarse como el proceso darwiniano

108
0:05:25.796,000 --> 0:05:28,000
que condujo a nosotros, y ser aún más maravilloso.

109
0:05:29.077,000 --> 0:05:31,000
Y, en efecto, la evolución futura ocurrirá mucho más rápido,

110
0:05:31.741,000 --> 0:05:33,000
a escala de tiempo tecnológico,

111
0:05:33.94,000 --> 0:05:35,000
no a escala de tiempo de selección natural.

112
0:05:36.239,000 --> 0:05:4,000
Así que sin duda, en vista de lo mucho que está en juego,

113
0:05:40.434,000 --> 0:05:43,000
no deberíamos aceptar un riesgo ni de 1 en 1000 millones

114
0:05:43.82,000 --> 0:05:45,000
de que la extinción humana nos quite

115
0:05:46.049,000 --> 0:05:48,000
este inmenso potencial.

116
0:05:48.359,000 --> 0:05:49,000
Algunos de los escenarios previstos

117
0:05:50.131,000 --> 0:05:51,000
pueden ser incluso de ciencia ficción,

118
0:05:51.95,000 --> 0:05:54,000
pero otros pueden ser inquietantemente reales.

119
0:05:55.336,000 --> 0:05:57,000
Es una máxima importante que lo no familiar

120
0:05:58.21,000 --> 0:06:,000
no es lo mismo que lo improbable,

121
0:06:00.907,000 --> 0:06:02,000
y, de hecho, por eso en la Universidad de Cambridge

122
0:06:03.305,000 --> 0:06:06,000
creamos un centro para estudiar cómo mitigar

123
0:06:06.68,000 --> 0:06:08,000
estos riesgos existenciales.

124
0:06:08.712,000 --> 0:06:11,000
Parece que vale la pena que unas pocas personas

125
0:06:11.775,000 --> 0:06:13,000
piensen en estos desastres potenciales.

126
0:06:14.091,000 --> 0:06:17,000
Necesitamos toda la ayuda que podamos conseguir de otros,

127
0:06:17.104,000 --> 0:06:19,000
porque somos guardianes de un valioso

128
0:06:19.583,000 --> 0:06:22,000
punto azul pálido en un vasto cosmos,

129
0:06:23.066,000 --> 0:06:26,000
un planeta con 50 millones de siglos por delante.

130
0:06:26.444,000 --> 0:06:28,000
Así que no pongamos en peligro ese futuro.

131
0:06:29,000 --> 0:06:3,000
Y quiero terminar con la cita

132
0:06:30.795,000 --> 0:06:33,000
de un gran científico llamado Peter Medawar.

133
0:06:34.296,000 --> 0:06:37,000
Cito: "Las campanas que doblan por la humanidad

134
0:06:37.569,000 --> 0:06:39,000
son como los cencerros del ganado alpino.

135
0:06:40.213,000 --> 0:06:42,000
Están unidas a nuestros propios cuellos,

136
0:06:42.499,000 --> 0:06:44,000
y debe ser culpa nuestra si no producen

137
0:06:45.174,000 --> 0:06:46,000
un sonido armonioso y melódico".

138
0:06:47,000 --> 0:06:48,000
Muchas gracias.

139
0:06:48.5,000 --> 0:06:5,000
(Aplausos)

