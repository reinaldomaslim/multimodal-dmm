1
0:00:12.54,000 --> 0:00:16,000
People have been using media to talk about sex for a long time.

2
0:00:17.42,000 --> 0:00:2,000
Love letters, phone sex, racy Polaroids.

3
0:00:21.3,000 --> 0:00:27,000
There's even a story of a girl who eloped with a man that she met over the telegraph

4
0:00:27.38,000 --> 0:00:28,000
in 1886.

5
0:00:30.38,000 --> 0:00:35,000
Today we have sexting, and I am a sexting expert.

6
0:00:35.5,000 --> 0:00:36,000
Not an expert sexter.

7
0:00:38.62,000 --> 0:00:42,000
Though, I do know what this means -- I think you do too.

8
0:00:42.82,000 --> 0:00:43,000
[it's a penis]

9
0:00:44.22,000 --> 0:00:46,000
(Laughter)

10
0:00:48.18,000 --> 0:00:54,000
I have been studying sexting since the media attention to it began in 2008.

11
0:00:54.54,000 --> 0:00:56,000
I wrote a book on the moral panic about sexting.

12
0:00:57.54,000 --> 0:00:58,000
And here's what I found:

13
0:00:59.18,000 --> 0:01:02,000
most people are worrying about the wrong thing.

14
0:01:02.42,000 --> 0:01:06,000
They're trying to just prevent sexting from happening entirely.

15
0:01:06.62,000 --> 0:01:07,000
But let me ask you this:

16
0:01:08.18,000 --> 0:01:12,000
As long as it's completely consensual, what's the problem with sexting?

17
0:01:13.06,000 --> 0:01:17,000
People are into all sorts of things that you may not be into,

18
0:01:17.1,000 --> 0:01:19,000
like blue cheese or cilantro.

19
0:01:19.42,000 --> 0:01:2,000
(Laughter)

20
0:01:22.42,000 --> 0:01:26,000
Sexting is certainly risky, like anything that's fun,

21
0:01:26.58,000 --> 0:01:32,000
but as long as you're not sending an image to someone who doesn't want to receive it,

22
0:01:33.3,000 --> 0:01:34,000
there's no harm.

23
0:01:35.1,000 --> 0:01:37,000
What I do think is a serious problem

24
0:01:37.74,000 --> 0:01:4,000
is when people share private images of others

25
0:01:41.02,000 --> 0:01:42,000
without their permission.

26
0:01:43.18,000 --> 0:01:45,000
And instead of worrying about sexting,

27
0:01:45.54,000 --> 0:01:49,000
what I think we need to do is think a lot more about digital privacy.

28
0:01:50.7,000 --> 0:01:52,000
The key is consent.

29
0:01:53.5,000 --> 0:01:56,000
Right now most people are thinking about sexting

30
0:01:56.82,000 --> 0:01:58,000
without really thinking about consent at all.

31
0:02:00.22,000 --> 0:02:03,000
Did you know that we currently criminalize teen sexting?

32
0:02:05.22,000 --> 0:02:08,000
It can be a crime because it counts as child pornography,

33
0:02:08.7,000 --> 0:02:1,000
if there's an image of someone under 18,

34
0:02:11.58,000 --> 0:02:12,000
and it doesn't even matter

35
0:02:12.94,000 --> 0:02:16,000
if they took that image of themselves and shared it willingly.

36
0:02:17.62,000 --> 0:02:19,000
So we end up with this bizarre legal situation

37
0:02:20.62,000 --> 0:02:24,000
where two 17-year-olds can legally have sex in most US states

38
0:02:25.18,000 --> 0:02:26,000
but they can't photograph it.

39
0:02:28.38,000 --> 0:02:32,000
Some states have also tried passing sexting misdemeanor laws

40
0:02:32.66,000 --> 0:02:35,000
but these laws repeat the same problem

41
0:02:35.7,000 --> 0:02:38,000
because they still make consensual sexting illegal.

42
0:02:40.34,000 --> 0:02:41,000
It doesn't make sense

43
0:02:41.62,000 --> 0:02:45,000
to try to ban all sexting to try to address privacy violations.

44
0:02:46.38,000 --> 0:02:47,000
This is kind of like saying,

45
0:02:47.9,000 --> 0:02:52,000
let's solve the problem of date rape by just making dating completely illegal.

46
0:02:54.94,000 --> 0:02:59,000
Most teens don't get arrested for sexting, but can you guess who does?

47
0:03:00.34,000 --> 0:03:04,000
It's often teens who are disliked by their partner's parents.

48
0:03:05.34,000 --> 0:03:09,000
And this can be because of class bias, racism or homophobia.

49
0:03:10.78,000 --> 0:03:12,000
Most prosecutors are, of course, smart enough

50
0:03:13.58,000 --> 0:03:18,000
not to use child pornography charges against teenagers, but some do.

51
0:03:19.54,000 --> 0:03:22,000
According to researchers at the University of New Hampshire

52
0:03:23.22,000 --> 0:03:28,000
seven percent of all child pornography possession arrests are teens,

53
0:03:28.9,000 --> 0:03:31,000
sexting consensually with other teens.

54
0:03:33.3,000 --> 0:03:35,000
Child pornography is a serious crime,

55
0:03:35.86,000 --> 0:03:38,000
but it's just not the same thing as teen sexting.

56
0:03:40.86,000 --> 0:03:43,000
Parents and educators are also responding to sexting

57
0:03:44.3,000 --> 0:03:47,000
without really thinking too much about consent.

58
0:03:47.46,000 --> 0:03:51,000
Their message to teens is often: just don't do it.

59
0:03:52.02,000 --> 0:03:55,000
And I totally get it -- there are serious legal risks

60
0:03:55.54,000 --> 0:03:58,000
and of course, that potential for privacy violations.

61
0:03:59.22,000 --> 0:04:,000
And when you were a teen,

62
0:04:00.5,000 --> 0:04:03,000
I'm sure you did exactly as you were told, right?

63
0:04:05.26,000 --> 0:04:08,000
You're probably thinking, my kid would never sext.

64
0:04:08.74,000 --> 0:04:11,000
And that's true, your little angel may not be sexting

65
0:04:12.22,000 --> 0:04:15,000
because only 33 percent

66
0:04:15.38,000 --> 0:04:17,000
of 16- and 17-year-olds are sexting.

67
0:04:19.02,000 --> 0:04:23,000
But, sorry, by the time they're older, odds are they will be sexting.

68
0:04:23.66,000 --> 0:04:29,000
Every study I've seen puts the rate above 50 percent for 18- to 24-year-olds.

69
0:04:30.54,000 --> 0:04:33,000
And most of the time, nothing goes wrong.

70
0:04:33.62,000 --> 0:04:38,000
People ask me all the time things like, isn't sexting just so dangerous, though?

71
0:04:39.02,000 --> 0:04:42,000
It's like you wouldn't leave your wallet on a park bench

72
0:04:42.62,000 --> 0:04:45,000
and you expect it's going to get stolen if you do that, right?

73
0:04:46.7,000 --> 0:04:47,000
Here's how I think about it:

74
0:04:48.18,000 --> 0:04:51,000
sexting is like leaving your wallet at your boyfriend's house.

75
0:04:52.14,000 --> 0:04:53,000
If you come back the next day

76
0:04:53.94,000 --> 0:04:55,000
and all the money is just gone,

77
0:04:56.86,000 --> 0:04:58,000
you really need to dump that guy.

78
0:04:59.51,000 --> 0:05:01,000
(Laughter)

79
0:05:03.18,000 --> 0:05:05,000
So instead of criminalizing sexting

80
0:05:05.54,000 --> 0:05:07,000
to try to prevent these privacy violations,

81
0:05:08.18,000 --> 0:05:11,000
instead we need to make consent central

82
0:05:11.5,000 --> 0:05:15,000
to how we think about the circulation of our private information.

83
0:05:16.3,000 --> 0:05:2,000
Every new media technology raises privacy concerns.

84
0:05:20.58,000 --> 0:05:24,000
In fact, in the US the very first major debates about privacy

85
0:05:25.22,000 --> 0:05:29,000
were in response to technologies that were relatively new at the time.

86
0:05:29.74,000 --> 0:05:32,000
In the late 1800s, people were worried about cameras,

87
0:05:33.66,000 --> 0:05:36,000
which were just suddenly more portable than ever before,

88
0:05:37.14,000 --> 0:05:39,000
and newspaper gossip columns.

89
0:05:39.66,000 --> 0:05:42,000
They were worried that the camera would capture information about them,

90
0:05:43.5,000 --> 0:05:46,000
take it out of context and widely disseminate it.

91
0:05:47.06,000 --> 0:05:48,000
Does this sound familiar?

92
0:05:48.7,000 --> 0:05:52,000
It's exactly what we're worrying about now with social media and drone cameras,

93
0:05:53.58,000 --> 0:05:54,000
and, of course, sexting.

94
0:05:55.74,000 --> 0:05:57,000
And these fears about technology,

95
0:05:57.98,000 --> 0:05:58,000
they make sense

96
0:05:59.22,000 --> 0:06:02,000
because technologies can amplify and bring out

97
0:06:02.66,000 --> 0:06:04,000
our worst qualities and behaviors.

98
0:06:05.98,000 --> 0:06:07,000
But there are solutions.

99
0:06:08.38,000 --> 0:06:11,000
And we've been here before with a dangerous new technology.

100
0:06:12.54,000 --> 0:06:15,000
In 1908, Ford introduced the Model T car.

101
0:06:16.34,000 --> 0:06:18,000
Traffic fatality rates were rising.

102
0:06:18.94,000 --> 0:06:2,000
It was a serious problem -- it looks so safe, right?

103
0:06:23.9,000 --> 0:06:26,000
Our first response was to try to change drivers' behavior,

104
0:06:27.9,000 --> 0:06:3,000
so we developed speed limits and enforced them through fines.

105
0:06:32.06,000 --> 0:06:33,000
But over the following decades,

106
0:06:33.94,000 --> 0:06:38,000
we started to realize the technology of the car itself is not just neutral.

107
0:06:39.46,000 --> 0:06:42,000
We could design the car to make it safer.

108
0:06:42.7,000 --> 0:06:45,000
So in the 1920s, we got shatter-resistant windshields.

109
0:06:46.18,000 --> 0:06:48,000
In the 1950s, seat belts.

110
0:06:48.7,000 --> 0:06:51,000
And in the 1990s, airbags.

111
0:06:52.26,000 --> 0:06:54,000
All three of these areas:

112
0:06:54.66,000 --> 0:06:58,000
laws, individuals and industry came together over time

113
0:06:59.46,000 --> 0:07:02,000
to help solve the problem that a new technology causes.

114
0:07:03.26,000 --> 0:07:06,000
And we can do the same thing with digital privacy.

115
0:07:06.98,000 --> 0:07:08,000
Of course, it comes back to consent.

116
0:07:10.18,000 --> 0:07:11,000
Here's the idea.

117
0:07:11.42,000 --> 0:07:14,000
Before anyone can distribute your private information,

118
0:07:15.26,000 --> 0:07:17,000
they should have to get your permission.

119
0:07:18.06,000 --> 0:07:22,000
This idea of affirmative consent comes from anti-rape activists

120
0:07:22.9,000 --> 0:07:25,000
who tell us that we need consent for every sexual act.

121
0:07:26.7,000 --> 0:07:3,000
And we have really high standards for consent in a lot of other areas.

122
0:07:31.3,000 --> 0:07:32,000
Think about having surgery.

123
0:07:33.18,000 --> 0:07:34,000
Your doctor has to make sure

124
0:07:34.82,000 --> 0:07:38,000
that you are meaningfully and knowingly consenting to that medical procedure.

125
0:07:39.34,000 --> 0:07:42,000
This is not the type of consent like with an iTunes Terms of Service

126
0:07:43.06,000 --> 0:07:46,000
where you just scroll to the bottom and you're like, agree, agree, whatever.

127
0:07:46.74,000 --> 0:07:47,000
(Laughter)

128
0:07:48.98,000 --> 0:07:53,000
If we think more about consent, we can have better privacy laws.

129
0:07:54.26,000 --> 0:07:57,000
Right now, we just don't have that many protections.

130
0:07:57.7,000 --> 0:08:,000
If your ex-husband or your ex-wife is a terrible person,

131
0:08:01.3,000 --> 0:08:05,000
they can take your nude photos and upload them to a porn site.

132
0:08:05.54,000 --> 0:08:08,000
It can be really hard to get those images taken down.

133
0:08:08.78,000 --> 0:08:09,000
And in a lot of states,

134
0:08:10.02,000 --> 0:08:13,000
you're actually better off if you took the images of yourself

135
0:08:13.86,000 --> 0:08:15,000
because then you can file a copyright claim.

136
0:08:17.14,000 --> 0:08:19,000
(Laughter)

137
0:08:19.22,000 --> 0:08:21,000
Right now, if someone violates your privacy,

138
0:08:22.22,000 --> 0:08:26,000
whether that's an individual or a company or the NSA,

139
0:08:27.1,000 --> 0:08:29,000
you can try filing a lawsuit,

140
0:08:29.86,000 --> 0:08:31,000
though you may not be successful

141
0:08:32.02,000 --> 0:08:36,000
because many courts assume that digital privacy is just impossible.

142
0:08:36.82,000 --> 0:08:39,000
So they're not willing to punish anyone for violating it.

143
0:08:41.02,000 --> 0:08:43,000
I still hear people asking me all the time,

144
0:08:43.94,000 --> 0:08:48,000
isn't a digital image somehow blurring the line between public and private

145
0:08:49.26,000 --> 0:08:5,000
because it's digital, right?

146
0:08:51.42,000 --> 0:08:52,000
No! No!

147
0:08:52.78,000 --> 0:08:55,000
Everything digital is not just automatically public.

148
0:08:56.14,000 --> 0:08:57,000
That doesn't make any sense.

149
0:08:58.06,000 --> 0:09:01,000
As NYU legal scholar Helen Nissenbaum tells us,

150
0:09:01.58,000 --> 0:09:03,000
we have laws and policies and norms

151
0:09:04.22,000 --> 0:09:07,000
that protect all kinds of information that's private,

152
0:09:07.38,000 --> 0:09:1,000
and it doesn't make a difference if it's digital or not.

153
0:09:10.82,000 --> 0:09:12,000
All of your health records are digitized

154
0:09:13.5,000 --> 0:09:16,000
but your doctor can't just share them with anyone.

155
0:09:16.66,000 --> 0:09:2,000
All of your financial information is held in digital databases,

156
0:09:21.14,000 --> 0:09:25,000
but your credit card company can't just post your purchase history online.

157
0:09:26.9,000 --> 0:09:31,000
Better laws could help address privacy violations after they happen,

158
0:09:32.38,000 --> 0:09:36,000
but one of the easiest things we can all do is make personal changes

159
0:09:36.78,000 --> 0:09:38,000
to help protect each other's privacy.

160
0:09:40.18,000 --> 0:09:41,000
We're always told that privacy

161
0:09:42.1,000 --> 0:09:45,000
is our own, sole, individual responsibility.

162
0:09:45.18,000 --> 0:09:49,000
We're told, constantly monitor and update your privacy settings.

163
0:09:49.46,000 --> 0:09:53,000
We're told, never share anything you wouldn't want the entire world to see.

164
0:09:55.22,000 --> 0:09:56,000
This doesn't make sense.

165
0:09:56.46,000 --> 0:09:58,000
Digital media are social environments

166
0:09:59.46,000 --> 0:10:03,000
and we share things with people we trust all day, every day.

167
0:10:04.58,000 --> 0:10:06,000
As Princeton researcher Janet Vertesi argues,

168
0:10:07.58,000 --> 0:10:11,000
our data and our privacy, they're not just personal,

169
0:10:11.62,000 --> 0:10:13,000
they're actually interpersonal.

170
0:10:14.22,000 --> 0:10:17,000
And so one thing you can do that's really easy

171
0:10:17.5,000 --> 0:10:22,000
is just start asking for permission before you share anyone else's information.

172
0:10:22.62,000 --> 0:10:26,000
If you want to post a photo of someone online, ask for permission.

173
0:10:27.18,000 --> 0:10:29,000
If you want to forward an email thread,

174
0:10:29.66,000 --> 0:10:3,000
ask for permission.

175
0:10:31.06,000 --> 0:10:33,000
And if you want to share someone's nude selfie,

176
0:10:33.86,000 --> 0:10:35,000
obviously, ask for permission.

177
0:10:37.38,000 --> 0:10:41,000
These individual changes can really help us protect each other's privacy,

178
0:10:41.86,000 --> 0:10:44,000
but we need technology companies on board as well.

179
0:10:46.18,000 --> 0:10:5,000
These companies have very little incentive to help protect our privacy

180
0:10:50.7,000 --> 0:10:53,000
because their business models depend on us sharing everything

181
0:10:54.02,000 --> 0:10:56,000
with as many people as possible.

182
0:10:56.9,000 --> 0:10:57,000
Right now, if I send you an image,

183
0:10:58.86,000 --> 0:11:01,000
you can forward that to anyone that you want.

184
0:11:01.98,000 --> 0:11:05,000
But what if I got to decide if that image was forwardable or not?

185
0:11:06.26,000 --> 0:11:1,000
This would tell you, you don't have my permission to send this image out.

186
0:11:10.34,000 --> 0:11:14,000
We do this kind of thing all the time to protect copyright.

187
0:11:14.5,000 --> 0:11:18,000
If you buy an e-book, you can't just send it out to as many people as you want.

188
0:11:19.3,000 --> 0:11:21,000
So why not try this with mobile phones?

189
0:11:22.78,000 --> 0:11:26,000
What you can do is we can demand that tech companies add these protections

190
0:11:27.58,000 --> 0:11:3,000
to our devices and our platforms as the default.

191
0:11:31.34,000 --> 0:11:34,000
After all, you can choose the color of your car,

192
0:11:34.78,000 --> 0:11:36,000
but the airbags are always standard.

193
0:11:39.9,000 --> 0:11:42,000
If we don't think more about digital privacy and consent,

194
0:11:43.74,000 --> 0:11:45,000
there can be serious consequences.

195
0:11:47.18,000 --> 0:11:49,000
There was a teenager from Ohio --

196
0:11:49.46,000 --> 0:11:51,000
let's call her Jennifer, for the sake of her privacy.

197
0:11:52.94,000 --> 0:11:55,000
She shared nude photos of herself with her high school boyfriend,

198
0:11:56.54,000 --> 0:11:57,000
thinking she could trust him.

199
0:11:59.54,000 --> 0:12:,000
Unfortunately, he betrayed her

200
0:12:01.5,000 --> 0:12:03,000
and sent her photos around the entire school.

201
0:12:04.5,000 --> 0:12:07,000
Jennifer was embarrassed and humiliated,

202
0:12:08.62,000 --> 0:12:12,000
but instead of being compassionate, her classmates harassed her.

203
0:12:12.78,000 --> 0:12:13,000
They called her a slut and a whore

204
0:12:14.66,000 --> 0:12:15,000
and they made her life miserable.

205
0:12:17.18,000 --> 0:12:2,000
Jennifer started missing school and her grades dropped.

206
0:12:21.34,000 --> 0:12:24,000
Ultimately, Jennifer decided to end her own life.

207
0:12:26.54,000 --> 0:12:28,000
Jennifer did nothing wrong.

208
0:12:29.26,000 --> 0:12:31,000
All she did was share a nude photo

209
0:12:31.54,000 --> 0:12:33,000
with someone she thought that she could trust.

210
0:12:34.38,000 --> 0:12:36,000
And yet our laws tell her

211
0:12:37.02,000 --> 0:12:41,000
that she committed a horrible crime equivalent to child pornography.

212
0:12:41.74,000 --> 0:12:42,000
Our gender norms tell her

213
0:12:43.26,000 --> 0:12:46,000
that by producing this nude image of herself,

214
0:12:46.5,000 --> 0:12:49,000
she somehow did the most horrible, shameful thing.

215
0:12:50.22,000 --> 0:12:54,000
And when we assume that privacy is impossible in digital media,

216
0:12:54.46,000 --> 0:12:59,000
we completely write off and excuse her boyfriend's bad, bad behavior.

217
0:13:01.02,000 --> 0:13:06,000
People are still saying all the time to victims of privacy violations,

218
0:13:06.78,000 --> 0:13:07,000
"What were you thinking?

219
0:13:08.06,000 --> 0:13:1,000
You should have never sent that image."

220
0:13:11.46,000 --> 0:13:15,000
If you're trying to figure out what to say instead, try this.

221
0:13:15.98,000 --> 0:13:18,000
Imagine you've run into your friend who broke their leg skiing.

222
0:13:20.06,000 --> 0:13:24,000
They took a risk to do something fun, and it didn't end well.

223
0:13:24.66,000 --> 0:13:26,000
But you're probably not going to be the jerk who says,

224
0:13:27.22,000 --> 0:13:29,000
"Well, I guess you shouldn't have gone skiing then."

225
0:13:31.9,000 --> 0:13:33,000
If we think more about consent,

226
0:13:34.06,000 --> 0:13:37,000
we can see that victims of privacy violations

227
0:13:37.34,000 --> 0:13:38,000
deserve our compassion,

228
0:13:39.1,000 --> 0:13:43,000
not criminalization, shaming, harassment or punishment.

229
0:13:44.26,000 --> 0:13:48,000
We can support victims, and we can prevent some privacy violations

230
0:13:48.78,000 --> 0:13:52,000
by making these legal, individual and technological changes.

231
0:13:53.66,000 --> 0:13:58,000
Because the problem is not sexting, the issue is digital privacy.

232
0:13:59.5,000 --> 0:14:01,000
And one solution is consent.

233
0:14:02.5,000 --> 0:14:06,000
So the next time a victim of a privacy violation comes up to you,

234
0:14:07.1,000 --> 0:14:09,000
instead of blaming them, let's do this instead:

235
0:14:09.86,000 --> 0:14:12,000
let's shift our ideas about digital privacy,

236
0:14:13.3,000 --> 0:14:15,000
and let's respond with compassion.

237
0:14:16.5,000 --> 0:14:17,000
Thank you.

238
0:14:17.74,000 --> 0:14:23,000
(Applause)

