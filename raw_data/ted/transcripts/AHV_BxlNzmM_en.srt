1
0:00:13.096,000 --> 0:00:17,000
In the months following the 2009 presidential election in Iran,

2
0:00:17.834,000 --> 0:00:19,000
protests erupted across the country.

3
0:00:21.685,000 --> 0:00:23,000
The Iranian government violently suppressed

4
0:00:24.605,000 --> 0:00:27,000
what came to be known as the Iranian Green Movement,

5
0:00:28.608,000 --> 0:00:3,000
even blocking mobile signals

6
0:00:30.685,000 --> 0:00:32,000
to cut off communication between the protesters.

7
0:00:34.316,000 --> 0:00:38,000
My parents, who emigrated to the United States in the late 1960s,

8
0:00:39.009,000 --> 0:00:4,000
spend substantial time there,

9
0:00:40.827,000 --> 0:00:43,000
where all of my large, extended family live.

10
0:00:44.832,000 --> 0:00:47,000
When I would call my family in Tehran

11
0:00:47.985,000 --> 0:00:5,000
during some of the most violent crackdowns of the protest,

12
0:00:51.461,000 --> 0:00:54,000
none of them dared discuss with me what was happening.

13
0:00:55.196,000 --> 0:00:58,000
They or I knew to quickly steer the conversation to other topics.

14
0:00:59.163,000 --> 0:01:02,000
All of us understood what the consequences could be

15
0:01:02.567,000 --> 0:01:04,000
of a perceived dissident action.

16
0:01:06.095,000 --> 0:01:09,000
But I still wish I could have known what they were thinking

17
0:01:09.588,000 --> 0:01:1,000
or what they were feeling.

18
0:01:12.217,000 --> 0:01:13,000
What if I could have?

19
0:01:14.149,000 --> 0:01:15,000
Or more frighteningly,

20
0:01:15.324,000 --> 0:01:17,000
what if the Iranian government could have?

21
0:01:18.695,000 --> 0:01:21,000
Would they have arrested them based on what their brains revealed?

22
0:01:22.933,000 --> 0:01:24,000
That day may be closer than you think.

23
0:01:26.527,000 --> 0:01:29,000
With our growing capabilities in neuroscience, artificial intelligence

24
0:01:30.362,000 --> 0:01:31,000
and machine learning,

25
0:01:32.089,000 --> 0:01:36,000
we may soon know a lot more of what's happening in the human brain.

26
0:01:37.083,000 --> 0:01:4,000
As a bioethicist, a lawyer, a philosopher

27
0:01:40.417,000 --> 0:01:41,000
and an Iranian-American,

28
0:01:42.308,000 --> 0:01:45,000
I'm deeply concerned about what this means for our freedoms

29
0:01:46.119,000 --> 0:01:48,000
and what kinds of protections we need.

30
0:01:48.993,000 --> 0:01:51,000
I believe we need a right to cognitive liberty,

31
0:01:52.477,000 --> 0:01:54,000
as a human right that needs to be protected.

32
0:01:55.772,000 --> 0:01:57,000
If not, our freedom of thought,

33
0:01:58.439,000 --> 0:02:01,000
access and control over our own brains

34
0:02:01.487,000 --> 0:02:03,000
and our mental privacy will be threatened.

35
0:02:05.698,000 --> 0:02:06,000
Consider this:

36
0:02:06.88,000 --> 0:02:09,000
the average person thinks thousands of thoughts each day.

37
0:02:10.697,000 --> 0:02:11,000
As a thought takes form,

38
0:02:11.872,000 --> 0:02:16,000
like a math calculation or a number, a word,

39
0:02:16.952,000 --> 0:02:18,000
neurons are interacting in the brain,

40
0:02:19.861,000 --> 0:02:22,000
creating a miniscule electrical discharge.

41
0:02:23.713,000 --> 0:02:26,000
When you have a dominant mental state, like relaxation,

42
0:02:27.189,000 --> 0:02:31,000
hundreds and thousands of neurons are firing in the brain,

43
0:02:31.388,000 --> 0:02:35,000
creating concurrent electrical discharges in characteristic patterns

44
0:02:35.63,000 --> 0:02:39,000
that can be measured with electroencephalography, or EEG.

45
0:02:41.118,000 --> 0:02:43,000
In fact, that's what you're seeing right now.

46
0:02:43.956,000 --> 0:02:46,000
You're seeing my brain activity that was recorded in real time

47
0:02:47.944,000 --> 0:02:49,000
with a simple device that was worn on my head.

48
0:02:51.669,000 --> 0:02:56,000
What you're seeing is my brain activity when I was relaxed and curious.

49
0:02:58.097,000 --> 0:02:59,000
To share this information with you,

50
0:02:59.876,000 --> 0:03:02,000
I wore one of the early consumer-based EEG devices

51
0:03:02.92,000 --> 0:03:03,000
like this one,

52
0:03:04.155,000 --> 0:03:07,000
which recorded the electrical activity in my brain in real time.

53
0:03:08.849,000 --> 0:03:11,000
It's not unlike the fitness trackers that some of you may be wearing

54
0:03:12.699,000 --> 0:03:15,000
to measure your heart rate or the steps that you've taken,

55
0:03:16.309,000 --> 0:03:17,000
or even your sleep activity.

56
0:03:19.154,000 --> 0:03:22,000
It's hardly the most sophisticated neuroimaging technique on the market.

57
0:03:23.597,000 --> 0:03:25,000
But it's already the most portable

58
0:03:25.999,000 --> 0:03:28,000
and the most likely to impact our everyday lives.

59
0:03:29.915,000 --> 0:03:3,000
This is extraordinary.

60
0:03:31.442,000 --> 0:03:33,000
Through a simple, wearable device,

61
0:03:33.971,000 --> 0:03:36,000
we can literally see inside the human brain

62
0:03:37.543,000 --> 0:03:43,000
and learn aspects of our mental landscape without ever uttering a word.

63
0:03:44.829,000 --> 0:03:47,000
While we can't reliably decode complex thoughts just yet,

64
0:03:48.506,000 --> 0:03:5,000
we can already gauge a person's mood,

65
0:03:51.049,000 --> 0:03:53,000
and with the help of artificial intelligence,

66
0:03:53.946,000 --> 0:03:57,000
we can even decode some single-digit numbers

67
0:03:58.311,000 --> 0:04:02,000
or shapes or simple words that a person is thinking

68
0:04:03.217,000 --> 0:04:05,000
or hearing, or seeing.

69
0:04:06.345,000 --> 0:04:09,000
Despite some inherent limitations in EEG,

70
0:04:09.734,000 --> 0:04:13,000
I think it's safe to say that with our advances in technology,

71
0:04:14.478,000 --> 0:04:17,000
more and more of what's happening in the human brain

72
0:04:18.311,000 --> 0:04:2,000
can and will be decoded over time.

73
0:04:21.362,000 --> 0:04:23,000
Already, using one of these devices,

74
0:04:24.132,000 --> 0:04:27,000
an epileptic can know they're going to have an epileptic seizure

75
0:04:27.411,000 --> 0:04:28,000
before it happens.

76
0:04:28.871,000 --> 0:04:32,000
A paraplegic can type on a computer with their thoughts alone.

77
0:04:34.485,000 --> 0:04:38,000
A US-based company has developed a technology to embed these sensors

78
0:04:38.692,000 --> 0:04:4,000
into the headrest of automobilies

79
0:04:40.946,000 --> 0:04:42,000
so they can track driver concentration,

80
0:04:43.475,000 --> 0:04:45,000
distraction and cognitive load while driving.

81
0:04:46.912,000 --> 0:04:5,000
Nissan, insurance companies and AAA have all taken note.

82
0:04:51.949,000 --> 0:04:55,000
You could even watch this choose-your-own-adventure movie

83
0:04:56.481,000 --> 0:05:,000
"The Moment," which, with an EEG headset,

84
0:05:00.745,000 --> 0:05:03,000
changes the movie based on your brain-based reactions,

85
0:05:04.695,000 --> 0:05:08,000
giving you a different ending every time your attention wanes.

86
0:05:11.154,000 --> 0:05:13,000
This may all sound great,

87
0:05:13.941,000 --> 0:05:15,000
and as a bioethicist,

88
0:05:16.154,000 --> 0:05:19,000
I am a huge proponent of empowering people

89
0:05:19.791,000 --> 0:05:21,000
to take charge of their own health and well-being

90
0:05:22.431,000 --> 0:05:24,000
by giving them access to information about themselves,

91
0:05:25.373,000 --> 0:05:27,000
including this incredible new brain-decoding technology.

92
0:05:29.878,000 --> 0:05:3,000
But I worry.

93
0:05:31.736,000 --> 0:05:35,000
I worry that we will voluntarily or involuntarily give up

94
0:05:36.52,000 --> 0:05:4,000
our last bastion of freedom, our mental privacy.

95
0:05:41.302,000 --> 0:05:43,000
That we will trade our brain activity

96
0:05:44.251,000 --> 0:05:47,000
for rebates or discounts on insurance,

97
0:05:48.391,000 --> 0:05:5,000
or free access to social-media accounts ...

98
0:05:52.444,000 --> 0:05:53,000
or even to keep our jobs.

99
0:05:54.9,000 --> 0:05:55,000
In fact, in China,

100
0:05:58.199,000 --> 0:06:03,000
the train drivers on the Beijing-Shanghai high-speed rail,

101
0:06:04.12,000 --> 0:06:06,000
the busiest of its kind in the world,

102
0:06:06.676,000 --> 0:06:08,000
are required to wear EEG devices

103
0:06:09.176,000 --> 0:06:11,000
to monitor their brain activity while driving.

104
0:06:12.157,000 --> 0:06:14,000
According to some news sources,

105
0:06:14.407,000 --> 0:06:16,000
in government-run factories in China,

106
0:06:17.11,000 --> 0:06:22,000
the workers are required to wear EEG sensors to monitor their productivity

107
0:06:22.498,000 --> 0:06:24,000
and their emotional state at work.

108
0:06:25.267,000 --> 0:06:27,000
Workers are even sent home

109
0:06:27.601,000 --> 0:06:31,000
if their brains show less-than-stellar concentration on their jobs,

110
0:06:31.679,000 --> 0:06:33,000
or emotional agitation.

111
0:06:35.189,000 --> 0:06:36,000
It's not going to happen tomorrow,

112
0:06:36.958,000 --> 0:06:39,000
but we're headed to a world of brain transparency.

113
0:06:40.537,000 --> 0:06:43,000
And I don't think people understand that that could change everything.

114
0:06:44.474,000 --> 0:06:47,000
Everything from our definitions of data privacy to our laws,

115
0:06:48.173,000 --> 0:06:49,000
to our ideas about freedom.

116
0:06:50.731,000 --> 0:06:53,000
In fact, in my lab at Duke University,

117
0:06:53.832,000 --> 0:06:56,000
we recently conducted a nationwide study in the United States

118
0:06:57.031,000 --> 0:06:58,000
to see if people appreciated

119
0:06:59.014,000 --> 0:07:01,000
the sensitivity of their brain information.

120
0:07:02.356,000 --> 0:07:05,000
We asked people to rate their perceived sensitivity

121
0:07:05.736,000 --> 0:07:07,000
of 33 different kinds of information,

122
0:07:07.991,000 --> 0:07:09,000
from their social security numbers

123
0:07:10.235,000 --> 0:07:12,000
to the content of their phone conversations,

124
0:07:12.856,000 --> 0:07:14,000
their relationship history,

125
0:07:15.073,000 --> 0:07:16,000
their emotions, their anxiety,

126
0:07:17.039,000 --> 0:07:18,000
the mental images in their mind

127
0:07:19.009,000 --> 0:07:2,000
and the thoughts in their mind.

128
0:07:21.481,000 --> 0:07:26,000
Shockingly, people rated their social security number as far more sensitive

129
0:07:26.734,000 --> 0:07:28,000
than any other kind of information,

130
0:07:28.961,000 --> 0:07:3,000
including their brain data.

131
0:07:32.38,000 --> 0:07:35,000
I think this is because people don't yet understand

132
0:07:35.62,000 --> 0:07:39,000
or believe the implications of this new brain-decoding technology.

133
0:07:40.629,000 --> 0:07:43,000
After all, if we can know the inner workings of the human brain,

134
0:07:43.942,000 --> 0:07:45,000
our social security numbers are the least of our worries.

135
0:07:46.672,000 --> 0:07:47,000
(Laughter)

136
0:07:47.981,000 --> 0:07:48,000
Think about it.

137
0:07:49.172,000 --> 0:07:51,000
In a world of total brain transparency,

138
0:07:51.592,000 --> 0:07:53,000
who would dare have a politically dissident thought?

139
0:07:55.279,000 --> 0:07:56,000
Or a creative one?

140
0:07:57.503,000 --> 0:08:,000
I worry that people will self-censor

141
0:08:01.003,000 --> 0:08:04,000
in fear of being ostracized by society,

142
0:08:04.329,000 --> 0:08:07,000
or that people will lose their jobs because of their waning attention

143
0:08:08.166,000 --> 0:08:1,000
or emotional instability,

144
0:08:10.34,000 --> 0:08:13,000
or because they're contemplating collective action against their employers.

145
0:08:14.478,000 --> 0:08:17,000
That coming out will no longer be an option,

146
0:08:17.679,000 --> 0:08:22,000
because people's brains will long ago have revealed their sexual orientation,

147
0:08:22.77,000 --> 0:08:23,000
their political ideology

148
0:08:24.616,000 --> 0:08:26,000
or their religious preferences,

149
0:08:26.665,000 --> 0:08:29,000
well before they were ready to consciously share that information

150
0:08:29.769,000 --> 0:08:3,000
with other people.

151
0:08:31.565,000 --> 0:08:35,000
I worry about the ability of our laws to keep up with technological change.

152
0:08:36.986,000 --> 0:08:38,000
Take the First Amendment of the US Constitution,

153
0:08:39.33,000 --> 0:08:4,000
which protects freedom of speech.

154
0:08:41.312,000 --> 0:08:42,000
Does it also protect freedom of thought?

155
0:08:43.944,000 --> 0:08:47,000
And if so, does that mean that we're free to alter our thoughts however we want?

156
0:08:48.137,000 --> 0:08:52,000
Or can the government or society tell us what we can do with our own brains?

157
0:08:53.591,000 --> 0:08:56,000
Can the NSA spy on our brains using these new mobile devices?

158
0:08:58.053,000 --> 0:09:02,000
Can the companies that collect the brain data through their applications

159
0:09:02.196,000 --> 0:09:04,000
sell this information to third parties?

160
0:09:05.174,000 --> 0:09:08,000
Right now, no laws prevent them from doing so.

161
0:09:09.203,000 --> 0:09:11,000
It could be even more problematic

162
0:09:11.252,000 --> 0:09:13,000
in countries that don't share the same freedoms

163
0:09:13.795,000 --> 0:09:15,000
enjoyed by people in the United States.

164
0:09:16.883,000 --> 0:09:19,000
What would've happened during the Iranian Green Movement

165
0:09:20.694,000 --> 0:09:23,000
if the government had been monitoring my family's brain activity,

166
0:09:24.619,000 --> 0:09:28,000
and had believed them to be sympathetic to the protesters?

167
0:09:30.091,000 --> 0:09:33,000
Is it so far-fetched to imagine a society

168
0:09:33.162,000 --> 0:09:35,000
in which people are arrested based on their thoughts

169
0:09:36.028,000 --> 0:09:37,000
of committing a crime,

170
0:09:37.219,000 --> 0:09:41,000
like in the science-fiction dystopian society in "Minority Report."

171
0:09:42.286,000 --> 0:09:46,000
Already, in the United States, in Indiana,

172
0:09:46.633,000 --> 0:09:5,000
an 18-year-old was charged with attempting to intimidate his school

173
0:09:51.594,000 --> 0:09:54,000
by posting a video of himself shooting people in the hallways ...

174
0:09:55.881,000 --> 0:09:58,000
Except the people were zombies

175
0:09:58.912,000 --> 0:10:03,000
and the video was of him playing an augmented-reality video game,

176
0:10:03.983,000 --> 0:10:07,000
all interpreted to be a mental projection of his subjective intent.

177
0:10:10.456,000 --> 0:10:14,000
This is exactly why our brains need special protection.

178
0:10:15.092,000 --> 0:10:18,000
If our brains are just as subject to data tracking and aggregation

179
0:10:18.672,000 --> 0:10:2,000
as our financial records and transactions,

180
0:10:21.228,000 --> 0:10:25,000
if our brains can be hacked and tracked like our online activities,

181
0:10:25.537,000 --> 0:10:27,000
our mobile phones and applications,

182
0:10:27.922,000 --> 0:10:31,000
then we're on the brink of a dangerous threat to our collective humanity.

183
0:10:33.406,000 --> 0:10:34,000
Before you panic,

184
0:10:36.012,000 --> 0:10:39,000
I believe that there are solutions to these concerns,

185
0:10:39.18,000 --> 0:10:41,000
but we have to start by focusing on the right things.

186
0:10:42.58,000 --> 0:10:44,000
When it comes to privacy protections in general,

187
0:10:45.525,000 --> 0:10:46,000
I think we're fighting a losing battle

188
0:10:47.375,000 --> 0:10:49,000
by trying to restrict the flow of information.

189
0:10:50.257,000 --> 0:10:54,000
Instead, we should be focusing on securing rights and remedies

190
0:10:54.338,000 --> 0:10:56,000
against the misuse of our information.

191
0:10:57.291,000 --> 0:11:,000
If people had the right to decide how their information was shared,

192
0:11:00.6,000 --> 0:11:02,000
and more importantly, have legal redress

193
0:11:03.545,000 --> 0:11:05,000
if their information was misused against them,

194
0:11:05.997,000 --> 0:11:07,000
say to discriminate against them in an employment setting

195
0:11:08.807,000 --> 0:11:1,000
or in health care or education,

196
0:11:11.616,000 --> 0:11:13,000
this would go a long way to build trust.

197
0:11:14.843,000 --> 0:11:15,000
In fact, in some instances,

198
0:11:16.585,000 --> 0:11:19,000
we want to be sharing more of our personal information.

199
0:11:20.697,000 --> 0:11:23,000
Studying aggregated information can tell us so much

200
0:11:23.768,000 --> 0:11:25,000
about our health and our well-being,

201
0:11:26.539,000 --> 0:11:29,000
but to be able to safely share our information,

202
0:11:29.876,000 --> 0:11:32,000
we need special protections for mental privacy.

203
0:11:33.832,000 --> 0:11:36,000
This is why we need a right to cognitive liberty.

204
0:11:37.543,000 --> 0:11:41,000
This right would secure for us our freedom of thought and rumination,

205
0:11:41.646,000 --> 0:11:43,000
our freedom of self-determination,

206
0:11:44.21,000 --> 0:11:48,000
and it would insure that we have the right to consent to or refuse

207
0:11:48.624,000 --> 0:11:5,000
access and alteration of our brains by others.

208
0:11:51.811,000 --> 0:11:53,000
This right could be recognized

209
0:11:53.947,000 --> 0:11:55,000
as part of the Universal Declaration of Human Rights,

210
0:11:56.854,000 --> 0:11:58,000
which has established mechanisms

211
0:11:59.266,000 --> 0:12:01,000
for the enforcement of these kinds of social rights.

212
0:12:03.872,000 --> 0:12:05,000
During the Iranian Green Movement,

213
0:12:05.966,000 --> 0:12:1,000
the protesters used the internet and good old-fashioned word of mouth

214
0:12:11.176,000 --> 0:12:12,000
to coordinate their marches.

215
0:12:14.238,000 --> 0:12:16,000
And some of the most oppressive restrictions in Iran

216
0:12:17.031,000 --> 0:12:18,000
were lifted as a result.

217
0:12:20.047,000 --> 0:12:24,000
But what if the Iranian government had used brain surveillance

218
0:12:24.158,000 --> 0:12:27,000
to detect and prevent the protest?

219
0:12:28.847,000 --> 0:12:31,000
Would the world have ever heard the protesters' cries?

220
0:12:33.732,000 --> 0:12:38,000
The time has come for us to call for a cognitive liberty revolution.

221
0:12:39.559,000 --> 0:12:42,000
To make sure that we responsibly advance technology

222
0:12:42.847,000 --> 0:12:44,000
that could enable us to embrace the future

223
0:12:45.849,000 --> 0:12:51,000
while fiercely protecting all of us from any person, company or government

224
0:12:52.59,000 --> 0:12:57,000
that attempts to unlawfully access or alter our innermost lives.

225
0:12:58.659,000 --> 0:12:59,000
Thank you.

226
0:12:59.857,000 --> 0:13:02,000
(Applause)

