1
0:00:,000 --> 0:00:07,000
Translator: Joseph Geni Reviewer: Joanna Pietrulewicz

2
0:00:12.76,000 --> 0:00:13,000
So earlier this year,

3
0:00:14.4,000 --> 0:00:17,000
I was informed that I would be doing a TED Talk.

4
0:00:18.24,000 --> 0:00:19,000
So I was excited, then I panicked,

5
0:00:20.24,000 --> 0:00:22,000
then I was excited, then I panicked,

6
0:00:22.28,000 --> 0:00:24,000
and in between the excitement and the panicking,

7
0:00:24.84,000 --> 0:00:26,000
I started to do my research,

8
0:00:27.16,000 --> 0:00:31,000
and my research primarily consisted of Googling how to give a great TED Talk.

9
0:00:31.64,000 --> 0:00:32,000
(Laughter)

10
0:00:32.88,000 --> 0:00:33,000
And interspersed with that,

11
0:00:34.56,000 --> 0:00:36,000
I was Googling Chimamanda Ngozi Adichie.

12
0:00:37.28,000 --> 0:00:38,000
How many of you know who that is?

13
0:00:38.92,000 --> 0:00:4,000
(Cheers)

14
0:00:41.72,000 --> 0:00:43,000
So I was Googling her because I always Google her

15
0:00:44.08,000 --> 0:00:45,000
because I'm just a fan,

16
0:00:45.36,000 --> 0:00:48,000
but also because she always has important and interesting things to say.

17
0:00:49,000 --> 0:00:52,000
And the combination of those searches

18
0:00:52.48,000 --> 0:00:54,000
kept leading me to her talk

19
0:00:55.12,000 --> 0:00:58,000
on the dangers of a single story,

20
0:00:58.32,000 --> 0:01:01,000
on what happens when we have a solitary lens

21
0:01:01.72,000 --> 0:01:03,000
through which to understand certain groups of people,

22
0:01:04.24,000 --> 0:01:05,000
and it is the perfect talk.

23
0:01:07.72,000 --> 0:01:11,000
It's the talk that I would have given if I had been famous first.

24
0:01:12.08,000 --> 0:01:14,000
(Laughter)

25
0:01:14.28,000 --> 0:01:17,000
You know, and you know, like, she's African and I'm African,

26
0:01:17.68,000 --> 0:01:18,000
and she's a feminist and I'm a feminist,

27
0:01:19.64,000 --> 0:01:21,000
and she's a storyteller and I'm a storyteller,

28
0:01:21.84,000 --> 0:01:22,000
so I really felt like it's my talk.

29
0:01:23.68,000 --> 0:01:25,000
(Laughter)

30
0:01:26.44,000 --> 0:01:29,000
So I decided that I was going to learn how to code,

31
0:01:29.76,000 --> 0:01:31,000
and then I was going to hack the internet

32
0:01:31.8,000 --> 0:01:34,000
and I would take down all the copies of that talk that existed,

33
0:01:35.56,000 --> 0:01:36,000
and then I would memorize it,

34
0:01:37,000 --> 0:01:4,000
and then I would come here and deliver it as if it was my own speech.

35
0:01:40.28,000 --> 0:01:43,000
So that plan was going really well, except the coding part,

36
0:01:43.48,000 --> 0:01:46,000
and then one morning a few months ago,

37
0:01:47.4,000 --> 0:01:48,000
I woke up

38
0:01:49,000 --> 0:01:54,000
to the news that the wife of a certain presidential candidate

39
0:01:54.48,000 --> 0:01:56,000
had given a speech that --

40
0:01:57.48,000 --> 0:01:58,000
(Laughter)

41
0:01:59.44,000 --> 0:02:01,000
(Applause)

42
0:02:04.96,000 --> 0:02:08,000
that sounded eerily like a speech given by one of my other faves,

43
0:02:09.6,000 --> 0:02:1,000
Michelle Obama.

44
0:02:10.84,000 --> 0:02:12,000
(Cheers)

45
0:02:12.96,000 --> 0:02:16,000
And so I decided that I should probably write my own TED Talk,

46
0:02:17,000 --> 0:02:19,000
and so that is what I am here to do.

47
0:02:19.52,000 --> 0:02:23,000
I'm here to talk about my own observations about storytelling.

48
0:02:24.64,000 --> 0:02:27,000
I want to talk to you about the power of stories, of course,

49
0:02:28.64,000 --> 0:02:3,000
but I also want to talk about their limitations,

50
0:02:31.6,000 --> 0:02:35,000
particularly for those of us who are interested in social justice.

51
0:02:36.28,000 --> 0:02:38,000
So since Adichie gave that talk seven years ago,

52
0:02:39.2,000 --> 0:02:41,000
there has been a boom in storytelling.

53
0:02:41.48,000 --> 0:02:43,000
Stories are everywhere,

54
0:02:44.24,000 --> 0:02:47,000
and if there was a danger in the telling of one tired old tale,

55
0:02:48.2,000 --> 0:02:52,000
then I think there has got to be lots to celebrate about the flourishing

56
0:02:52.56,000 --> 0:02:54,000
of so many stories and so many voices.

57
0:02:55.36,000 --> 0:02:57,000
Stories are the antidote to bias.

58
0:02:58.96,000 --> 0:03:03,000
In fact, today, if you are middle class and connected via the internet,

59
0:03:04.04,000 --> 0:03:07,000
you can download stories at the touch of a button

60
0:03:07.2,000 --> 0:03:08,000
or the swipe of a screen.

61
0:03:08.6,000 --> 0:03:09,000
You can listen to a podcast

62
0:03:10.44,000 --> 0:03:13,000
about what it's like to grow up Dalit in Kolkata.

63
0:03:14.36,000 --> 0:03:16,000
You can hear an indigenous man in Australia

64
0:03:16.88,000 --> 0:03:2,000
talk about the trials and triumphs of raising his children in dignity

65
0:03:21,000 --> 0:03:22,000
and in pride.

66
0:03:22.36,000 --> 0:03:23,000
Stories make us fall in love.

67
0:03:24.36,000 --> 0:03:27,000
They heal rifts and they bridge divides.

68
0:03:27.56,000 --> 0:03:28,000
Stories can even make it easier for us

69
0:03:29.44,000 --> 0:03:31,000
to talk about the deaths of people in our societies

70
0:03:32.12,000 --> 0:03:34,000
who don't matter, because they make us care.

71
0:03:34.6,000 --> 0:03:35,000
Right?

72
0:03:36.8,000 --> 0:03:37,000
I'm not so sure,

73
0:03:38.08,000 --> 0:03:41,000
and I actually work for a place called the Centre for Stories.

74
0:03:41.84,000 --> 0:03:45,000
And my job is to help to tell stories

75
0:03:46.28,000 --> 0:03:49,000
that challenge mainstream narratives about what it means to be black

76
0:03:49.84,000 --> 0:03:52,000
or a Muslim or a refugee or any of those other categories

77
0:03:52.92,000 --> 0:03:55,000
that we talk about all the time.

78
0:03:55.96,000 --> 0:03:56,000
But I come to this work

79
0:03:57.2,000 --> 0:04:,000
after a long history as a social justice activist,

80
0:04:00.72,000 --> 0:04:02,000
and so I'm really interested in the ways

81
0:04:02.88,000 --> 0:04:04,000
that people talk about nonfiction storytelling

82
0:04:05.6,000 --> 0:04:07,000
as though it's about more than entertainment,

83
0:04:07.96,000 --> 0:04:09,000
as though it's about being a catalyst for social action.

84
0:04:11.56,000 --> 0:04:13,000
It's not uncommon to hear people say

85
0:04:14.24,000 --> 0:04:17,000
that stories make the world a better place.

86
0:04:18.96,000 --> 0:04:21,000
Increasingly, though, I worry that even the most poignant stories,

87
0:04:22.2,000 --> 0:04:25,000
particularly the stories about people who no one seems to care about,

88
0:04:26.16,000 --> 0:04:29,000
can often get in the way of action towards social justice.

89
0:04:29.6,000 --> 0:04:32,000
Now, this is not because storytellers mean any harm.

90
0:04:33.44,000 --> 0:04:34,000
Quite the contrary.

91
0:04:34.72,000 --> 0:04:38,000
Storytellers are often do-gooders like me and, I suspect, yourselves.

92
0:04:39.6,000 --> 0:04:42,000
And the audiences of storytellers

93
0:04:42.68,000 --> 0:04:45,000
are often deeply compassionate and empathetic people.

94
0:04:46.36,000 --> 0:04:5,000
Still, good intentions can have unintended consequences,

95
0:04:51.2,000 --> 0:04:55,000
and so I want to propose that stories are not as magical as they seem.

96
0:04:55.68,000 --> 0:04:57,000
So three -- because it's always got to be three --

97
0:04:58.6,000 --> 0:05:,000
three reasons why I think

98
0:05:00.84,000 --> 0:05:04,000
that stories don't necessarily make the world a better place.

99
0:05:06.32,000 --> 0:05:1,000
Firstly, stories can create an illusion of solidarity.

100
0:05:10.4,000 --> 0:05:12,000
There is nothing like that feel-good factor you get

101
0:05:12.96,000 --> 0:05:14,000
from listening to a fantastic story

102
0:05:15.12,000 --> 0:05:18,000
where you feel like you climbed that mountain, right,

103
0:05:18.52,000 --> 0:05:2,000
or that you befriended that death row inmate.

104
0:05:21.84,000 --> 0:05:22,000
But you didn't.

105
0:05:23.28,000 --> 0:05:24,000
You haven't done anything.

106
0:05:25.12,000 --> 0:05:26,000
Listening is an important

107
0:05:26.92,000 --> 0:05:28,000
but insufficient step towards social action.

108
0:05:31.12,000 --> 0:05:33,000
Secondly, I think often we are drawn

109
0:05:34,000 --> 0:05:36,000
towards characters and protagonists

110
0:05:36.96,000 --> 0:05:39,000
who are likable and human.

111
0:05:40.44,000 --> 0:05:41,000
And this makes sense, of course, right?

112
0:05:42.36,000 --> 0:05:45,000
Because if you like someone, then you care about them.

113
0:05:45.44,000 --> 0:05:46,000
But the inverse is also true.

114
0:05:47.4,000 --> 0:05:48,000
If you don't like someone,

115
0:05:49.2,000 --> 0:05:5,000
then you don't care about them.

116
0:05:51.16,000 --> 0:05:52,000
And if you don't care about them,

117
0:05:53.04,000 --> 0:05:56,000
you don't have to see yourself as having a moral obligation

118
0:05:56.96,000 --> 0:05:59,000
to think about the circumstances that shaped their lives.

119
0:06:01,000 --> 0:06:04,000
I learned this lesson when I was 14 years old.

120
0:06:04.32,000 --> 0:06:06,000
I learned that actually, you don't have to like someone

121
0:06:07.12,000 --> 0:06:08,000
to recognize their wisdom,

122
0:06:08.52,000 --> 0:06:1,000
and you certainly don't have to like someone

123
0:06:10.64,000 --> 0:06:11,000
to take a stand by their side.

124
0:06:12.8,000 --> 0:06:13,000
So my bike was stolen

125
0:06:15.52,000 --> 0:06:16,000
while I was riding it --

126
0:06:17,000 --> 0:06:18,000
(Laughter)

127
0:06:18.16,000 --> 0:06:21,000
which is possible if you're riding slowly enough, which I was.

128
0:06:21.76,000 --> 0:06:22,000
(Laughter)

129
0:06:23.28,000 --> 0:06:25,000
So one minute I'm cutting across this field

130
0:06:26.28,000 --> 0:06:28,000
in the Nairobi neighborhood where I grew up,

131
0:06:28.6,000 --> 0:06:3,000
and it's like a very bumpy path,

132
0:06:31.08,000 --> 0:06:32,000
and so when you're riding a bike,

133
0:06:32.92,000 --> 0:06:34,000
you don't want to be like, you know --

134
0:06:35.2,000 --> 0:06:36,000
(Laughter)

135
0:06:38.16,000 --> 0:06:42,000
And so I'm going like this, slowly pedaling,

136
0:06:42.8,000 --> 0:06:44,000
and all of a sudden, I'm on the floor.

137
0:06:45.4,000 --> 0:06:47,000
I'm on the ground, and I look up,

138
0:06:47.6,000 --> 0:06:49,000
and there's this kid peddling away in the getaway vehicle,

139
0:06:50.4,000 --> 0:06:51,000
which is my bike,

140
0:06:51.92,000 --> 0:06:54,000
and he's about 11 or 12 years old, and I'm on the floor,

141
0:06:55.2,000 --> 0:06:57,000
and I'm crying because I saved a lot of money for that bike,

142
0:06:58.08,000 --> 0:07:,000
and I'm crying and I stand up and I start screaming.

143
0:07:00.68,000 --> 0:07:04,000
Instinct steps in, and I start screaming, "Mwizi, mwizi!"

144
0:07:04.96,000 --> 0:07:05,000
which means "thief" in Swahili.

145
0:07:07.56,000 --> 0:07:12,000
And out of the woodworks, all of these people come out

146
0:07:12.6,000 --> 0:07:13,000
and they start to give chase.

147
0:07:14.04,000 --> 0:07:16,000
This is Africa, so mob justice in action.

148
0:07:16.32,000 --> 0:07:17,000
Right?

149
0:07:17.8,000 --> 0:07:19,000
And I round the corner, and they've captured him,

150
0:07:20.6,000 --> 0:07:21,000
they've caught him.

151
0:07:22.08,000 --> 0:07:24,000
The suspect has been apprehended,

152
0:07:24.16,000 --> 0:07:27,000
and they make him give me my bike back,

153
0:07:27.76,000 --> 0:07:28,000
and they also make him apologize.

154
0:07:29.4,000 --> 0:07:32,000
Again, you know, typical African justice, right?

155
0:07:33,000 --> 0:07:34,000
And so they make him say sorry.

156
0:07:34.52,000 --> 0:07:36,000
And so we stand there facing each other,

157
0:07:36.88,000 --> 0:07:38,000
and he looks at me, and he says sorry,

158
0:07:39.84,000 --> 0:07:42,000
but he looks at me with this unbridled fury.

159
0:07:43.36,000 --> 0:07:46,000
He is very, very angry.

160
0:07:47.44,000 --> 0:07:5,000
And it is the first time that I have been confronted with someone

161
0:07:50.52,000 --> 0:07:52,000
who doesn't like me simply because of what I represent.

162
0:07:53.16,000 --> 0:07:55,000
He looks at me with this look as if to say,

163
0:07:55.24,000 --> 0:07:58,000
"You, with your shiny skin and your bike, you're angry at me?"

164
0:08:01.24,000 --> 0:08:04,000
So it was a hard lesson that he didn't like me,

165
0:08:04.52,000 --> 0:08:06,000
but you know what, he was right.

166
0:08:06.6,000 --> 0:08:09,000
I was a middle-class kid living in a poor country.

167
0:08:10.12,000 --> 0:08:13,000
I had a bike, and he barely had food.

168
0:08:13.76,000 --> 0:08:15,000
Sometimes, it's the messages that we don't want to hear,

169
0:08:16.72,000 --> 0:08:18,000
the ones that make us want to crawl out of ourselves,

170
0:08:19.24,000 --> 0:08:21,000
that we need to hear the most.

171
0:08:21.84,000 --> 0:08:24,000
For every lovable storyteller who steals your heart,

172
0:08:25.04,000 --> 0:08:29,000
there are hundreds more whose voices are slurred and ragged,

173
0:08:29.44,000 --> 0:08:33,000
who don't get to stand up on a stage dressed in fine clothes like this.

174
0:08:34.64,000 --> 0:08:38,000
There are a million angry-boy-on-a-bike stories

175
0:08:38.96,000 --> 0:08:39,000
and we can't afford to ignore them

176
0:08:40.64,000 --> 0:08:43,000
simply because we don't like their protagonists

177
0:08:43.8,000 --> 0:08:45,000
or because that's not the kid that we would bring home with us

178
0:08:46.76,000 --> 0:08:47,000
from the orphanage.

179
0:08:48.6,000 --> 0:08:49,000
The third reason that I think

180
0:08:50.48,000 --> 0:08:53,000
that stories don't necessarily make the world a better place

181
0:08:54.12,000 --> 0:08:57,000
is that too often we are so invested in the personal narrative

182
0:08:57.6,000 --> 0:08:59,000
that we forget to look at the bigger picture.

183
0:09:00.88,000 --> 0:09:01,000
And so we applaud someone

184
0:09:02.8,000 --> 0:09:04,000
when they tell us about their feelings of shame,

185
0:09:05.48,000 --> 0:09:08,000
but we don't necessarily link that to oppression.

186
0:09:09.08,000 --> 0:09:12,000
We nod understandingly when someone says they felt small,

187
0:09:12.76,000 --> 0:09:14,000
but we don't link that to discrimination.

188
0:09:15.6,000 --> 0:09:17,000
The most important stories, especially for social justice,

189
0:09:18.44,000 --> 0:09:19,000
are those that do both,

190
0:09:20.28,000 --> 0:09:24,000
that are both personal and allow us to explore and understand the political.

191
0:09:25.92,000 --> 0:09:27,000
But it's not just about the stories we like

192
0:09:27.96,000 --> 0:09:28,000
versus the stories we choose to ignore.

193
0:09:29.88,000 --> 0:09:32,000
Increasingly, we are living in a society where there are larger forces at play,

194
0:09:33.84,000 --> 0:09:37,000
where stories are actually for many people beginning to replace the news.

195
0:09:38.64,000 --> 0:09:39,000
Yeah?

196
0:09:39.88,000 --> 0:09:42,000
We live in a time where we are witnessing the decline of facts,

197
0:09:43.28,000 --> 0:09:45,000
when emotions rule

198
0:09:45.52,000 --> 0:09:48,000
and analysis, it's kind of boring, right?

199
0:09:48.64,000 --> 0:09:52,000
Where we value what we feel more than what we actually know.

200
0:09:54.04,000 --> 0:09:58,000
A recent report by the Pew Center on trends in America

201
0:09:58.36,000 --> 0:10:03,000
indicates that only 10 percent of young adults under the age of 30

202
0:10:04.16,000 --> 0:10:07,000
"place a lot of trust in the media."

203
0:10:07.56,000 --> 0:10:08,000
Now, this is significant.

204
0:10:09.84,000 --> 0:10:11,000
It means that storytellers are gaining trust

205
0:10:12.48,000 --> 0:10:13,000
at precisely the same moment

206
0:10:13.88,000 --> 0:10:16,000
that many in the media are losing the confidence in the public.

207
0:10:18.04,000 --> 0:10:2,000
This is not a good thing,

208
0:10:20.64,000 --> 0:10:21,000
because while stories are important

209
0:10:22.44,000 --> 0:10:24,000
and they help us to have insights in many ways,

210
0:10:24.68,000 --> 0:10:25,000
we need the media.

211
0:10:26.56,000 --> 0:10:28,000
From my years as a social justice activist,

212
0:10:29.08,000 --> 0:10:35,000
I know very well that we need credible facts from media institutions

213
0:10:35.2,000 --> 0:10:39,000
combined with the powerful voices of storytellers.

214
0:10:39.24,000 --> 0:10:42,000
That's what pushes the needle forward in terms of social justice.

215
0:10:43.84,000 --> 0:10:45,000
In the final analysis, of course,

216
0:10:48.48,000 --> 0:10:49,000
it is justice

217
0:10:50.32,000 --> 0:10:51,000
that makes the world a better place,

218
0:10:52.08,000 --> 0:10:53,000
not stories. Right?

219
0:10:55.08,000 --> 0:10:58,000
And so if it is justice that we are after,

220
0:10:58.16,000 --> 0:11:01,000
then I think we mustn't focus on the media or on storytellers.

221
0:11:01.6,000 --> 0:11:03,000
We must focus on audiences,

222
0:11:04.32,000 --> 0:11:07,000
on anyone who has ever turned on a radio

223
0:11:07.44,000 --> 0:11:08,000
or listened to a podcast,

224
0:11:09.28,000 --> 0:11:11,000
and that means all of us.

225
0:11:11.4,000 --> 0:11:13,000
So a few concluding thoughts

226
0:11:13.56,000 --> 0:11:16,000
on what audiences can do to make the world a better place.

227
0:11:18,000 --> 0:11:21,000
So firstly, the world would be a better place, I think,

228
0:11:21.96,000 --> 0:11:24,000
if audiences were more curious and more skeptical

229
0:11:25.56,000 --> 0:11:27,000
and asked more questions about the social context

230
0:11:28.2,000 --> 0:11:31,000
that created those stories that they love so much.

231
0:11:32.2,000 --> 0:11:34,000
Secondly, the world would be a better place

232
0:11:34.48,000 --> 0:11:37,000
if audiences recognized that storytelling is intellectual work.

233
0:11:39.64,000 --> 0:11:41,000
And I think it would be important for audiences

234
0:11:42.6,000 --> 0:11:47,000
to demand more buttons on their favorite websites,

235
0:11:47.96,000 --> 0:11:49,000
buttons for example that say,

236
0:11:50.68,000 --> 0:11:51,000
"If you liked this story,

237
0:11:52.32,000 --> 0:11:56,000
click here to support a cause your storyteller believes in."

238
0:11:56.4,000 --> 0:12:01,000
Or "click here to contribute to your storyteller's next big idea."

239
0:12:02.48,000 --> 0:12:04,000
Often, we are committed to the platforms,

240
0:12:05.08,000 --> 0:12:07,000
but not necessarily to the storytellers themselves.

241
0:12:07.56,000 --> 0:12:12,000
And then lastly, I think that audiences can make the world a better place

242
0:12:12.68,000 --> 0:12:14,000
by switching off their phones,

243
0:12:15.56,000 --> 0:12:17,000
by stepping away from their screens

244
0:12:17.6,000 --> 0:12:21,000
and stepping out into the real world beyond what feels safe.

245
0:12:22.84,000 --> 0:12:24,000
Alice Walker has said,

246
0:12:24.88,000 --> 0:12:27,000
"Look closely at the present you are constructing.

247
0:12:28.68,000 --> 0:12:31,000
It should look like the future you are dreaming."

248
0:12:32.64,000 --> 0:12:34,000
Storytellers can help us to dream,

249
0:12:34.88,000 --> 0:12:37,000
but it's up to all of us to have a plan for justice.

250
0:12:39.48,000 --> 0:12:4,000
Thank you.

251
0:12:40.72,000 --> 0:12:44,000
(Applause)

