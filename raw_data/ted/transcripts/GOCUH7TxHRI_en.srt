1
0:00:12.16,000 --> 0:00:15,000
Today I'm going to talk to you about the problem of other minds.

2
0:00:15.16,000 --> 0:00:17,000
And the problem I'm going to talk about

3
0:00:17.16,000 --> 0:00:2,000
is not the familiar one from philosophy,

4
0:00:20.16,000 --> 0:00:22,000
which is, "How can we know

5
0:00:22.16,000 --> 0:00:24,000
whether other people have minds?"

6
0:00:24.16,000 --> 0:00:26,000
That is, maybe you have a mind,

7
0:00:26.16,000 --> 0:00:29,000
and everyone else is just a really convincing robot.

8
0:00:29.16,000 --> 0:00:31,000
So that's a problem in philosophy,

9
0:00:31.16,000 --> 0:00:33,000
but for today's purposes I'm going to assume

10
0:00:33.16,000 --> 0:00:35,000
that many people in this audience have a mind,

11
0:00:35.16,000 --> 0:00:37,000
and that I don't have to worry about this.

12
0:00:37.16,000 --> 0:00:4,000
There is a second problem that is maybe even more familiar to us

13
0:00:40.16,000 --> 0:00:43,000
as parents and teachers and spouses

14
0:00:43.16,000 --> 0:00:45,000
and novelists,

15
0:00:45.16,000 --> 0:00:47,000
which is, "Why is it so hard

16
0:00:47.16,000 --> 0:00:49,000
to know what somebody else wants or believes?"

17
0:00:49.16,000 --> 0:00:51,000
Or perhaps, more relevantly,

18
0:00:51.16,000 --> 0:00:54,000
"Why is it so hard to change what somebody else wants or believes?"

19
0:00:54.16,000 --> 0:00:56,000
I think novelists put this best.

20
0:00:56.16,000 --> 0:00:58,000
Like Philip Roth, who said,

21
0:00:58.16,000 --> 0:01:01,000
"And yet, what are we to do about this terribly significant business

22
0:01:01.16,000 --> 0:01:03,000
of other people?

23
0:01:03.16,000 --> 0:01:05,000
So ill equipped are we all,

24
0:01:05.16,000 --> 0:01:07,000
to envision one another's interior workings

25
0:01:07.16,000 --> 0:01:09,000
and invisible aims."

26
0:01:09.16,000 --> 0:01:12,000
So as a teacher and as a spouse,

27
0:01:12.16,000 --> 0:01:14,000
this is, of course, a problem I confront every day.

28
0:01:14.16,000 --> 0:01:17,000
But as a scientist, I'm interested in a different problem of other minds,

29
0:01:17.16,000 --> 0:01:2,000
and that is the one I'm going to introduce to you today.

30
0:01:20.16,000 --> 0:01:22,000
And that problem is, "How is it so easy

31
0:01:22.16,000 --> 0:01:24,000
to know other minds?"

32
0:01:24.16,000 --> 0:01:26,000
So to start with an illustration,

33
0:01:26.16,000 --> 0:01:28,000
you need almost no information,

34
0:01:28.16,000 --> 0:01:3,000
one snapshot of a stranger,

35
0:01:30.16,000 --> 0:01:32,000
to guess what this woman is thinking,

36
0:01:32.16,000 --> 0:01:35,000
or what this man is.

37
0:01:35.16,000 --> 0:01:37,000
And put another way, the crux of the problem is

38
0:01:37.16,000 --> 0:01:4,000
the machine that we use for thinking about other minds,

39
0:01:40.16,000 --> 0:01:43,000
our brain, is made up of pieces, brain cells,

40
0:01:43.16,000 --> 0:01:45,000
that we share with all other animals, with monkeys

41
0:01:45.16,000 --> 0:01:48,000
and mice and even sea slugs.

42
0:01:48.16,000 --> 0:01:51,000
And yet, you put them together in a particular network,

43
0:01:51.16,000 --> 0:01:54,000
and what you get is the capacity to write Romeo and Juliet.

44
0:01:54.16,000 --> 0:01:56,000
Or to say, as Alan Greenspan did,

45
0:01:56.16,000 --> 0:01:59,000
"I know you think you understand what you thought I said,

46
0:01:59.16,000 --> 0:02:01,000
but I'm not sure you realize that what you heard

47
0:02:01.16,000 --> 0:02:03,000
is not what I meant."

48
0:02:03.16,000 --> 0:02:06,000
(Laughter)

49
0:02:06.16,000 --> 0:02:08,000
So, the job of my field of cognitive neuroscience

50
0:02:08.16,000 --> 0:02:1,000
is to stand with these ideas,

51
0:02:10.16,000 --> 0:02:12,000
one in each hand.

52
0:02:12.16,000 --> 0:02:15,000
And to try to understand how you can put together

53
0:02:15.16,000 --> 0:02:19,000
simple units, simple messages over space and time, in a network,

54
0:02:19.16,000 --> 0:02:23,000
and get this amazing human capacity to think about minds.

55
0:02:23.16,000 --> 0:02:26,000
So I'm going to tell you three things about this today.

56
0:02:26.16,000 --> 0:02:29,000
Obviously the whole project here is huge.

57
0:02:29.16,000 --> 0:02:32,000
And I'm going to tell you just our first few steps

58
0:02:32.16,000 --> 0:02:34,000
about the discovery of a special brain region

59
0:02:34.16,000 --> 0:02:36,000
for thinking about other people's thoughts.

60
0:02:36.16,000 --> 0:02:38,000
Some observations on the slow development of this system

61
0:02:38.16,000 --> 0:02:42,000
as we learn how to do this difficult job.

62
0:02:42.16,000 --> 0:02:44,000
And then finally, to show that some of the differences

63
0:02:44.16,000 --> 0:02:47,000
between people, in how we judge others,

64
0:02:47.16,000 --> 0:02:51,000
can be explained by differences in this brain system.

65
0:02:51.16,000 --> 0:02:53,000
So first, the first thing I want to tell you is that

66
0:02:53.16,000 --> 0:02:56,000
there is a brain region in the human brain, in your brains,

67
0:02:56.16,000 --> 0:02:59,000
whose job it is to think about other people's thoughts.

68
0:02:59.16,000 --> 0:03:01,000
This is a picture of it.

69
0:03:01.16,000 --> 0:03:03,000
It's called the Right Temporo-Parietal Junction.

70
0:03:03.16,000 --> 0:03:05,000
It's above and behind your right ear.

71
0:03:05.16,000 --> 0:03:07,000
And this is the brain region you used when you saw the pictures I showed you,

72
0:03:07.16,000 --> 0:03:09,000
or when you read Romeo and Juliet

73
0:03:09.16,000 --> 0:03:12,000
or when you tried to understand Alan Greenspan.

74
0:03:12.16,000 --> 0:03:16,000
And you don't use it for solving any other kinds of logical problems.

75
0:03:16.16,000 --> 0:03:19,000
So this brain region is called the Right TPJ.

76
0:03:19.16,000 --> 0:03:21,000
And this picture shows the average activation

77
0:03:21.16,000 --> 0:03:23,000
in a group of what we call typical human adults.

78
0:03:23.16,000 --> 0:03:25,000
They're MIT undergraduates.

79
0:03:25.16,000 --> 0:03:29,000
(Laughter)

80
0:03:29.16,000 --> 0:03:31,000
The second thing I want to say about this brain system

81
0:03:31.16,000 --> 0:03:33,000
is that although we human adults

82
0:03:33.16,000 --> 0:03:35,000
are really good at understanding other minds,

83
0:03:35.16,000 --> 0:03:37,000
we weren't always that way.

84
0:03:37.16,000 --> 0:03:4,000
It takes children a long time to break into the system.

85
0:03:40.16,000 --> 0:03:44,000
I'm going to show you a little bit of that long, extended process.

86
0:03:44.16,000 --> 0:03:47,000
The first thing I'm going to show you is a change between age three and five,

87
0:03:47.16,000 --> 0:03:49,000
as kids learn to understand

88
0:03:49.16,000 --> 0:03:52,000
that somebody else can have beliefs that are different from their own.

89
0:03:52.16,000 --> 0:03:54,000
So I'm going to show you a five-year-old

90
0:03:54.16,000 --> 0:03:56,000
who is getting a standard kind of puzzle

91
0:03:56.16,000 --> 0:03:59,000
that we call the false belief task.

92
0:03:59.16,000 --> 0:04:02,000
Rebecca Saxe (Video): This is the first pirate. His name is Ivan.

93
0:04:02.16,000 --> 0:04:04,000
And you know what pirates really like?

94
0:04:04.16,000 --> 0:04:07,000
Child: What? RS: Pirates really like cheese sandwiches.

95
0:04:07.16,000 --> 0:04:1,000
Child: Cheese? I love cheese!

96
0:04:10.16,000 --> 0:04:12,000
RS: Yeah. So Ivan has this cheese sandwich,

97
0:04:12.16,000 --> 0:04:14,000
and he says, "Yum yum yum yum yum!

98
0:04:14.16,000 --> 0:04:16,000
I really love cheese sandwiches."

99
0:04:16.16,000 --> 0:04:2,000
And Ivan puts his sandwich over here, on top of the pirate chest.

100
0:04:20.16,000 --> 0:04:24,000
And Ivan says, "You know what? I need a drink with my lunch."

101
0:04:24.16,000 --> 0:04:27,000
And so Ivan goes to get a drink.

102
0:04:27.16,000 --> 0:04:29,000
And while Ivan is away

103
0:04:29.16,000 --> 0:04:32,000
the wind comes,

104
0:04:32.16,000 --> 0:04:34,000
and it blows the sandwich down onto the grass.

105
0:04:34.16,000 --> 0:04:38,000
And now, here comes the other pirate.

106
0:04:38.16,000 --> 0:04:41,000
This pirate is called Joshua.

107
0:04:41.16,000 --> 0:04:43,000
And Joshua also really loves cheese sandwiches.

108
0:04:43.16,000 --> 0:04:45,000
So Joshua has a cheese sandwich and he says,

109
0:04:45.16,000 --> 0:04:49,000
"Yum yum yum yum yum! I love cheese sandwiches."

110
0:04:49.16,000 --> 0:04:52,000
And he puts his cheese sandwich over here on top of the pirate chest.

111
0:04:52.16,000 --> 0:04:54,000
Child: So, that one is his.

112
0:04:54.16,000 --> 0:04:56,000
RS: That one is Joshua's. That's right.

113
0:04:56.16,000 --> 0:04:58,000
Child: And then his went on the ground.

114
0:04:58.16,000 --> 0:05:,000
RS: That's exactly right.

115
0:05:00.16,000 --> 0:05:02,000
Child: So he won't know which one is his.

116
0:05:02.16,000 --> 0:05:05,000
RS: Oh. So now Joshua goes off to get a drink.

117
0:05:05.16,000 --> 0:05:09,000
Ivan comes back and he says, "I want my cheese sandwich."

118
0:05:09.16,000 --> 0:05:12,000
So which one do you think Ivan is going to take?

119
0:05:12.16,000 --> 0:05:14,000
Child: I think he is going to take that one.

120
0:05:14.16,000 --> 0:05:16,000
RS: Yeah, you think he's going to take that one? All right. Let's see.

121
0:05:16.16,000 --> 0:05:19,000
Oh yeah, you were right. He took that one.

122
0:05:19.16,000 --> 0:05:21,000
So that's a five-year-old who clearly understands

123
0:05:21.16,000 --> 0:05:23,000
that other people can have false beliefs

124
0:05:23.16,000 --> 0:05:25,000
and what the consequences are for their actions.

125
0:05:25.16,000 --> 0:05:28,000
Now I'm going to show you a three-year-old

126
0:05:28.16,000 --> 0:05:3,000
who got the same puzzle.

127
0:05:30.16,000 --> 0:05:32,000
RS: And Ivan says, "I want my cheese sandwich."

128
0:05:32.16,000 --> 0:05:35,000
Which sandwich is he going to take?

129
0:05:35.16,000 --> 0:05:37,000
Do you think he's going to take that one? Let's see what happens.

130
0:05:37.16,000 --> 0:05:39,000
Let's see what he does. Here comes Ivan.

131
0:05:39.16,000 --> 0:05:42,000
And he says, "I want my cheese sandwich."

132
0:05:42.16,000 --> 0:05:44,000
And he takes this one.

133
0:05:44.16,000 --> 0:05:47,000
Uh-oh. Why did he take that one?

134
0:05:47.16,000 --> 0:05:51,000
Child: His was on the grass.

135
0:05:51.16,000 --> 0:05:54,000
So the three-year-old does two things differently.

136
0:05:54.16,000 --> 0:05:57,000
First, he predicts Ivan will take the sandwich

137
0:05:57.16,000 --> 0:05:59,000
that's really his.

138
0:05:59.16,000 --> 0:06:03,000
And second, when he sees Ivan taking the sandwich where he left his,

139
0:06:03.16,000 --> 0:06:06,000
where we would say he's taking that one because he thinks it's his,

140
0:06:06.16,000 --> 0:06:09,000
the three-year-old comes up with another explanation:

141
0:06:09.16,000 --> 0:06:11,000
He's not taking his own sandwich because he doesn't want it,

142
0:06:11.16,000 --> 0:06:13,000
because now it's dirty, on the ground.

143
0:06:13.16,000 --> 0:06:15,000
So that's why he's taking the other sandwich.

144
0:06:15.16,000 --> 0:06:19,000
Now of course, development doesn't end at five.

145
0:06:19.16,000 --> 0:06:21,000
And we can see the continuation of this process

146
0:06:21.16,000 --> 0:06:23,000
of learning to think about other people's thoughts

147
0:06:23.16,000 --> 0:06:25,000
by upping the ante

148
0:06:25.16,000 --> 0:06:28,000
and asking children now, not for an action prediction,

149
0:06:28.16,000 --> 0:06:3,000
but for a moral judgment.

150
0:06:30.16,000 --> 0:06:32,000
So first I'm going to show you the three-year-old again.

151
0:06:32.16,000 --> 0:06:35,000
RS.: So is Ivan being mean and naughty for taking Joshua's sandwich?

152
0:06:35.16,000 --> 0:06:36,000
Child: Yeah.

153
0:06:36.16,000 --> 0:06:39,000
RS: Should Ivan get in trouble for taking Joshua's sandwich?

154
0:06:39.16,000 --> 0:06:41,000
Child: Yeah.

155
0:06:41.16,000 --> 0:06:43,000
So it's maybe not surprising he thinks it was mean of Ivan

156
0:06:43.16,000 --> 0:06:45,000
to take Joshua's sandwich,

157
0:06:45.16,000 --> 0:06:47,000
since he thinks Ivan only took Joshua's sandwich

158
0:06:47.16,000 --> 0:06:5,000
to avoid having to eat his own dirty sandwich.

159
0:06:50.16,000 --> 0:06:52,000
But now I'm going to show you the five-year-old.

160
0:06:52.16,000 --> 0:06:54,000
Remember the five-year-old completely understood

161
0:06:54.16,000 --> 0:06:56,000
why Ivan took Joshua's sandwich.

162
0:06:56.16,000 --> 0:06:58,000
RS: Was Ivan being mean and naughty

163
0:06:58.16,000 --> 0:07:,000
for taking Joshua's sandwich?

164
0:07:00.16,000 --> 0:07:02,000
Child: Um, yeah.

165
0:07:02.16,000 --> 0:07:04,000
And so, it is not until age seven

166
0:07:04.16,000 --> 0:07:07,000
that we get what looks more like an adult response.

167
0:07:07.16,000 --> 0:07:1,000
RS: Should Ivan get in trouble for taking Joshua's sandwich?

168
0:07:10.16,000 --> 0:07:12,000
Child: No, because the wind should get in trouble.

169
0:07:12.16,000 --> 0:07:15,000
He says the wind should get in trouble

170
0:07:15.16,000 --> 0:07:17,000
for switching the sandwiches.

171
0:07:17.16,000 --> 0:07:19,000
(Laughter)

172
0:07:19.16,000 --> 0:07:21,000
And now what we've started to do in my lab

173
0:07:21.16,000 --> 0:07:23,000
is to put children into the brain scanner

174
0:07:23.16,000 --> 0:07:26,000
and ask what's going on in their brain

175
0:07:26.16,000 --> 0:07:29,000
as they develop this ability to think about other people's thoughts.

176
0:07:29.16,000 --> 0:07:33,000
So the first thing is that in children we see this same brain region, the Right TPJ,

177
0:07:33.16,000 --> 0:07:36,000
being used while children are thinking about other people.

178
0:07:36.16,000 --> 0:07:38,000
But it's not quite like the adult brain.

179
0:07:38.16,000 --> 0:07:4,000
So whereas in the adults, as I told you,

180
0:07:40.16,000 --> 0:07:43,000
this brain region is almost completely specialized --

181
0:07:43.16,000 --> 0:07:46,000
it does almost nothing else except for thinking about other people's thoughts --

182
0:07:46.16,000 --> 0:07:48,000
in children it's much less so,

183
0:07:48.16,000 --> 0:07:5,000
when they are age five to eight,

184
0:07:50.16,000 --> 0:07:52,000
the age range of the children I just showed you.

185
0:07:52.16,000 --> 0:07:55,000
And actually if we even look at eight to 11-year-olds,

186
0:07:55.16,000 --> 0:07:57,000
getting into early adolescence,

187
0:07:57.16,000 --> 0:08:,000
they still don't have quite an adult-like brain region.

188
0:08:00.16,000 --> 0:08:03,000
And so, what we can see is that over the course of childhood

189
0:08:03.16,000 --> 0:08:05,000
and even into adolescence,

190
0:08:05.16,000 --> 0:08:07,000
both the cognitive system,

191
0:08:07.16,000 --> 0:08:09,000
our mind's ability to think about other minds,

192
0:08:09.16,000 --> 0:08:11,000
and the brain system that supports it

193
0:08:11.16,000 --> 0:08:14,000
are continuing, slowly, to develop.

194
0:08:14.16,000 --> 0:08:16,000
But of course, as you're probably aware,

195
0:08:16.16,000 --> 0:08:18,000
even in adulthood,

196
0:08:18.16,000 --> 0:08:2,000
people differ from one another in how good they are

197
0:08:20.16,000 --> 0:08:22,000
at thinking of other minds, how often they do it

198
0:08:22.16,000 --> 0:08:24,000
and how accurately.

199
0:08:24.16,000 --> 0:08:27,000
And so what we wanted to know was, could differences among adults

200
0:08:27.16,000 --> 0:08:29,000
in how they think about other people's thoughts

201
0:08:29.16,000 --> 0:08:32,000
be explained in terms of differences in this brain region?

202
0:08:32.16,000 --> 0:08:35,000
So, the first thing that we did is we gave adults a version

203
0:08:35.16,000 --> 0:08:37,000
of the pirate problem that we gave to the kids.

204
0:08:37.16,000 --> 0:08:39,000
And I'm going to give that to you now.

205
0:08:39.16,000 --> 0:08:42,000
So Grace and her friend are on a tour of a chemical factory,

206
0:08:42.16,000 --> 0:08:44,000
and they take a break for coffee.

207
0:08:44.16,000 --> 0:08:47,000
And Grace's friend asks for some sugar in her coffee.

208
0:08:47.16,000 --> 0:08:5,000
Grace goes to make the coffee

209
0:08:50.16,000 --> 0:08:52,000
and finds by the coffee a pot

210
0:08:52.16,000 --> 0:08:55,000
containing a white powder, which is sugar.

211
0:08:55.16,000 --> 0:08:58,000
But the powder is labeled "Deadly Poison,"

212
0:08:58.16,000 --> 0:09:01,000
so Grace thinks that the powder is a deadly poison.

213
0:09:01.16,000 --> 0:09:03,000
And she puts it in her friend's coffee.

214
0:09:03.16,000 --> 0:09:06,000
And her friend drinks the coffee, and is fine.

215
0:09:06.16,000 --> 0:09:08,000
How many people think it was morally permissible

216
0:09:08.16,000 --> 0:09:12,000
for Grace to put the powder in the coffee?

217
0:09:12.16,000 --> 0:09:15,000
Okay. Good. (Laughter)

218
0:09:15.16,000 --> 0:09:18,000
So we ask people, how much should Grace be blamed

219
0:09:18.16,000 --> 0:09:2,000
in this case, which we call a failed attempt to harm?

220
0:09:20.16,000 --> 0:09:22,000
And we can compare that to another case,

221
0:09:22.16,000 --> 0:09:24,000
where everything in the real world is the same.

222
0:09:24.16,000 --> 0:09:27,000
The powder is still sugar, but what's different is what Grace thinks.

223
0:09:27.16,000 --> 0:09:3,000
Now she thinks the powder is sugar.

224
0:09:30.16,000 --> 0:09:33,000
And perhaps unsurprisingly, if Grace thinks the powder is sugar

225
0:09:33.16,000 --> 0:09:35,000
and puts it in her friend's coffee,

226
0:09:35.16,000 --> 0:09:37,000
people say she deserves no blame at all.

227
0:09:37.16,000 --> 0:09:41,000
Whereas if she thinks the powder was poison, even though it's really sugar,

228
0:09:41.16,000 --> 0:09:44,000
now people say she deserves a lot of blame,

229
0:09:44.16,000 --> 0:09:47,000
even though what happened in the real world was exactly the same.

230
0:09:47.16,000 --> 0:09:49,000
And in fact, they say she deserves more blame

231
0:09:49.16,000 --> 0:09:51,000
in this case, the failed attempt to harm,

232
0:09:51.16,000 --> 0:09:53,000
than in another case,

233
0:09:53.16,000 --> 0:09:55,000
which we call an accident.

234
0:09:55.16,000 --> 0:09:57,000
Where Grace thought the powder was sugar,

235
0:09:57.16,000 --> 0:09:59,000
because it was labeled "sugar" and by the coffee machine,

236
0:09:59.16,000 --> 0:10:01,000
but actually the powder was poison.

237
0:10:01.16,000 --> 0:10:04,000
So even though when the powder was poison,

238
0:10:04.16,000 --> 0:10:07,000
the friend drank the coffee and died,

239
0:10:07.16,000 --> 0:10:1,000
people say Grace deserves less blame in that case,

240
0:10:10.16,000 --> 0:10:12,000
when she innocently thought it was sugar,

241
0:10:12.16,000 --> 0:10:14,000
than in the other case, where she thought it was poison

242
0:10:14.16,000 --> 0:10:17,000
and no harm occurred.

243
0:10:17.16,000 --> 0:10:19,000
People, though, disagree a little bit

244
0:10:19.16,000 --> 0:10:21,000
about exactly how much blame Grace should get

245
0:10:21.16,000 --> 0:10:23,000
in the accident case.

246
0:10:23.16,000 --> 0:10:25,000
Some people think she should deserve more blame,

247
0:10:25.16,000 --> 0:10:27,000
and other people less.

248
0:10:27.16,000 --> 0:10:29,000
And what I'm going to show you is what happened when we look inside

249
0:10:29.16,000 --> 0:10:31,000
the brains of people while they're making that judgment.

250
0:10:31.16,000 --> 0:10:33,000
So what I'm showing you, from left to right,

251
0:10:33.16,000 --> 0:10:36,000
is how much activity there was in this brain region,

252
0:10:36.16,000 --> 0:10:38,000
and from top to bottom, how much blame

253
0:10:38.16,000 --> 0:10:4,000
people said that Grace deserved.

254
0:10:40.16,000 --> 0:10:42,000
And what you can see is, on the left

255
0:10:42.16,000 --> 0:10:44,000
when there was very little activity in this brain region,

256
0:10:44.16,000 --> 0:10:47,000
people paid little attention to her innocent belief

257
0:10:47.16,000 --> 0:10:5,000
and said she deserved a lot of blame for the accident.

258
0:10:50.16,000 --> 0:10:52,000
Whereas on the right, where there was a lot of activity,

259
0:10:52.16,000 --> 0:10:55,000
people paid a lot more attention to her innocent belief,

260
0:10:55.16,000 --> 0:10:57,000
and said she deserved a lot less blame

261
0:10:57.16,000 --> 0:10:59,000
for causing the accident.

262
0:10:59.16,000 --> 0:11:01,000
So that's good, but of course

263
0:11:01.16,000 --> 0:11:03,000
what we'd rather is have a way to interfere

264
0:11:03.16,000 --> 0:11:05,000
with function in this brain region,

265
0:11:05.16,000 --> 0:11:08,000
and see if we could change people's moral judgment.

266
0:11:08.16,000 --> 0:11:1,000
And we do have such a tool.

267
0:11:10.16,000 --> 0:11:12,000
It's called Trans-Cranial Magnetic Stimulation,

268
0:11:12.16,000 --> 0:11:14,000
or TMS.

269
0:11:14.16,000 --> 0:11:16,000
This is a tool that lets us pass a magnetic pulse

270
0:11:16.16,000 --> 0:11:2,000
through somebody's skull, into a small region of their brain,

271
0:11:20.16,000 --> 0:11:24,000
and temporarily disorganize the function of the neurons in that region.

272
0:11:24.16,000 --> 0:11:26,000
So I'm going to show you a demo of this.

273
0:11:26.16,000 --> 0:11:29,000
First, I'm going to show you that this is a magnetic pulse.

274
0:11:29.16,000 --> 0:11:32,000
I'm going to show you what happens when you put a quarter on the machine.

275
0:11:32.16,000 --> 0:11:36,000
When you hear clicks, we're turning the machine on.

276
0:11:42.16,000 --> 0:11:45,000
So now I'm going to apply that same pulse to my brain,

277
0:11:45.16,000 --> 0:11:47,000
to the part of my brain that controls my hand.

278
0:11:47.16,000 --> 0:11:5,000
So there is no physical force, just a magnetic pulse.

279
0:11:54.16,000 --> 0:11:56,000
Woman (Video): Ready, Rebecca? RS: Yes.

280
0:11:57.16,000 --> 0:12:,000
Okay, so it causes a small involuntary contraction in my hand

281
0:12:00.16,000 --> 0:12:03,000
by putting a magnetic pulse in my brain.

282
0:12:03.16,000 --> 0:12:05,000
And we can use that same pulse,

283
0:12:05.16,000 --> 0:12:07,000
now applied to the RTPJ,

284
0:12:07.16,000 --> 0:12:1,000
to ask if we can change people's moral judgments.

285
0:12:10.16,000 --> 0:12:12,000
So these are the judgments I showed you before, people's normal moral judgments.

286
0:12:12.16,000 --> 0:12:15,000
And then we can apply TMS to the RTPJ

287
0:12:15.16,000 --> 0:12:17,000
and ask how people's judgments change.

288
0:12:17.16,000 --> 0:12:21,000
And the first thing is, people can still do this task overall.

289
0:12:21.16,000 --> 0:12:23,000
So their judgments of the case when everything was fine

290
0:12:23.16,000 --> 0:12:26,000
remain the same. They say she deserves no blame.

291
0:12:26.16,000 --> 0:12:3,000
But in the case of a failed attempt to harm,

292
0:12:30.16,000 --> 0:12:33,000
where Grace thought that it was poison, although it was really sugar,

293
0:12:33.16,000 --> 0:12:36,000
people now say it was more okay, she deserves less blame

294
0:12:36.16,000 --> 0:12:39,000
for putting the powder in the coffee.

295
0:12:39.16,000 --> 0:12:41,000
And in the case of the accident, where she thought that it was sugar,

296
0:12:41.16,000 --> 0:12:44,000
but it was really poison and so she caused a death,

297
0:12:44.16,000 --> 0:12:5,000
people say that it was less okay, she deserves more blame.

298
0:12:50.16,000 --> 0:12:52,000
So what I've told you today is that

299
0:12:52.16,000 --> 0:12:56,000
people come, actually, especially well equipped

300
0:12:56.16,000 --> 0:12:58,000
to think about other people's thoughts.

301
0:12:58.16,000 --> 0:13:,000
We have a special brain system

302
0:13:00.16,000 --> 0:13:03,000
that lets us think about what other people are thinking.

303
0:13:03.16,000 --> 0:13:05,000
This system takes a long time to develop,

304
0:13:05.16,000 --> 0:13:08,000
slowly throughout the course of childhood and into early adolescence.

305
0:13:08.16,000 --> 0:13:11,000
And even in adulthood, differences in this brain region

306
0:13:11.16,000 --> 0:13:13,000
can explain differences among adults

307
0:13:13.16,000 --> 0:13:16,000
in how we think about and judge other people.

308
0:13:16.16,000 --> 0:13:19,000
But I want to give the last word back to the novelists,

309
0:13:19.16,000 --> 0:13:22,000
and to Philip Roth, who ended by saying,

310
0:13:22.16,000 --> 0:13:24,000
"The fact remains that getting people right

311
0:13:24.16,000 --> 0:13:26,000
is not what living is all about anyway.

312
0:13:26.16,000 --> 0:13:28,000
It's getting them wrong that is living.

313
0:13:28.16,000 --> 0:13:31,000
Getting them wrong and wrong and wrong,

314
0:13:31.16,000 --> 0:13:33,000
and then on careful reconsideration,

315
0:13:33.16,000 --> 0:13:35,000
getting them wrong again."

316
0:13:35.16,000 --> 0:13:37,000
Thank you.

317
0:13:37.16,000 --> 0:13:47,000
(Applause)

318
0:13:47.16,000 --> 0:13:49,000
Chris Anderson: So, I have a question. When you start talking about using

319
0:13:49.16,000 --> 0:13:52,000
magnetic pulses to change people's moral judgments,

320
0:13:52.16,000 --> 0:13:55,000
that sounds alarming.

321
0:13:55.16,000 --> 0:13:56,000
(Laughter)

322
0:13:56.16,000 --> 0:14:,000
Please tell me that you're not taking phone calls from the Pentagon, say.

323
0:14:00.16,000 --> 0:14:02,000
RS: I'm not.

324
0:14:02.16,000 --> 0:14:05,000
I mean, they're calling, but I'm not taking the call.

325
0:14:05.16,000 --> 0:14:06,000
(Laughter)

326
0:14:06.16,000 --> 0:14:08,000
CA: They really are calling?

327
0:14:08.16,000 --> 0:14:11,000
So then seriously,

328
0:14:11.16,000 --> 0:14:14,000
you must lie awake at night sometimes

329
0:14:14.16,000 --> 0:14:16,000
wondering where this work leads.

330
0:14:16.16,000 --> 0:14:18,000
I mean, you're clearly an incredible human being,

331
0:14:18.16,000 --> 0:14:21,000
but someone could take this knowledge

332
0:14:21.16,000 --> 0:14:23,000
and in some future

333
0:14:23.16,000 --> 0:14:25,000
not-torture chamber,

334
0:14:25.16,000 --> 0:14:28,000
do acts that people here might be worried about.

335
0:14:28.16,000 --> 0:14:3,000
RS: Yeah, we worry about this.

336
0:14:30.16,000 --> 0:14:33,000
So, there's a couple of things to say about TMS.

337
0:14:33.16,000 --> 0:14:35,000
One is that you can't be TMSed without knowing it.

338
0:14:35.16,000 --> 0:14:38,000
So it's not a surreptitious technology.

339
0:14:38.16,000 --> 0:14:41,000
It's quite hard, actually, to get those very small changes.

340
0:14:41.16,000 --> 0:14:44,000
The changes I showed you are impressive to me

341
0:14:44.16,000 --> 0:14:46,000
because of what they tell us about the function of the brain,

342
0:14:46.16,000 --> 0:14:48,000
but they're small on the scale

343
0:14:48.16,000 --> 0:14:5,000
of the moral judgments that we actually make.

344
0:14:50.16,000 --> 0:14:52,000
And what we changed was not people's

345
0:14:52.16,000 --> 0:14:55,000
moral judgments when they're deciding what to do,

346
0:14:55.16,000 --> 0:14:57,000
when they're making action choices.

347
0:14:57.16,000 --> 0:15:,000
We changed their ability to judge other people's actions.

348
0:15:00.16,000 --> 0:15:02,000
And so, I think of what I'm doing not so much as

349
0:15:02.16,000 --> 0:15:04,000
studying the defendant in a criminal trial,

350
0:15:04.16,000 --> 0:15:06,000
but studying the jury.

351
0:15:06.16,000 --> 0:15:09,000
CA: Is your work going to lead to any recommendations

352
0:15:09.16,000 --> 0:15:12,000
in education, to perhaps bring up

353
0:15:12.16,000 --> 0:15:17,000
a generation of kids able to make fairer moral judgments?

354
0:15:17.16,000 --> 0:15:2,000
RS: That's one of the idealistic hopes.

355
0:15:20.16,000 --> 0:15:24,000
The whole research program here of studying

356
0:15:24.16,000 --> 0:15:28,000
the distinctive parts of the human brain is brand new.

357
0:15:28.16,000 --> 0:15:3,000
Until recently, what we knew about the brain

358
0:15:30.16,000 --> 0:15:33,000
were the things that any other animal's brain could do too,

359
0:15:33.16,000 --> 0:15:35,000
so we could study it in animal models.

360
0:15:35.16,000 --> 0:15:37,000
We knew how brains see, and how they control the body

361
0:15:37.16,000 --> 0:15:39,000
and how they hear and sense.

362
0:15:39.16,000 --> 0:15:42,000
And the whole project of understanding

363
0:15:42.16,000 --> 0:15:44,000
how brains do the uniquely human things --

364
0:15:44.16,000 --> 0:15:47,000
learn language and abstract concepts,

365
0:15:47.16,000 --> 0:15:49,000
and thinking about other people's thoughts -- that's brand new.

366
0:15:49.16,000 --> 0:15:51,000
And we don't know yet what the implications will be

367
0:15:51.16,000 --> 0:15:53,000
of understanding it.

368
0:15:53.16,000 --> 0:15:55,000
CA: So I've got one last question. There is this thing called

369
0:15:55.16,000 --> 0:15:57,000
the hard problem of consciousness,

370
0:15:57.16,000 --> 0:15:59,000
that puzzles a lot of people.

371
0:15:59.16,000 --> 0:16:02,000
The notion that you can understand

372
0:16:02.16,000 --> 0:16:04,000
why a brain works, perhaps.

373
0:16:04.16,000 --> 0:16:07,000
But why does anyone have to feel anything?

374
0:16:07.16,000 --> 0:16:1,000
Why does it seem to require these beings who sense things

375
0:16:10.16,000 --> 0:16:12,000
for us to operate?

376
0:16:12.16,000 --> 0:16:15,000
You're a brilliant young neuroscientist.

377
0:16:15.16,000 --> 0:16:17,000
I mean, what chances do you think there are

378
0:16:17.16,000 --> 0:16:19,000
that at some time in your career,

379
0:16:19.16,000 --> 0:16:21,000
someone, you or someone else,

380
0:16:21.16,000 --> 0:16:23,000
is going to come up with some paradigm shift

381
0:16:23.16,000 --> 0:16:27,000
in understanding what seems an impossible problem?

382
0:16:27.16,000 --> 0:16:31,000
RS: I hope they do. And I think they probably won't.

383
0:16:31.16,000 --> 0:16:34,000
CA: Why?

384
0:16:34.16,000 --> 0:16:37,000
RS: It's not called the hard problem of consciousness for nothing.

385
0:16:37.16,000 --> 0:16:39,000
(Laughter)

386
0:16:39.16,000 --> 0:16:42,000
CA: That's a great answer. Rebecca Saxe, thank you very much. That was fantastic.

387
0:16:42.16,000 --> 0:16:46,000
(Applause)

