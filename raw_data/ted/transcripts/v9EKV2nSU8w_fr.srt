1
0:00:,000 --> 0:00:07,000
Traducteur: Morgane Quilfen Relecteur: Natalie Thibault

2
0:00:12.777,000 --> 0:00:13,000
Je m'appelle James.

3
0:00:13.984,000 --> 0:00:14,000
Je suis écrivain et artiste,

4
0:00:15.694,000 --> 0:00:17,000
et je créé des œuvres sur la technologie.

5
0:00:18.314,000 --> 0:00:19,000
Je fais des choses

6
0:00:19.559,000 --> 0:00:21,000
comme dessiner le contour de drones militaires à taille réelle

7
0:00:22.459,000 --> 0:00:23,000
dans des rues à travers le monde

8
0:00:24.241,000 --> 0:00:26,000
afin que les gens commencent à réfléchir et à comprendre

9
0:00:27.215,000 --> 0:00:3,000
ces technologies difficiles à voir et difficiles à imaginer.

10
0:00:31.494,000 --> 0:00:33,000
Je fais des choses telles que des réseaux neuronaux

11
0:00:33.884,000 --> 0:00:34,000
prévoyant le résultat des élections

12
0:00:35.604,000 --> 0:00:36,000
selon les bulletins météo

13
0:00:37.115,000 --> 0:00:38,000
car les réelles possibilités

14
0:00:38.459,000 --> 0:00:41,000
de ces étranges et nouvelles technologies m'intriguent.

15
0:00:43.405,000 --> 0:00:45,000
L'année dernière, j'ai créé ma voiture autonome.

16
0:00:45.855,000 --> 0:00:47,000
Puisque je ne fais pas confiance à la technologie,

17
0:00:48.405,000 --> 0:00:49,000
j'ai également conçu un piège.

18
0:00:50.777,000 --> 0:00:51,000
(Rires)

19
0:00:51.887,000 --> 0:00:55,000
Je fais ces choses surtout car je les trouve très fascinantes

20
0:00:56.209,000 --> 0:00:58,000
et car je pense que quand nous parlons de technologie,

21
0:00:58.835,000 --> 0:01:,000
nous parlons principalement de nous-mêmes

22
0:01:01.478,000 --> 0:01:03,000
et comment nous comprenons le monde.

23
0:01:03.801,000 --> 0:01:05,000
Voici une histoire au sujet de la technologie.

24
0:01:07.52,000 --> 0:01:09,000
C'est une vidéo « œuf surprise ».

25
0:01:10.374,000 --> 0:01:13,000
C'est une vidéo de quelqu'un ouvrant un tas d’œufs en chocolat

26
0:01:13.746,000 --> 0:01:15,000
et montrant les jeux à l'intérieur au spectateur.

27
0:01:16.461,000 --> 0:01:18,000
C'est tout. C'est ce qu'elle fait pendant sept longues minutes.

28
0:01:19.428,000 --> 0:01:22,000
Je veux que vous remarquiez deux choses.

29
0:01:22.503,000 --> 0:01:26,000
Tout d'abord, cette vidéo a 30 millions de vues.

30
0:01:26.601,000 --> 0:01:27,000
(Rires)

31
0:01:28.376,000 --> 0:01:29,000
Et l'autre chose est

32
0:01:29.566,000 --> 0:01:32,000
qu'elle vient d'une chaîne qui a 6,3 millions d'abonnés,

33
0:01:33.459,000 --> 0:01:35,000
huit milliards de vues au total

34
0:01:36.163,000 --> 0:01:39,000
et il ne s'agit que de vidéos comme celle-ci --

35
0:01:40.256,000 --> 0:01:43,000
30 millions de personnes regardant quelqu'un ouvrir ces œufs.

36
0:01:44.188,000 --> 0:01:48,000
Cela semble bizarre, mais si vous cherchez « œuf surprise » sur YouTube,

37
0:01:48.693,000 --> 0:01:51,000
il vous dira qu'il y a 10 millions de vidéos

38
0:01:52.24,000 --> 0:01:53,000
et c'est une sous-estimation.

39
0:01:53.977,000 --> 0:01:54,000
Je crois qu'il y en a bien plus.

40
0:01:55.842,000 --> 0:01:57,000
Si vous continuez à chercher, c'est sans fin.

41
0:01:58.108,000 --> 0:02:,000
Il y a des millions et des millions de ces vidéos

42
0:02:00.407,000 --> 0:02:03,000
dans des combinaisons de plus en plus baroques de marques et de contenu

43
0:02:03.769,000 --> 0:02:06,000
et il y en a de plus en plus téléchargées chaque jour.

44
0:02:07.639,000 --> 0:02:1,000
C'est un monde étrange, n'est-ce pas ?

45
0:02:11.174,000 --> 0:02:14,000
Le fait est que ce ne sont pas des adultes qui regardent ces vidéos.

46
0:02:14.581,000 --> 0:02:16,000
Ce sont des enfants, de jeunes enfants.

47
0:02:17.526,000 --> 0:02:19,000
Ces vidéos sont une drogue pour les enfants.

48
0:02:19.704,000 --> 0:02:21,000
Il y a quelque chose dans la répétition,

49
0:02:21.803,000 --> 0:02:23,000
dans la bouffée constante de dopamine à la révélation,

50
0:02:24.321,000 --> 0:02:25,000
qui les rend accros.

51
0:02:26.185,000 --> 0:02:3,000
Et les jeunes enfants regardent ces vidéos encore et encore,

52
0:02:31.018,000 --> 0:02:33,000
pendant des heures et des heures.

53
0:02:33.369,000 --> 0:02:35,000
Si vous essayez de leur enlever l'écran,

54
0:02:35.749,000 --> 0:02:36,000
ils vont crier sans fin.

55
0:02:37.555,000 --> 0:02:38,000
Si vous ne me croyez pas --

56
0:02:38.857,000 --> 0:02:4,000
j'ai vu des gens dans le public acquiescer --

57
0:02:41.472,000 --> 0:02:44,000
si vous ne me croyez pas, demandez à quelqu'un avec de jeunes enfants

58
0:02:44.887,000 --> 0:02:46,000
et ils connaîtront les vidéos d’œufs surprise.

59
0:02:47.251,000 --> 0:02:49,000
C'est là que nous commençons.

60
0:02:49.345,000 --> 0:02:52,000
Nous sommes en 2018 et quelqu'un, beaucoup de monde,

61
0:02:53.011,000 --> 0:02:56,000
utilise le même mécanisme que Facebook et Instagram utilisent

62
0:02:56.976,000 --> 0:02:57,000
pour vous garder sur l'application

63
0:02:58.989,000 --> 0:03:01,000
et l'utilise sur YouTube pour s'introduire dans le cerveau de jeunes enfants

64
0:03:02.998,000 --> 0:03:03,000
en échange de revenus publicitaires.

65
0:03:06.346,000 --> 0:03:08,000
J'espère que telle est leur motivation.

66
0:03:08.371,000 --> 0:03:09,000
J'espère qu'ils le font pour cela

67
0:03:10.35,000 --> 0:03:15,000
car il y a des moyens plus simples d'avoir des revenus publicitaires sur YouTube.

68
0:03:15.682,000 --> 0:03:17,000
Vous pouvez inventer ou voler des trucs.

69
0:03:17.974,000 --> 0:03:19,000
Si vous cherchez des dessins animés populaires

70
0:03:20.339,000 --> 0:03:22,000
comme « Peppa Pig » ou « La Pat' Patrouille »,

71
0:03:22.581,000 --> 0:03:24,000
vous trouverez des millions et millions de ces vidéos en ligne.

72
0:03:25.546,000 --> 0:03:28,000
La plupart ne sont pas postées par les créateurs du contenu original.

73
0:03:28.922,000 --> 0:03:3,000
Elles viennent de tout un tas de différents comptes aléatoires

74
0:03:31.945,000 --> 0:03:33,000
et il est impossible de savoir qui les poste

75
0:03:34.209,000 --> 0:03:35,000
ou quelles sont leurs motivations.

76
0:03:36.428,000 --> 0:03:37,000
Cela semble-t-il familier ?

77
0:03:38.382,000 --> 0:03:39,000
Car c'est également le même mécanisme

78
0:03:40.386,000 --> 0:03:42,000
qui a lieu pour la majorité de nos services numériques,

79
0:03:43.01,000 --> 0:03:46,000
où il est impossible de savoir d'où provient cette information.

80
0:03:46.241,000 --> 0:03:47,000
Ce sont des « fake news » pour les enfants

81
0:03:48.19,000 --> 0:03:5,000
et nous leur apprenons dès la naissance

82
0:03:50.279,000 --> 0:03:52,000
à cliquer sur le premier lien qui vient,

83
0:03:52.809,000 --> 0:03:53,000
peu importe sa source.

84
0:03:54.786,000 --> 0:03:56,000
Cela ne semble pas être une super bonne idée.

85
0:03:58.399,000 --> 0:04:,000
Une autre chose très populaire sur YouTube pour enfants :

86
0:04:01.133,000 --> 0:04:02,000
« La chanson de la famille des doigts ».

87
0:04:03.085,000 --> 0:04:05,000
J'ai entendu quelqu'un grogner dans le public.

88
0:04:05.223,000 --> 0:04:06,000
C'est « la famille des doigts ».

89
0:04:06.775,000 --> 0:04:07,000
C'est la première que j'ai pu trouver.

90
0:04:08.729,000 --> 0:04:1,000
Elle est de 2007 et a seulement 200 000 vues,

91
0:04:11.582,000 --> 0:04:12,000
ce qui n'est rien.

92
0:04:13.582,000 --> 0:04:15,000
Il y a cette mélodie incroyablement entêtante,

93
0:04:16.458,000 --> 0:04:17,000
que je ne vais pas vous passer,

94
0:04:18.164,000 --> 0:04:2,000
car elle s'incrustera dans votre cerveau

95
0:04:20.196,000 --> 0:04:22,000
comme elle s'est incrustée dans le mien

96
0:04:22.615,000 --> 0:04:23,000
et je ne vais pas vous faire ça.

97
0:04:24.409,000 --> 0:04:25,000
Mais comme les œufs surprise,

98
0:04:25.823,000 --> 0:04:27,000
elle est entrée dans la tête des enfants

99
0:04:27.965,000 --> 0:04:28,000
et les a rendus accros.

100
0:04:29.596,000 --> 0:04:31,000
En quelques années, ces vidéos de la famille des doigts

101
0:04:32.167,000 --> 0:04:33,000
sont apparues partout

102
0:04:33.418,000 --> 0:04:35,000
et il y a des versions dans différentes langues,

103
0:04:35.657,000 --> 0:04:37,000
avec des dessins animés populaires, avec de la nourriture

104
0:04:38.338,000 --> 0:04:39,000
ou n'importe quel élément d'animation

105
0:04:40.2,000 --> 0:04:42,000
qui leur tombe sous la main.

106
0:04:43.002,000 --> 0:04:48,000
De nouveau, il y a des millions de vidéos

107
0:04:48.223,000 --> 0:04:51,000
disponibles en ligne avec toutes ces combinaisons folles.

108
0:04:51.682,000 --> 0:04:53,000
Plus vous passez de temps dessus,

109
0:04:53.934,000 --> 0:04:56,000
plus vous avez l'impression d'être fou.

110
0:04:57.652,000 --> 0:05:,000
C'est à ce moment-là que je me suis lancé là-dedans,

111
0:05:01.009,000 --> 0:05:04,000
ce sentiment profond d'étrangeté et ce profond manque de compréhension

112
0:05:04.699,000 --> 0:05:08,000
quant à comment était construite la chose qui se présentait autour de moi.

113
0:05:08.898,000 --> 0:05:11,000
Car il est impossible de savoir d'où viennent ces choses.

114
0:05:12.089,000 --> 0:05:13,000
Qui les crée ?

115
0:05:13.354,000 --> 0:05:16,000
Elles semblent parfois créées par des équipes d'animateurs professionnels,

116
0:05:16.847,000 --> 0:05:18,000
parfois assemblées aléatoirement par un logiciel,

117
0:05:19.427,000 --> 0:05:23,000
parfois elles semblent être créées par de vrais artistes pour enfants.

118
0:05:23.704,000 --> 0:05:24,000
Certaines sont clairement de gens

119
0:05:25.296,000 --> 0:05:27,000
qui ne devraient pas s'approcher d'enfants.

120
0:05:28.311,000 --> 0:05:29,000
(Rires)

121
0:05:30.987,000 --> 0:05:34,000
De nouveau, cette impossibilité de découvrir qui crée ces choses --

122
0:05:35.651,000 --> 0:05:36,000
est-ce un bot ?

123
0:05:36.831,000 --> 0:05:38,000
Est-ce une personne ? Est-ce un troll ?

124
0:05:39.502,000 --> 0:05:41,000
Qu'est-ce que cela signifie que nous ne puissions plus

125
0:05:42.034,000 --> 0:05:43,000
différencier ces choses ?

126
0:05:43.515,000 --> 0:05:47,000
Cette incertitude ne semble-t-elle pas familière actuellement ?

127
0:05:50.145,000 --> 0:05:52,000
La façon dont les gens ont des vues sur leurs vidéos --

128
0:05:52.749,000 --> 0:05:53,000
les vues, ce sont de l'argent --

129
0:05:54.48,000 --> 0:05:58,000
est de farcir les titres de ces vidéos avec des mots populaires.

130
0:05:59.246,000 --> 0:06:,000
Vous prenez « œufs surprise »

131
0:06:00.957,000 --> 0:06:02,000
et « La Pat' Patrouille », « œuf de Pâques »

132
0:06:03.047,000 --> 0:06:04,000
ou quoi que ce soit d'autre,

133
0:06:04.464,000 --> 0:06:06,000
tous ces mots issus d'autres vidéos populaires dans votre titre

134
0:06:07.447,000 --> 0:06:09,000
jusqu'à finir avec ce mélange linguistique dénué de sens

135
0:06:10.373,000 --> 0:06:12,000
qui n'a aucun sens pour les êtres humains.

136
0:06:12.895,000 --> 0:06:15,000
Car seuls les jeunes enfants regardent votre vidéo

137
0:06:16.465,000 --> 0:06:17,000
et qu'en savent-ils ?

138
0:06:18.316,000 --> 0:06:21,000
Votre vrai public pour ces choses-là est logiciel.

139
0:06:21.347,000 --> 0:06:22,000
Ce sont les algorithmes.

140
0:06:22.527,000 --> 0:06:23,000
C'est le logiciel que YouTube utilise

141
0:06:24.406,000 --> 0:06:26,000
pour sélectionner quelles vidéos sont comme les autres,

142
0:06:26.989,000 --> 0:06:28,000
pour les rendre populaires, les recommander.

143
0:06:29.18,000 --> 0:06:32,000
C'est pourquoi vous finissez avec ce mélange complètement dénué de sens

144
0:06:32.665,000 --> 0:06:34,000
à la fois dans le titre et le contenu.

145
0:06:35.792,000 --> 0:06:36,000
Le fait est, rappelez-vous,

146
0:06:37.71,000 --> 0:06:41,000
il y a encore des gens au sein de ce système optimisé par algorithme

147
0:06:42.212,000 --> 0:06:44,000
qui sont de plus en plus forcés à mettre en scène

148
0:06:45.026,000 --> 0:06:48,000
ces combinaisons de mots de plus en plus bizarres,

149
0:06:48.116,000 --> 0:06:53,000
tels des artistes d'improvisation désespérés répondant aux cris

150
0:06:53.313,000 --> 0:06:55,000
d'un million d'enfants en même temps.

151
0:06:57.168,000 --> 0:06:59,000
Il y a de vraies personnes piégées dans ces systèmes

152
0:06:59.66,000 --> 0:07:,000
et c'est l'autre aspect étrange

153
0:07:01.309,000 --> 0:07:03,000
de cette culture dirigée par les algorithmes

154
0:07:03.699,000 --> 0:07:04,000
car si vous êtes un être humain,

155
0:07:05.25,000 --> 0:07:07,000
vous devez agir comme une machine

156
0:07:07.313,000 --> 0:07:08,000
pour survivre.

157
0:07:09.137,000 --> 0:07:11,000
De l'autre côté de l'écran,

158
0:07:11.261,000 --> 0:07:13,000
il y a encore de jeunes enfants regardant ces trucs,

159
0:07:14.232,000 --> 0:07:18,000
coincés, toute leur attention attirée par ces étranges mécanismes.

160
0:07:18.768,000 --> 0:07:2,000
Ces enfants sont trop petits pour utiliser un site internet.

161
0:07:21.616,000 --> 0:07:24,000
Ils se contentent de taper sur l'écran avec leurs petites mains.

162
0:07:24.89,000 --> 0:07:25,000
Il y a la lecture automatique,

163
0:07:26.327,000 --> 0:07:29,000
qui continue à lire ces vidéos en boucle de façon constante,

164
0:07:29.734,000 --> 0:07:31,000
sans cesse durant des heures et des heures.

165
0:07:31.817,000 --> 0:07:33,000
Il y a maintenant tellement d'étrangeté dans le système

166
0:07:34.684,000 --> 0:07:37,000
que la lecture automatique vous mène à des endroits étranges.

167
0:07:37.717,000 --> 0:07:39,000
C'est ainsi qu'en une dizaine d'étapes,

168
0:07:40.229,000 --> 0:07:43,000
vous pouvez passer d'une vidéo mignonne d'un train qui compte

169
0:07:43.411,000 --> 0:07:45,000
à Mickey Mouse se masturbant.

170
0:07:46.529,000 --> 0:07:48,000
Oui. Je suis désolé.

171
0:07:48.841,000 --> 0:07:49,000
Il y a pire.

172
0:07:50.565,000 --> 0:07:51,000
Voici ce qu'il se passe

173
0:07:51.871,000 --> 0:07:54,000
quand tous ces mots-clés,

174
0:07:54.981,000 --> 0:07:56,000
tous ces éléments d'attention,

175
0:07:57.466,000 --> 0:07:59,000
cette génération désespérée de contenu,

176
0:08:00.297,000 --> 0:08:02,000
sont réunis en un seul endroit.

177
0:08:03.871,000 --> 0:08:07,000
Voici où tous ces mots-clés très étranges se retournent contre vous.

178
0:08:08.367,000 --> 0:08:1,000
Vous croisez la vidéo de la famille des doigts

179
0:08:10.782,000 --> 0:08:12,000
avec un truc de super-héros en direct,

180
0:08:12.894,000 --> 0:08:15,000
ajoutez des blagues bizarres et de troll

181
0:08:16.174,000 --> 0:08:19,000
et soudain vous arrivez dans un lieu très étrange.

182
0:08:19.564,000 --> 0:08:21,000
Ce qui a tendance à déranger les parents

183
0:08:21.701,000 --> 0:08:24,000
est le contenu violent ou sexuel, n'est-ce pas ?

184
0:08:25.056,000 --> 0:08:27,000
Les personnages pour enfants se faisant agresser,

185
0:08:27.902,000 --> 0:08:29,000
se faisant tuer,

186
0:08:29.944,000 --> 0:08:32,000
des plaisanteries étranges qui terrifient les enfants.

187
0:08:33.311,000 --> 0:08:36,000
Vous avez un logiciel qui recherche toutes ces différentes influences

188
0:08:37.01,000 --> 0:08:39,000
pour générer automatiquement les pires cauchemars des enfants.

189
0:08:39.995,000 --> 0:08:41,000
Cela affecte vraiment les jeunes enfants.

190
0:08:42.72,000 --> 0:08:44,000
Les parents déclarent leurs enfants traumatisés,

191
0:08:45.61,000 --> 0:08:46,000
développant une peur du noir,

192
0:08:47.026,000 --> 0:08:5,000
une peur de leurs personnages de dessins animés préférés.

193
0:08:50.524,000 --> 0:08:53,000
Si vous retenez une chose de ceci, c'est que si vous avez de jeunes enfants,

194
0:08:54.159,000 --> 0:08:55,000
tenez-les éloignés de YouTube.

195
0:08:56.743,000 --> 0:08:59,000
(Applaudissements)

196
0:09:02.504,000 --> 0:09:05,000
Mais l'autre chose, ce qui m'atteint vraiment,

197
0:09:05.624,000 --> 0:09:06,000
est que je ne suis pas sûr

198
0:09:06.871,000 --> 0:09:1,000
que nous comprenions comment nous en sommes arrivés là.

199
0:09:10.951,000 --> 0:09:12,000
Nous avons pris l'influence de toutes ces choses

200
0:09:13.906,000 --> 0:09:15,000
et créé un mélange que personne n'avait l'intention de faire.

201
0:09:16.883,000 --> 0:09:19,000
Pourtant, c'est aussi la façon dont nous créons le monde entier.

202
0:09:20.063,000 --> 0:09:21,000
Nous prenons toutes ces données,

203
0:09:21.86,000 --> 0:09:22,000
beaucoup de mauvaises données,

204
0:09:23.331,000 --> 0:09:26,000
beaucoup de données historiques pleines de préjugés,

205
0:09:26.384,000 --> 0:09:28,000
pleines de nos pires pulsions au cours de l'histoire,

206
0:09:29.245,000 --> 0:09:31,000
et en faisons d'énormes ensembles de données

207
0:09:31.318,000 --> 0:09:32,000
et les automatisons.

208
0:09:32.765,000 --> 0:09:35,000
Nous les incluons à des choses comme les rapports de crédit,

209
0:09:36.291,000 --> 0:09:37,000
les primes d'assurance,

210
0:09:37.949,000 --> 0:09:39,000
des systèmes de prévision policière,

211
0:09:40.666,000 --> 0:09:42,000
des directives de détermination des peines.

212
0:09:42.678,000 --> 0:09:44,000
Aujourd'hui, nous construisons le monde

213
0:09:45.297,000 --> 0:09:46,000
à partir de ces données.

214
0:09:46.472,000 --> 0:09:47,000
Je ne sais pas ce qui est le pire :

215
0:09:48.194,000 --> 0:09:51,000
que nous créions un système semblant entièrement optimisé

216
0:09:51.446,000 --> 0:09:53,000
pour les pires aspects du comportement humain

217
0:09:54.278,000 --> 0:09:56,000
ou que nous l'ayons fait par accident,

218
0:09:56.727,000 --> 0:09:58,000
sans même réaliser que nous le faisions

219
0:09:58.958,000 --> 0:10:01,000
car nous ne comprenions pas vraiment les systèmes que nous créions

220
0:10:02.364,000 --> 0:10:05,000
et nous ne comprenions pas vraiment comment faire les choses autrement.

221
0:10:06.769,000 --> 0:10:09,000
Il y a deux choses qui, à mon avis, semblent stimuler cela

222
0:10:10.158,000 --> 0:10:11,000
principalement sur YouTube

223
0:10:11.397,000 --> 0:10:12,000
et la première est la publicité,

224
0:10:13.222,000 --> 0:10:15,000
la monétisation de l'attention

225
0:10:16.083,000 --> 0:10:19,000
sans autre réelle variable à l’œuvre,

226
0:10:19.243,000 --> 0:10:22,000
sans s'inquiéter des personnes qui élaborent ce contenu,

227
0:10:23.152,000 --> 0:10:26,000
la centralisation du pouvoir, la séparation de ces choses-là.

228
0:10:26.812,000 --> 0:10:29,000
Je pense que peu importe votre avis sur l'utilisation de la publicité

229
0:10:30.046,000 --> 0:10:31,000
pour subventionner cela,

230
0:10:31.242,000 --> 0:10:34,000
la vision d'hommes adultes en couche se roulant dans le sable

231
0:10:34.333,000 --> 0:10:36,000
en espérant qu'un algorithme qu'ils ne comprennent pas vraiment

232
0:10:37.34,000 --> 0:10:38,000
leur donnera de l'argent

233
0:10:38.679,000 --> 0:10:4,000
suggère que ce n'est probablement pas

234
0:10:40.74,000 --> 0:10:42,000
ce sur quoi nous devrions baser notre société et culture

235
0:10:43.373,000 --> 0:10:45,000
ni la façon dont nous devrions les financer.

236
0:10:45.511,000 --> 0:10:48,000
L'autre facteur-clé est l'automatisation,

237
0:10:49.054,000 --> 0:10:51,000
le déploiement de toute cette technologie

238
0:10:51.407,000 --> 0:10:53,000
dès qu'elle arrive, sans supervision,

239
0:10:53.952,000 --> 0:10:54,000
et, une fois disponible,

240
0:10:55.388,000 --> 0:10:56,000
nous levons les mains et disons :

241
0:10:57.135,000 --> 0:10:59,000
« Ce n'est pas nous, c'est la technologie. »

242
0:10:59.255,000 --> 0:11:,000
Comme si nous n'étions pas impliqués.

243
0:11:01.037,000 --> 0:11:02,000
Cela ne suffit pas

244
0:11:02.712,000 --> 0:11:04,000
car ces trucs ne sont pas que dirigés par des algorithmes,

245
0:11:05.446,000 --> 0:11:07,000
ils sont surveillés par des algorithmes.

246
0:11:07.968,000 --> 0:11:09,000
Quand YouTube a commencé à prêter attention à cela,

247
0:11:10.84,000 --> 0:11:12,000
ils ont d'abord dit vouloir

248
0:11:12.871,000 --> 0:11:14,000
déployer de meilleurs algorithmes d'apprentissage automatique

249
0:11:15.796,000 --> 0:11:16,000
pour modérer le contenu.

250
0:11:17.023,000 --> 0:11:18,000
L'apprentissage automatique,

251
0:11:18.412,000 --> 0:11:2,000
comme vous le dirait n'importe quel expert,

252
0:11:20.532,000 --> 0:11:21,000
est ce que nous appelons

253
0:11:22.402,000 --> 0:11:24,000
un logiciel dont nous ne comprenons pas le fonctionnement.

254
0:11:25.12,000 --> 0:11:28,000
Nous en avons déjà assez.

255
0:11:29.071,000 --> 0:11:32,000
Nous ne devrions pas laisser l'IA décider

256
0:11:32.261,000 --> 0:11:33,000
ce qui est approprié ou pas,

257
0:11:33.602,000 --> 0:11:34,000
nous savons ce qu'il se passe.

258
0:11:35.072,000 --> 0:11:36,000
Il va censurer d'autres choses.

259
0:11:36.708,000 --> 0:11:37,000
Il va censurer le contenu queer.

260
0:11:38.515,000 --> 0:11:4,000
Il va censurer un discours public légitime.

261
0:11:40.776,000 --> 0:11:41,000
Ce qui est autorisé dans ces discours

262
0:11:42.725,000 --> 0:11:45,000
ne devrait pas dépendre de systèmes inexplicables et irresponsables.

263
0:11:45.932,000 --> 0:11:47,000
Cela fait partie d'une discussion nous devrions tous avoir.

264
0:11:48.817,000 --> 0:11:49,000
Je vais également rappeler

265
0:11:50.149,000 --> 0:11:52,000
que l'alternative n'est pas très plaisante non plus.

266
0:11:52.926,000 --> 0:11:53,000
YouTube a récemment annoncé

267
0:11:54.485,000 --> 0:11:56,000
la mise en ligne d'une version de l'application pour enfants

268
0:11:57.322,000 --> 0:11:59,000
entièrement modérée par des êtres humains.

269
0:12:00.134,000 --> 0:12:03,000
Facebook, Zuckerberg a dit la même chose au Congrès

270
0:12:03.776,000 --> 0:12:06,000
quand on lui a demandé comment ils allaient modérer leur contenu :

271
0:12:06.893,000 --> 0:12:07,000
des êtres humains le feraient.

272
0:12:08.558,000 --> 0:12:09,000
Cela signifie

273
0:12:10.041,000 --> 0:12:13,000
que plutôt que ces choses soient vues d'abord par des enfants,

274
0:12:13.288,000 --> 0:12:15,000
il y aura des travailleurs contractuels sous-payés

275
0:12:16.1,000 --> 0:12:17,000
sans soutien psychologique adéquat

276
0:12:17.85,000 --> 0:12:18,000
auxquels elles nuiront aussi.

277
0:12:19.276,000 --> 0:12:2,000
(Rires)

278
0:12:20.37,000 --> 0:12:22,000
Nous pouvons tous faire bien mieux que cela.

279
0:12:22.995,000 --> 0:12:24,000
(Applaudissements)

280
0:12:26.068,000 --> 0:12:3,000
L'idée qui, pour moi, relie vraiment ces deux choses ensemble

281
0:12:30.705,000 --> 0:12:31,000
est la capacité d'action.

282
0:12:32.149,000 --> 0:12:35,000
Combien nous comprenons vraiment -- par capacité d'action, je parle

283
0:12:35.33,000 --> 0:12:39,000
de comment nous savons comment agir dans notre intérêt.

284
0:12:39.744,000 --> 0:12:4,000
C'est presque impossible à faire

285
0:12:41.555,000 --> 0:12:44,000
dans ces systèmes que nous ne comprenons pas complètement.

286
0:12:45.064,000 --> 0:12:48,000
L'inégalité des pouvoirs mène toujours à la violence.

287
0:12:48.159,000 --> 0:12:49,000
Nous voyons au sein de ces systèmes

288
0:12:49.868,000 --> 0:12:51,000
que l'inégalité de compréhension fait la même chose.

289
0:12:52.503,000 --> 0:12:55,000
S'il y a une chose que nous pouvons faire pour améliorer ces systèmes,

290
0:12:56.306,000 --> 0:12:58,000
c'est les rendre plus lisibles pour leurs utilisateurs

291
0:12:59.048,000 --> 0:13:01,000
afin que nous partagions une compréhension

292
0:13:01.268,000 --> 0:13:02,000
de ce qu'il se passe.

293
0:13:03.97,000 --> 0:13:05,000
Le fait est que je pense que le problème avec ces systèmes

294
0:13:06.962,000 --> 0:13:09,000
est que, j'espère l'avoir expliqué, qu'il ne s'agit pas vraiment de YouTube.

295
0:13:10.843,000 --> 0:13:11,000
Il s'agit de tout.

296
0:13:12.179,000 --> 0:13:14,000
Ces problèmes de responsabilité et capacité d'action,

297
0:13:14.693,000 --> 0:13:16,000
d'opacité et de complexité,

298
0:13:16.896,000 --> 0:13:19,000
de violence et d'exploitation qui résultent de façon inhérente

299
0:13:20.097,000 --> 0:13:22,000
de la concentration du pouvoir dans quelques mains --

300
0:13:22.915,000 --> 0:13:24,000
ce sont des problèmes bien plus larges.

301
0:13:26.325,000 --> 0:13:28,000
Ce ne sont pas des problèmes que pour YouTube

302
0:13:28.416,000 --> 0:13:29,000
mais pour la technologie en général

303
0:13:30.096,000 --> 0:13:31,000
et ils ne sont pas nouveaux.

304
0:13:31.441,000 --> 0:13:32,000
Ils existent depuis toujours.

305
0:13:32.886,000 --> 0:13:36,000
Nous avons finalement créé ce système, ce système mondial, internet,

306
0:13:37.294,000 --> 0:13:4,000
qui nous les montre de façon extraordinaire,

307
0:13:40.337,000 --> 0:13:41,000
les rendant incontestables.

308
0:13:41.908,000 --> 0:13:43,000
La technologie a cette capacité extraordinaire

309
0:13:44.752,000 --> 0:13:47,000
à instancier et à maintenir

310
0:13:48.749,000 --> 0:13:52,000
tous nos désirs et préjugés les plus extraordinaires et cachés

311
0:13:53.021,000 --> 0:13:54,000
et à les encoder dans le monde,

312
0:13:54.911,000 --> 0:13:57,000
mais également à les écrire afin que nous les voyions,

313
0:13:58.409,000 --> 0:14:01,000
afin que nous ne puissions pas prétendre qu'ils n'existent plus.

314
0:14:01.763,000 --> 0:14:05,000
Nous devons arrêter de voir la technologie comme la solution à tous nos problèmes

315
0:14:06.106,000 --> 0:14:09,000
et la voir comme un guide vers ce que sont nos problèmes

316
0:14:09.887,000 --> 0:14:11,000
afin de pouvoir y réfléchir correctement

317
0:14:12.055,000 --> 0:14:13,000
et commencer à y remédier.

318
0:14:13.845,000 --> 0:14:14,000
Merci beaucoup.

319
0:14:15.204,000 --> 0:14:2,000
(Applaudissements)

320
0:14:21.733,000 --> 0:14:22,000
Merci.

321
0:14:22.945,000 --> 0:14:24,000
(Applaudissements)

322
0:14:28.839,000 --> 0:14:31,000
Helen Walter : James, merci d'être venu et d'être intervenu ainsi.

323
0:14:32.041,000 --> 0:14:33,000
C'est intéressant :

324
0:14:33.254,000 --> 0:14:36,000
quand vous pensez aux films où des robots envahissent le monde,

325
0:14:36.773,000 --> 0:14:39,000
c'est un peu plus glamour que ce que vous décrivez.

326
0:14:40.076,000 --> 0:14:43,000
Je me demande -- dans ces films, la résistance s'organise.

327
0:14:43.849,000 --> 0:14:46,000
Y a-t-il une résistance qui s'organise au sujet de ces choses-là ?

328
0:14:47.089,000 --> 0:14:5,000
Voyez-vous des signes positifs, des précurseurs d'une résistance ?

329
0:14:52.507,000 --> 0:14:54,000
James Bridle : Une résistance directe, je ne sais pas,

330
0:14:55.053,000 --> 0:14:57,000
car ce sont des choses à très long terme.

331
0:14:57.235,000 --> 0:14:59,000
C'est intégré à la culture très profondément.

332
0:14:59.769,000 --> 0:15:01,000
Une amie à moi, Eleanor Saitta, dit toujours

333
0:15:01.935,000 --> 0:15:04,000
que tout problème technologique d'une certaine échelle et envergure

334
0:15:05.568,000 --> 0:15:07,000
est d'abord un problème politique.

335
0:15:07.859,000 --> 0:15:09,000
Tout ce à quoi nous essayons de remédier

336
0:15:10.668,000 --> 0:15:13,000
ne trouvera pas de solution en créant de meilleures technologies

337
0:15:13.966,000 --> 0:15:16,000
mais en changeant la société qui produit ces technologies.

338
0:15:17.454,000 --> 0:15:2,000
Actuellement, nous avons un très long chemin à parcourir.

339
0:15:20.505,000 --> 0:15:22,000
Je l'ai dit, en décortiquant les problèmes,

340
0:15:22.515,000 --> 0:15:24,000
en les expliquant, en en parlant très honnêtement,

341
0:15:25.236,000 --> 0:15:27,000
nous pouvons commencer ce processus.

342
0:15:27.765,000 --> 0:15:3,000
HW : Quand vous parler de lisibilité et d'alphabétisation numérique,

343
0:15:31.351,000 --> 0:15:32,000
j'ai du mal à imaginer

344
0:15:32.966,000 --> 0:15:35,000
que nous devons porter nous-mêmes le fardeau de l'alphabétisation numérique.

345
0:15:36.67,000 --> 0:15:4,000
De qui relève la responsabilité de l'éducation dans ce nouveau monde ?

346
0:15:41.256,000 --> 0:15:44,000
JB : Je crois que c'est de notre responsabilité à tous,

347
0:15:44.892,000 --> 0:15:46,000
que tout ce que nous faisons, construisons et créons

348
0:15:47.9,000 --> 0:15:5,000
doit être fait au sein d'une discussion consensuelle

349
0:15:51.616,000 --> 0:15:52,000
avec tous ceux qui l'évitent ;

350
0:15:53.58,000 --> 0:15:57,000
nous ne créons pas de systèmes dans le but de piéger et surprendre les gens

351
0:15:57.945,000 --> 0:15:59,000
pour qu'ils agissent bien

352
0:16:00.269,000 --> 0:16:03,000
mais ils sont impliqués à chaque étape de leur éducation

353
0:16:03.529,000 --> 0:16:05,000
car chacun de ces systèmes est éducatif.

354
0:16:05.831,000 --> 0:16:08,000
C'est pour cela que j'ai espoir, même pour ce qui est sinistre,

355
0:16:08.957,000 --> 0:16:1,000
que si vous le prenez et l'observez correctement,

356
0:16:11.274,000 --> 0:16:13,000
c'est éducatif en soi

357
0:16:13.356,000 --> 0:16:14,000
et nous permet de voir

358
0:16:14.562,000 --> 0:16:16,000
comment des systèmes complexes fonctionnent ensemble

359
0:16:17.142,000 --> 0:16:2,000
et d'appliquer ce savoir ailleurs dans le monde.

360
0:16:20.667,000 --> 0:16:22,000
HW : C'est une discussion si importante

361
0:16:22.806,000 --> 0:16:25,000
et beaucoup de gens ici sont ouverts et prêts à en discuter,

362
0:16:26.057,000 --> 0:16:27,000
merci d'avoir démarré notre matinée.

363
0:16:27.94,000 --> 0:16:28,000
JB : Merci beaucoup.

364
0:16:29.364,000 --> 0:16:3,000
(Applaudissements)

