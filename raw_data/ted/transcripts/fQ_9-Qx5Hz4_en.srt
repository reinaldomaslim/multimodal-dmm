1
0:00:18.33,000 --> 0:00:21,000
Cultural evolution is a dangerous child

2
0:00:21.33,000 --> 0:00:24,000
for any species to let loose on its planet.

3
0:00:24.33,000 --> 0:00:28,000
By the time you realize what's happening, the child is a toddler,

4
0:00:28.33,000 --> 0:00:34,000
up and causing havoc, and it's too late to put it back.

5
0:00:34.33,000 --> 0:00:37,000
We humans are Earth's Pandoran species.

6
0:00:37.33,000 --> 0:00:42,000
We're the ones who let the second replicator out of its box,

7
0:00:42.33,000 --> 0:00:44,000
and we can't push it back in.

8
0:00:44.33,000 --> 0:00:47,000
We're seeing the consequences all around us.

9
0:00:48.33,000 --> 0:00:52,000
Now that, I suggest, is the view that

10
0:00:52.33,000 --> 0:00:54,000
comes out of taking memetics seriously.

11
0:00:54.33,000 --> 0:00:56,000
And it gives us a new way of thinking about

12
0:00:56.33,000 --> 0:00:58,000
not only what's going on on our planet,

13
0:00:58.33,000 --> 0:01:01,000
but what might be going on elsewhere in the cosmos.

14
0:01:01.33,000 --> 0:01:04,000
So first of all, I'd like to say something about memetics

15
0:01:04.33,000 --> 0:01:06,000
and the theory of memes,

16
0:01:06.33,000 --> 0:01:11,000
and secondly, how this might answer questions about who's out there,

17
0:01:11.33,000 --> 0:01:14,000
if indeed anyone is.

18
0:01:14.33,000 --> 0:01:16,000
So, memetics:

19
0:01:16.33,000 --> 0:01:2,000
memetics is founded on the principle of Universal Darwinism.

20
0:01:20.33,000 --> 0:01:23,000
Darwin had this amazing idea.

21
0:01:23.33,000 --> 0:01:25,000
Indeed, some people say

22
0:01:25.33,000 --> 0:01:28,000
it's the best idea anybody ever had.

23
0:01:28.33,000 --> 0:01:32,000
Isn't that a wonderful thought, that there could be such a thing

24
0:01:32.33,000 --> 0:01:34,000
as a best idea anybody ever had?

25
0:01:34.33,000 --> 0:01:35,000
Do you think there could?

26
0:01:35.33,000 --> 0:01:36,000
Audience: No.

27
0:01:36.33,000 --> 0:01:37,000
(Laughter)

28
0:01:37.33,000 --> 0:01:39,000
Susan Blackmore: Someone says no, very loudly, from over there.

29
0:01:39.33,000 --> 0:01:43,000
Well, I say yes, and if there is, I give the prize to Darwin.

30
0:01:43.33,000 --> 0:01:45,000
Why?

31
0:01:45.33,000 --> 0:01:48,000
Because the idea was so simple,

32
0:01:48.33,000 --> 0:01:54,000
and yet it explains all design in the universe.

33
0:01:54.33,000 --> 0:01:56,000
I would say not just biological design,

34
0:01:56.33,000 --> 0:01:58,000
but all of the design that we think of as human design.

35
0:01:58.33,000 --> 0:02:,000
It's all just the same thing happening.

36
0:02:00.33,000 --> 0:02:02,000
What did Darwin say?

37
0:02:02.33,000 --> 0:02:04,000
I know you know the idea, natural selection,

38
0:02:04.33,000 --> 0:02:09,000
but let me just paraphrase "The Origin of Species," 1859,

39
0:02:09.33,000 --> 0:02:11,000
in a few sentences.

40
0:02:11.33,000 --> 0:02:14,000
What Darwin said was something like this:

41
0:02:14.33,000 --> 0:02:18,000
if you have creatures that vary, and that can't be doubted --

42
0:02:18.33,000 --> 0:02:21,000
I've been to the Galapagos, and I've measured the size of the beaks

43
0:02:21.33,000 --> 0:02:23,000
and the size of the turtle shells and so on, and so on.

44
0:02:23.33,000 --> 0:02:25,000
And 100 pages later.

45
0:02:25.33,000 --> 0:02:27,000
(Laughter)

46
0:02:27.33,000 --> 0:02:31,000
And if there is a struggle for life,

47
0:02:31.33,000 --> 0:02:34,000
such that nearly all of these creatures die --

48
0:02:34.33,000 --> 0:02:37,000
and this can't be doubted, I've read Malthus

49
0:02:37.33,000 --> 0:02:39,000
and I've calculated how long it would take for elephants

50
0:02:39.33,000 --> 0:02:42,000
to cover the whole world if they bred unrestricted, and so on and so on.

51
0:02:42.33,000 --> 0:02:46,000
And another 100 pages later.

52
0:02:46.33,000 --> 0:02:51,000
And if the very few that survive pass onto their offspring

53
0:02:51.33,000 --> 0:02:54,000
whatever it was that helped them survive,

54
0:02:54.33,000 --> 0:02:56,000
then those offspring must be better adapted

55
0:02:56.33,000 --> 0:02:58,000
to the circumstances in which all this happened

56
0:02:58.33,000 --> 0:03:01,000
than their parents were.

57
0:03:01.33,000 --> 0:03:03,000
You see the idea?

58
0:03:03.33,000 --> 0:03:05,000
If, if, if, then.

59
0:03:05.33,000 --> 0:03:07,000
He had no concept of the idea of an algorithm,

60
0:03:07.33,000 --> 0:03:1,000
but that's what he described in that book,

61
0:03:10.33,000 --> 0:03:13,000
and this is what we now know as the evolutionary algorithm.

62
0:03:13.33,000 --> 0:03:17,000
The principle is you just need those three things --

63
0:03:17.33,000 --> 0:03:2,000
variation, selection and heredity.

64
0:03:20.33,000 --> 0:03:24,000
And as Dan Dennett puts it, if you have those,

65
0:03:24.33,000 --> 0:03:26,000
then you must get evolution.

66
0:03:26.33,000 --> 0:03:31,000
Or design out of chaos, without the aid of mind.

67
0:03:31.33,000 --> 0:03:33,000
There's one word I love on that slide.

68
0:03:33.33,000 --> 0:03:35,000
What do you think my favorite word is?

69
0:03:35.33,000 --> 0:03:36,000
Audience: Chaos.

70
0:03:36.33,000 --> 0:03:39,000
SB: Chaos? No. What? Mind? No.

71
0:03:39.33,000 --> 0:03:4,000
Audience: Without.

72
0:03:40.33,000 --> 0:03:41,000
SB: No, not without.

73
0:03:41.33,000 --> 0:03:42,000
(Laughter)

74
0:03:42.33,000 --> 0:03:44,000
You try them all in order: Mmm...?

75
0:03:44.33,000 --> 0:03:45,000
Audience: Must.

76
0:03:45.33,000 --> 0:03:49,000
SB: Must, at must. Must, must.

77
0:03:49.33,000 --> 0:03:51,000
This is what makes it so amazing.

78
0:03:51.33,000 --> 0:03:54,000
You don't need a designer,

79
0:03:54.33,000 --> 0:03:57,000
or a plan, or foresight, or anything else.

80
0:03:57.33,000 --> 0:04:,000
If there's something that is copied with variation

81
0:04:00.33,000 --> 0:04:04,000
and it's selected, then you must get design appearing out of nowhere.

82
0:04:04.33,000 --> 0:04:06,000
You can't stop it.

83
0:04:06.33,000 --> 0:04:1,000
Must is my favorite word there.

84
0:04:11.33,000 --> 0:04:13,000
Now, what's this to do with memes?

85
0:04:13.33,000 --> 0:04:18,000
Well, the principle here applies to anything

86
0:04:18.33,000 --> 0:04:19,000
that is copied with variation and selection.

87
0:04:19.33,000 --> 0:04:22,000
We're so used to thinking in terms of biology,

88
0:04:22.33,000 --> 0:04:24,000
we think about genes this way.

89
0:04:24.33,000 --> 0:04:27,000
Darwin didn't, of course; he didn't know about genes.

90
0:04:27.33,000 --> 0:04:29,000
He talked mostly about animals and plants,

91
0:04:29.33,000 --> 0:04:32,000
but also about languages evolving and becoming extinct.

92
0:04:32.33,000 --> 0:04:34,000
But the principle of Universal Darwinism

93
0:04:34.33,000 --> 0:04:38,000
is that any information that is varied and selected

94
0:04:38.33,000 --> 0:04:4,000
will produce design.

95
0:04:40.33,000 --> 0:04:42,000
And this is what Richard Dawkins was on about

96
0:04:42.33,000 --> 0:04:45,000
in his 1976 bestseller, "The Selfish Gene."

97
0:04:45.33,000 --> 0:04:49,000
The information that is copied, he called the replicator.

98
0:04:49.33,000 --> 0:04:51,000
It selfishly copies.

99
0:04:51.33,000 --> 0:04:55,000
Not meaning it kind of sits around inside cells going, "I want to get copied."

100
0:04:55.33,000 --> 0:04:57,000
But that it will get copied if it can,

101
0:04:57.33,000 --> 0:04:59,000
regardless of the consequences.

102
0:05:00.33,000 --> 0:05:03,000
It doesn't care about the consequences because it can't,

103
0:05:03.33,000 --> 0:05:05,000
because it's just information being copied.

104
0:05:06.33,000 --> 0:05:07,000
And he wanted to get away

105
0:05:07.33,000 --> 0:05:1,000
from everybody thinking all the time about genes,

106
0:05:10.33,000 --> 0:05:13,000
and so he said, "Is there another replicator out there on the planet?"

107
0:05:13.33,000 --> 0:05:15,000
Ah, yes, there is.

108
0:05:15.33,000 --> 0:05:18,000
Look around you -- here will do, in this room.

109
0:05:18.33,000 --> 0:05:21,000
All around us, still clumsily drifting about

110
0:05:21.33,000 --> 0:05:24,000
in its primeval soup of culture, is another replicator.

111
0:05:24.33,000 --> 0:05:29,000
Information that we copy from person to person, by imitation,

112
0:05:29.33,000 --> 0:05:31,000
by language, by talking, by telling stories,

113
0:05:31.33,000 --> 0:05:34,000
by wearing clothes, by doing things.

114
0:05:34.33,000 --> 0:05:39,000
This is information copied with variation and selection.

115
0:05:39.33,000 --> 0:05:42,000
This is design process going on.

116
0:05:42.33,000 --> 0:05:45,000
He wanted a name for the new replicator.

117
0:05:45.33,000 --> 0:05:49,000
So, he took the Greek word "mimeme," which means that which is imitated.

118
0:05:49.33,000 --> 0:05:51,000
Remember that, that's the core definition:

119
0:05:52.33,000 --> 0:05:53,000
that which is imitated.

120
0:05:53.33,000 --> 0:05:56,000
And abbreviated it to meme, just because it sounds good

121
0:05:56.33,000 --> 0:05:59,000
and made a good meme, an effective spreading meme.

122
0:05:59.33,000 --> 0:06:02,000
So that's how the idea came about.

123
0:06:03.33,000 --> 0:06:06,000
It's important to stick with that definition.

124
0:06:06.33,000 --> 0:06:1,000
The whole science of memetics is much maligned,

125
0:06:10.33,000 --> 0:06:13,000
much misunderstood, much feared.

126
0:06:13.33,000 --> 0:06:16,000
But a lot of these problems can be avoided

127
0:06:16.33,000 --> 0:06:18,000
by remembering the definition.

128
0:06:18.33,000 --> 0:06:2,000
A meme is not equivalent to an idea.

129
0:06:20.33,000 --> 0:06:22,000
It's not an idea. It's not equivalent to anything else, really.

130
0:06:22.33,000 --> 0:06:24,000
Stick with the definition.

131
0:06:24.33,000 --> 0:06:26,000
It's that which is imitated,

132
0:06:26.33,000 --> 0:06:29,000
or information which is copied from person to person.

133
0:06:30.33,000 --> 0:06:31,000
So, let's see some memes.

134
0:06:31.33,000 --> 0:06:34,000
Well, you sir, you've got those glasses hung around your neck

135
0:06:34.33,000 --> 0:06:36,000
in that particularly fetching way.

136
0:06:36.33,000 --> 0:06:38,000
I wonder whether you invented that idea for yourself,

137
0:06:38.33,000 --> 0:06:4,000
or copied it from someone else?

138
0:06:40.33,000 --> 0:06:43,000
If you copied it from someone else, it's a meme.

139
0:06:43.33,000 --> 0:06:46,000
And what about, oh, I can't see any interesting memes here.

140
0:06:46.33,000 --> 0:06:49,000
All right everyone, who's got some interesting memes for me?

141
0:06:49.33,000 --> 0:06:51,000
Oh, well, your earrings,

142
0:06:51.33,000 --> 0:06:53,000
I don't suppose you invented the idea of earrings.

143
0:06:53.33,000 --> 0:06:55,000
You probably went out and bought them.

144
0:06:55.33,000 --> 0:06:57,000
There are plenty more in the shops.

145
0:06:57.33,000 --> 0:06:59,000
That's something that's passed on from person to person.

146
0:06:59.33,000 --> 0:07:02,000
All the stories that we're telling -- well, of course,

147
0:07:02.33,000 --> 0:07:06,000
TED is a great meme-fest, masses of memes.

148
0:07:06.33,000 --> 0:07:08,000
The way to think about memes, though,

149
0:07:08.33,000 --> 0:07:1,000
is to think, why do they spread?

150
0:07:10.33,000 --> 0:07:14,000
They're selfish information, they will get copied, if they can.

151
0:07:14.33,000 --> 0:07:17,000
But some of them will be copied because they're good,

152
0:07:17.33,000 --> 0:07:19,000
or true, or useful, or beautiful.

153
0:07:19.33,000 --> 0:07:21,000
Some of them will be copied even though they're not.

154
0:07:21.33,000 --> 0:07:23,000
Some, it's quite hard to tell why.

155
0:07:24.33,000 --> 0:07:27,000
There's one particular curious meme which I rather enjoy.

156
0:07:27.33,000 --> 0:07:3,000
And I'm glad to say, as I expected, I found it when I came here,

157
0:07:30.33,000 --> 0:07:32,000
and I'm sure all of you found it, too.

158
0:07:32.33,000 --> 0:07:35,000
You go to your nice, posh, international hotel somewhere,

159
0:07:36.33,000 --> 0:07:38,000
and you come in and you put down your clothes

160
0:07:38.33,000 --> 0:07:41,000
and you go to the bathroom, and what do you see?

161
0:07:41.33,000 --> 0:07:42,000
Audience: Bathroom soap.

162
0:07:42.33,000 --> 0:07:43,000
SB: Pardon?

163
0:07:43.33,000 --> 0:07:44,000
Audience: Soap.

164
0:07:44.33,000 --> 0:07:46,000
SB: Soap, yeah. What else do you see?

165
0:07:46.33,000 --> 0:07:47,000
Audience: (Inaudible)

166
0:07:47.33,000 --> 0:07:48,000
SB: Mmm mmm.

167
0:07:48.33,000 --> 0:07:49,000
Audience: Sink, toilet!

168
0:07:49.33,000 --> 0:07:51,000
SB: Sink, toilet, yes, these are all memes, they're all memes,

169
0:07:51.33,000 --> 0:07:54,000
but they're sort of useful ones, and then there's this one.

170
0:07:54.33,000 --> 0:07:57,000
(Laughter)

171
0:07:58.33,000 --> 0:08:,000
What is this one doing?

172
0:08:00.33,000 --> 0:08:01,000
(Laughter)

173
0:08:01.33,000 --> 0:08:03,000
This has spread all over the world.

174
0:08:03.33,000 --> 0:08:05,000
It's not surprising that you all found it

175
0:08:05.33,000 --> 0:08:07,000
when you arrived in your bathrooms here.

176
0:08:07.33,000 --> 0:08:12,000
But I took this photograph in a toilet at the back of a tent

177
0:08:12.33,000 --> 0:08:14,000
in the eco-camp in the jungle in Assam.

178
0:08:14.33,000 --> 0:08:15,000
(Laughter)

179
0:08:16.33,000 --> 0:08:19,000
Who folded that thing up there, and why?

180
0:08:19.33,000 --> 0:08:2,000
(Laughter)

181
0:08:20.33,000 --> 0:08:22,000
Some people get carried away.

182
0:08:22.33,000 --> 0:08:25,000
(Laughter)

183
0:08:26.33,000 --> 0:08:29,000
Other people are just lazy and make mistakes.

184
0:08:29.33,000 --> 0:08:32,000
Some hotels exploit the opportunity to put even more memes

185
0:08:32.33,000 --> 0:08:34,000
with a little sticker.

186
0:08:34.33,000 --> 0:08:35,000
(Laughter)

187
0:08:35.33,000 --> 0:08:37,000
What is this all about?

188
0:08:37.33,000 --> 0:08:39,000
I suppose it's there to tell you that somebody's

189
0:08:39.33,000 --> 0:08:41,000
cleaned the place, and it's all lovely.

190
0:08:41.33,000 --> 0:08:44,000
And you know, actually, all it tells you is that another person

191
0:08:44.33,000 --> 0:08:47,000
has potentially spread germs from place to place.

192
0:08:47.33,000 --> 0:08:48,000
(Laughter)

193
0:08:48.33,000 --> 0:08:5,000
So, think of it this way.

194
0:08:50.33,000 --> 0:08:52,000
Imagine a world full of brains

195
0:08:52.33,000 --> 0:08:55,000
and far more memes than can possibly find homes.

196
0:08:55.33,000 --> 0:08:58,000
The memes are all trying to get copied --

197
0:08:58.33,000 --> 0:09:01,000
trying, in inverted commas -- i.e.,

198
0:09:01.33,000 --> 0:09:04,000
that's the shorthand for, if they can get copied, they will.

199
0:09:04.33,000 --> 0:09:1,000
They're using you and me as their propagating, copying machinery,

200
0:09:10.33,000 --> 0:09:13,000
and we are the meme machines.

201
0:09:13.33,000 --> 0:09:15,000
Now, why is this important?

202
0:09:15.33,000 --> 0:09:17,000
Why is this useful, or what does it tell us?

203
0:09:17.33,000 --> 0:09:21,000
It gives us a completely new view of human origins

204
0:09:21.33,000 --> 0:09:22,000
and what it means to be human,

205
0:09:22.33,000 --> 0:09:26,000
all conventional theories of cultural evolution,

206
0:09:26.33,000 --> 0:09:28,000
of the origin of humans,

207
0:09:28.33,000 --> 0:09:32,000
and what makes us so different from other species.

208
0:09:32.33,000 --> 0:09:34,000
All other theories explaining the big brain, and language, and tool use

209
0:09:34.33,000 --> 0:09:36,000
and all these things that make us unique,

210
0:09:36.33,000 --> 0:09:39,000
are based upon genes.

211
0:09:39.33,000 --> 0:09:42,000
Language must have been useful for the genes.

212
0:09:42.33,000 --> 0:09:45,000
Tool use must have enhanced our survival, mating and so on.

213
0:09:45.33,000 --> 0:09:48,000
It always comes back, as Richard Dawkins complained

214
0:09:48.33,000 --> 0:09:51,000
all that long time ago, it always comes back to genes.

215
0:09:51.33,000 --> 0:09:55,000
The point of memetics is to say, "Oh no, it doesn't."

216
0:09:55.33,000 --> 0:09:58,000
There are two replicators now on this planet.

217
0:09:58.33,000 --> 0:10:01,000
From the moment that our ancestors,

218
0:10:01.33,000 --> 0:10:03,000
perhaps two and a half million years ago or so,

219
0:10:03.33,000 --> 0:10:07,000
began imitating, there was a new copying process.

220
0:10:07.33,000 --> 0:10:09,000
Copying with variation and selection.

221
0:10:09.33,000 --> 0:10:14,000
A new replicator was let loose, and it could never be --

222
0:10:14.33,000 --> 0:10:15,000
right from the start -- it could never be

223
0:10:15.33,000 --> 0:10:2,000
that human beings who let loose this new creature,

224
0:10:20.33,000 --> 0:10:23,000
could just copy the useful, beautiful, true things,

225
0:10:23.33,000 --> 0:10:25,000
and not copy the other things.

226
0:10:25.33,000 --> 0:10:28,000
While their brains were having an advantage from being able to copy --

227
0:10:28.33,000 --> 0:10:33,000
lighting fires, keeping fires going, new techniques of hunting,

228
0:10:33.33,000 --> 0:10:35,000
these kinds of things --

229
0:10:35.33,000 --> 0:10:38,000
inevitably they were also copying putting feathers in their hair,

230
0:10:38.33,000 --> 0:10:4,000
or wearing strange clothes, or painting their faces,

231
0:10:40.33,000 --> 0:10:41,000
or whatever.

232
0:10:41.33,000 --> 0:10:45,000
So, you get an arms race between the genes

233
0:10:45.33,000 --> 0:10:49,000
which are trying to get the humans to have small economical brains

234
0:10:49.33,000 --> 0:10:51,000
and not waste their time copying all this stuff,

235
0:10:51.33,000 --> 0:10:55,000
and the memes themselves, like the sounds that people made and copied --

236
0:10:56.33,000 --> 0:10:58,000
in other words, what turned out to be language --

237
0:10:58.33,000 --> 0:11:01,000
competing to get the brains to get bigger and bigger.

238
0:11:01.33,000 --> 0:11:05,000
So, the big brain, on this theory, is driven by the memes.

239
0:11:05.33,000 --> 0:11:09,000
This is why, in "The Meme Machine," I called it memetic drive.

240
0:11:09.33,000 --> 0:11:12,000
As the memes evolve, as they inevitably must,

241
0:11:12.33,000 --> 0:11:16,000
they drive a bigger brain that is better at copying the memes

242
0:11:16.33,000 --> 0:11:18,000
that are doing the driving.

243
0:11:18.33,000 --> 0:11:22,000
This is why we've ended up with such peculiar brains,

244
0:11:22.33,000 --> 0:11:25,000
that we like religion, and music, and art.

245
0:11:25.33,000 --> 0:11:28,000
Language is a parasite that we've adapted to,

246
0:11:28.33,000 --> 0:11:3,000
not something that was there originally for our genes,

247
0:11:30.33,000 --> 0:11:32,000
on this view.

248
0:11:32.33,000 --> 0:11:35,000
And like most parasites, it can begin dangerous,

249
0:11:35.33,000 --> 0:11:38,000
but then it coevolves and adapts,

250
0:11:38.33,000 --> 0:11:4,000
and we end up with a symbiotic relationship

251
0:11:40.33,000 --> 0:11:41,000
with this new parasite.

252
0:11:41.33,000 --> 0:11:43,000
And so, from our perspective,

253
0:11:43.33,000 --> 0:11:46,000
we don't realize that that's how it began.

254
0:11:46.33,000 --> 0:11:49,000
So, this is a view of what humans are.

255
0:11:49.33,000 --> 0:11:52,000
All other species on this planet are gene machines only,

256
0:11:52.33,000 --> 0:11:55,000
they don't imitate at all well, hardly at all.

257
0:11:55.33,000 --> 0:12:,000
We alone are gene machines and meme machines as well.

258
0:12:00.33,000 --> 0:12:04,000
The memes took a gene machine and turned it into a meme machine.

259
0:12:04.33,000 --> 0:12:06,000
But that's not all.

260
0:12:06.33,000 --> 0:12:09,000
We have a new kind of memes now.

261
0:12:09.33,000 --> 0:12:1,000
I've been wondering for a long time,

262
0:12:10.33,000 --> 0:12:12,000
since I've been thinking about memes a lot,

263
0:12:12.33,000 --> 0:12:14,000
is there a difference between the memes that we copy --

264
0:12:14.33,000 --> 0:12:16,000
the words we speak to each other,

265
0:12:16.33,000 --> 0:12:18,000
the gestures we copy, the human things --

266
0:12:18.33,000 --> 0:12:2,000
and all these technological things around us?

267
0:12:20.33,000 --> 0:12:24,000
I have always, until now, called them all memes,

268
0:12:24.33,000 --> 0:12:27,000
but I do honestly think now

269
0:12:27.33,000 --> 0:12:3,000
we need a new word for technological memes.

270
0:12:30.33,000 --> 0:12:33,000
Let's call them techno-memes or temes.

271
0:12:33.33,000 --> 0:12:36,000
Because the processes are getting different.

272
0:12:37.33,000 --> 0:12:4,000
We began, perhaps 5,000 years ago, with writing.

273
0:12:40.33,000 --> 0:12:47,000
We put the storage of memes out there on a clay tablet,

274
0:12:48.33,000 --> 0:12:5,000
but in order to get true temes and true teme machines,

275
0:12:50.33,000 --> 0:12:53,000
you need to get the variation, the selection and the copying,

276
0:12:53.33,000 --> 0:12:55,000
all done outside of humans.

277
0:12:55.33,000 --> 0:12:57,000
And we're getting there.

278
0:12:57.33,000 --> 0:12:59,000
We're at this extraordinary point where we're nearly there,

279
0:12:59.33,000 --> 0:13:01,000
that there are machines like that.

280
0:13:01.33,000 --> 0:13:03,000
And indeed, in the short time I've already been at TED,

281
0:13:03.33,000 --> 0:13:05,000
I see we're even closer than I thought we were before.

282
0:13:05.33,000 --> 0:13:11,000
So actually, now the temes are forcing our brains

283
0:13:11.33,000 --> 0:13:13,000
to become more like teme machines.

284
0:13:13.33,000 --> 0:13:16,000
Our children are growing up very quickly learning to read,

285
0:13:16.33,000 --> 0:13:18,000
learning to use machinery.

286
0:13:18.33,000 --> 0:13:19,000
We're going to have all kinds of implants,

287
0:13:19.33,000 --> 0:13:22,000
drugs that force us to stay awake all the time.

288
0:13:22.33,000 --> 0:13:24,000
We'll think we're choosing these things,

289
0:13:24.33,000 --> 0:13:27,000
but the temes are making us do it.

290
0:13:28.33,000 --> 0:13:29,000
So, we're at this cusp now

291
0:13:29.33,000 --> 0:13:33,000
of having a third replicator on our planet.

292
0:13:34.33,000 --> 0:13:39,000
Now, what about what else is going on out there in the universe?

293
0:13:39.33,000 --> 0:13:41,000
Is there anyone else out there?

294
0:13:41.33,000 --> 0:13:44,000
People have been asking this question for a long time.

295
0:13:44.33,000 --> 0:13:46,000
We've been asking it here at TED already.

296
0:13:46.33,000 --> 0:13:5,000
In 1961, Frank Drake made his famous equation,

297
0:13:50.33,000 --> 0:13:52,000
but I think he concentrated on the wrong things.

298
0:13:52.33,000 --> 0:13:54,000
It's been very productive, that equation.

299
0:13:54.33,000 --> 0:13:56,000
He wanted to estimate N,

300
0:13:56.33,000 --> 0:14:,000
the number of communicative civilizations out there in our galaxy,

301
0:14:00.33,000 --> 0:14:04,000
and he included in there the rate of star formation,

302
0:14:04.33,000 --> 0:14:08,000
the rate of planets, but crucially, intelligence.

303
0:14:08.33,000 --> 0:14:12,000
I think that's the wrong way to think about it.

304
0:14:12.33,000 --> 0:14:15,000
Intelligence appears all over the place, in all kinds of guises.

305
0:14:15.33,000 --> 0:14:17,000
Human intelligence is only one kind of a thing.

306
0:14:17.33,000 --> 0:14:2,000
But what's really important is the replicators you have

307
0:14:20.33,000 --> 0:14:24,000
and the levels of replicators, one feeding on the one before.

308
0:14:24.33,000 --> 0:14:29,000
So, I would suggest that we don't think intelligence,

309
0:14:29.33,000 --> 0:14:31,000
we think replicators.

310
0:14:31.33,000 --> 0:14:34,000
And on that basis, I've suggested a different kind of equation.

311
0:14:34.33,000 --> 0:14:36,000
A very simple equation.

312
0:14:36.33,000 --> 0:14:38,000
N, the same thing,

313
0:14:38.33,000 --> 0:14:41,000
the number of communicative civilizations out there

314
0:14:41.33,000 --> 0:14:43,000
[that] we might expect in our galaxy.

315
0:14:43.33,000 --> 0:14:47,000
Just start with the number of planets there are in our galaxy.

316
0:14:47.33,000 --> 0:14:51,000
The fraction of those which get a first replicator.

317
0:14:51.33,000 --> 0:14:55,000
The fraction of those that get the second replicator.

318
0:14:55.33,000 --> 0:14:57,000
The fraction of those that get the third replicator.

319
0:14:58.33,000 --> 0:15:01,000
Because it's only the third replicator that's going to reach out --

320
0:15:01.33,000 --> 0:15:04,000
sending information, sending probes, getting out there,

321
0:15:04.33,000 --> 0:15:06,000
and communicating with anywhere else.

322
0:15:06.33,000 --> 0:15:09,000
OK, so if we take that equation,

323
0:15:09.33,000 --> 0:15:14,000
why haven't we heard from anybody out there?

324
0:15:14.33,000 --> 0:15:18,000
Because every step is dangerous.

325
0:15:18.33,000 --> 0:15:21,000
Getting a new replicator is dangerous.

326
0:15:21.33,000 --> 0:15:23,000
You can pull through, we have pulled through,

327
0:15:23.33,000 --> 0:15:25,000
but it's dangerous.

328
0:15:25.33,000 --> 0:15:28,000
Take the first step, as soon as life appeared on this earth.

329
0:15:28.33,000 --> 0:15:3,000
We may take the Gaian view.

330
0:15:30.33,000 --> 0:15:33,000
I loved Peter Ward's talk yesterday -- it's not Gaian all the time.

331
0:15:33.33,000 --> 0:15:36,000
Actually, life forms produce things that kill themselves.

332
0:15:36.33,000 --> 0:15:39,000
Well, we did pull through on this planet.

333
0:15:39.33,000 --> 0:15:41,000
But then, a long time later, billions of years later,

334
0:15:41.33,000 --> 0:15:44,000
we got the second replicator, the memes.

335
0:15:44.33,000 --> 0:15:46,000
That was dangerous, all right.

336
0:15:46.33,000 --> 0:15:48,000
Think of the big brain.

337
0:15:48.33,000 --> 0:15:51,000
How many mothers do we have here?

338
0:15:51.33,000 --> 0:15:53,000
You know all about big brains.

339
0:15:53.33,000 --> 0:15:55,000
They are dangerous to give birth to,

340
0:15:55.33,000 --> 0:15:57,000
are agonizing to give birth to.

341
0:15:57.33,000 --> 0:15:58,000
(Laughter)

342
0:15:59.33,000 --> 0:16:01,000
My cat gave birth to four kittens, purring all the time.

343
0:16:01.33,000 --> 0:16:03,000
Ah, mm -- slightly different.

344
0:16:03.33,000 --> 0:16:05,000
(Laughter)

345
0:16:05.33,000 --> 0:16:08,000
But not only is it painful, it kills lots of babies,

346
0:16:08.33,000 --> 0:16:1,000
it kills lots of mothers,

347
0:16:10.33,000 --> 0:16:12,000
and it's very expensive to produce.

348
0:16:12.33,000 --> 0:16:14,000
The genes are forced into producing all this myelin,

349
0:16:14.33,000 --> 0:16:16,000
all the fat to myelinate the brain.

350
0:16:16.33,000 --> 0:16:18,000
Do you know, sitting here,

351
0:16:18.33,000 --> 0:16:22,000
your brain is using about 20 percent of your body's energy output

352
0:16:22.33,000 --> 0:16:24,000
for two percent of your body weight?

353
0:16:24.33,000 --> 0:16:26,000
It's a really expensive organ to run.

354
0:16:26.33,000 --> 0:16:28,000
Why? Because it's producing the memes.

355
0:16:28.33,000 --> 0:16:32,000
Now, it could have killed us off. It could have killed us off,

356
0:16:32.33,000 --> 0:16:34,000
and maybe it nearly did, but you see, we don't know.

357
0:16:34.33,000 --> 0:16:36,000
But maybe it nearly did.

358
0:16:36.33,000 --> 0:16:37,000
Has it been tried before?

359
0:16:37.33,000 --> 0:16:39,000
What about all those other species?

360
0:16:39.33,000 --> 0:16:41,000
Louise Leakey talked yesterday

361
0:16:41.33,000 --> 0:16:44,000
about how we're the only one in this branch left.

362
0:16:44.33,000 --> 0:16:46,000
What happened to the others?

363
0:16:46.33,000 --> 0:16:48,000
Could it be that this experiment in imitation,

364
0:16:48.33,000 --> 0:16:5,000
this experiment in a second replicator,

365
0:16:50.33,000 --> 0:16:54,000
is dangerous enough to kill people off?

366
0:16:54.33,000 --> 0:16:56,000
Well, we did pull through, and we adapted.

367
0:16:56.33,000 --> 0:16:59,000
But now, we're hitting, as I've just described,

368
0:16:59.33,000 --> 0:17:01,000
we're hitting the third replicator point.

369
0:17:01.33,000 --> 0:17:04,000
And this is even more dangerous --

370
0:17:04.33,000 --> 0:17:06,000
well, it's dangerous again.

371
0:17:06.33,000 --> 0:17:1,000
Why? Because the temes are selfish replicators

372
0:17:10.33,000 --> 0:17:13,000
and they don't care about us, or our planet, or anything else.

373
0:17:13.33,000 --> 0:17:16,000
They're just information, why would they?

374
0:17:17.33,000 --> 0:17:19,000
They are using us to suck up the planet's resources

375
0:17:19.33,000 --> 0:17:21,000
to produce more computers,

376
0:17:21.33,000 --> 0:17:24,000
and more of all these amazing things we're hearing about here at TED.

377
0:17:24.33,000 --> 0:17:28,000
Don't think, "Oh, we created the Internet for our own benefit."

378
0:17:28.33,000 --> 0:17:3,000
That's how it seems to us.

379
0:17:30.33,000 --> 0:17:34,000
Think, temes spreading because they must.

380
0:17:34.33,000 --> 0:17:36,000
We are the old machines.

381
0:17:36.33,000 --> 0:17:38,000
Now, are we going to pull through?

382
0:17:38.33,000 --> 0:17:4,000
What's going to happen?

383
0:17:40.33,000 --> 0:17:42,000
What does it mean to pull through?

384
0:17:42.33,000 --> 0:17:44,000
Well, there are kind of two ways of pulling through.

385
0:17:45.33,000 --> 0:17:47,000
One that is obviously happening all around us now,

386
0:17:47.33,000 --> 0:17:51,000
is that the temes turn us into teme machines,

387
0:17:51.33,000 --> 0:17:53,000
with these implants, with the drugs,

388
0:17:53.33,000 --> 0:17:56,000
with us merging with the technology.

389
0:17:56.33,000 --> 0:17:58,000
And why would they do that?

390
0:17:58.33,000 --> 0:18:,000
Because we are self-replicating.

391
0:18:00.33,000 --> 0:18:02,000
We have babies.

392
0:18:02.33,000 --> 0:18:05,000
We make new ones, and so it's convenient to piggyback on us,

393
0:18:05.33,000 --> 0:18:09,000
because we're not yet at the stage on this planet

394
0:18:09.33,000 --> 0:18:11,000
where the other option is viable.

395
0:18:11.33,000 --> 0:18:13,000
Although it's closer, I heard this morning,

396
0:18:13.33,000 --> 0:18:15,000
it's closer than I thought it was.

397
0:18:15.33,000 --> 0:18:18,000
Where the teme machines themselves will replicate themselves.

398
0:18:18.33,000 --> 0:18:22,000
That way, it wouldn't matter if the planet's climate

399
0:18:22.33,000 --> 0:18:24,000
was utterly destabilized,

400
0:18:24.33,000 --> 0:18:26,000
and it was no longer possible for humans to live here.

401
0:18:26.33,000 --> 0:18:28,000
Because those teme machines, they wouldn't need --

402
0:18:28.33,000 --> 0:18:3,000
they're not squishy, wet, oxygen-breathing,

403
0:18:30.33,000 --> 0:18:33,000
warmth-requiring creatures.

404
0:18:33.33,000 --> 0:18:35,000
They could carry on without us.

405
0:18:35.33,000 --> 0:18:38,000
So, those are the two possibilities.

406
0:18:38.33,000 --> 0:18:42,000
The second, I don't think we're that close.

407
0:18:42.33,000 --> 0:18:44,000
It's coming, but we're not there yet.

408
0:18:44.33,000 --> 0:18:46,000
The first, it's coming too.

409
0:18:46.33,000 --> 0:18:49,000
But the damage that is already being done

410
0:18:49.33,000 --> 0:18:54,000
to the planet is showing us how dangerous the third point is,

411
0:18:54.33,000 --> 0:18:57,000
that third danger point, getting a third replicator.

412
0:18:58.33,000 --> 0:19:,000
And will we get through this third danger point,

413
0:19:00.33,000 --> 0:19:03,000
like we got through the second and like we got through the first?

414
0:19:04.33,000 --> 0:19:06,000
Maybe we will, maybe we won't.

415
0:19:06.33,000 --> 0:19:09,000
I have no idea.

416
0:19:13.33,000 --> 0:19:23,000
(Applause)

417
0:19:24.33,000 --> 0:19:26,000
Chris Anderson: That was an incredible talk.

418
0:19:26.33,000 --> 0:19:28,000
SB: Thank you. I scared myself.

419
0:19:28.33,000 --> 0:19:29,000
CA: (Laughter)

