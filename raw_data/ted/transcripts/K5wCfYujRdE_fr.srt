1
0:00:,000 --> 0:00:07,000
Traducteur: Hugo Wagner Relecteur: Florence Divet

2
0:00:15.26,000 --> 0:00:17,000
Nous sommes pendant la Seconde Guerre mondiale,

3
0:00:17.26,000 --> 0:00:2,000
dans un camp de prisonniers allemand,

4
0:00:20.26,000 --> 0:00:23,000
et cet homme,

5
0:00:23.26,000 --> 0:00:26,000
Archie Cochrane,

6
0:00:26.26,000 --> 0:00:29,000
est un prisonnier de guerre et un médecin,

7
0:00:29.26,000 --> 0:00:32,000
et il a un problème.

8
0:00:32.26,000 --> 0:00:35,000
Le problème est que les hommes qu'il soigne

9
0:00:35.26,000 --> 0:00:37,000
souffrent

10
0:00:37.26,000 --> 0:00:4,000
d'une condition extrêmement douloureuse et débilitante

11
0:00:40.26,000 --> 0:00:43,000
qu'Archie ne comprend pas vraiment.

12
0:00:43.26,000 --> 0:00:45,000
Les symptômes

13
0:00:45.26,000 --> 0:00:48,000
sont d'horribles gonflements des fluides sous la peau.

14
0:00:48.26,000 --> 0:00:51,000
Mais il ne sait pas si c'est une infection, ou si c'est lié à la malnutrition.

15
0:00:51.26,000 --> 0:00:53,000
Il ne sait pas comment y remédier.

16
0:00:53.26,000 --> 0:00:56,000
Il travaille dans un environnement hostile.

17
0:00:56.26,000 --> 0:00:58,000
Les gens font des choses effroyables en temps de guerre.

18
0:00:58.26,000 --> 0:01:01,000
Les gardes du camp allemand s'ennuyaient

19
0:01:01.26,000 --> 0:01:03,000
Ils se mirent à tirer de manière complètement aléatoire à l’intérieur du camp de prisonniers

20
0:01:03.26,000 --> 0:01:05,000
pour s'amuser.

21
0:01:05.26,000 --> 0:01:07,000
Une fois, lors d’une occasion spécifique,

22
0:01:07.26,000 --> 0:01:1,000
l'un des gardes a même jeté une grenade dans les toilettes des prisonniers

23
0:01:10.26,000 --> 0:01:13,000
alors qu'elles étaient pleines de prisonniers.

24
0:01:13.26,000 --> 0:01:15,000
Il a dit avoir entendu des rires suspects.

25
0:01:15.26,000 --> 0:01:18,000
Archie Cochrane, en tant que médecin du camp,

26
0:01:18.26,000 --> 0:01:2,000
était l'un des premiers hommes à y entrer

27
0:01:20.26,000 --> 0:01:22,000
pour nettoyer le carnage.

28
0:01:22.26,000 --> 0:01:24,000
D'autre part,

29
0:01:24.26,000 --> 0:01:27,000
Archie souffrait lui-même de cette maladie.

30
0:01:27.26,000 --> 0:01:3,000
La situation semblait donc assez désespérée.

31
0:01:30.26,000 --> 0:01:32,000
Mais Archie Cochrane

32
0:01:32.26,000 --> 0:01:35,000
était un homme plein de ressources.

33
0:01:35.26,000 --> 0:01:38,000
Il avait déjà fait passer clandestinement de la vitamine C dans le camp,

34
0:01:38.26,000 --> 0:01:4,000
et il trouva le moyen

35
0:01:40.26,000 --> 0:01:42,000
de se procurer des provisions de marmite

36
0:01:42.26,000 --> 0:01:44,000
au marché noir.

37
0:01:44.26,000 --> 0:01:47,000
Certains d'entre vous se demandent maintenant ce qu'est la marmite.

38
0:01:47.26,000 --> 0:01:5,000
La marmite est une pâte à tartiner que les Anglais adorent.

39
0:01:50.26,000 --> 0:01:52,000
Ça ressemble à du pétrole brut.

40
0:01:52.26,000 --> 0:01:54,000
Son goût est...

41
0:01:54.26,000 --> 0:01:56,000
...épicé.

42
0:01:56.26,000 --> 0:01:58,000
De façon plus importante,

43
0:01:58.26,000 --> 0:02:,000
c'est une source riche

44
0:02:00.26,000 --> 0:02:02,000
en vitamine B12.

45
0:02:02.26,000 --> 0:02:05,000
Archie sépare alors les hommes sous ses soins aussi bien qu’il le peut

46
0:02:05.26,000 --> 0:02:07,000
en deux groupes égaux.

47
0:02:07.26,000 --> 0:02:09,000
Il donne à la moitié d’entre eux de la vitamine C.

48
0:02:09.26,000 --> 0:02:12,000
Il donne de la vitamine B12 à l'autre moitié.

49
0:02:12.26,000 --> 0:02:15,000
Il note ses résultats très soigneusement et méticuleusement

50
0:02:15.26,000 --> 0:02:17,000
dans un cahier.

51
0:02:17.26,000 --> 0:02:19,000
Après seulement quelques jours,

52
0:02:19.26,000 --> 0:02:21,000
il apparaît évident

53
0:02:21.26,000 --> 0:02:24,000
que quelle que soit l'origine de la maladie,

54
0:02:24.26,000 --> 0:02:27,000
la marmite en est le remède.

55
0:02:27.26,000 --> 0:02:3,000
Cochrane va donc voir les Allemands en charge du camp de prisonniers.

56
0:02:30.26,000 --> 0:02:32,000
Vous devez vous représenter à cet instant --

57
0:02:32.26,000 --> 0:02:34,000
oubliez cette photo, imaginez-vous un type

58
0:02:34.26,000 --> 0:02:37,000
avec une longue barbe rousse et un tas de cheveux roux.

59
0:02:37.26,000 --> 0:02:4,000
Il n’avait pas pu se raser -- une silhouette à la Billy Connolly.

60
0:02:40.26,000 --> 0:02:42,000
Cochrane commence à haranguer ces Allemands

61
0:02:42.26,000 --> 0:02:44,000
avec son accent écossais --

62
0:02:44.26,000 --> 0:02:47,000
dans un allemand courant, au passage, mais avec un accent écossais --

63
0:02:47.26,000 --> 0:02:5,000
et il leur explique que la culture allemande est la culture

64
0:02:50.26,000 --> 0:02:52,000
qui a donné Schiller et Goethe au monde.

65
0:02:52.26,000 --> 0:02:54,000
Il ne peut comprendre

66
0:02:54.26,000 --> 0:02:56,000
comment ce barbarisme peut être toléré.

67
0:02:56.26,000 --> 0:02:59,000
Il décharge sa frustration.

68
0:02:59.26,000 --> 0:03:02,000
Puis il retourne dans ses quartiers,

69
0:03:02.26,000 --> 0:03:05,000
il se décompose et pleure

70
0:03:05.26,000 --> 0:03:08,000
parce qu'il est convaincu que la situation est sans espoir.

71
0:03:10.26,000 --> 0:03:13,000
Mais un jeune médecin allemand

72
0:03:13.26,000 --> 0:03:16,000
ramasse le cahier d'Archie Cochrane

73
0:03:16.26,000 --> 0:03:2,000
et dit à ses collègues :

74
0:03:20.26,000 --> 0:03:25,000
« Cette preuve est irréfutable.

75
0:03:25.26,000 --> 0:03:28,000
Si nous ne fournissons pas des vitamines aux prisonniers,

76
0:03:28.26,000 --> 0:03:3,000
c'est un crime de guerre. »

77
0:03:30.26,000 --> 0:03:32,000
Le matin suivant,

78
0:03:32.26,000 --> 0:03:35,000
des provisions de vitamine B12 sont livrées au camp,

79
0:03:35.26,000 --> 0:03:38,000
et les prisonniers commencent à se rétablir.

80
0:03:39.26,000 --> 0:03:41,000
Je ne vous raconte pas maintenant cette histoire

81
0:03:41.26,000 --> 0:03:43,000
parce que je pense qu'Archie Cochrane est un type bien,

82
0:03:43.26,000 --> 0:03:47,000
bien qu'Archie Cochrane soit un type bien

83
0:03:47.26,000 --> 0:03:49,000
Je ne vous raconte même pas cette histoire

84
0:03:49.26,000 --> 0:03:51,000
parce que je pense qu'on devrait exploiter

85
0:03:51.26,000 --> 0:03:53,000
plus soigneusement les essais contrôlés aléatoires

86
0:03:53.26,000 --> 0:03:55,000
dans tous les aspects des politiques publiques,

87
0:03:55.26,000 --> 0:03:59,000
bien que je pense que ça serait complètement génial.

88
0:03:59.26,000 --> 0:04:01,000
Je vous raconte cette histoire

89
0:04:01.26,000 --> 0:04:04,000
parce qu'Archie Cochrane, durant toute sa vie,

90
0:04:04.26,000 --> 0:04:08,000
s'est battu contre une maladie terrible.

91
0:04:08.26,000 --> 0:04:12,000
Il a compris qu'elle était débilitante pour les individus

92
0:04:12.26,000 --> 0:04:14,000
et corrosive pour les sociétés.

93
0:04:14.26,000 --> 0:04:16,000
Il lui avait donné un nom.

94
0:04:16.26,000 --> 0:04:19,000
Il l'appelait le complexe de Dieu.

95
0:04:19.26,000 --> 0:04:23,000
Je peux décrire maintenant les symptômes du complexe de Dieu très, très aisément.

96
0:04:23.26,000 --> 0:04:26,000
Les symptômes du complexe sont que,

97
0:04:26.26,000 --> 0:04:29,000
peu importe la complexité du problème,

98
0:04:29.26,000 --> 0:04:32,000
vous avez la conviction absolument écrasante

99
0:04:32.26,000 --> 0:04:36,000
que votre solution au problème est infaillible.

100
0:04:36.26,000 --> 0:04:38,000
Archie était médecin.

101
0:04:38.26,000 --> 0:04:4,000
Il trainait donc beaucoup avec des médecins.

102
0:04:40.26,000 --> 0:04:43,000
Les médecins souffrent beaucoup du complexe de Dieu.

103
0:04:43.26,000 --> 0:04:45,000
Moi, je suis un économiste, je ne suis pas médecin,

104
0:04:45.26,000 --> 0:04:47,000
mais je rencontre tout le temps le complexe de Dieu autour de moi

105
0:04:47.26,000 --> 0:04:49,000
chez mes confrères économistes.

106
0:04:49.26,000 --> 0:04:51,000
Je le rencontre chez nos dirigeants d'entreprises.

107
0:04:51.26,000 --> 0:04:53,000
Je le rencontre chez les hommes politiques pour qui nous votons --

108
0:04:53.26,000 --> 0:04:57,000
des gens qui, face à un monde incroyablement compliqué,

109
0:04:57.26,000 --> 0:05:,000
sont malgré tout absolument convaincus

110
0:05:00.26,000 --> 0:05:03,000
qu'ils comprennent la façon dont le monde fonctionne.

111
0:05:03.26,000 --> 0:05:06,000
Vous savez, avec les prochains milliards d'individus dont on nous parle,

112
0:05:06.26,000 --> 0:05:08,000
le monde est tout simplement bien trop compliqué

113
0:05:08.26,000 --> 0:05:1,000
pour le comprendre de cette façon.

114
0:05:10.26,000 --> 0:05:12,000
Laissez-moi vous donner un exemple.

115
0:05:12.26,000 --> 0:05:14,000
Imaginez pour l'instant

116
0:05:14.26,000 --> 0:05:16,000
qu'à la place de Tim Harford devant vous,

117
0:05:16.26,000 --> 0:05:19,000
il y ait Hans Rosling en train de présenter ses graphiques.

118
0:05:19.26,000 --> 0:05:21,000
Vous connaissez Hans :

119
0:05:21.26,000 --> 0:05:23,000
le Mick Jagger de TED.

120
0:05:23.26,000 --> 0:05:25,000
(Rires)

121
0:05:25.26,000 --> 0:05:27,000
Il serait en train de vous montrer ces statistiques étonnantes,

122
0:05:27.26,000 --> 0:05:29,000
ces animations incroyables.

123
0:05:29.26,000 --> 0:05:31,000
Elles sont brillantes ; c'est un travail merveilleux.

124
0:05:31.26,000 --> 0:05:33,000
Mais prenez un graph typique d'Hans Rosling :

125
0:05:33.26,000 --> 0:05:36,000
pensez un instant, non pas à ce qu'il montre,

126
0:05:36.26,000 --> 0:05:39,000
mais pensez plutôt à ce qu'il ne montre pas.

127
0:05:39.26,000 --> 0:05:42,000
Il vous montrera le PIB par habitant,

128
0:05:42.26,000 --> 0:05:44,000
la population, la longévité,

129
0:05:44.26,000 --> 0:05:46,000
C’est à peu près tout.

130
0:05:46.26,000 --> 0:05:48,000
Trois ensembles de données pour chaque pays.

131
0:05:48.26,000 --> 0:05:5,000
Trois ensembles de données.

132
0:05:50.26,000 --> 0:05:52,000
Trois ensembles de données, ce n'est rien.

133
0:05:52.26,000 --> 0:05:54,000
Je veux dire, regardez ce graphique.

134
0:05:54.26,000 --> 0:05:56,000
Il a été réalisé par le physicien Cesar Hidalgo.

135
0:05:56.26,000 --> 0:05:58,000
Il travaille au MIT.

136
0:05:58.26,000 --> 0:06:,000
Vous ne pourrez pas y comprendre quoi que ce soit

137
0:06:00.26,000 --> 0:06:02,000
mais voilà à quoi ça ressemble.

138
0:06:02.26,000 --> 0:06:04,000
Cesar a parcouru la base de données

139
0:06:04.26,000 --> 0:06:07,000
de plus de 5000 produits différents,

140
0:06:07.26,000 --> 0:06:12,000
et il a utilisé les techniques d'analyse de réseau

141
0:06:12.26,000 --> 0:06:14,000
pour interroger cette base de données

142
0:06:14.26,000 --> 0:06:16,000
et pour représenter graphiquement les relations entre les différents produits.

143
0:06:16.26,000 --> 0:06:18,000
C'est un travail absolument merveilleux.

144
0:06:18.26,000 --> 0:06:21,000
Vous voyez toutes ces interconnexions, toutes ces interdépendances.

145
0:06:21.26,000 --> 0:06:23,000
Je pense que ce sera profondément utile

146
0:06:23.26,000 --> 0:06:26,000
pour comprendre les croissances économiques.

147
0:06:26.26,000 --> 0:06:28,000
Un travail remarquable.

148
0:06:28.26,000 --> 0:06:3,000
Cesar et moi avons essayé d'écrire un article pour le New York Times Magazine

149
0:06:30.26,000 --> 0:06:32,000
en expliquant comment ça fonctionne.

150
0:06:32.26,000 --> 0:06:34,000
Ce que nous avons appris

151
0:06:34.26,000 --> 0:06:36,000
est que le travail de Cesar est bien trop bon pour être expliqué

152
0:06:36.26,000 --> 0:06:38,000
dans le New York Times Magazine.

153
0:06:40.26,000 --> 0:06:43,000
5000 produits --

154
0:06:43.26,000 --> 0:06:45,000
ça n'est pas grand chose.

155
0:06:45.26,000 --> 0:06:47,000
5000 produits --

156
0:06:47.26,000 --> 0:06:49,000
imaginez-vous dénombrer chaque catégorie de produit

157
0:06:49.26,000 --> 0:06:51,000
dans les données de Cesar Hidalgo.

158
0:06:51.26,000 --> 0:06:53,000
Imaginez-vous avoir entendu une seconde

159
0:06:53.26,000 --> 0:06:55,000
par catégorie de produit.

160
0:06:55.26,000 --> 0:06:58,000
Dans la durée de cette session,

161
0:06:58.26,000 --> 0:07:,000
vous auriez compté les 5000.

162
0:07:00.26,000 --> 0:07:02,000
Imaginez faire la même chose

163
0:07:02.26,000 --> 0:07:05,000
pour tous les types de produits différents en vente à Walmart.

164
0:07:05.26,000 --> 0:07:08,000
Il y en a 100 000. Ça vous prendrait la journée.

165
0:07:08.26,000 --> 0:07:1,000
Imaginez maintenant que vous essayez de compter

166
0:07:10.26,000 --> 0:07:13,000
tous les différents produits et services spécifiques

167
0:07:13.26,000 --> 0:07:15,000
en vente dans une économie importante

168
0:07:15.26,000 --> 0:07:17,000
comme celles de Tokyo, Londres, ou New York.

169
0:07:17.26,000 --> 0:07:19,000
C'est encore plus difficile à Edinburgh

170
0:07:19.26,000 --> 0:07:22,000
parce que vous devez compter tout le whisky et le tartan.

171
0:07:22.26,000 --> 0:07:24,000
Si vous voulez dénombrer tous les produits et services

172
0:07:24.26,000 --> 0:07:26,000
en vente à New York --

173
0:07:26.26,000 --> 0:07:28,000
il y en a 10 milliards --

174
0:07:28.26,000 --> 0:07:31,000
cela vous prendrait 317 ans.

175
0:07:31.26,000 --> 0:07:34,000
C'est le niveau de complexité de l'économie que l'on a créée.

176
0:07:34.26,000 --> 0:07:36,000
Et je compte juste les grille-pains.

177
0:07:36.26,000 --> 0:07:38,000
Je n'essaie pas de résoudre le problème du Moyen-Orient.

178
0:07:39.26,000 --> 0:07:42,000
La complexité est ici incroyable.

179
0:07:42.26,000 --> 0:07:44,000
Pour vous mettre dans le contexte :

180
0:07:44.26,000 --> 0:07:46,000
les sociétés dans lesquelles nos cerveaux ont évolué

181
0:07:46.26,000 --> 0:07:48,000
offraient environ 300 produits et services.

182
0:07:48.26,000 --> 0:07:51,000
Vous pouviez les dénombrer en cinq minutes.

183
0:07:51.26,000 --> 0:07:54,000
Voilà donc la complexité du monde qui nous entoure.

184
0:07:54.26,000 --> 0:07:56,000
C'est peut-être la raison pour laquelle

185
0:07:56.26,000 --> 0:07:59,000
nous trouvons que le complexe de Dieu est si tentant.

186
0:07:59.26,000 --> 0:08:02,000
Nous avons tendance à nous replier et dire : « Nous pouvons dessiner une image,

187
0:08:02.26,000 --> 0:08:04,000
nous pouvons afficher des graphiques,

188
0:08:04.26,000 --> 0:08:07,000
nous comprenons comment ça marche. »

189
0:08:07.26,000 --> 0:08:09,000
Mais nous ne le comprenons pas

190
0:08:09.26,000 --> 0:08:11,000
Nous ne le comprenons jamais.

191
0:08:11.26,000 --> 0:08:13,000
Je n'essaye pas de propager un message nihiliste ici.

192
0:08:13.26,000 --> 0:08:15,000
Je ne dis pas que nous ne pouvons pas résoudre

193
0:08:15.26,000 --> 0:08:17,000
des problèmes compliqués dans un monde compliqué.

194
0:08:17.26,000 --> 0:08:19,000
Nous le pouvons clairement.

195
0:08:19.26,000 --> 0:08:21,000
Mais la façon dont nous les résolvons

196
0:08:21.26,000 --> 0:08:23,000
est faite d'humilité --

197
0:08:23.26,000 --> 0:08:25,000
pour renoncer au complexe de Dieu

198
0:08:25.26,000 --> 0:08:28,000
et pour utiliser une technique de résolution qui fonctionne.

199
0:08:28.26,000 --> 0:08:31,000
Nous avons une technique de résolution qui marche.

200
0:08:31.26,000 --> 0:08:33,000
Montrez-moi

201
0:08:33.26,000 --> 0:08:35,000
un système complexe couronné de succès,

202
0:08:35.26,000 --> 0:08:38,000
et je vous montrerai un système

203
0:08:38.26,000 --> 0:08:4,000
qui a évolué par tâtonnements successifs.

204
0:08:40.26,000 --> 0:08:42,000
Voici un exemple.

205
0:08:42.26,000 --> 0:08:45,000
Ce bébé est né par tâtonnements successifs.

206
0:08:46.26,000 --> 0:08:49,000
Je me rends compte que c'est une déclaration ambiguë.

207
0:08:49.26,000 --> 0:08:51,000
Peut-être devrais-je la clarifier.

208
0:08:51.26,000 --> 0:08:54,000
Ce bébé est un corps humain : il a évolué.

209
0:08:54.26,000 --> 0:08:56,000
Qu'est-ce que l'évolution ?

210
0:08:56.26,000 --> 0:08:59,000
Pendant des millions d'années, une variation et une sélection,

211
0:08:59.26,000 --> 0:09:02,000
une variation et une sélection --

212
0:09:02.26,000 --> 0:09:04,000
un essai et une erreur,

213
0:09:04.26,000 --> 0:09:07,000
un essai et une erreur.

214
0:09:07.26,000 --> 0:09:09,000
Il n'y a pas que les systèmes biologiques

215
0:09:09.26,000 --> 0:09:11,000
qui produisent des miracles via l'essai et l'erreur.

216
0:09:11.26,000 --> 0:09:13,000
Vous pourriez l'utiliser dans un contexte industriel.

217
0:09:13.26,000 --> 0:09:15,000
Disons que vous vouliez fabriquer un détergent.

218
0:09:15.26,000 --> 0:09:17,000
Disons que vous êtes Unilever

219
0:09:17.26,000 --> 0:09:2,000
et que vous voulez fabriquer un détergent dans une usine près de Liverpool.

220
0:09:20.26,000 --> 0:09:22,000
Comment faites-vous ?

221
0:09:22.26,000 --> 0:09:25,000
Vous avez ce grand réservoir plein de détergent liquide.

222
0:09:25.26,000 --> 0:09:27,000
Vous le pompez à haute pression grâce à un ajutage.

223
0:09:27.26,000 --> 0:09:3,000
Vous créez un pulvérisateur de détergent.

224
0:09:30.26,000 --> 0:09:32,000
Puis le pulvérisateur sèche et ça devient de la poudre.

225
0:09:32.26,000 --> 0:09:34,000
Ça tombe par terre.

226
0:09:34.26,000 --> 0:09:36,000
Vous le ramassez, vous le mettez dans des boîtes en carton.

227
0:09:36.26,000 --> 0:09:38,000
Vous le vendez dans un supermarché.

228
0:09:38.26,000 --> 0:09:4,000
Vous gagnez plein d'argent.

229
0:09:40.26,000 --> 0:09:43,000
Comment concevez-vous l'ajutage ?

230
0:09:43.26,000 --> 0:09:46,000
Cela s'avère très important.

231
0:09:46.26,000 --> 0:09:48,000
Si vous souscrivez au complexe de Dieu,

232
0:09:48.26,000 --> 0:09:51,000
vous vous dénichez un petit dieu.

233
0:09:51.26,000 --> 0:09:54,000
Vous dénichez un mathématicien, un physicien,

234
0:09:54.26,000 --> 0:09:57,000
quelqu'un qui comprend la dynamique de ce fluide.

235
0:09:57.26,000 --> 0:10:,000
Et il ou elle

236
0:10:00.26,000 --> 0:10:03,000
calculera le design optimal de l'ajutage.

237
0:10:03.26,000 --> 0:10:05,000
C'est ce qu'a fait Unilever, et ça n'a pas marché.

238
0:10:05.26,000 --> 0:10:07,000
C'était trop compliqué.

239
0:10:07.26,000 --> 0:10:1,000
Même ce problème était trop compliqué.

240
0:10:10.26,000 --> 0:10:13,000
Mais le professeur de génétique Steve Jones

241
0:10:13.26,000 --> 0:10:16,000
décrit comment Unilever a en fait résolu le problème.

242
0:10:16.26,000 --> 0:10:18,000
Par essais et erreurs,

243
0:10:18.26,000 --> 0:10:2,000
variations et sélections.

244
0:10:20.26,000 --> 0:10:22,000
Vous prenez un ajutage

245
0:10:22.26,000 --> 0:10:26,000
et vous créez 10 variations au hasard sur l'ajutage.

246
0:10:26.26,000 --> 0:10:29,000
Vous les essayez toutes les 10, et vous gardez celle qui marche le mieux.

247
0:10:29.26,000 --> 0:10:31,000
Vous créez 10 variations sur celui-ci.

248
0:10:31.26,000 --> 0:10:34,000
Vous les essayez toutes les 10. Vous gardez celle qui marche le mieux.

249
0:10:34.26,000 --> 0:10:36,000
Vous essayez 10 variations sur celui-là.

250
0:10:36.26,000 --> 0:10:38,000
Vous voyez comment ça fonctionne, n'est-ce pas ?

251
0:10:38.26,000 --> 0:10:4,000
Après 45 générations,

252
0:10:40.26,000 --> 0:10:42,000
vous obtenez cet ajutage incroyable.

253
0:10:42.26,000 --> 0:10:44,000
Il ressemble un peu à une pièce d'échecs.

254
0:10:44.26,000 --> 0:10:47,000
Il fonctionne de manière absolument brillante.

255
0:10:47.26,000 --> 0:10:49,000
Nous n'avons aucune idée

256
0:10:49.26,000 --> 0:10:51,000
de pourquoi ça fonctionne,

257
0:10:51.26,000 --> 0:10:53,000
vraiment aucune idée.

258
0:10:53.26,000 --> 0:10:55,000
Dès l'instant où vous sortez du complexe de Dieu --

259
0:10:55.26,000 --> 0:10:57,000
essayons d'avoir un ensemble de choses,

260
0:10:57.26,000 --> 0:11:,000
et d'avoir un moyen systématique pour déterminer ce qui marche bien et mal.

261
0:11:00.26,000 --> 0:11:02,000
Vous pouvez résoudre votre problème.

262
0:11:02.26,000 --> 0:11:04,000
Ce procédé par tâtonnements successifs

263
0:11:04.26,000 --> 0:11:07,000
est en fait bien plus répandu dans les institutions qui fonctionnent

264
0:11:07.26,000 --> 0:11:09,000
que nous daignons le reconnaitre.

265
0:11:09.26,000 --> 0:11:12,000
Nous avons beaucoup entendu parler du fonctionnement des économies.

266
0:11:12.26,000 --> 0:11:16,000
L'économie américaine est toujours la plus grande économie au monde.

267
0:11:16.26,000 --> 0:11:19,000
Comment est-elle devenue la plus grande économie mondiale ?

268
0:11:19.26,000 --> 0:11:21,000
Je pourrais vous donner toutes sortes de faits et de chiffres

269
0:11:21.26,000 --> 0:11:23,000
sur l'économie américaine,

270
0:11:23.26,000 --> 0:11:26,000
mais je pense que le plus marquant est celui-ci :

271
0:11:26.26,000 --> 0:11:29,000
10% des entreprises américaines

272
0:11:29.26,000 --> 0:11:32,000
disparaissent chaque année.

273
0:11:32.26,000 --> 0:11:35,000
C'est un énorme taux d'échec.

274
0:11:35.26,000 --> 0:11:37,000
C'est bien plus que le taux d'échec des Américains par exemple.

275
0:11:37.26,000 --> 0:11:4,000
10% des Américains ne disparaissent pas chaque année.

276
0:11:40.26,000 --> 0:11:42,000
Ce qui nous amène à conclure

277
0:11:42.26,000 --> 0:11:45,000
que les entreprises américaines échouent plus vite que les Américains,

278
0:11:45.26,000 --> 0:11:48,000
et donc que les entreprises américaines évoluent plus vite que les Américains.

279
0:11:48.26,000 --> 0:11:51,000
Au final, elles auront évolué jusqu'à un tel degré de perfection

280
0:11:51.26,000 --> 0:11:54,000
qu'elles feront de nous leurs animaux domestiques.

281
0:11:54.26,000 --> 0:11:56,000
(Rires)

282
0:11:56.26,000 --> 0:11:59,000
Si, bien sûr, tel n'est pas déjà le cas.

283
0:11:59.26,000 --> 0:12:02,000
Je me pose la question parfois.

284
0:12:02.26,000 --> 0:12:04,000
Mais c'est ce procédé par tâtonnements successifs

285
0:12:04.26,000 --> 0:12:08,000
qui explique cette grande divergence,

286
0:12:08.26,000 --> 0:12:11,000
cet incroyable accomplissement des économies occidentales.

287
0:12:11.26,000 --> 0:12:14,000
Ce n'est pas dû au fait que vous ayez placé une personne incroyablement douée aux commandes.

288
0:12:14.26,000 --> 0:12:16,000
C'est l'aboutissement d'essais et d'erreurs.

289
0:12:16.26,000 --> 0:12:18,000
Je n'arrête pas de parler de ça

290
0:12:18.26,000 --> 0:12:2,000
depuis deux mois,

291
0:12:20.26,000 --> 0:12:22,000
et les gens me disent parfois :

292
0:12:22.26,000 --> 0:12:24,000
« Voyons, Tim, c'est assez évident.

293
0:12:24.26,000 --> 0:12:26,000
Évidemment que le tâtonnement successif est très important.

294
0:12:26.26,000 --> 0:12:28,000
Évidemment que l'expérimentation est très importante.

295
0:12:28.26,000 --> 0:12:31,000
Pourquoi cours-tu donc partout pour dire cette chose évidente ? »

296
0:12:31.26,000 --> 0:12:33,000
Je dis : « Bon, d'accord.

297
0:12:33.26,000 --> 0:12:35,000
Vous pensez que c'est évident ?

298
0:12:35.26,000 --> 0:12:37,000
J'admettrai que c'est évident

299
0:12:37.26,000 --> 0:12:39,000
quand les écoles

300
0:12:39.26,000 --> 0:12:42,000
commenceront à enseigner aux enfants

301
0:12:42.26,000 --> 0:12:45,000
qu'il y a des problèmes qui n'ont pas de réponse exacte.

302
0:12:45.26,000 --> 0:12:48,000
Arrêtez de leur donner des listes de questions

303
0:12:48.26,000 --> 0:12:5,000
qui ont toutes une réponse.

304
0:12:50.26,000 --> 0:12:52,000
Comme s'il y avait une figure d'autorité dans le coin

305
0:12:52.26,000 --> 0:12:54,000
derrière le bureau de l'enseignant qui connaissait toutes les réponses.

306
0:12:54.26,000 --> 0:12:56,000
Si vous ne pouvez pas trouver les réponses,

307
0:12:56.26,000 --> 0:12:58,000
vous devez être fainéant, ou stupide.

308
0:12:58.26,000 --> 0:13:,000
Quand les écoles arrêteront de faire tout le temps ça,

309
0:13:00.26,000 --> 0:13:02,000
j'admettrai que, oui,

310
0:13:02.26,000 --> 0:13:04,000
c'est évident que l'essai et l'erreur est une bonne chose.

311
0:13:04.26,000 --> 0:13:07,000
Quand un homme politique prendra position

312
0:13:07.26,000 --> 0:13:09,000
lors d'une campagne pour être élu

313
0:13:09.26,000 --> 0:13:11,000
et dira : « Je veux réparer notre système de santé.

314
0:13:11.26,000 --> 0:13:13,000
Je veux réparer notre système éducatif.

315
0:13:13.26,000 --> 0:13:16,000
Je n'ai aucune idée de la façon de procéder.

316
0:13:16.26,000 --> 0:13:18,000
J'ai une demi-douzaine d'idées.

317
0:13:18.26,000 --> 0:13:21,000
Nous allons toutes les tester. Elles échoueront probablement toutes.

318
0:13:21.26,000 --> 0:13:23,000
Puis nous essayerons d'autres idées.

319
0:13:23.26,000 --> 0:13:25,000
Nous en trouverons qui fonctionnent. Nous les adopterons.

320
0:13:25.26,000 --> 0:13:27,000
Nous nous débarrasserons de celles qui ne fonctionnent pas. »

321
0:13:27.26,000 --> 0:13:3,000
Quand un homme politique fera campagne sur ce programme,

322
0:13:30.26,000 --> 0:13:33,000
et plus important, quand les électeurs comme vous et moi

323
0:13:33.26,000 --> 0:13:35,000
voudront voter pour ce genre d'homme politique,

324
0:13:35.26,000 --> 0:13:37,000
alors j'admettrai

325
0:13:37.26,000 --> 0:13:4,000
qu'il est évident que l'expérimentation par tâtonnements fonctionne -- merci.

326
0:13:40.26,000 --> 0:13:44,000
(Applaudissements)

327
0:13:44.26,000 --> 0:13:47,000
Jusqu'à ce que ça arrive,

328
0:13:47.26,000 --> 0:13:49,000
je vais continuer à parler partout de l'expérimentation par tâtonnements

329
0:13:49.26,000 --> 0:13:52,000
et de pourquoi nous devrions abandonner le complexe de Dieu.

330
0:13:52.26,000 --> 0:13:55,000
Parce qu'il est dur

331
0:13:55.26,000 --> 0:13:57,000
d'admettre notre propre faillibilité.

332
0:13:57.26,000 --> 0:13:59,000
C'est si pénible.

333
0:13:59.26,000 --> 0:14:02,000
Archie Cochrane comprenait ça aussi bien que quiconque.

334
0:14:02.26,000 --> 0:14:04,000
Il y a une expérience qu'il a menée

335
0:14:04.26,000 --> 0:14:06,000
plusieurs années après la Seconde Guerre mondiale.

336
0:14:06.26,000 --> 0:14:09,000
Il voulait tester

337
0:14:09.26,000 --> 0:14:11,000
la question de savoir à quel endroit

338
0:14:11.26,000 --> 0:14:13,000
les patients devraient se rétablir

339
0:14:13.26,000 --> 0:14:15,000
après une attaque cardiaque.

340
0:14:15.26,000 --> 0:14:18,000
Devraient-ils se rétablir dans un service cardiologique spécialisé à l'hôpital,

341
0:14:18.26,000 --> 0:14:21,000
ou devraient-ils se rétablir chez eux ?

342
0:14:21.26,000 --> 0:14:24,000
Tous les cardiologues ont essayé de l'arrêter.

343
0:14:24.26,000 --> 0:14:27,000
Ils avaient le complexe de Dieu à la pelle.

344
0:14:27.26,000 --> 0:14:3,000
Ils savaient que leurs hôpitaux étaient le bon endroit pour les patients.

345
0:14:30.26,000 --> 0:14:32,000
Ils savaient que cela allait contre l'éthique

346
0:14:32.26,000 --> 0:14:35,000
de mener un essai ou une expérimentation quelconque.

347
0:14:35.26,000 --> 0:14:37,000
Néanmoins, Archie a réussi à obtenir la permission de le faire.

348
0:14:37.26,000 --> 0:14:39,000
Il a mené ses essais.

349
0:14:39.26,000 --> 0:14:41,000
Après avoir mené les essais pendant un moment,

350
0:14:41.26,000 --> 0:14:43,000
il a rassemblé tous ses collègues ensemble

351
0:14:43.26,000 --> 0:14:45,000
autour de sa table,

352
0:14:45.26,000 --> 0:14:47,000
et il a dit : « Eh bien, messieurs,

353
0:14:47.26,000 --> 0:14:49,000
nous avons des résultats préliminaires.

354
0:14:49.26,000 --> 0:14:51,000
Ils ne sont pas statistiquement significatifs.

355
0:14:51.26,000 --> 0:14:54,000
Mais nous avons quelque chose.

356
0:14:54.26,000 --> 0:14:57,000
Il s'avère que vous avez raison et que j'ai tort.

357
0:14:57.26,000 --> 0:14:59,000
Il est dangereux pour les patients

358
0:14:59.26,000 --> 0:15:01,000
de se rétablir d'attaques cardiaques à la maison.

359
0:15:01.26,000 --> 0:15:04,000
Ils devraient être à l'hôpital. »

360
0:15:04.26,000 --> 0:15:06,000
Il y a ce tintamarre, et tous les médecins se mettent à taper du poing sur la table

361
0:15:06.26,000 --> 0:15:09,000
et ils disent : « Nous avons toujours dit que tu allais à l'encontre de la déontologie, Archie.

362
0:15:09.26,000 --> 0:15:12,000
Tu tues des gens avec tes tests cliniques. Tu dois les arrêter maintenant.

363
0:15:12.26,000 --> 0:15:14,000
Ferme-les immédiatement. »

364
0:15:14.26,000 --> 0:15:16,000
Et il y a ce grand brouhaha.

365
0:15:16.26,000 --> 0:15:18,000
Archie le laisse s'éteindre.

366
0:15:18.26,000 --> 0:15:2,000
Puis il dit : « Eh bien, c'est très intéressant, messieurs,

367
0:15:20.26,000 --> 0:15:23,000
car lorsque je vous ai donné le tableau des résultats,

368
0:15:23.26,000 --> 0:15:27,000
j'ai permuté les deux colonnes entre elles.

369
0:15:27.26,000 --> 0:15:29,000
Il s'avère que vos hôpitaux tuent les gens,

370
0:15:29.26,000 --> 0:15:31,000
et qu'ils devraient être chez eux.

371
0:15:31.26,000 --> 0:15:34,000
Voulez-vous arrêter les essais maintenant,

372
0:15:34.26,000 --> 0:15:37,000
ou devrions-nous attendre avant d'avoir des résultats solides ? »

373
0:15:38.26,000 --> 0:15:4,000
Un froid glacial

374
0:15:40.26,000 --> 0:15:43,000
s'abattit sur la salle de réunion.

375
0:15:43.26,000 --> 0:15:46,000
Mais Cochrane avait l'habitude de faire ce genre de chose.

376
0:15:46.26,000 --> 0:15:48,000
La raison pour laquelle il faisait ça

377
0:15:48.26,000 --> 0:15:5,000
est qu'il avait compris

378
0:15:50.26,000 --> 0:15:52,000
qu'il est bien plus facile

379
0:15:52.26,000 --> 0:15:54,000
de prendre position et dire :

380
0:15:54.26,000 --> 0:15:56,000
« Ici, dans mon propre petit monde,

381
0:15:56.26,000 --> 0:15:58,000
je suis un dieu, je comprends tout.

382
0:15:58.26,000 --> 0:16:,000
Je ne veux pas que mes opinions soient remises en question.

383
0:16:00.26,000 --> 0:16:03,000
Je ne veux pas que mes propres conclusions soient analysées. »

384
0:16:03.26,000 --> 0:16:05,000
Il est tellement plus aisé

385
0:16:05.26,000 --> 0:16:08,000
de simplement faire la loi.

386
0:16:08.26,000 --> 0:16:1,000
Cochrane avait compris

387
0:16:10.26,000 --> 0:16:12,000
que l'incertitude, la faillibilité,

388
0:16:12.26,000 --> 0:16:14,000
le fait d'être contesté, font mal.

389
0:16:14.26,000 --> 0:16:18,000
Et que vous avez parfois besoin d'être secoué hors de cette façon de pensée.

390
0:16:18.26,000 --> 0:16:21,000
Maintenant, je ne vais pas prétendre que c'est facile.

391
0:16:21.26,000 --> 0:16:23,000
Ça n'est pas facile.

392
0:16:23.26,000 --> 0:16:25,000
C'est incroyablement douloureux.

393
0:16:25.26,000 --> 0:16:27,000
Depuis que j'ai commencé à parler de ce sujet

394
0:16:27.26,000 --> 0:16:29,000
et à me documenter sur ce sujet,

395
0:16:29.26,000 --> 0:16:31,000
j'ai vraiment été hanté par quelque chose

396
0:16:31.26,000 --> 0:16:33,000
qu'un mathématicien japonais a dit sur le sujet.

397
0:16:33.26,000 --> 0:16:35,000
Peu de temps après la guerre,

398
0:16:35.26,000 --> 0:16:38,000
ce jeune homme, Yutaka Taniyama,

399
0:16:38.26,000 --> 0:16:4,000
a développé une conjecture incroyable

400
0:16:40.26,000 --> 0:16:42,000
appelée la Conjecture de Taniyama-Shimura.

401
0:16:42.26,000 --> 0:16:45,000
Elle s’avéra être absolument fondamentale

402
0:16:45.26,000 --> 0:16:47,000
plusieurs décennies plus tard,

403
0:16:47.26,000 --> 0:16:49,000
pour prouver le dernier théorème de Fermat.

404
0:16:49.26,000 --> 0:16:51,000
En fait, il s'avère qu'elle est équivalente

405
0:16:51.26,000 --> 0:16:53,000
à démontrer le dernier théorème de Fermat.

406
0:16:53.26,000 --> 0:16:57,000
Vous en démontrez un, vous démontrez l'autre.

407
0:16:57.26,000 --> 0:17:,000
Mais c'était toujours resté une conjecture.

408
0:17:00.26,000 --> 0:17:03,000
Taniyama a essayé, encore et encore,

409
0:17:03.26,000 --> 0:17:06,000
et il n'arrivait jamais à montrer qu'elle était vraie.

410
0:17:06.26,000 --> 0:17:09,000
Peu de temps avant son 30ème anniversaire en 1958,

411
0:17:09.26,000 --> 0:17:13,000
Yutaka Taniyama se donna la mort.

412
0:17:13.26,000 --> 0:17:15,000
Son ami, Goro Shimura,

413
0:17:15.26,000 --> 0:17:17,000
qui travaillait sur les mathématiques avec lui,

414
0:17:17.26,000 --> 0:17:2,000
plusieurs décennies plus tard, a réfléchi sur la vie de Taniyama.

415
0:17:22.26,000 --> 0:17:25,000
Il a dit :

416
0:17:25.26,000 --> 0:17:27,000
« Il n'était pas quelqu'un de très soigneux

417
0:17:27.26,000 --> 0:17:29,000
en tant que mathématicien.

418
0:17:29.26,000 --> 0:17:32,000
Il faisait beaucoup d'erreurs.

419
0:17:32.26,000 --> 0:17:36,000
Mais il faisait des erreurs dans la bonne direction.

420
0:17:36.26,000 --> 0:17:39,000
J'ai essayé de l'égaler,

421
0:17:39.26,000 --> 0:17:41,000
mais j'ai compris

422
0:17:41.26,000 --> 0:17:43,000
qu'il était très difficile

423
0:17:43.26,000 --> 0:17:46,000
de commettre de bonnes erreurs. »

424
0:17:46.26,000 --> 0:17:48,000
Merci.

425
0:17:48.26,000 --> 0:18:,000
(Applaudissements)

