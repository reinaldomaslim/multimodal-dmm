1
0:00:,000 --> 0:00:07,000
Traductor: Lidia Cámara de la Fuente Revisor: Sebastian Betti

2
0:00:12.56,000 --> 0:00:13,000
Les guste o no,

3
0:00:13.92,000 --> 0:00:18,000
la transparencia radical y la toma algorítmica de decisiones llegarán rápido

4
0:00:19.32,000 --> 0:00:2,000
y cambiarán su vida.

5
0:00:21.32,000 --> 0:00:23,000
Esto se debe a que ahora es fácil tomar algoritmos,

6
0:00:24.16,000 --> 0:00:25,000
incorporarlos en computadoras

7
0:00:26.08,000 --> 0:00:28,000
y juntar todos los datos que dejan sobre Uds.

8
0:00:29.04,000 --> 0:00:3,000
por todas partes.

9
0:00:30.44,000 --> 0:00:31,000
Y al saber cómo son Uds.,

10
0:00:32.16,000 --> 0:00:34,000
luego se instruye a las computadoras para que interactúen con Uds.

11
0:00:35.12,000 --> 0:00:37,000
mucho mejor de lo que lo haría la mayoría de las personas.

12
0:00:38.16,000 --> 0:00:39,000
Bueno, eso puede sonar aterrador.

13
0:00:39.8,000 --> 0:00:42,000
He estado haciendo esto por mucho tiempo y me di cuenta de que me encanta.

14
0:00:44.159,000 --> 0:00:46,000
Mi objetivo ha sido tener un trabajo significativo

15
0:00:46.84,000 --> 0:00:48,000
y relaciones significativas con mis compañeros de trabajo,

16
0:00:49.72,000 --> 0:00:51,000
y aprendí que no podría tener eso

17
0:00:51.8,000 --> 0:00:55,000
sin tener transparencia radical y una toma de decisiones algorítmica.

18
0:00:56.68,000 --> 0:00:58,000
Y les quiero mostrar por qué es eso,

19
0:00:58.72,000 --> 0:00:59,000
les quiero mostrar cómo funciona.

20
0:01:00.44,000 --> 0:01:02,000
Y les advierto que las cosas que les mostraré

21
0:01:02.66,000 --> 0:01:04,000
posiblemente sean un poco chocantes.

22
0:01:05.76,000 --> 0:01:08,000
Desde que era un niño, he tenido una memoria terrible,

23
0:01:10.12,000 --> 0:01:12,000
y no me gustaba seguir las instrucciones,

24
0:01:12.32,000 --> 0:01:14,000
no era bueno siguiendo instrucciones,

25
0:01:14.76,000 --> 0:01:17,000
pero me encantaba averiguar cómo funcionaban las cosas.

26
0:01:18.68,000 --> 0:01:19,000
Cuando tenía 12 años,

27
0:01:20.08,000 --> 0:01:23,000
odiaba ir a la escuela, pero me enamoré del comercio de mercados.

28
0:01:23.92,000 --> 0:01:24,000
Era caddie en ese entonces,

29
0:01:25.6,000 --> 0:01:26,000
ganaba cinco dólares por bolsa.

30
0:01:27.2,000 --> 0:01:3,000
Y tomé mi dinero de caddie, y lo puse en el mercado de valores.

31
0:01:31.24,000 --> 0:01:34,000
Y eso solo porque la bolsa de valores estaba agitada en ese momento.

32
0:01:34.64,000 --> 0:01:35,000
La primera empresa que compré

33
0:01:36.12,000 --> 0:01:38,000
era una empresa llamada Northeast Airlines.

34
0:01:39.36,000 --> 0:01:41,000
Northeast Airlines era la única empresa de la que supe

35
0:01:42.12,000 --> 0:01:44,000
que se vendía por menos de cinco dólares por acción.

36
0:01:44.84,000 --> 0:01:45,000
(Risas)

37
0:01:46.84,000 --> 0:01:47,000
Y pensé que podría comprar más acciones

38
0:01:48.72,000 --> 0:01:5,000
y si subían, ganaría más dinero.

39
0:01:50.84,000 --> 0:01:52,000
Así que, era una estrategia tonta, ¿no?

40
0:01:54.36,000 --> 0:01:55,000
Pero tripliqué mi dinero,

41
0:01:55.84,000 --> 0:01:57,000
y tripliqué mi dinero porque tuve suerte.

42
0:01:58.52,000 --> 0:01:59,000
La compañía estaba a punto de quebrar,

43
0:02:00.36,000 --> 0:02:02,000
pero otra compañía la adquirió,

44
0:02:02.48,000 --> 0:02:03,000
y tripliqué mi dinero.

45
0:02:03.96,000 --> 0:02:04,000
Y estaba enganchado.

46
0:02:05.72,000 --> 0:02:07,000
Y pensé "Este juego es fácil".

47
0:02:09.2,000 --> 0:02:1,000
Con el tiempo,

48
0:02:10.44,000 --> 0:02:12,000
aprendí que este juego es todo menos fácil.

49
0:02:12.88,000 --> 0:02:14,000
Para ser un inversor eficaz,

50
0:02:15.04,000 --> 0:02:17,000
uno tiene que apostar contra el consenso

51
0:02:17.96,000 --> 0:02:18,000
y tener razón.

52
0:02:19.24,000 --> 0:02:21,000
Y no es fácil apostar contra el consenso y tener razón.

53
0:02:22.12,000 --> 0:02:24,000
Uno tiene que apostar en contra y tener razón,

54
0:02:24.48,000 --> 0:02:26,000
porque el consenso está basado en el precio.

55
0:02:28.12,000 --> 0:02:3,000
Y para ser un emprendedor,

56
0:02:30.6,000 --> 0:02:31,000
un emprendedor exitoso,

57
0:02:32.24,000 --> 0:02:35,000
uno tiene que apostar contra el consenso y tener razón.

58
0:02:37.4,000 --> 0:02:39,000
Tenía que ser emprendedor e inversor

59
0:02:40.36,000 --> 0:02:44,000
y lo que va unido a eso es cometer un montón de errores dolorosos.

60
0:02:45.44,000 --> 0:02:47,000
Así que cometí muchos errores dolorosos

61
0:02:48.28,000 --> 0:02:49,000
y, con el tiempo,

62
0:02:49.56,000 --> 0:02:51,000
mi actitud sobre esos errores empezó a cambiar.

63
0:02:53.16,000 --> 0:02:55,000
Empecé a mirarlos como rompecabezas

64
0:02:55.28,000 --> 0:02:56,000
y, si podía resolver el rompecabezas,

65
0:02:57.24,000 --> 0:02:58,000
me darían tesoros.

66
0:02:59.16,000 --> 0:03:,000
Y los rompecabezas eran:

67
0:03:00.84,000 --> 0:03:03,000
¿Qué haría diferente en el futuro para no cometer ese doloroso error?

68
0:03:05.28,000 --> 0:03:07,000
Y los tesoros eran principios

69
0:03:07.88,000 --> 0:03:1,000
que luego escribiría para recordarlos

70
0:03:11.04,000 --> 0:03:12,000
y ayudarme en el futuro.

71
0:03:13,000 --> 0:03:15,000
Y debido a que los escribí muy claramente.

72
0:03:15.72,000 --> 0:03:16,000
Podría entonces...

73
0:03:17.08,000 --> 0:03:18,000
--finalmente descubrí--

74
0:03:18.68,000 --> 0:03:21,000
ponerlos en algoritmos.

75
0:03:23.4,000 --> 0:03:26,000
Y esos algoritmos serían incorporados en las computadoras,

76
0:03:26.88,000 --> 0:03:29,000
y las computadoras tomarían decisiones conmigo;

77
0:03:30.24,000 --> 0:03:33,000
y así en paralelo, tomaríamos estas decisiones.

78
0:03:33.4,000 --> 0:03:36,000
Y podría ver cómo esas decisiones se comparan con mis propias decisiones,

79
0:03:37.4,000 --> 0:03:4,000
y podría ver que esas decisiones son mucho mejores.

80
0:03:40.52,000 --> 0:03:44,000
Y eso es porque la computadora podría tomar decisiones mucho más rápido.

81
0:03:45.28,000 --> 0:03:47,000
Podría procesar mucha más información

82
0:03:47.56,000 --> 0:03:5,000
y tomar decisiones mucho menos,

83
0:03:51.88,000 --> 0:03:52,000
menos emocionales.

84
0:03:54.76,000 --> 0:03:57,000
Así que mejoró radicalmente mi toma de decisiones.

85
0:04:00.44,000 --> 0:04:04,000
Ocho años después empecé Bridgewater.

86
0:04:05.36,000 --> 0:04:06,000
Tuve mi mayor fracaso,

87
0:04:06.92,000 --> 0:04:07,000
mi mayor error.

88
0:04:09.68,000 --> 0:04:11,000
Fue a finales de 1970,

89
0:04:11.84,000 --> 0:04:12,000
tenía 34 años,

90
0:04:13.84,000 --> 0:04:16,000
y había calculado que los bancos estadounidenses

91
0:04:17.52,000 --> 0:04:19,000
habían prestado mucho más dinero a países emergentes

92
0:04:20.4,000 --> 0:04:22,000
y esos países no serían capaces de devolvérselos

93
0:04:23.24,000 --> 0:04:25,000
y que tendríamos la mayor crisis de deuda

94
0:04:25.96,000 --> 0:04:26,000
desde la Gran Depresión.

95
0:04:28.2,000 --> 0:04:3,000
Y, con ello, una crisis económica

96
0:04:30.44,000 --> 0:04:32,000
y un gran mercado con acciones bajas.

97
0:04:33.68,000 --> 0:04:35,000
Fue un raro punto de vista en ese momento.

98
0:04:36.16,000 --> 0:04:38,000
La gente pensó que era un punto de vista alocado.

99
0:04:39.48,000 --> 0:04:41,000
Pero en agosto de 1982,

100
0:04:41.72,000 --> 0:04:42,000
México incumplió su deuda,

101
0:04:44.52,000 --> 0:04:46,000
y muchos otros países lo siguieron.

102
0:04:46.8,000 --> 0:04:49,000
Y así tuvimos la mayor crisis de deuda desde la Gran Depresión.

103
0:04:51.08,000 --> 0:04:53,000
Y como yo había anticipado eso,

104
0:04:53.88,000 --> 0:04:57,000
me solicitaron que testificara ante el Congreso y la revista de Wall Street

105
0:04:58.24,000 --> 0:04:59,000
qué es lo que pasaba en ese momento.

106
0:05:00.24,000 --> 0:05:02,000
Para que vean de lo que hablo, tengo aquí un video

107
0:05:03.2,000 --> 0:05:04,000
y me verán allí.

108
0:05:06.48,000 --> 0:05:07,000
(Video) Sr. Presidente, Sr. Mitchell,

109
0:05:08.2,000 --> 0:05:11,000
es un gran placer y un honor estar ante Uds.

110
0:05:11.6,000 --> 0:05:14,000
para analizar qué va mal en nuestra economía.

111
0:05:15.64,000 --> 0:05:16,000
La economía ahora es plan...

112
0:05:17.6,000 --> 0:05:19,000
se balancea al borde del fracaso.

113
0:05:19.76,000 --> 0:05:21,000
Martin Zweig: Fue hace poco citado en un artículo.

114
0:05:22.28,000 --> 0:05:24,000
Dijo: "Puedo decir esto con absoluta certeza

115
0:05:24.64,000 --> 0:05:25,000
porque así funciona el mercado".

116
0:05:26.356,000 --> 0:05:28,000
Ray Dalio: Puedo decir con absoluta certeza

117
0:05:28.4,000 --> 0:05:29,000
que si miran la base de liquidez

118
0:05:30.28,000 --> 0:05:33,000
en las corporaciones y el mundo en su conjunto,

119
0:05:33.68,000 --> 0:05:35,000
verán un nivel tan reducido de liquidez

120
0:05:35.8,000 --> 0:05:38,000
que no podrían volver a una era de "estanflación".

121
0:05:39.04,000 --> 0:05:42,000
Miro eso ahora, y pienso: "¡Pero qué estúpido arrogante!"

122
0:05:42.16,000 --> 0:05:44,000
(Risas)

123
0:05:45.76,000 --> 0:05:47,000
Era arrogante y estaba muy equivocado.

124
0:05:48.24,000 --> 0:05:5,000
Es decir, mientras la crisis de la deuda ocurría,

125
0:05:50.84,000 --> 0:05:53,000
la bolsa de valores y la economía subieron en lugar de bajar,

126
0:05:54.84,000 --> 0:05:59,000
y perdí tanto dinero mío y de mis clientes

127
0:05:59.88,000 --> 0:06:02,000
que tuve que dar de baja mis operaciones,

128
0:06:03.32,000 --> 0:06:04,000
tuve que dejar ir a casi todos.

129
0:06:05.64,000 --> 0:06:06,000
Y eran como una familia extendida,

130
0:06:07.4,000 --> 0:06:08,000
estaba con el corazón partido.

131
0:06:09.04,000 --> 0:06:1,000
Y había perdido mucho dinero.

132
0:06:10.88,000 --> 0:06:13,000
y tenía que pedir prestado USD 4000 de mi papá

133
0:06:14.24,000 --> 0:06:15,000
para ayudar con las facturas familiares.

134
0:06:16.84,000 --> 0:06:19,000
Fue una de las experiencias más dolorosas de mi vida...

135
0:06:21.24,000 --> 0:06:24,000
pero resultó ser una de las más grandes experiencias de mi vida

136
0:06:25.04,000 --> 0:06:27,000
porque cambió la manera en la que tomo decisiones.

137
0:06:28.36,000 --> 0:06:31,000
En lugar de pensar "tengo razón",

138
0:06:31.44,000 --> 0:06:32,000
empecé a preguntarme:

139
0:06:33.04,000 --> 0:06:34,000
"¿Cómo sé que tengo razón?"

140
0:06:36.48,000 --> 0:06:37,000
Conseguí la humildad que necesitaba

141
0:06:38.44,000 --> 0:06:4,000
para equilibrarla con mi audacia.

142
0:06:41.88,000 --> 0:06:45,000
Quería llegar a las personas más capaces que estuviesen en desacuerdo conmigo

143
0:06:46.12,000 --> 0:06:47,000
para intentar entender sus perspectivas

144
0:06:48.04,000 --> 0:06:5,000
o dejar que ellos probaran mi perspectiva.

145
0:06:51.4,000 --> 0:06:53,000
Quería hacer una idea meritocrática.

146
0:06:54.2,000 --> 0:06:55,000
En otras palabras,

147
0:06:55.44,000 --> 0:06:58,000
no una autocracia en donde yo lideraría y otros me seguirían

148
0:06:59.28,000 --> 0:07:02,000
y no una democracia donde los puntos de vista de todos son evaluados,

149
0:07:02.92,000 --> 0:07:07,000
quería tener una idea meritocrática en donde las mejores ideas saldrían ganando.

150
0:07:08.04,000 --> 0:07:09,000
Y para hacer esto

151
0:07:09.32,000 --> 0:07:12,000
me di cuenta de que necesitaríamos una veracidad radical

152
0:07:12.92,000 --> 0:07:13,000
y una transparencia radical.

153
0:07:14.56,000 --> 0:07:17,000
Lo que quiero decir con estos términos

154
0:07:18.44,000 --> 0:07:2,000
es que la gente necesita decir lo que en realidad piensa

155
0:07:21.12,000 --> 0:07:23,000
y ver todo.

156
0:07:23.77,000 --> 0:07:26,000
Y, literalmente, grabamos casi todas nuestras conversaciones

157
0:07:27.44,000 --> 0:07:28,000
y dejamos a todos ver todo.

158
0:07:29.08,000 --> 0:07:3,000
porque si no hacíamos eso,

159
0:07:30.52,000 --> 0:07:33,000
no podíamos tener una verdadera idea meritocrática.

160
0:07:34.76,000 --> 0:07:37,000
Para llegar a esto,

161
0:07:38.48,000 --> 0:07:4,000
dejamos a las personas decir y opinar lo que quieren.

162
0:07:40.956,000 --> 0:07:41,000
Para darles un ejemplo,

163
0:07:42.28,000 --> 0:07:44,000
este es un email de Jim Haskel,

164
0:07:45,000 --> 0:07:46,000
alguien que trabaja para mí,

165
0:07:46.4,000 --> 0:07:49,000
y esto se le permite a todos en mi empresa:

166
0:07:49.8,000 --> 0:07:51,000
"Ray, te mereces una mala nota

167
0:07:52.36,000 --> 0:07:54,000
por tu rendimiento hoy en la reunión...

168
0:07:54.64,000 --> 0:07:55,000
no te preparaste para nada bien

169
0:07:56.36,000 --> 0:07:59,000
porque no hay razón para que estuvieras así de desorganizado.

170
0:08:01.52,000 --> 0:08:02,000
¿No es genial?

171
0:08:02.76,000 --> 0:08:03,000
(Risas)

172
0:08:04,000 --> 0:08:05,000
Es genial.

173
0:08:05.24,000 --> 0:08:07,000
Lo es porque, antes que nada, necesitaba una opinión como esa.

174
0:08:08.2,000 --> 0:08:09,000
La necesito.

175
0:08:09.84,000 --> 0:08:12,000
Y es genial porque si no dejo a Jim, y a otros como Jim,

176
0:08:13.32,000 --> 0:08:14,000
expresar sus puntos de vista,

177
0:08:14.92,000 --> 0:08:16,000
nuestra relación no sería la misma.

178
0:08:17,000 --> 0:08:2,000
Y si no dejo que todos los demás lo vean,

179
0:08:20.08,000 --> 0:08:21,000
no tendríamos una idea de meritocracia.

180
0:08:23.76,000 --> 0:08:26,000
Así que durante los últimos 25 años así fue como operamos.

181
0:08:27.64,000 --> 0:08:3,000
Trabajamos con esta transparencia radical

182
0:08:30.72,000 --> 0:08:32,000
y luego, recolectando estos principios

183
0:08:33.04,000 --> 0:08:35,000
la mayoría sobre cometer errores,

184
0:08:35.12,000 --> 0:08:39,000
y luego colocando esos principios en algoritmos.

185
0:08:39.56,000 --> 0:08:41,000
Y luego esos algoritmos proveen...

186
0:08:42.28,000 --> 0:08:44,000
nosotros estamos siguiendo los algoritmos

187
0:08:44.32,000 --> 0:08:45,000
en paralelo con nuestras ideas.

188
0:08:47.28,000 --> 0:08:5,000
Así fue como manejamos el negocio de inversiones

189
0:08:50.48,000 --> 0:08:52,000
y así es como lidiamos con la gestión de las personas.

190
0:08:53.24,000 --> 0:08:56,000
Para darles un pantallazo sobre como se ve esto,

191
0:08:57,000 --> 0:08:59,000
me gustaría llevarlos a una reunión

192
0:08:59.36,000 --> 0:09:02,000
y presentarles una herramienta nuestra llamada "colector de puntos"

193
0:09:02.52,000 --> 0:09:03,000
que nos ayuda con esto.

194
0:09:07.64,000 --> 0:09:09,000
Una semana tras las elecciones de EE.UU.,

195
0:09:09.84,000 --> 0:09:11,000
nuestro equipo de investigación se reunió

196
0:09:11.96,000 --> 0:09:15,000
para hablar sobre la presidencia de Trump y la economía estadounidense.

197
0:09:15.99,000 --> 0:09:17,000
Naturalmente, la gente tenía diferentes opiniones al respecto

198
0:09:18.88,000 --> 0:09:2,000
y sobre cómo abordaríamos la discusión.

199
0:09:21.84,000 --> 0:09:23,000
El "colector de puntos" recolectó estos puntos de vista.

200
0:09:24.64,000 --> 0:09:26,000
Tiene una lista de varias decenas de atributos

201
0:09:26.96,000 --> 0:09:3,000
así que cada vez que alguien piensa algo sobre las ideas de otra persona,

202
0:09:31,000 --> 0:09:33,000
es fácil para ellos transmitir su evaluación

203
0:09:33.96,000 --> 0:09:37,000
simplemente seleccionan el atributo y lo califican del 1 al 10.

204
0:09:39.52,000 --> 0:09:41,000
Por ejemplo, cuando comenzó la reunión

205
0:09:41.8,000 --> 0:09:44,000
una investigadora llamada Jen me calificó con un 3

206
0:09:45.64,000 --> 0:09:47,000
-- en otras palabras, mal --

207
0:09:47.68,000 --> 0:09:48,000
(Risas)

208
0:09:49.08,000 --> 0:09:53,000
por no mostrar un buen equilibrio de mente abierta y asertividad.

209
0:09:54.08,000 --> 0:09:55,000
A medida que transcurrió la reunión,

210
0:09:55.816,000 --> 0:09:58,000
las evaluaciones de Jen sobre las personas ocurrieron de esta manera.

211
0:09:59.92,000 --> 0:10:01,000
Otros allí, tuvieron diferentes opiniones.

212
0:10:02.12,000 --> 0:10:03,000
Es normal.

213
0:10:03.36,000 --> 0:10:05,000
Diferentes personas siempre van a tener diferentes opiniones.

214
0:10:06.8,000 --> 0:10:07,000
¿Y quién sabe quién tiene razón?

215
0:10:09.24,000 --> 0:10:12,000
Veamos lo que la gente pensaba acerca de cómo estaba.

216
0:10:13.64,000 --> 0:10:15,000
Algunas personas pensaron que lo hice bien,

217
0:10:16.016,000 --> 0:10:17,000
otros no.

218
0:10:18.08,000 --> 0:10:19,000
Con todas estas opiniones,

219
0:10:19.44,000 --> 0:10:22,000
podemos explorar el pensamiento que hay detrás de los números.

220
0:10:22.52,000 --> 0:10:24,000
Aquí está lo que dieron Jen y Larry.

221
0:10:25.76,000 --> 0:10:27,000
Tengan en cuenta que todos expresan sus pensamientos

222
0:10:28.416,000 --> 0:10:29,000
incluyendo su pensamiento crítico,

223
0:10:30.08,000 --> 0:10:32,000
independientemente de su posición en la compañía.

224
0:10:33.12,000 --> 0:10:36,000
Jen, que tiene 24 años y acaba de salir de la universidad,

225
0:10:36.24,000 --> 0:10:39,000
puede decirme, al CEO, que tengo un enfoque terrible.

226
0:10:40.48,000 --> 0:10:43,000
Esta herramienta le ayuda a las personas a expresar sus opiniones

227
0:10:44.28,000 --> 0:10:47,000
y luego separarlas de sus opiniones

228
0:10:47.4,000 --> 0:10:49,000
para ver las cosas de un nivel más alto.

229
0:10:50.64,000 --> 0:10:54,000
Cuando Jen y otros cambian sus atención de introducir sus propias opiniones

230
0:10:55.56,000 --> 0:10:57,000
a ver toda la pantalla,

231
0:10:58.16,000 --> 0:10:59,000
sus perspectivas cambian.

232
0:11:00.68,000 --> 0:11:02,000
Ven sus propias opiniones como solo una de muchas

233
0:11:03.756,000 --> 0:11:05,000
y naturalmente, empiezan a preguntarse:

234
0:11:06.4,000 --> 0:11:08,000
"¿Cómo sé si mi opinión es acertada?"

235
0:11:09.48,000 --> 0:11:13,000
Ese cambio en la perspectiva es como pasar de mirar en una dimensión

236
0:11:13.56,000 --> 0:11:15,000
a mirar en múltiples dimensiones.

237
0:11:15.84,000 --> 0:11:19,000
Y cambia la conversación desde argumentar nuestras opiniones

238
0:11:19.96,000 --> 0:11:23,000
a encontrar criterios objetivos para determinar qué opiniones son las mejores.

239
0:11:24.92,000 --> 0:11:27,000
Detrás del "recolector de puntos" hay una computadora que observa.

240
0:11:29.12,000 --> 0:11:31,000
Observa todo lo que estas personas piensan

241
0:11:31.32,000 --> 0:11:33,000
y relaciona esto con cómo lo piensan.

242
0:11:33.92,000 --> 0:11:36,000
Y ofrece consejos a cada uno basado en ello.

243
0:11:38.52,000 --> 0:11:41,000
Luego, dibuja los datos de todas las reuniones

244
0:11:41.96,000 --> 0:11:44,000
para crear una imagen de puntos de cómo son las personas

245
0:11:45.2,000 --> 0:11:46,000
y cómo piensan.

246
0:11:47.16,000 --> 0:11:49,000
Y hace esto guiado por algoritmos.

247
0:11:50.8,000 --> 0:11:53,000
Saber cómo son las personas les ayuda a coincidir mejor con sus trabajos.

248
0:11:55.14,000 --> 0:11:57,000
Por ejemplo, un pensador creativo que es irresponsable

249
0:11:57.89,000 --> 0:12:,000
puede ser puesto con alguien responsable pero no creativo.

250
0:12:02.29,000 --> 0:12:05,000
Saber cómo son las personas también nos permite decidir

251
0:12:05.72,000 --> 0:12:07,000
qué responsabilidades darles

252
0:12:07.888,000 --> 0:12:1,000
y medir nuestras decisiones basándonos en el mérito de las personas.

253
0:12:12.04,000 --> 0:12:13,000
Lo llamamos credibilidad.

254
0:12:14.56,000 --> 0:12:16,000
Aquí hay un ejemplo de un voto que tomamos

255
0:12:16.56,000 --> 0:12:19,000
donde la mayoría de la gente se sentía de una manera...

256
0:12:21.06,000 --> 0:12:23,000
pero si medimos las opiniones basadas en los méritos

257
0:12:23.84,000 --> 0:12:25,000
la respuesta es muy diferente.

258
0:12:26.944,000 --> 0:12:3,000
Este proceso nos permite tomar decisiones no basadas en la democracia

259
0:12:31.61,000 --> 0:12:32,000
ni basadas en la autocracia,

260
0:12:33.57,000 --> 0:12:38,000
sino en algoritmos que consideran la credibilidad de las personas.

261
0:12:41.542,000 --> 0:12:42,000
Sí, en serio hacemos esto.

262
0:12:43.354,000 --> 0:12:46,000
(Risas)

263
0:12:46.56,000 --> 0:12:48,000
Lo hacemos porque elimina

264
0:12:49.44,000 --> 0:12:53,000
lo que creo es una de las mayores tragedias de la humanidad,

265
0:12:53.92,000 --> 0:12:55,000
y eso es gente arrogante

266
0:12:56.76,000 --> 0:13:,000
e ingenua que sostienen opiniones equivocadas,

267
0:13:01.24,000 --> 0:13:02,000
y actuar sobre ellas,

268
0:13:02.52,000 --> 0:13:04,000
y no poniéndolos sobre la mesa y poniéndolos a prueba.

269
0:13:06,000 --> 0:13:07,000
Y eso es una tragedia.

270
0:13:07.36,000 --> 0:13:12,000
Y lo hacemos porque nos eleva en nuestras propias opiniones.

271
0:13:12.8,000 --> 0:13:14,000
Para que podamos ver las cosas a través de los ojos de todos,

272
0:13:15.72,000 --> 0:13:16,000
para ver las cosas colectivamente.

273
0:13:18.36,000 --> 0:13:22,000
La toma de decisiones colectiva es mejor que la toma de decisiones individual

274
0:13:22.72,000 --> 0:13:23,000
si se hace bien.

275
0:13:24.36,000 --> 0:13:26,000
Ha sido el ingrediente secreto de nuestro éxito.

276
0:13:27,000 --> 0:13:28,000
Así hicimos más dinero para los clientes

277
0:13:28.996,000 --> 0:13:3,000
que cualquier otro fondo de cobertura existente

278
0:13:31.226,000 --> 0:13:33,000
ganando dinero 23 años de los últimos 26 años.

279
0:13:35.88,000 --> 0:13:39,000
Entonces, ¿cuál es el problema con ser radicalmente honestos

280
0:13:40.44,000 --> 0:13:42,000
y radicalmente transparentes entre sí?

281
0:13:45.4,000 --> 0:13:47,000
La gente dice que es emocionalmente difícil.

282
0:13:48.24,000 --> 0:13:52,000
Los críticos dicen que es la fórmula para un ambiente de trabajo bestial.

283
0:13:52.84,000 --> 0:13:57,000
Los neurocientíficos dicen que así está cableado el cerebro.

284
0:13:58.28,000 --> 0:14:01,000
A una parte del cerebro le gustaría saber nuestros errores

285
0:14:01.52,000 --> 0:14:04,000
y le gustaría ver nuestras debilidades para así mejorar.

286
0:14:06.12,000 --> 0:14:08,000
Me dijeron que ese es el córtex prefrontal.

287
0:14:09.04,000 --> 0:14:13,000
Y también hay una parte del cerebro que ve todo esto como un ataque.

288
0:14:13.92,000 --> 0:14:14,000
Me dijeron que esa es la amígdala.

289
0:14:16.44,000 --> 0:14:19,000
En otras palabras, hay dos "yo" dentro de cada uno:

290
0:14:19.52,000 --> 0:14:2,000
hay un "yo" emocional

291
0:14:20.96,000 --> 0:14:21,000
y hay un "yo" intelectual

292
0:14:22.76,000 --> 0:14:23,000
y a veces están en desacuerdo,

293
0:14:24.56,000 --> 0:14:25,000
y a veces están en contra.

294
0:14:27.16,000 --> 0:14:3,000
Sabemos por experiencia que podemos ganar esta batalla.

295
0:14:30.92,000 --> 0:14:31,000
La ganamos como grupo.

296
0:14:33,000 --> 0:14:35,000
Típicamente lleva unos 18 meses

297
0:14:35.36,000 --> 0:14:38,000
ver que la mayoría de la gente prefiere operar de esta manera,

298
0:14:38.496,000 --> 0:14:39,000
con una transparencia radical

299
0:14:40.48,000 --> 0:14:43,000
que operar en un ambiente más opaco.

300
0:14:43.84,000 --> 0:14:47,000
No hay política, no existe la brutalidad de...

301
0:14:48.16,000 --> 0:14:5,000
me entienden, todo lo típico entre bastidores,

302
0:14:50.56,000 --> 0:14:52,000
hay una idea meritocrática donde las personas tienen voz.

303
0:14:53.52,000 --> 0:14:54,000
Y eso ha sido genial.

304
0:14:54.8,000 --> 0:14:55,000
Nos dio un trabajo más efectivo,

305
0:14:56.496,000 --> 0:14:58,000
y también nos dio relaciones más efectivas.

306
0:14:59.4,000 --> 0:15:,000
Pero no es para todos.

307
0:15:01.68,000 --> 0:15:03,000
Encontramos que cerca del 25 o 30 % de la población

308
0:15:04.64,000 --> 0:15:05,000
simplemente no puede hacerlo.

309
0:15:06.4,000 --> 0:15:07,000
Y, por cierto,

310
0:15:07.64,000 --> 0:15:08,000
cuando digo transparencia radical,

311
0:15:09.48,000 --> 0:15:11,000
no estoy hablando de la transparencia sobre todo.

312
0:15:11.84,000 --> 0:15:14,000
Sino de no tener que decirle a alguien que cada vez está más calvo

313
0:15:15.68,000 --> 0:15:16,000
o que su bebé es feo.

314
0:15:17.32,000 --> 0:15:19,000
Solo estoy hablando de...

315
0:15:19.44,000 --> 0:15:2,000
(Risas)

316
0:15:20.68,000 --> 0:15:22,000
hablando de las cosas importantes.

317
0:15:22.88,000 --> 0:15:23,000
Así que...

318
0:15:24.12,000 --> 0:15:27,000
(Risas)

319
0:15:28.6,000 --> 0:15:29,000
Así que cuando dejen la sala,

320
0:15:30.04,000 --> 0:15:34,000
me gustaría que se observen conversando con otros.

321
0:15:35.36,000 --> 0:15:38,000
Imaginen si supieran lo que en realidad estuvieron pensando,

322
0:15:39.76,000 --> 0:15:41,000
e imaginen si supieran cómo son ellos en realidad...

323
0:15:43.84,000 --> 0:15:46,000
e imaginen si ellos supieran lo que Uds. pensaron

324
0:15:47.84,000 --> 0:15:48,000
y cómo son en realidad.

325
0:15:50.16,000 --> 0:15:52,000
Seguramente, se les aclararán mucho las cosas

326
0:15:52.76,000 --> 0:15:54,000
y hagan sus operaciones juntos más efectivas.

327
0:15:55.64,000 --> 0:15:57,000
Yo creo que mejorará su relación.

328
0:15:58.6,000 --> 0:16:01,000
Ahora imagínense que tienen algoritmos

329
0:16:01.92,000 --> 0:16:04,000
que les ayudan a unir esa información,

330
0:16:05.76,000 --> 0:16:09,000
incluso les ayudan a tomar decisiones de una manera meritocrática.

331
0:16:12.64,000 --> 0:16:16,000
Este tipo de transparencia radical se acerca a Uds.

332
0:16:17,000 --> 0:16:18,000
y afectará sus vidas.

333
0:16:19.6,000 --> 0:16:21,000
Y en mi opinión,

334
0:16:21.68,000 --> 0:16:22,000
va a ser maravilloso.

335
0:16:23.04,000 --> 0:16:25,000
Así que espero que sea tan maravilloso para Uds.

336
0:16:25.416,000 --> 0:16:26,000
como lo es para mí.

337
0:16:27.16,000 --> 0:16:28,000
Muchas gracias.

338
0:16:28.44,000 --> 0:16:31,000
(Aplausos)

