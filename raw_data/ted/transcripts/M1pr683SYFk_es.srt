1
0:00:,000 --> 0:00:07,000
Traductor: Ana María Pérez Revisor: Hazael Jaramillo Molina

2
0:00:13.16,000 --> 0:00:15,000
Pensaba comenzar con una escena de guerra.

3
0:00:15.16,000 --> 0:00:17,000
Había poco que advertir sobre el peligro inminente.

4
0:00:17.16,000 --> 0:00:19,000
El insurgente iraquí había colocado el IED,

5
0:00:19.16,000 --> 0:00:22,000
un artefacto explosivo improvisado,

6
0:00:22.16,000 --> 0:00:24,000
cuidadosamente al borde de la carretera.

7
0:00:24.16,000 --> 0:00:28,000
En 2006 hubo más de 2,500

8
0:00:28.16,000 --> 0:00:31,000
ataques de este tipo cada mes,

9
0:00:31.16,000 --> 0:00:33,000
y fueron la principal causa de

10
0:00:33.16,000 --> 0:00:35,000
víctimas entre soldados estadounidenses

11
0:00:35.16,000 --> 0:00:37,000
y civiles iraquíes.

12
0:00:37.16,000 --> 0:00:39,000
El equipo que estaba a la caza de este IED

13
0:00:39.16,000 --> 0:00:41,000
se llama EOD

14
0:00:41.16,000 --> 0:00:43,000
-Eliminación de Artefactos Explosivos-

15
0:00:43.16,000 --> 0:00:45,000
y son la punta de lanza en el esfuerzo

16
0:00:45.16,000 --> 0:00:48,000
estadounidense para suprimir estas bombas artesanales.

17
0:00:48.16,000 --> 0:00:5,000
Cada equipo EOD interviene

18
0:00:50.16,000 --> 0:00:52,000
unas 600 veces al año

19
0:00:52.16,000 --> 0:00:55,000
desactivando alrededor de dos bombas al día.

20
0:00:55.16,000 --> 0:00:57,000
Quizás la mejor indicación de su valor

21
0:00:57.16,000 --> 0:00:59,000
al esfuerzo de guerra, es que

22
0:00:59.16,000 --> 0:01:01,000
los insurgentes iraquíes ofrecían una recompensa de 50,000

23
0:01:01.16,000 --> 0:01:04,000
dólares por la cabeza de cada soldado EOD.

24
0:01:04.16,000 --> 0:01:06,000
Por desgracia, esa llamada en particular

25
0:01:06.16,000 --> 0:01:08,000
no terminaría bien.

26
0:01:08.16,000 --> 0:01:1,000
Cuando el soldado avanzó suficientemente

27
0:01:10.16,000 --> 0:01:12,000
cerca para ver los cables

28
0:01:12.16,000 --> 0:01:15,000
reveladores de la bomba, ésta explotó en una ola de fuego.

29
0:01:15.16,000 --> 0:01:17,000
Ahora, dependiendo de lo cerca que uno esté

30
0:01:17.16,000 --> 0:01:19,000
y la cantidad de explosivo que haya sido

31
0:01:19.16,000 --> 0:01:21,000
colocado en la bomba, puede causar la muerte

32
0:01:21.16,000 --> 0:01:23,000
o lesiones. Hay que estar a una distancia

33
0:01:23.16,000 --> 0:01:25,000
aproximada de 50 metros para estar a salvo.

34
0:01:25.16,000 --> 0:01:27,000
La explosión es tan fuerte que puede incluso romper

35
0:01:27.16,000 --> 0:01:29,000
un miembro, aunque el golpe no sea directo.

36
0:01:29.16,000 --> 0:01:31,000
Ese soldado estaba encima de la bomba.

37
0:01:31.16,000 --> 0:01:34,000
Cuando el resto del equipo se acercó,

38
0:01:34.16,000 --> 0:01:36,000
de él había quedado poco. Esa noche el comandante

39
0:01:36.16,000 --> 0:01:38,000
de la unidad tuvo el penoso deber de escribir una carta

40
0:01:38.16,000 --> 0:01:4,000
de condolencias a los EE.UU.

41
0:01:40.16,000 --> 0:01:42,000
que hablaba de lo duro que había sido

42
0:01:42.16,000 --> 0:01:44,000
para su unidad la pérdida, del hecho

43
0:01:44.16,000 --> 0:01:46,000
de haber perdido el soldado más valiente,

44
0:01:46.16,000 --> 0:01:48,000
un soldado que más de una vez

45
0:01:48.16,000 --> 0:01:5,000
les había salvado la vida.

46
0:01:50.16,000 --> 0:01:52,000
Luego se disculpó

47
0:01:52.16,000 --> 0:01:54,000
por no poder llevarlo de vuelta a casa.

48
0:01:54.16,000 --> 0:01:56,000
Pero también habló de la lección positiva

49
0:01:56.16,000 --> 0:01:58,000
que aprendió de esa pérdida.

50
0:01:58.16,000 --> 0:02:,000
"Al menos", escribió, "cuando un robot muere,

51
0:02:00.16,000 --> 0:02:02,000
no hay necesidad de escribir una carta

52
0:02:02.16,000 --> 0:02:04,000
a su madre".

53
0:02:04.16,000 --> 0:02:06,000
Suena a ciencia ficción

54
0:02:06.16,000 --> 0:02:08,000
pero ya es una realidad en el campo de batalla.

55
0:02:08.16,000 --> 0:02:11,000
En ese caso el soldado

56
0:02:11.16,000 --> 0:02:14,000
era un robot de 21 kilos llamado PackBot.

57
0:02:14.16,000 --> 0:02:17,000
La carta del comandante no se dirigía

58
0:02:17.16,000 --> 0:02:19,000
a una granja en Iowa como se ve

59
0:02:19.16,000 --> 0:02:22,000
en las viejas películas de guerra,

60
0:02:22.16,000 --> 0:02:24,000
sino a la iRobot Company, que toma

61
0:02:24.16,000 --> 0:02:27,000
el nombre de la novela de Asimov

62
0:02:27.16,000 --> 0:02:29,000
y de la no tan buena película con Will Smith,

63
0:02:29.16,000 --> 0:02:31,000
y... uh... (Risas)...

64
0:02:31.16,000 --> 0:02:33,000
si Uds. recuerdan,

65
0:02:33.16,000 --> 0:02:35,000
en ese mundo ficticio los robots comenzaron

66
0:02:35.16,000 --> 0:02:37,000
realizando tareas ordinarias, y luego

67
0:02:37.16,000 --> 0:02:39,000
comenzaron a tomar decisiones de vida o muerte.

68
0:02:39.16,000 --> 0:02:41,000
Es una realidad que hoy conocemos.

69
0:02:41.16,000 --> 0:02:43,000
Lo que vamos a hacer es simplemente

70
0:02:43.16,000 --> 0:02:45,000
mostrarles una serie de fotos que muestran

71
0:02:45.16,000 --> 0:02:48,000
la realidad de los robots utilizados en la guerra

72
0:02:48.16,000 --> 0:02:5,000
en este momento o ya en fase de prototipo.

73
0:02:50.16,000 --> 0:02:53,000
Es solo para darles una idea.

74
0:02:53.16,000 --> 0:02:55,000
En otras palabras, no van a ver nada

75
0:02:55.16,000 --> 0:02:57,000
que funcione con la tecnología Vulcano

76
0:02:57.16,000 --> 0:02:59,000
o con las hormonas de algún geniecillo

77
0:02:59.16,000 --> 0:03:01,000
adolescente o cosas por el estilo.

78
0:03:01.16,000 --> 0:03:03,000
Todo esto es real. Así que sigamos adelante

79
0:03:03.16,000 --> 0:03:05,000
y comencemos a ver las imágenes.

80
0:03:05.16,000 --> 0:03:07,000
Algo importante está sucediendo en la guerra,

81
0:03:07.16,000 --> 0:03:09,000
y quizás también en la historia de la humanidad.

82
0:03:09.16,000 --> 0:03:12,000
El ejército de Estados Unidos fue a Irak

83
0:03:12.16,000 --> 0:03:14,000
con unos cuantos aviones no tripulados.

84
0:03:14.16,000 --> 0:03:17,000
Ahora tenemos 5300.

85
0:03:17.16,000 --> 0:03:19,000
Fuimos sin sistemas terrestres no tripulados.

86
0:03:19.16,000 --> 0:03:23,000
Ahora tenemos 12000.

87
0:03:23.16,000 --> 0:03:25,000
Y el término técnico "aplicación asesina"

88
0:03:25.16,000 --> 0:03:28,000
adquiere un nuevo significado en este contexto.

89
0:03:28.16,000 --> 0:03:3,000
Y no olvidemos que estamos

90
0:03:30.16,000 --> 0:03:32,000
hablando de los Ford Modelo T,

91
0:03:32.16,000 --> 0:03:34,000
los aviones de los hermanos Wright,

92
0:03:34.16,000 --> 0:03:36,000
en comparación con lo que vendrá pronto.

93
0:03:36.16,000 --> 0:03:38,000
Aquí es donde estamos ahora.

94
0:03:38.16,000 --> 0:03:4,000
Una de las personas que conocí hace poco

95
0:03:40.16,000 --> 0:03:42,000
fue un general de tres estrellas de la Fuerza Aérea,

96
0:03:42.16,000 --> 0:03:44,000
y dijo, básicamente, que muy pronto

97
0:03:44.16,000 --> 0:03:46,000
tendremos decenas de miles de robots

98
0:03:46.16,000 --> 0:03:48,000
operando en nuestros conflictos, y estas

99
0:03:48.16,000 --> 0:03:5,000
son cifras importantes ya que no se habla solo

100
0:03:50.16,000 --> 0:03:52,000
de decenas de miles de robots modernos,

101
0:03:52.16,000 --> 0:03:54,000
sino de decenas de miles de estos

102
0:03:54.16,000 --> 0:03:56,000
prototipos y robots del futuro, porque,

103
0:03:56.16,000 --> 0:03:59,000
por supuesto, uno de los factores que funciona

104
0:03:59.16,000 --> 0:04:01,000
en la tecnología es la Ley de Moore,

105
0:04:01.16,000 --> 0:04:03,000
la cual puede incorporar más y más

106
0:04:03.16,000 --> 0:04:05,000
potencia de cálculo a estos robots, así que

107
0:04:05.16,000 --> 0:04:07,000
si la Ley de Moore sigue vigente

108
0:04:07.16,000 --> 0:04:09,000
dentro de 25 años,

109
0:04:09.16,000 --> 0:04:12,000
esos robots serán unos mil millones de veces

110
0:04:12.16,000 --> 0:04:15,000
más potentes que ahora.

111
0:04:15.16,000 --> 0:04:17,000
Esto significa que ese tipo de cosas

112
0:04:17.16,000 --> 0:04:19,000
de las cuales se hablaba solo en las

113
0:04:19.16,000 --> 0:04:21,000
convenciones de ciencia ficción como la Comic-Con

114
0:04:21.16,000 --> 0:04:23,000
tendrán que ser discutidas en los centros

115
0:04:23.16,000 --> 0:04:25,000
de poder y en lugares como el Pentágono.

116
0:04:25.16,000 --> 0:04:28,000
Se acerca una revolución de los robots.

117
0:04:28.16,000 --> 0:04:3,000
Ahora, y en esto debo ser claro,

118
0:04:30.16,000 --> 0:04:32,000
no estoy hablando de una revolución en la que hay

119
0:04:32.16,000 --> 0:04:34,000
que preocuparse porque el gobernador de

120
0:04:34.16,000 --> 0:04:36,000
California se aparezca en su puerta

121
0:04:36.16,000 --> 0:04:38,000
a la Terminator. (Risas)

122
0:04:38.16,000 --> 0:04:4,000
Cuando los historiadores miren este periodo,

123
0:04:40.16,000 --> 0:04:42,000
van a concluir que estamos viviendo un tipo

124
0:04:42.16,000 --> 0:04:44,000
de revolución diferente: una revolución en la guerra,

125
0:04:44.16,000 --> 0:04:46,000
como la invención de la bomba atómica.

126
0:04:46.16,000 --> 0:04:48,000
Pero podría ser aún más importante

127
0:04:48.16,000 --> 0:04:5,000
porque nuestros sistemas no tripulados no solo

128
0:04:50.16,000 --> 0:04:52,000
afectan el "cómo" de la guerra,

129
0:04:52.16,000 --> 0:04:54,000
sino también el "quién" de la guerra

130
0:04:54.16,000 --> 0:04:56,000
en su nivel más fundamental.

131
0:04:56.16,000 --> 0:04:58,000
Es decir, cada revolución anterior en la guerra,

132
0:04:58.16,000 --> 0:05:,000
ya sea la ametralladora o la bomba atómica,

133
0:05:00.16,000 --> 0:05:03,000
se basaba en un sistema que disparaba más rápido,

134
0:05:03.16,000 --> 0:05:06,000
o más lejos, o más fuerte.

135
0:05:06.16,000 --> 0:05:09,000
Ese es ciertamente el caso de la robótica,

136
0:05:09.16,000 --> 0:05:12,000
pero también cambia la experiencia del guerrero

137
0:05:12.16,000 --> 0:05:15,000
e incluso su propia identidad.

138
0:05:15.16,000 --> 0:05:18,000
En otras palabras, el monopolio que la humanidad

139
0:05:18.16,000 --> 0:05:2,000
ha tenido en los últimos cinco mil años

140
0:05:20.16,000 --> 0:05:23,000
para combatir la guerra se está desmoronando

141
0:05:23.16,000 --> 0:05:25,000
en nuestra vida. He pasado

142
0:05:25.16,000 --> 0:05:27,000
los últimos años por ahí reuniéndome

143
0:05:27.16,000 --> 0:05:29,000
con todos los actores en este campo,

144
0:05:29.16,000 --> 0:05:31,000
desde creadores de robots a los autores

145
0:05:31.16,000 --> 0:05:33,000
de ciencia ficción que los inspiró, a los

146
0:05:33.16,000 --> 0:05:35,000
pilotos de 19 años de aviones no tripulados que combaten

147
0:05:35.16,000 --> 0:05:37,000
desde Nevada, a los generales de cuatro estrellas

148
0:05:37.16,000 --> 0:05:39,000
que los manejan, hasta los insurgentes

149
0:05:39.16,000 --> 0:05:41,000
iraquíes que son atacados para saber

150
0:05:41.16,000 --> 0:05:43,000
qué opinan de nuestros sistemas,

151
0:05:43.16,000 --> 0:05:45,000
y me parecieron interesantes no solo

152
0:05:45.16,000 --> 0:05:47,000
sus historias, sino cómo sus experiencias

153
0:05:47.16,000 --> 0:05:49,000
indican que estos efectos dominó se reflejan

154
0:05:49.16,000 --> 0:05:51,000
en nuestra sociedad, en nuestras leyes,

155
0:05:51.16,000 --> 0:05:53,000
en nuestra ética, etc. Por eso quisiera

156
0:05:53.16,000 --> 0:05:55,000
utilizar el tiempo que queda para analizar

157
0:05:55.16,000 --> 0:05:57,000
un par de estos efectos.

158
0:05:57.16,000 --> 0:05:59,000
El primero es que el futuro de la guerra,

159
0:05:59.16,000 --> 0:06:01,000
incluyendo la robótica, no va a ser

160
0:06:01.16,000 --> 0:06:03,000
exclusivamente americano.

161
0:06:03.16,000 --> 0:06:05,000
Actualmente los Estados Unidos llevan la delantera

162
0:06:05.16,000 --> 0:06:07,000
en cuanto a robótica militar, pero sabemos

163
0:06:07.16,000 --> 0:06:09,000
que en la tecnología no hay

164
0:06:09.16,000 --> 0:06:12,000
avance o ventaja permanente.

165
0:06:12.16,000 --> 0:06:14,000
Una encuesta rápida: ¿Cuántas

166
0:06:14.16,000 --> 0:06:16,000
personas aquí siguen utilizando

167
0:06:16.16,000 --> 0:06:18,000
computadoras Wang? (Risas)

168
0:06:18.16,000 --> 0:06:2,000
Lo mismo ocurre en la guerra. Los británicos

169
0:06:20.16,000 --> 0:06:23,000
y los franceses inventaron el tanque.

170
0:06:23.16,000 --> 0:06:25,000
Los alemanes descubrieron cómo

171
0:06:25.16,000 --> 0:06:27,000
usarlo mejor, así que lo que hay que pensar

172
0:06:27.16,000 --> 0:06:29,000
para los Estados Unidos, es que estamos

173
0:06:29.16,000 --> 0:06:31,000
por delante en este momento, pero hay

174
0:06:31.16,000 --> 0:06:33,000
otros 43 países por ahí

175
0:06:33.16,000 --> 0:06:35,000
trabajando en robótica militar,

176
0:06:35.16,000 --> 0:06:37,000
incluyendo países interesantes como

177
0:06:37.16,000 --> 0:06:4,000
Rusia, China, Pakistán, Irán.

178
0:06:40.16,000 --> 0:06:43,000
Esto me plantea una gran preocupación:

179
0:06:43.16,000 --> 0:06:45,000
¿Cómo podemos avanzar en esta revolución,

180
0:06:45.16,000 --> 0:06:47,000
dado nuestro nivel de producción,

181
0:06:47.16,000 --> 0:06:49,000
el estado de nuestra ciencia y

182
0:06:49.16,000 --> 0:06:51,000
la formación matemática en las escuelas?

183
0:06:51.16,000 --> 0:06:53,000
También se puede pensar de este modo:

184
0:06:53.16,000 --> 0:06:55,000
¿Qué significa enviar cada vez más soldados a la guerra

185
0:06:55.16,000 --> 0:06:58,000
con equipos cuyo hardware es hecho

186
0:06:58.16,000 --> 0:07:03,000
en China y el software programado en India?

187
0:07:03.16,000 --> 0:07:06,000
Pero así como el software se ha vuelto de código abierto,

188
0:07:06.16,000 --> 0:07:08,000
también lo ha hecho la guerra.

189
0:07:08.16,000 --> 0:07:11,000
A diferencia de un portaaviones o una bomba atómica,

190
0:07:11.16,000 --> 0:07:13,000
no es necesario un sistema de fabricación masiva

191
0:07:13.16,000 --> 0:07:15,000
para construir robots. Muchos ya están a la venta.

192
0:07:15.16,000 --> 0:07:17,000
Incluso muchos son "hágalo usted mismo".

193
0:07:17.16,000 --> 0:07:19,000
Una de las cosas que acaban de ver pasar en frente

194
0:07:19.16,000 --> 0:07:21,000
es un Raven no tripulado, que se lanza

195
0:07:21.16,000 --> 0:07:23,000
con la mano. Con unos mil dólares

196
0:07:23.16,000 --> 0:07:25,000
se pueden construir uno equivalente

197
0:07:25.16,000 --> 0:07:27,000
a los que usan los soldados en Irak.

198
0:07:27.16,000 --> 0:07:29,000
Esto plantea otro problema cuando se trata

199
0:07:29.16,000 --> 0:07:31,000
de guerras y conflictos. Los buenos podrían jugar

200
0:07:31.16,000 --> 0:07:33,000
y trabajar en ellos como kits de pasatiempo,

201
0:07:33.16,000 --> 0:07:35,000
pero también podrían hacerlo los malos.

202
0:07:35.16,000 --> 0:07:37,000
Este cruce entre robótica y cosas como

203
0:07:37.16,000 --> 0:07:39,000
el terrorismo resultará fascinante

204
0:07:39.16,000 --> 0:07:41,000
y hasta perturbador,

205
0:07:41.16,000 --> 0:07:43,000
y ya lo hemos visto comenzar.

206
0:07:43.16,000 --> 0:07:45,000
Durante la guerra entre Israel, un estado

207
0:07:45.16,000 --> 0:07:48,000
y Hezbolá, un actor no estatal,

208
0:07:48.16,000 --> 0:07:5,000
el actor no estatal lanzó

209
0:07:50.16,000 --> 0:07:52,000
cuatro aviones no tripulados contra Israel.

210
0:07:52.16,000 --> 0:07:54,000
Ya existe un sitio web yihadista

211
0:07:54.16,000 --> 0:07:56,000
en el que se puede entrar y detonar

212
0:07:56.16,000 --> 0:07:58,000
a distancia un IED en Irak sentado

213
0:07:58.16,000 --> 0:08:,000
desde su computadora.

214
0:08:00.16,000 --> 0:08:02,000
Y entonces creo que vamos a ver surgir

215
0:08:02.16,000 --> 0:08:04,000
dos tendencias.

216
0:08:04.16,000 --> 0:08:06,000
La primera es que va a reforzar el poder

217
0:08:06.16,000 --> 0:08:1,000
de los individuos contra los gobiernos,

218
0:08:10.16,000 --> 0:08:12,000
pero la segunda es que

219
0:08:12.16,000 --> 0:08:14,000
vamos a ver una expansión

220
0:08:14.16,000 --> 0:08:16,000
en el ámbito del terrorismo.

221
0:08:16.16,000 --> 0:08:18,000
El futuro de esto prodría ser una mezcla entre

222
0:08:18.16,000 --> 0:08:2,000
Al Qaeda 2.0

223
0:08:20.16,000 --> 0:08:22,000
y la próxima generación de Unabomber.

224
0:08:22.16,000 --> 0:08:24,000
Y otra forma de verlo

225
0:08:24.16,000 --> 0:08:26,000
es el hecho que, recuerden,

226
0:08:26.16,000 --> 0:08:28,000
no hay que convencer a un robot que recibirá

227
0:08:28.16,000 --> 0:08:31,000
72 vírgenes después de su muerte

228
0:08:31.16,000 --> 0:08:34,000
para hacerlo inmolar.

229
0:08:34.16,000 --> 0:08:36,000
Pero las repercusiones se van a hacer sentir

230
0:08:36.16,000 --> 0:08:38,000
en nuestra política. Una de las personas que

231
0:08:38.16,000 --> 0:08:4,000
conocí era un asistente del secretario de defensa

232
0:08:40.16,000 --> 0:08:42,000
de Ronald Reagan, y me dijo

233
0:08:42.16,000 --> 0:08:44,000
lo siguiente: "Me gustan estos sistemas porque

234
0:08:44.16,000 --> 0:08:46,000
salvan vidas americanas, pero me preocupa

235
0:08:46.16,000 --> 0:08:48,000
la comercialización de las guerras,

236
0:08:48.16,000 --> 0:08:51,000
el lenguaje sensacionalista

237
0:08:51.16,000 --> 0:08:53,000
que distrae la atención acerca de los costos.

238
0:08:53.16,000 --> 0:08:55,000
La gente es más propensa a apoyar el uso

239
0:08:55.16,000 --> 0:08:58,000
de la fuerza si ve que no cuesta nada".

240
0:08:58.16,000 --> 0:09:,000
Para mí, los robots siguen ciertas tendencias

241
0:09:00.16,000 --> 0:09:03,000
que ya están jugando un papel importante en nuestra

242
0:09:03.16,000 --> 0:09:05,000
vida política y tal vez los llevan

243
0:09:05.16,000 --> 0:09:07,000
a su conclusión lógica.

244
0:09:07.16,000 --> 0:09:09,000
No tenemos ningún proyecto.

245
0:09:09.16,000 --> 0:09:12,000
Ya no hacemos declaraciones de guerra

246
0:09:12.16,000 --> 0:09:14,000
ni compramos bonos de guerra.

247
0:09:14.16,000 --> 0:09:16,000
Y ahora hay que considerar que cada vez más

248
0:09:16.16,000 --> 0:09:18,000
estamos reemplazando nuestros soldados

249
0:09:18.16,000 --> 0:09:2,000
americanos que mandaríamos al peligro

250
0:09:20.16,000 --> 0:09:23,000
por máquinas, y así poder superar

251
0:09:23.16,000 --> 0:09:26,000
los obstáculos que quedan en la guerra

252
0:09:26.16,000 --> 0:09:29,000
y hacerlos caer al suelo.

253
0:09:29.16,000 --> 0:09:31,000
Pero el futuro de la guerra también va a ser

254
0:09:31.16,000 --> 0:09:33,000
una guerra en YouTube.

255
0:09:33.16,000 --> 0:09:35,000
Es decir, nuestras nuevas tecnologías no se limitan

256
0:09:35.16,000 --> 0:09:37,000
a alejar la gente del riesgo.

257
0:09:37.16,000 --> 0:09:4,000
También registran todo lo que ven.

258
0:09:40.16,000 --> 0:09:43,000
No solo desvinculan el público:

259
0:09:43.16,000 --> 0:09:46,000
redefinen su relación con la guerra.

260
0:09:46.16,000 --> 0:09:48,000
Ya hay miles de video clips

261
0:09:48.16,000 --> 0:09:5,000
de escenas de combates en Irak

262
0:09:50.16,000 --> 0:09:52,000
en este momento en Youtube,

263
0:09:52.16,000 --> 0:09:54,000
la mayoría filmados por aviones no tripulados.

264
0:09:54.16,000 --> 0:09:56,000
Ahora, esto podría ser una cosa positiva.

265
0:09:56.16,000 --> 0:09:58,000
Podría crear conexiones entre

266
0:09:58.16,000 --> 0:10:,000
el frente interno y el frente de guerra

267
0:10:00.16,000 --> 0:10:02,000
como nunca antes.

268
0:10:02.16,000 --> 0:10:04,000
Pero recuerden, todo esto sucede

269
0:10:04.16,000 --> 0:10:07,000
en nuestro extraño y bizarro mundo, y así,

270
0:10:07.16,000 --> 0:10:09,000
inevitablemente, la posibilidad de descargar estos

271
0:10:09.16,000 --> 0:10:11,000
video clips en el iPod o Zune

272
0:10:11.16,000 --> 0:10:14,000
nos da la capacidad

273
0:10:14.16,000 --> 0:10:18,000
para convertirlos en entretenimiento.

274
0:10:18.16,000 --> 0:10:2,000
Los soldados tienen un nombre para estos videos.

275
0:10:20.16,000 --> 0:10:22,000
Los llaman pornografía bélica.

276
0:10:22.16,000 --> 0:10:24,000
Un ejemplo típico fue uno que me enviaron

277
0:10:24.16,000 --> 0:10:26,000
por email con un archivo adjunto

278
0:10:26.16,000 --> 0:10:28,000
de un video del ataque de un Predator

279
0:10:28.16,000 --> 0:10:3,000
a una base enemiga. Golpes de misiles,

280
0:10:30.16,000 --> 0:10:33,000
cuerpos volando por el aire por la explosión.

281
0:10:33.16,000 --> 0:10:35,000
Fue hecho con música.

282
0:10:35.16,000 --> 0:10:37,000
Era con la canción

283
0:10:37.16,000 --> 0:10:4,000
"I Just Want To Fly" de Sugar Ray.

284
0:10:40.16,000 --> 0:10:43,000
Esta capacidad de ver más

285
0:10:43.16,000 --> 0:10:46,000
pero sufrir menos crea un desequilibrio

286
0:10:46.16,000 --> 0:10:48,000
en la relación del público con la guerra.

287
0:10:48.16,000 --> 0:10:5,000
Hago una comparación con el deporte.

288
0:10:50.16,000 --> 0:10:53,000
Es como la diferencia entre

289
0:10:53.16,000 --> 0:10:56,000
ver un partido de la NBA, un partido de baloncesto

290
0:10:56.16,000 --> 0:10:59,000
profesional en televisión, donde los jugadores

291
0:10:59.16,000 --> 0:11:01,000
son pequeñas figuras en la pantalla,

292
0:11:01.16,000 --> 0:11:04,000
y estar en el mismo partido en persona

293
0:11:04.16,000 --> 0:11:06,000
y darse cuenta cómo es realmente alguien

294
0:11:06.16,000 --> 0:11:08,000
de 2,10 metros.

295
0:11:08.16,000 --> 0:11:1,000
Pero hay que recordar

296
0:11:10.16,000 --> 0:11:12,000
que estos son solo videos.

297
0:11:12.16,000 --> 0:11:14,000
Es solo la versión del partido

298
0:11:14.16,000 --> 0:11:16,000
de ESPN. Pierden el contexto.

299
0:11:16.16,000 --> 0:11:18,000
Pierden la estrategia.

300
0:11:18.16,000 --> 0:11:2,000
Pierden la humanidad. La guerra se convierte

301
0:11:20.16,000 --> 0:11:23,000
solo en mates y bombas inteligentes.

302
0:11:23.16,000 --> 0:11:26,000
La cosa irónica en todo esto es que

303
0:11:26.16,000 --> 0:11:28,000
mientras el futuro de la guerra puede involucrar

304
0:11:28.16,000 --> 0:11:3,000
cada vez más máquinas,

305
0:11:30.16,000 --> 0:11:32,000
es nuestra psique humana la que impulsa

306
0:11:32.16,000 --> 0:11:34,000
todo esto, son nuestros errores humanos

307
0:11:34.16,000 --> 0:11:36,000
los que están llevando a estas guerras.

308
0:11:36.16,000 --> 0:11:38,000
Un ejemplo de esto que tiene

309
0:11:38.16,000 --> 0:11:4,000
gran resonancia en la esfera política es

310
0:11:40.16,000 --> 0:11:42,000
cómo se manifiesta en nuestra verdadera

311
0:11:42.16,000 --> 0:11:44,000
guerra de ideas que estamos librando

312
0:11:44.16,000 --> 0:11:46,000
contra los grupos radicales.

313
0:11:46.16,000 --> 0:11:48,000
Qué mensaje creemos que estamos enviando

314
0:11:48.16,000 --> 0:11:5,000
con estas máquinas, frente al mensaje que

315
0:11:50.16,000 --> 0:11:53,000
se está recibiendo del otro lado.

316
0:11:53.16,000 --> 0:11:55,000
Una de las personas que conocí era

317
0:11:55.16,000 --> 0:11:57,000
un alto funcionario del gobierno Bush,

318
0:11:57.16,000 --> 0:11:59,000
que dijo lo siguiente acerca

319
0:11:59.16,000 --> 0:12:01,000
de la deshumanización de la guerra:

320
0:12:01.16,000 --> 0:12:03,000
"Contribuye a nuestra fuerza. Lo que

321
0:12:03.16,000 --> 0:12:05,000
asusta a la gente es nuestra tecnología".

322
0:12:05.16,000 --> 0:12:07,000
Pero cuando conoces a la gente del Líbano,

323
0:12:07.16,000 --> 0:12:09,000
por ejemplo, es una historia

324
0:12:09.16,000 --> 0:12:11,000
muy diferente. Allá conocí

325
0:12:11.16,000 --> 0:12:13,000
a un editor de noticias. Mientras hablábamos,

326
0:12:13.16,000 --> 0:12:15,000
un avión no tripulado volaba sobre nosotros,

327
0:12:15.16,000 --> 0:12:17,000
y dijo esto al respecto:

328
0:12:17.16,000 --> 0:12:19,000
"Esto es otra muestra más de la insensibilidad

329
0:12:19.16,000 --> 0:12:22,000
de los israelíes y los americanos,

330
0:12:22.16,000 --> 0:12:24,000
que son cobardes porque

331
0:12:24.16,000 --> 0:12:26,000
envían máquinas para luchar contra nosotros.

332
0:12:26.16,000 --> 0:12:28,000
No quieren luchar contra nosotros como hombres de verdad,

333
0:12:28.16,000 --> 0:12:3,000
pero tienen miedo de luchar,

334
0:12:30.16,000 --> 0:12:32,000
así que es suficiente matar a algunos de sus soldados

335
0:12:32.16,000 --> 0:12:35,000
para derrotarlos".

336
0:12:35.16,000 --> 0:12:37,000
El futuro de la guerra trae consigo

337
0:12:37.16,000 --> 0:12:39,000
un nuevo tipo de guerrero

338
0:12:39.16,000 --> 0:12:42,000
que en realidad está redefiniendo la experiencia

339
0:12:42.16,000 --> 0:12:44,000
de ir a la guerra.

340
0:12:44.16,000 --> 0:12:46,000
Se les puede llamar guerreros de cubículo.

341
0:12:46.16,000 --> 0:12:48,000
Fue así que un piloto de avión no tripulado Predator

342
0:12:48.16,000 --> 0:12:5,000
describió su experiencia de lucha

343
0:12:50.16,000 --> 0:12:53,000
en la guerra de Irak sin salir de Nevada:

344
0:12:53.16,000 --> 0:12:55,000
"Vas a la guerra durante 12 horas,

345
0:12:55.16,000 --> 0:12:57,000
disparas a los blancos,

346
0:12:57.16,000 --> 0:13:,000
matas directamente a los enemigos,

347
0:13:00.16,000 --> 0:13:02,000
luego tomas el coche,

348
0:13:02.16,000 --> 0:13:04,000
conduces hasta tu casa y en 20 minutos

349
0:13:04.16,000 --> 0:13:06,000
estás sentado en la mesa

350
0:13:06.16,000 --> 0:13:08,000
hablando con tus hijos de sus tareas".

351
0:13:08.16,000 --> 0:13:1,000
Pues bien, el equilibrio psicológico

352
0:13:10.16,000 --> 0:13:12,000
de estas experiencias es increíblemente difícil,

353
0:13:12.16,000 --> 0:13:15,000
y de hecho los pilotos de aviones no tripulados tienen

354
0:13:15.16,000 --> 0:13:17,000
mayores índices de trastorno por estrés postraumático

355
0:13:17.16,000 --> 0:13:2,000
que muchas de las unidades físicas en Irak.

356
0:13:20.16,000 --> 0:13:22,000
Pero algunos temen que esta

357
0:13:22.16,000 --> 0:13:24,000
desconexión conducirá a otra cosa,

358
0:13:24.16,000 --> 0:13:26,000
que hará que sea más fácil aceptar

359
0:13:26.16,000 --> 0:13:28,000
los crímines de guerra cuando se tiene

360
0:13:28.16,000 --> 0:13:3,000
esta distancia. "Es como un videojuego",

361
0:13:30.16,000 --> 0:13:32,000
me dijo un joven piloto hablando del ataque

362
0:13:32.16,000 --> 0:13:34,000
de las tropas enemigas desde la distancia.

363
0:13:34.16,000 --> 0:13:37,000
Cualquiera que haya jugado Grand Theft Auto,

364
0:13:37.16,000 --> 0:13:4,000
sabe que en el mundo virtual hacemos cosas

365
0:13:40.16,000 --> 0:13:43,000
que nunca haríamos en la vida real.

366
0:13:43.16,000 --> 0:13:45,000
Gran parte de lo que estoy diciendo

367
0:13:45.16,000 --> 0:13:47,000
es que hay otro aspecto

368
0:13:47.16,000 --> 0:13:49,000
de las revoluciones tecnológicas

369
0:13:49.16,000 --> 0:13:51,000
que está dando forma a nuestro presente,

370
0:13:51.16,000 --> 0:13:54,000
y quizás dará forma a nuestro futuro en la guerra.

371
0:13:54.16,000 --> 0:13:56,000
La Ley de Moore se aplica,

372
0:13:56.16,000 --> 0:13:58,000
al igual que la Ley de Murphy.

373
0:13:58.16,000 --> 0:14:,000
La niebla de la guerra no se levanta.

374
0:14:00.16,000 --> 0:14:02,000
El enemigo tiene un voto.

375
0:14:02.16,000 --> 0:14:04,000
Estamos ganando increíbles nuevas capacidades,

376
0:14:04.16,000 --> 0:14:06,000
pero también estamos viendo y experimentando

377
0:14:06.16,000 --> 0:14:08,000
nuevos dilemas humanos.

378
0:14:08.16,000 --> 0:14:1,000
A veces no son más que momentos "¡oops!",

379
0:14:10.16,000 --> 0:14:12,000
que es lo que el jefe de una compañía

380
0:14:12.16,000 --> 0:14:14,000
de robótica describió como "patinazos".

381
0:14:14.16,000 --> 0:14:16,000
Bien, ¿Cuáles son los patinazos

382
0:14:16.16,000 --> 0:14:18,000
de los robots en la guerra?

383
0:14:18.16,000 --> 0:14:2,000
Bueno, a veces son graciosos. A veces

384
0:14:20.16,000 --> 0:14:22,000
son como esa escena de la película

385
0:14:22.16,000 --> 0:14:24,000
con Eddie Murphy "La mejor defensa, ¡el ataque!",

386
0:14:24.16,000 --> 0:14:26,000
por ejemplo, cuando pusieron a prueba

387
0:14:26.16,000 --> 0:14:28,000
un robot que estaba armado, y durante

388
0:14:28.16,000 --> 0:14:3,000
la demostración, éste comenzó a girar

389
0:14:30.16,000 --> 0:14:33,000
en un círculo apuntando con sus ametralladoras

390
0:14:33.16,000 --> 0:14:36,000
hacia la tribuna de las personalidades.

391
0:14:36.16,000 --> 0:14:38,000
Afortunadamente el arma no estaba cargada

392
0:14:38.16,000 --> 0:14:4,000
y nadie resultó herido, pero otras veces

393
0:14:40.16,000 --> 0:14:42,000
los patinazos son trágicos,

394
0:14:42.16,000 --> 0:14:44,000
como el año pasado en Sudáfrica, donde

395
0:14:44.16,000 --> 0:14:47,000
un cañón antiaéreo tuvo un

396
0:14:47.16,000 --> 0:14:5,000
"problema de software", y en realidad se activó

397
0:14:50.16,000 --> 0:14:53,000
y disparó, matando a nueve soldados.

398
0:14:53.16,000 --> 0:14:56,000
Existen nuevos escollos en las leyes de guerra

399
0:14:56.16,000 --> 0:14:58,000
y la rendición de cuentas. ¿Qué hacemos

400
0:14:58.16,000 --> 0:15:,000
en situaciones como la masacre no tripulada?

401
0:15:00.16,000 --> 0:15:02,000
¿Qué es masacre no tripulada?

402
0:15:02.16,000 --> 0:15:04,000
Ya hemos tenido tres casos de ataques

403
0:15:04.16,000 --> 0:15:06,000
con aviones no tripulados Predator donde

404
0:15:06.16,000 --> 0:15:08,000
pensábamos que tenían a Bin Laden,

405
0:15:08.16,000 --> 0:15:1,000
y resultó no ser así.

406
0:15:10.16,000 --> 0:15:12,000
Y ahí es donde estamos ahora.

407
0:15:12.16,000 --> 0:15:14,000
Ni siquiera estamos hablando de sistemas

408
0:15:14.16,000 --> 0:15:16,000
autónomos armados

409
0:15:16.16,000 --> 0:15:18,000
con plena autoridad para usar la fuerza.

410
0:15:18.16,000 --> 0:15:2,000
Y no creo que esto no vaya a suceder.

411
0:15:20.16,000 --> 0:15:22,000
Durante mi investigación me topé con cuatro

412
0:15:22.16,000 --> 0:15:24,000
diferentes proyectos del Pentágono

413
0:15:24.16,000 --> 0:15:26,000
sobre diversos aspectos del problema.

414
0:15:26.16,000 --> 0:15:28,000
Y entonces surge la pregunta:

415
0:15:28.16,000 --> 0:15:3,000
¿cómo plantear cuestiones relacionadas

416
0:15:30.16,000 --> 0:15:32,000
con crímenes de guerra? Los robots no tienen emociones,

417
0:15:32.16,000 --> 0:15:35,000
así que no se enojan si un compañero es asesinado.

418
0:15:35.16,000 --> 0:15:37,000
No cometen crímenes de rabia

419
0:15:37.16,000 --> 0:15:39,000
y venganza.

420
0:15:39.16,000 --> 0:15:42,000
Pero los robots no sienten emociones.

421
0:15:42.16,000 --> 0:15:44,000
Ven a una abuela de 80 años

422
0:15:44.16,000 --> 0:15:46,000
en silla de ruedas del mismo modo que ven

423
0:15:46.16,000 --> 0:15:49,000
un tanque T-80: ambos

424
0:15:49.16,000 --> 0:15:52,000
son solo una serie de ceros y unos.

425
0:15:52.16,000 --> 0:15:55,000
Debemos hallar entonces una respuesta a esta pregunta:

426
0:15:55.16,000 --> 0:15:57,000
¿Cómo podemos adaptar nuestras leyes

427
0:15:57.16,000 --> 0:15:59,000
de guerra del siglo XX, tan viejas

428
0:15:59.16,000 --> 0:16:02,000
que podrían jubilarse,

429
0:16:02.16,000 --> 0:16:05,000
a estas tecnologías del siglo XXI?

430
0:16:05.16,000 --> 0:16:08,000
Por último, he hablado de lo que parece

431
0:16:08.16,000 --> 0:16:11,000
ser el futuro de la guerra,

432
0:16:11.16,000 --> 0:16:13,000
pero tengan en cuenta que solo

433
0:16:13.16,000 --> 0:16:15,000
he usado ejemplos del mundo real y que solo

434
0:16:15.16,000 --> 0:16:17,000
han visto fotos y videos reales.

435
0:16:17.16,000 --> 0:16:19,000
Y esto representa un gran desafío

436
0:16:19.16,000 --> 0:16:21,000
del cual todos debemos preocuparnos,

437
0:16:21.16,000 --> 0:16:23,000
antes de tener que preocuparnos de que

438
0:16:23.16,000 --> 0:16:25,000
una aspiradora nos succione la vida.

439
0:16:25.16,000 --> 0:16:27,000
¿Vamos a dejar que esto que está

440
0:16:27.16,000 --> 0:16:3,000
sucediendo en la guerra,

441
0:16:30.16,000 --> 0:16:33,000
solo porque suena a ciencia ficción

442
0:16:33.16,000 --> 0:16:35,000
nos mantenga en la negación?

443
0:16:35.16,000 --> 0:16:37,000
¿Vamos a enfrentar la realidad

444
0:16:37.16,000 --> 0:16:39,000
de la guerra del siglo XXI?

445
0:16:39.16,000 --> 0:16:41,000
¿Nuestra generación va a repetir

446
0:16:41.16,000 --> 0:16:43,000
el error que cometió una generación pasada

447
0:16:43.16,000 --> 0:16:45,000
con las armas atómicas, y no va a lidiar con

448
0:16:45.16,000 --> 0:16:47,000
las cuestiones que lo rodean sino hasta

449
0:16:47.16,000 --> 0:16:49,000
que la caja de Pandora esté abierta?

450
0:16:49.16,000 --> 0:16:51,000
Ahora, yo podría estar equivocado,

451
0:16:51.16,000 --> 0:16:53,000
como afirmó un científico de robots

452
0:16:53.16,000 --> 0:16:55,000
del Pentágono diciendo: "No hay verdaderos

453
0:16:55.16,000 --> 0:16:57,000
problemas sociales, éticos y morales cuando

454
0:16:57.16,000 --> 0:16:59,000
se trata de robots.

455
0:16:59.16,000 --> 0:17:01,000
Es decir", añadió, "a menos que la máquina

456
0:17:01.16,000 --> 0:17:04,000
mate repetidamente a las personas equivocadas.

457
0:17:04.16,000 --> 0:17:07,000
Entonces es simplemente una cuestión de retiro del producto".

458
0:17:07.16,000 --> 0:17:1,000
Y el punto de esto es que

459
0:17:10.16,000 --> 0:17:15,000
podemos recurrir a Hollywood.

460
0:17:15.16,000 --> 0:17:17,000
Hace unos años, Hollywood reunió

461
0:17:17.16,000 --> 0:17:2,000
a los personajes más famosos y creó

462
0:17:20.16,000 --> 0:17:22,000
una lista de los 100 mejores héroes y

463
0:17:22.16,000 --> 0:17:25,000
los 100 mejores villanos de toda la historia de Hollywood,

464
0:17:25.16,000 --> 0:17:27,000
los personajes que representan lo mejor

465
0:17:27.16,000 --> 0:17:29,000
y lo peor de la humanidad.

466
0:17:29.16,000 --> 0:17:33,000
Solo un personaje aparece en ambas listas:

467
0:17:33.16,000 --> 0:17:36,000
Terminator, una máquina asesina.

468
0:17:36.16,000 --> 0:17:38,000
Y esto indica que

469
0:17:38.16,000 --> 0:17:4,000
nuestras máquinas pueden ser usadas

470
0:17:40.16,000 --> 0:17:42,000
ya sea para bien o para mal, pero para mí

471
0:17:42.16,000 --> 0:17:44,000
indica que hay una dualidad

472
0:17:44.16,000 --> 0:17:47,000
en el ser humano.

473
0:17:47.16,000 --> 0:17:49,000
Esta semana celebramos

474
0:17:49.16,000 --> 0:17:51,000
nuestra creatividad. Nuestra creatividad

475
0:17:51.16,000 --> 0:17:53,000
ha llevado nuestra especie a las estrellas.

476
0:17:53.16,000 --> 0:17:55,000
Nuestra creatividad ha creado obras de arte

477
0:17:55.16,000 --> 0:17:58,000
y la literatura para expresar nuestro amor.

478
0:17:58.16,000 --> 0:18:,000
Ahora estamos usando nuestra creatividad

479
0:18:00.16,000 --> 0:18:02,000
en una cierta dirección, para construir

480
0:18:02.16,000 --> 0:18:05,000
máquinas fantásticas con increíbles capacidades,

481
0:18:05.16,000 --> 0:18:07,000
y quizás, algún día,

482
0:18:07.16,000 --> 0:18:1,000
incluso una nueva especie.

483
0:18:10.16,000 --> 0:18:12,000
Pero una de las principales razones por las que

484
0:18:12.16,000 --> 0:18:14,000
hacemos esto se debe a nuestro instinto

485
0:18:14.16,000 --> 0:18:17,000
de destruirnos unos a otros. Por lo tanto,

486
0:18:17.16,000 --> 0:18:19,000
deberíamos preguntarnos:

487
0:18:19.16,000 --> 0:18:21,000
¿son nuestras máquinas, o estamos

488
0:18:21.16,000 --> 0:18:23,000
auto diseñados para la guerra?

489
0:18:23.16,000 --> 0:18:25,000
Gracias. (Aplausos)

