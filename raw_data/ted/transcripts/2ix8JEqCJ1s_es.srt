1
0:00:,000 --> 0:00:07,000
Traductor: Laura Feijóo Sánchez Revisor: Lily María Bello Sánchez

2
0:00:12.612,000 --> 0:00:13,000
Durante los últimos tres años

3
0:00:14.217,000 --> 0:00:17,000
he hablado con algunas de las peores personas del Internet.

4
0:00:18.131,000 --> 0:00:2,000
Si han estado navegando en Internet recientemente,

5
0:00:20.637,000 --> 0:00:23,000
puede que hayan notado la gran cantidad de basura tóxica que hay:

6
0:00:24.479,000 --> 0:00:28,000
memes racistas, propaganda misógina, desinformación viral.

7
0:00:28.862,000 --> 0:00:3,000
Y quería saber quien estaba creando estas cosas.

8
0:00:31.609,000 --> 0:00:33,000
Quería entender cómo las difundían.

9
0:00:33.957,000 --> 0:00:34,000
Básicamente, quería conocer

10
0:00:35.438,000 --> 0:00:37,000
el impacto que podría tener en nuestra sociedad.

11
0:00:37.761,000 --> 0:00:4,000
Así que en 2016 comencé a buscar el origen de algunos de estos memes

12
0:00:41.76,000 --> 0:00:44,000
para llegar a quienes los creaban o a quienes los hacían virales.

13
0:00:45.016,000 --> 0:00:46,000
Me acercaba a esta gente y les decía:

14
0:00:46.85,000 --> 0:00:48,000
"Soy periodista. ¿Puedo acompañarlo y ver lo que hace?"

15
0:00:49.5,000 --> 0:00:5,000
A menudo, la respuesta sería:

16
0:00:51.124,000 --> 0:00:53,000
"¿Por qué diablos yo quisiera hablar

17
0:00:53.171,000 --> 0:00:55,000
con un 'soy- boy' judío globalista de Brooklyn

18
0:00:55.818,000 --> 0:00:57,000
confabulado con el partido demócrata?".

19
0:00:57.929,000 --> 0:00:58,000
(Risas)

20
0:00:59.205,000 --> 0:01:02,000
Y mi respuesta sería: "Mira, eso solo es un 57 % cierto".

21
0:01:02.984,000 --> 0:01:03,000
(Risas)

22
0:01:04.376,000 --> 0:01:06,000
Pero muchas veces la respuesta era la opuesta.

23
0:01:06.563,000 --> 0:01:07,000
"Sí, por supuesto, siga."

24
0:01:08.555,000 --> 0:01:1,000
Y así fue cómo terminé en la sala de estar

25
0:01:10.556,000 --> 0:01:13,000
de un propagandista en el Sur de California.

26
0:01:14.336,000 --> 0:01:16,000
Era un hombre blanco, casado, cerca de los cuarenta.

27
0:01:16.841,000 --> 0:01:19,000
Sentado ante una mesa con una taza de café,

28
0:01:19.967,000 --> 0:01:2,000
un portátil para tuitear,

29
0:01:21.607,000 --> 0:01:22,000
un celular para textear

30
0:01:23.439,000 --> 0:01:26,000
y un iPad para hacer directos en Periscope y YouTube.

31
0:01:27.058,000 --> 0:01:28,000
Eso era todo.

32
0:01:28.998,000 --> 0:01:29,000
Y con esas herramientas

33
0:01:30.268,000 --> 0:01:33,000
era capaz de impulsar temas dañinos y alternativos

34
0:01:34.007,000 --> 0:01:36,000
en medio de la conversación estadounidense.

35
0:01:37.064,000 --> 0:01:39,000
Por ejemplo, uno de los días que estuve allí,

36
0:01:39.207,000 --> 0:01:42,000
una bomba acababa de explotar en Nueva York,

37
0:01:42.283,000 --> 0:01:45,000
y el chico acusado de haberla puesto tenía un sonante nombre musulmán.

38
0:01:45.842,000 --> 0:01:49,000
El propagandista de California vio esto como una oportunidad

39
0:01:50.008,000 --> 0:01:51,000
porque una de las cosas que quería

40
0:01:51.748,000 --> 0:01:53,000
era que EE. UU. cortara casi toda la inmigración,

41
0:01:54.394,000 --> 0:01:56,000
especialmente de los países mayoritariamente musulmanes.

42
0:01:57.294,000 --> 0:01:59,000
Así que empezó una transmisión en vivo,

43
0:01:59.499,000 --> 0:02:01,000
haciendo que sus seguidores se pusieran frenéticos

44
0:02:01.829,000 --> 0:02:03,000
diciendo que las fronteras libres nos iban a matar.

45
0:02:04.562,000 --> 0:02:05,000
Él les pedía que tuitiaran

46
0:02:06.354,000 --> 0:02:07,000
y usaran hashtags específicos

47
0:02:07.817,000 --> 0:02:08,000
para intentar hacerlos tendencia.

48
0:02:09.775,000 --> 0:02:1,000
Y tuitearon...

49
0:02:10.972,000 --> 0:02:11,000
Cientos y cientos de tuits,

50
0:02:12.836,000 --> 0:02:14,000
muchos de ellos mostraban imágenes como esta.

51
0:02:15.239,000 --> 0:02:16,000
Este es George Soros.

52
0:02:16.89,000 --> 0:02:18,000
Un multimillonario y filántropo húngaro

53
0:02:19.709,000 --> 0:02:21,000
y según varios conspiradores online,

54
0:02:22.328,000 --> 0:02:24,000
George Soros es una especie de monstruo globalista,

55
0:02:24.92,000 --> 0:02:28,000
perteneciente a la élite que secretamente manipula todos los asuntos globales.

56
0:02:29.078,000 --> 0:02:32,000
Situémonos aquí un momento: si esta idea les resulta familiar,

57
0:02:32.694,000 --> 0:02:34,000
que existe una élite que controla el mundo

58
0:02:35.086,000 --> 0:02:37,000
formada en su mayoría por judíos ricos,

59
0:02:37.691,000 --> 0:02:4,000
es porque es uno de las figuras más antisemitas que existen.

60
0:02:42.296,000 --> 0:02:45,000
Debo mencionar que el hombre que puso la bomba en Nueva York

61
0:02:45.694,000 --> 0:02:46,000
era un ciudadano estadounidense.

62
0:02:47.785,000 --> 0:02:49,000
Fuera cual fuera la razón

63
0:02:49.989,000 --> 0:02:51,000
la inmigración no era lo importante.

64
0:02:53.332,000 --> 0:02:55,000
El propagandista de California era consciente de ello.

65
0:02:56.164,000 --> 0:02:58,000
Era un hombre leído. En realidad, era abogado.

66
0:02:58.709,000 --> 0:02:59,000
Conocía los hechos subyacentes,

67
0:03:00.42,000 --> 0:03:03,000
pero también sabía que los hechos no dan de qué hablar.

68
0:03:03.635,000 --> 0:03:04,000
Los que sí dan de qué hablar

69
0:03:05.366,000 --> 0:03:06,000
es la emoción.

70
0:03:07.451,000 --> 0:03:09,000
La premisa original de las redes sociales

71
0:03:09.485,000 --> 0:03:1,000
era que iban a unirnos

72
0:03:11.081,000 --> 0:03:14,000
a hacer un mundo más abierto, tolerante y justo...

73
0:03:14.137,000 --> 0:03:15,000
Y algo de eso sí hizo.

74
0:03:16.503,000 --> 0:03:18,000
Pero los algoritmos no se crearon

75
0:03:19.226,000 --> 0:03:21,000
para distinguir lo que es verdad o mentira,

76
0:03:21.588,000 --> 0:03:24,000
lo que es bueno o malo para la sociedad, lo que es prosocial, lo que es antisocial.

77
0:03:25.965,000 --> 0:03:27,000
Eso no es lo que hacen los algoritmos.

78
0:03:28.202,000 --> 0:03:3,000
Lo que hacen es medir la interacción:

79
0:03:30.805,000 --> 0:03:33,000
clics, comentarios, qué se comparte, retweets, todas esas cosas.

80
0:03:33.85,000 --> 0:03:35,000
Y si quiere que su contenido genere interacción,

81
0:03:36.575,000 --> 0:03:37,000
tiene que provocar emoción,

82
0:03:38.137,000 --> 0:03:41,000
específicamente lo que los expertos de la conducta llaman: "de alta excitación".

83
0:03:42.343,000 --> 0:03:44,000
"Alta excitación" no se refiere solo a la sexual,

84
0:03:44.857,000 --> 0:03:46,000
aunque tratándose de internet eso obviamente funciona.

85
0:03:47.616,000 --> 0:03:51,000
Se refiere a cualquier cosa, positiva o negativa, que nos eleve el pulso.

86
0:03:51.649,000 --> 0:03:52,000
Me senté con estos propagandistas,

87
0:03:53.642,000 --> 0:03:55,000
docenas de ellos, no solo el de California,

88
0:03:56.075,000 --> 0:03:59,000
y miraba mientras hacían esto una y otra vez, con éxito,

89
0:03:59.847,000 --> 0:04:02,000
no porque fueran hackers rusos o porque fueran genios tecnológicos,

90
0:04:03.479,000 --> 0:04:05,000
no porque tuvieran conocimientos políticos...

91
0:04:05.712,000 --> 0:04:07,000
sino porque sabían cómo funcionaban las redes sociales

92
0:04:08.308,000 --> 0:04:09,000
y estaban dispuestos a usarlo a su favor.

93
0:04:10.272,000 --> 0:04:13,000
Al principio me decía que era un fenómeno aislado,

94
0:04:13.54,000 --> 0:04:15,000
algo que quedaba relegado al internet.

95
0:04:16.385,000 --> 0:04:2,000
Pero, en realidad, ya no hay separación entre el internet y todo lo demás.

96
0:04:20.761,000 --> 0:04:22,000
Este anuncio recorrió múltiples cadenas

97
0:04:22.969,000 --> 0:04:24,000
durante las elecciones al congreso del 2018,

98
0:04:25.6,000 --> 0:04:27,000
afirmando, sin casi pruebas, que el manipulador internacional,

99
0:04:28.58,000 --> 0:04:3,000
George Soros, tenía en el bolsillo a uno de los candidatos,

100
0:04:31.39,000 --> 0:04:34,000
quien aparece en este montaje al lado de varias pilas de dinero.

101
0:04:35.296,000 --> 0:04:37,000
Este es un tuit del presidente de EE. UU.

102
0:04:37.91,000 --> 0:04:38,000
afirmando, de nuevo, sin pruebas,

103
0:04:39.499,000 --> 0:04:42,000
que la política estadounidense está siendo manipulada por George Soros.

104
0:04:43.086,000 --> 0:04:46,000
Todo esto que antes parecía escandaloso, marginal y, francamente, ignorable,

105
0:04:47.084,000 --> 0:04:49,000
ahora está tan normalizado que casi ni lo notamos.

106
0:04:50.053,000 --> 0:04:52,000
Pasé tres años en este mundo.

107
0:04:52.061,000 --> 0:04:53,000
Hablé con mucha gente.

108
0:04:53.837,000 --> 0:04:55,000
Algunos parecen no tener valores fundamentales.

109
0:04:56.327,000 --> 0:04:58,000
Simplemente parecen estar apostando de manera racional

110
0:04:58.934,000 --> 0:05:,000
a que si ellos querían hacer dinero en línea

111
0:05:01.021,000 --> 0:05:02,000
o conseguir atención online,

112
0:05:02.357,000 --> 0:05:04,000
deberían ser lo más extravagantes posible.

113
0:05:04.77,000 --> 0:05:06,000
Pero hablé con otros quienes eran verdaderos ideólogos.

114
0:05:08.173,000 --> 0:05:11,000
Y aclaro, su ideología no era conservadurismo tradicional.

115
0:05:12.078,000 --> 0:05:15,000
Eran personas que querían revocar el sufragio femenino.

116
0:05:15.48,000 --> 0:05:17,000
Eran personas que querían volver a la segregación racial.

117
0:05:18.159,000 --> 0:05:21,000
Algunos querían eliminar la democracia de raíz.

118
0:05:21.304,000 --> 0:05:23,000
Obviamente, esta gente no nacieron creyendo estas cosas.

119
0:05:23.939,000 --> 0:05:24,000
No lo aprendieron en el colegio.

120
0:05:26.856,000 --> 0:05:28,000
Muchos de ellos, antes de entrar en internet,

121
0:05:29.872,000 --> 0:05:31,000
habían sido libertarios o socialistas

122
0:05:32.364,000 --> 0:05:34,000
o algo completamente diferente.

123
0:05:34.575,000 --> 0:05:35,000
¿Qué estaba pasando?

124
0:05:36.918,000 --> 0:05:37,000
No puedo generalizar cada caso,

125
0:05:38.904,000 --> 0:05:39,000
pero muchos con los que hablé,

126
0:05:40.715,000 --> 0:05:43,000
parecían tener una combinación de coeficiente intelectual alto y bajo.

127
0:05:44.619,000 --> 0:05:47,000
Parecían estar más cómodos en espacios anónimos en línea

128
0:05:48.154,000 --> 0:05:5,000
en vez de estar conectados en el mundo real.

129
0:05:50.81,000 --> 0:05:52,000
A menudo se refugiaban en esos tableros de mensajes

130
0:05:53.287,000 --> 0:05:54,000
o en esos subreddits,

131
0:05:54.483,000 --> 0:05:56,000
donde se magnificaban sus peores impulsos.

132
0:05:56.961,000 --> 0:05:59,000
Puede que comiencen con alguna broma de mal gusto

133
0:06:00.044,000 --> 0:06:02,000
y después recibirían tal refuerzo positivo por esa broma,

134
0:06:02.73,000 --> 0:06:05,000
tantos puntos de internet sin sentido,

135
0:06:05.97,000 --> 0:06:07,000
que puede que comiencen a creerse sus propias bromas.

136
0:06:10.014,000 --> 0:06:13,000
Hablé mucho con una joven que creció en Nueva Jersey

137
0:06:13.562,000 --> 0:06:15,000
y después del bachillerato se mudó

138
0:06:16.062,000 --> 0:06:18,000
y de repente se sintió alienada y aislada,

139
0:06:18.34,000 --> 0:06:19,000
y comenzó a refugiarse en su celular.

140
0:06:20.85,000 --> 0:06:22,000
Encontró alguno de estos espacios en internet

141
0:06:22.988,000 --> 0:06:24,000
donde la gente publicaba las cosas más atroces.

142
0:06:25.936,000 --> 0:06:27,000
Todo esto le pareció repulsivo

143
0:06:28.229,000 --> 0:06:29,000
pero a la vez interesante,

144
0:06:30.754,000 --> 0:06:32,000
no podía apartar la mirada.

145
0:06:33.304,000 --> 0:06:35,000
Comenzó a interactuar con gente en estos espacios

146
0:06:35.85,000 --> 0:06:37,000
y la hicieron sentir inteligente, la hicieron sentir válida.

147
0:06:38.702,000 --> 0:06:4,000
Comenzó a sentirse parte de una comunidad,

148
0:06:40.735,000 --> 0:06:42,000
comenzó a preguntarse si quizás alguno de esos memes

149
0:06:43.188,000 --> 0:06:45,000
podría contener algo de verdad.

150
0:06:46.151,000 --> 0:06:49,000
Meses después, estaba en un carro con sus nuevos amigos de internet

151
0:06:49.366,000 --> 0:06:5,000
camino a Charlottesville, en Virginia,

152
0:06:51.24,000 --> 0:06:53,000
para marchar con antorchas por la raza blanca.

153
0:06:55.033,000 --> 0:06:57,000
En pocos meses, había pasado de apoyar a Obama

154
0:06:57.338,000 --> 0:06:59,000
a ser una radical defensora de la supremacía blanca.

155
0:07:01.03,000 --> 0:07:03,000
En su caso en particular,

156
0:07:03.335,000 --> 0:07:07,000
ella fue capaz de salir de la secta de la supremacía blanca.

157
0:07:08.418,000 --> 0:07:1,000
Pero mucha gente con la que hablé no.

158
0:07:10.502,000 --> 0:07:11,000
Para ser claro:

159
0:07:12.248,000 --> 0:07:14,000
Nunca había estado tan convencido de que tenía que encontrar

160
0:07:15.059,000 --> 0:07:17,000
algo en común con todos con los que hablé

161
0:07:17.325,000 --> 0:07:18,000
y estar dispuesto a decir:

162
0:07:18.603,000 --> 0:07:21,000
"¿Sabes qué? Tú eres un propagandista fascista, yo no,

163
0:07:21.768,000 --> 0:07:24,000
pero da igual, démonos la mano y nuestras diferencias desaparecerán".

164
0:07:25.058,000 --> 0:07:26,000
No, por supuesto que no.

165
0:07:28.056,000 --> 0:07:31,000
Pero sí me convencí de que no podía mirar para otro lado.

166
0:07:31.601,000 --> 0:07:34,000
Tenemos que intentar entenderlo porque solo al entenderlo

167
0:07:34.841,000 --> 0:07:37,000
podemos vacunarnos contra ello.

168
0:07:39.361,000 --> 0:07:42,000
Durante mis tres años en este mundo, recibí llamadas crueles,

169
0:07:42.71,000 --> 0:07:43,000
incluso amenazas,

170
0:07:44.254,000 --> 0:07:47,000
pero tan solo fue una parte de lo que reciben las periodistas.

171
0:07:48.791,000 --> 0:07:49,000
Y sí, yo soy judío,

172
0:07:50.206,000 --> 0:07:53,000
aunque, irónicamente, muchos de los Nazis no se dieron cuenta,

173
0:07:53.879,000 --> 0:07:55,000
lo que, la verdad, me pareció decepcionante.

174
0:07:56.764,000 --> 0:07:57,000
(Risas)

175
0:07:58.588,000 --> 0:08:01,000
En serio, se dedica a ser un antisemita profesional.

176
0:08:03.228,000 --> 0:08:05,000
¿No ve nada que me delate?

177
0:08:05.674,000 --> 0:08:06,000
¿Nada?

178
0:08:06.774,000 --> 0:08:08,000
(Risas)

179
0:08:09.983,000 --> 0:08:1,000
No es ningún secreto.

180
0:08:11.202,000 --> 0:08:13,000
Me llamo Andrew Marantz, escribo para el "The New Yorker"

181
0:08:13.909,000 --> 0:08:14,000
mi personalidad es como si pusieran

182
0:08:15.654,000 --> 0:08:17,000
un episodio de Seinfeld en Park Slope Food Coop.

183
0:08:18.315,000 --> 0:08:19,000
¿Nada?

184
0:08:19.501,000 --> 0:08:21,000
(Risas)

185
0:08:24.804,000 --> 0:08:26,000
En fin... básicamente, estaría bien

186
0:08:27.059,000 --> 0:08:29,000
que hubiera una fórmula simple:

187
0:08:29.431,000 --> 0:08:33,000
un smartphone más un niño aislado es igual a un 12 % de posibilidades de ser Nazi.

188
0:08:33.918,000 --> 0:08:34,000
Obviamente no es tan simple.

189
0:08:36.19,000 --> 0:08:37,000
En mi forma de escribir,

190
0:08:37.377,000 --> 0:08:4,000
me resulta mucho más cómodo ser descriptivo, no prescriptivo.

191
0:08:41.049,000 --> 0:08:43,000
Pero esto es TED,

192
0:08:43.714,000 --> 0:08:44,000
así que seamos prácticos.

193
0:08:45.725,000 --> 0:08:46,000
Quiero compartir unas sugerencias

194
0:08:47.375,000 --> 0:08:5,000
de cosas que ciudadanos de internet como usted y como yo

195
0:08:50.525,000 --> 0:08:52,000
podemos hacer para que las cosas no sean tan tóxicas.

196
0:08:53.86,000 --> 0:08:53,000
[Sugerencia 1]

197
0:08:54.83,000 --> 0:08:56,000
Lo primero es ser un inteligente escéptico.

198
0:08:57.964,000 --> 0:08:59,000
Creo que hay dos tipos de escepticismo.

199
0:09:00.185,000 --> 0:09:04,000
No los quiero aburrir con información técnica que necesite explicación,

200
0:09:04.437,000 --> 0:09:06,000
pero lo llamo escepticismo inteligente y estúpido.

201
0:09:08.176,000 --> 0:09:1,000
Escepticismo inteligente:

202
0:09:10.707,000 --> 0:09:11,000
pensar por uno mismo,

203
0:09:11.935,000 --> 0:09:12,000
dudar de toda afirmación,

204
0:09:13.151,000 --> 0:09:14,000
demandar pruebas...

205
0:09:14.617,000 --> 0:09:15,000
es decir, escepticismo de verdad.

206
0:09:17.397,000 --> 0:09:19,000
Escepticismo estúpido: parece escepticismo,

207
0:09:20.051,000 --> 0:09:22,000
pero está más cerca de ser espíritu de contradicción.

208
0:09:23.817,000 --> 0:09:24,000
Dicen que la tierra es redonda,

209
0:09:25.414,000 --> 0:09:26,000
tú dices que es plana.

210
0:09:26.794,000 --> 0:09:27,000
Dicen que el racismo es malo,

211
0:09:28.385,000 --> 0:09:3,000
tú dices: "No sé, soy escéptico en el tema".

212
0:09:31.682,000 --> 0:09:34,000
No tienen una idea de cuántos jóvenes blancos

213
0:09:35.275,000 --> 0:09:36,000
me han dicho en los últimos años:

214
0:09:37.005,000 --> 0:09:4,000
"Los medios, mis profesores todos intentan adoctrinarme

215
0:09:40.11,000 --> 0:09:42,000
sobre el privilegio masculino y el privilegio blanco

216
0:09:42.556,000 --> 0:09:44,000
pero no sé, yo no lo creo".

217
0:09:45.152,000 --> 0:09:48,000
Adolescentes blancos del mundo,

218
0:09:48.43,000 --> 0:09:48,000
escuchen:

219
0:09:50.755,000 --> 0:09:53,000
si son escépticos acerca de que la tierra es redonda, el privilegio masculino

220
0:09:54.492,000 --> 0:09:56,000
o sobre que el racismo es malo,

221
0:09:56.826,000 --> 0:09:58,000
no están siendo escépticos sino imbéciles".

222
0:09:59.175,000 --> 0:10:02,000
(Aplausos)

223
0:10:04.394,000 --> 0:10:07,000
Está bien pensar por uno mismo, todos deberíamos hacerlo,

224
0:10:07.478,000 --> 0:10:08,000
pero hay que ser inteligentes.

225
0:10:08.996,000 --> 0:10:08,000
[Sugerencia 2]

226
0:10:09.896,000 --> 0:10:1,000
La siguiente es libertad de expresión.

227
0:10:11.769,000 --> 0:10:12,000
Escucharán a gente inteligente decir:

228
0:10:13.625,000 --> 0:10:15,000
"Estoy a favor de la libertad de expresión"

229
0:10:15.781,000 --> 0:10:18,000
y lo dirán como si estuvieran comenzando un debate,

230
0:10:19.078,000 --> 0:10:22,000
cuando en realidad es el inicio de cualquier conversación importante.

231
0:10:23.454,000 --> 0:10:25,000
Todas las cosas importantes ocurren a partir de allí.

232
0:10:26.027,000 --> 0:10:28,000
Bien, está a favor, ¿y eso qué significa?

233
0:10:28.285,000 --> 0:10:3,000
¿Significa que David Duke y Richard Spencer

234
0:10:30.316,000 --> 0:10:31,000
tienen que tener cuentas en Twitter?

235
0:10:32.735,000 --> 0:10:34,000
¿Significa que podemos acosar en línea a cualquier persona

236
0:10:35.555,000 --> 0:10:36,000
por cualquier razón?

237
0:10:37.031,000 --> 0:10:39,000
He visto la lista completa de oradores de TED este año.

238
0:10:39.672,000 --> 0:10:41,000
No encontré a ningún terraplanista.

239
0:10:41.997,000 --> 0:10:43,000
¿Eso es una violación de la libertad de expresión?

240
0:10:44.826,000 --> 0:10:47,000
Todos estamos a favor y es maravilloso estar a favor de la libertad de expresión,

241
0:10:48.652,000 --> 0:10:5,000
pero si es lo único que dicen una y otra vez,

242
0:10:51.297,000 --> 0:10:53,000
se interpondrán a una conversación más productiva.

243
0:10:54.756,000 --> 0:10:55,000
[Sugerencia 3]

244
0:10:56.105,000 --> 0:10:59,000
Hacer que la decencia vuelva a estar de moda.

245
0:10:59.264,000 --> 0:11:,000
¡Genial!

246
0:11:00.486,000 --> 0:11:01,000
(Aplausos)

247
0:11:02.051,000 --> 0:11:04,000
Sí. Ni siquiera tengo que explicarlo.

248
0:11:04.181,000 --> 0:11:07,000
En mi investigación, entré a Reddit, o a YouTube o a Facebook,

249
0:11:08.051,000 --> 0:11:1,000
y busqué "ley sharia"

250
0:11:10.375,000 --> 0:11:12,000
o "el Holocausto"

251
0:11:12.515,000 --> 0:11:15,000
y se pueden hacer una idea de lo que los algoritmos me mostraron.

252
0:11:16.386,000 --> 0:11:18,000
"¿Se está extendiendo la ley sharia en EE. UU.?"

253
0:11:19.34,000 --> 0:11:21,000
"¿De verdad ocurrió el Holocausto?"

254
0:11:22.291,000 --> 0:11:23,000
Escepticismo estúpido.

255
0:11:24.835,000 --> 0:11:26,000
Estamos en una extraña dinámica en línea

256
0:11:27.24,000 --> 0:11:29,000
donde vemos propaganda intolerante

257
0:11:29.356,000 --> 0:11:31,000
como provocadora, peligrosa y agradable,

258
0:11:32.046,000 --> 0:11:35,000
y vemos la verdad fundamental y la decencia como chocante

259
0:11:35.397,000 --> 0:11:37,000
como muestra de virtud o simplemente aburrida.

260
0:11:38.329,000 --> 0:11:41,000
Los algoritmos de las redes sociales, intencionadamente o no,

261
0:11:41.618,000 --> 0:11:43,000
lo han incentivado,

262
0:11:43.665,000 --> 0:11:45,000
porque la propaganda intolerante es genial para la interacción.

263
0:11:46.641,000 --> 0:11:48,000
Todo el mundo clica, todo el mundo comenta,

264
0:11:48.931,000 --> 0:11:49,000
tanto si les gusta como si lo odian.

265
0:11:51.463,000 --> 0:11:53,000
Lo primero que tiene que pasar

266
0:11:53.775,000 --> 0:11:55,000
es que las redes sociales arreglen sus plataformas.

267
0:11:57.069,000 --> 0:12:01,000
(Aplausos)

268
0:12:01.6,000 --> 0:12:04,000
Si me están escuchando y trabajan para una red social

269
0:12:05.054,000 --> 0:12:07,000
o invierten en una o, no sé, es dueño de una,

270
0:12:08.598,000 --> 0:12:09,000
este consejo va para Uds.

271
0:12:10.083,000 --> 0:12:13,000
Si están optimizando para una interacción emocional

272
0:12:14.028,000 --> 0:12:18,000
y esta interacción resulta que está dañando el mundo,

273
0:12:18.165,000 --> 0:12:2,000
es el momento de optimizar otra cosa.

274
0:12:20.725,000 --> 0:12:23,000
(Aplausos)

275
0:12:26.939,000 --> 0:12:29,000
Pero además de presionarlos para que lo hagan

276
0:12:30.476,000 --> 0:12:32,000
y esperar y desear que lo hagan,

277
0:12:33.134,000 --> 0:12:35,000
hay algo que nosotros podemos hacer.

278
0:12:35.66,000 --> 0:12:39,000
Podemos crear mejores caminos o sugerir mejores caminos

279
0:12:40.181,000 --> 0:12:41,000
para los adolescentes enfadados.

280
0:12:42.196,000 --> 0:12:44,000
Si ven algo que creen que es creativo y considerado

281
0:12:44.82,000 --> 0:12:46,000
y quieren compartirlo, sepan que pueden compartirlo

282
0:12:47.259,000 --> 0:12:49,000
aunque no les invada una alta excitación.

283
0:12:50.246,000 --> 0:12:52,000
Sé que es un paso pequeño

284
0:12:52.477,000 --> 0:12:54,000
pero en conjunto esto importa,

285
0:12:55.254,000 --> 0:12:57,000
porque estos algoritmos por muy poderosos que sean

286
0:12:57.587,000 --> 0:12:58,000
toman su comportamiento de nosotros.

287
0:13:01.556,000 --> 0:13:02,000
Los dejo con esto.

288
0:13:03.701,000 --> 0:13:05,000
Hace algunos años, estaba muy de moda decir

289
0:13:06.214,000 --> 0:13:08,000
que internet era una herramienta revolucionaria

290
0:13:08.551,000 --> 0:13:09,000
que iba a unirnos.

291
0:13:11.074,000 --> 0:13:12,000
Ahora está más de moda decir

292
0:13:12.687,000 --> 0:13:15,000
que el internet es un basurero irreversible.

293
0:13:16.787,000 --> 0:13:17,000
Ninguna afirmación es verdadera.

294
0:13:18.643,000 --> 0:13:2,000
Sabemos que el internet es muy vasto y complejo

295
0:13:21.04,000 --> 0:13:22,000
como para ser bueno o malo.

296
0:13:22.563,000 --> 0:13:24,000
Y el peligro de pensar así,

297
0:13:24.674,000 --> 0:13:27,000
bien sea la visión utópica de que internet nos salvará

298
0:13:28.161,000 --> 0:13:31,000
o la visión distópica de que nos destruirá,

299
0:13:31.633,000 --> 0:13:33,000
es que nos estamos saliendo de rositas.

300
0:13:35.564,000 --> 0:13:37,000
No hay nada inevitable en nuestro futuro.

301
0:13:38.878,000 --> 0:13:4,000
El internet lo hace la gente.

302
0:13:40.903,000 --> 0:13:42,000
La gente toma las decisiones en las empresas de redes sociales.

303
0:13:43.911,000 --> 0:13:45,000
La gente hace que los hashtags sean o no tendencia.

304
0:13:46.586,000 --> 0:13:49,000
La gente hace que la sociedad avance o retroceda.

305
0:13:51.12,000 --> 0:13:52,000
Cuando interioricemos esto,

306
0:13:52.679,000 --> 0:13:55,000
podremos dejar de esperar a que llegue el inevitable futuro

307
0:13:55.751,000 --> 0:13:56,000
y ponernos a trabajar ahora.

308
0:13:58.842,000 --> 0:14:01,000
A todos nos han enseñado que el arco del universo moral es grande,

309
0:14:02.033,000 --> 0:14:04,000
pero tiende a la justicia.

310
0:14:06.489,000 --> 0:14:07,000
Quizás.

311
0:14:08.814,000 --> 0:14:09,000
Quizás lo haga.

312
0:14:10.776,000 --> 0:14:12,000
Pero eso siempre ha sido una aspiración.

313
0:14:13.277,000 --> 0:14:14,000
No es una garantía.

314
0:14:15.856,000 --> 0:14:17,000
El arco no se inclina solo.

315
0:14:18.045,000 --> 0:14:21,000
No hay una fuerza misteriosa que lo incline inevitablemente.

316
0:14:21.744,000 --> 0:14:22,000
La única verdad,

317
0:14:23.44,000 --> 0:14:25,000
que asusta, pero a la vez es liberadora,

318
0:14:26.847,000 --> 0:14:27,000
es que nosotros lo inclinamos.

319
0:14:28.943,000 --> 0:14:29,000
Gracias.

320
0:14:30.176,000 --> 0:14:32,000
(Aplausos)

