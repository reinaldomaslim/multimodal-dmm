1
0:00:,000 --> 0:00:07,000
Traducteur: Elise LECAMP Relecteur: Drita Lubovci

2
0:00:12.843,000 --> 0:00:14,000
En 2007, je suis devenue procureur général

3
0:00:15.434,000 --> 0:00:16,000
de l'état du New Jersey.

4
0:00:17.159,000 --> 0:00:19,000
Auparavant, j'étais procureur général,

5
0:00:19.439,000 --> 0:00:21,000
d'abord au sein du bureau du procureur de Manhattan,

6
0:00:22.12,000 --> 0:00:24,000
puis au Ministère de la Justice des Etats-Unis.

7
0:00:24.77,000 --> 0:00:26,000
Mais lorsque je suis devenue procureur général,

8
0:00:26.971,000 --> 0:00:27,000
deux choses se sont passées et ont changé la façon

9
0:00:28.676,000 --> 0:00:3,000
dont je voyais la justice pénale.

10
0:00:30.921,000 --> 0:00:31,000
La première, c'est que j'ai posé, ce que je pensais être,

11
0:00:32.896,000 --> 0:00:34,000
des questions vraiment basiques.

12
0:00:35.082,000 --> 0:00:37,000
Je voulais comprendre qui étaient les personnes qu'on arrêtait,

13
0:00:37.938,000 --> 0:00:38,000
qui est-ce qu'on accusait,

14
0:00:39.602,000 --> 0:00:42,000
et qui est-ce qu'on mettait dans nos prisons d'état.

15
0:00:43.146,000 --> 0:00:44,000
Je voulais aussi comprendre

16
0:00:44.794,000 --> 0:00:45,000
si nous prenions les décisions

17
0:00:46.123,000 --> 0:00:48,000
de telle manière à ce qu'on soit plus en sécurité.

18
0:00:48.641,000 --> 0:00:51,000
Et je n'arrivais pas à obtenir ces informations.

19
0:00:51.893,000 --> 0:00:54,000
Il s'est avéré que la plupart des grandes organisations de justice

20
0:00:55.25,000 --> 0:00:56,000
comme la mienne

21
0:00:56.552,000 --> 0:00:58,000
ne suivent pas les choses qui comptent.

22
0:00:58.934,000 --> 0:01:01,000
Donc après un mois d'incroyable frustration,

23
0:01:02.252,000 --> 0:01:03,000
je suis entrée dans une salle de conférence

24
0:01:04.223,000 --> 0:01:05,000
remplie d'enquêteurs

25
0:01:06.113,000 --> 0:01:08,000
et de tas et de tas de dossiers,

26
0:01:08.895,000 --> 0:01:09,000
les enquêteurs étaient assis là

27
0:01:10.071,000 --> 0:01:12,000
avec des bloc-notes jaunes réglementaires.

28
0:01:12.305,000 --> 0:01:13,000
Ils essayaient d'obtenir les informations

29
0:01:13.891,000 --> 0:01:14,000
que je cherchais

30
0:01:15.109,000 --> 0:01:17,000
en vérifiant chaque affaire

31
0:01:17.154,000 --> 0:01:18,000
des cinq dernières années.

32
0:01:19.052,000 --> 0:01:2,000
Comme vous pouvez l'imaginer,

33
0:01:20.705,000 --> 0:01:22,000
quand on a finalement obtenu les résultats, ils n'étaient pas bons.

34
0:01:23.348,000 --> 0:01:24,000
Il s'est avéré que nous traitions

35
0:01:25.003,000 --> 0:01:27,000
beaucoup de petites affaires de drogue

36
0:01:27.023,000 --> 0:01:28,000
dans le quartier juste au coin de la rue

37
0:01:28.498,000 --> 0:01:3,000
de notre bureau de Trenton.

38
0:01:30.766,000 --> 0:01:31,000
La deuxième chose qui s'est passée

39
0:01:32.233,000 --> 0:01:34,000
c'est que j'ai passé la journée dans le département de la police

40
0:01:34.536,000 --> 0:01:35,000
de Camden, au New Jersey.

41
0:01:35.939,000 --> 0:01:36,000
A cette époque, Camden, New Jersey,

42
0:01:37.794,000 --> 0:01:39,000
était la ville la plus dangereuse en Amérique.

43
0:01:40.446,000 --> 0:01:43,000
J'ai choisi de diriger le département de police de Camden pour ça.

44
0:01:44.273,000 --> 0:01:46,000
J'ai passé la journée dans le département de la police,

45
0:01:46.385,000 --> 0:01:48,000
on m'a emmenée dans une salle avec les officiers de police,

46
0:01:49.111,000 --> 0:01:5,000
ils travaillaient tous très dur

47
0:01:50.786,000 --> 0:01:53,000
et essayaient vraiment de réduire la criminalité à Camden.

48
0:01:54.043,000 --> 0:01:55,000
Ce que j'ai vu dans cette salle,

49
0:01:55.869,000 --> 0:01:57,000
alors qu'on parlait de réduire la criminalité,

50
0:01:58.114,000 --> 0:02:01,000
c'est un groupe d'officiers avec beaucoup de post-it jaunes.

51
0:02:01.973,000 --> 0:02:03,000
Ils prenaient un post-it jaune et ils écrivaient quelque chose dessus

52
0:02:04.823,000 --> 0:02:05,000
et le plaçait sur un tableau.

53
0:02:06.622,000 --> 0:02:08,000
L'un deux a dit, « Nous avons eu un vol il y a deux semaines.

54
0:02:08.793,000 --> 0:02:09,000
Nous n'avons pas de suspects. »

55
0:02:10.504,000 --> 0:02:13,000
Un autre a dit : « Nous avons eu une fusillade dans le quartier la semaine dernière.

56
0:02:14.14,000 --> 0:02:15,000
Nous n'avons pas de suspects. »

57
0:02:15.576,000 --> 0:02:17,000
Nous n'utilisions pas de surveillance statistique.

58
0:02:18.114,000 --> 0:02:2,000
Nous combattions le crime essentiellement

59
0:02:20.156,000 --> 0:02:22,000
avec des notes sur des post-it jaunes.

60
0:02:22.683,000 --> 0:02:24,000
Ces deux choses m'ont fait prendre conscience

61
0:02:24.818,000 --> 0:02:27,000
qu'on échouait fondamentalement.

62
0:02:28.069,000 --> 0:02:31,000
Nous ne savions même pas qui était dans notre système de justice pénale,

63
0:02:31.192,000 --> 0:02:34,000
nous n'avions aucune idée des choses qui importaient,

64
0:02:34.427,000 --> 0:02:36,000
et nous ne partagions aucune données ou analyses

65
0:02:36.995,000 --> 0:02:38,000
ou encore outils pour nous aider à prendre de meilleures décisions

66
0:02:39.146,000 --> 0:02:41,000
et réduire la criminalité.

67
0:02:41.149,000 --> 0:02:43,000
Et pour la première fois, j'ai commencé à penser

68
0:02:43.373,000 --> 0:02:44,000
à la façon dont on prenait des décisions.

69
0:02:45.283,000 --> 0:02:46,000
Lorsque j'étais assistante du procureur

70
0:02:46.68,000 --> 0:02:47,000
puis quand j'étais procureur général,

71
0:02:48.55,000 --> 0:02:49,000
je regardais les affaires en face de moi,

72
0:02:50.296,000 --> 0:02:52,000
et je prenais généralement des décisions basées sur mon instinct

73
0:02:52.922,000 --> 0:02:53,000
et mon expérience.

74
0:02:54.614,000 --> 0:02:55,000
Lorsque je suis devenue procureur général,

75
0:02:56.273,000 --> 0:02:57,000
je pouvais observer le système dans son ensemble,

76
0:02:57.912,000 --> 0:02:58,000
et ce qui m'a surpris c'est que j'ai trouvé

77
0:02:59.73,000 --> 0:03:,000
que c'était exactement comme ça que nous le faisions

78
0:03:01.635,000 --> 0:03:03,000
au sein du système entier --

79
0:03:03.938,000 --> 0:03:05,000
dans les commissariats de police, les bureaux des procureurs,

80
0:03:06.339,000 --> 0:03:08,000
les tribunaux et les prisons.

81
0:03:09.139,000 --> 0:03:11,000
Ce que j'ai appris très rapidement

82
0:03:11.336,000 --> 0:03:14,000
c'est que nous ne faisions pas du bon travail.

83
0:03:14.969,000 --> 0:03:16,000
Donc j'ai voulu faire les choses différemment.

84
0:03:16.985,000 --> 0:03:18,000
Je voulais introduire des données et des analyses

85
0:03:19.182,000 --> 0:03:21,000
des analyses statistiques rigoureuses

86
0:03:21.231,000 --> 0:03:22,000
de notre travail.

87
0:03:22.631,000 --> 0:03:24,000
En clair, je voulais faire du moneyball en justice pénale.

88
0:03:25.601,000 --> 0:03:27,000
Maintenant, le moneyball, comme beaucoup d'entre vous le savent,

89
0:03:27.628,000 --> 0:03:28,000
c'est ce que l'équipe des Atlantics d'Oakland a fait

90
0:03:29.197,000 --> 0:03:3,000
lorsqu'ils ont utilisé des données pertinentes et des statistiques

91
0:03:31.17,000 --> 0:03:32,000
pour définir comment choisir des joueurs

92
0:03:32.792,000 --> 0:03:33,000
qui les aideraient à gagner des matchs,

93
0:03:34.313,000 --> 0:03:36,000
ils sont partis d'un système fondé sur des guetteurs de baseball

94
0:03:37.293,000 --> 0:03:38,000
qui sortaient voir les joueurs

95
0:03:39.153,000 --> 0:03:4,000
et utilisaient leur instinct et leur expérience,

96
0:03:40.79,000 --> 0:03:41,000
l'instinct de guetteur et l'expérience,

97
0:03:42.533,000 --> 0:03:43,000
pour sélectionner des joueurs, en utilisant

98
0:03:44.246,000 --> 0:03:46,000
des données pertinentes et une analyse statistique rigoureuse

99
0:03:47.068,000 --> 0:03:5,000
pour décider comment choisir les joueurs qui les aideraient à gagner des matchs.

100
0:03:50.439,000 --> 0:03:51,000
Ça a marché pour les Atlantic d'Oakland,

101
0:03:52.237,000 --> 0:03:54,000
et ça a marché pour l'état du New Jersey.

102
0:03:54.456,000 --> 0:03:56,000
Nous avons sorti Camden du haut de la liste

103
0:03:57.284,000 --> 0:03:58,000
des villes les plus dangereuses en Amérique.

104
0:03:58.7,000 --> 0:04:01,000
Nous avons réduit les meurtres de 41 pour cent,

105
0:04:01.855,000 --> 0:04:03,000
ce qui en réalité correspond à 37 vies sauvées.

106
0:04:04.837,000 --> 0:04:07,000
Et nous avons réduit la criminalité totale dans la ville de 26 pour cent.

107
0:04:08.577,000 --> 0:04:11,000
Nous avons aussi modifié la façon dont nous menons les poursuites criminelles.

108
0:04:11.816,000 --> 0:04:13,000
Donc nous sommes passé des délits mineurs liés à la drogue

109
0:04:13.821,000 --> 0:04:14,000
qui avaient lieu à la sortie de notre bâtiment

110
0:04:15.463,000 --> 0:04:17,000
à traiter des affaires d'importance à l'échelle de l'état,

111
0:04:17.805,000 --> 0:04:2,000
à réduire les violences issues des délinquants les plus violents

112
0:04:20.963,000 --> 0:04:21,000
poursuivre des gangs,

113
0:04:22.821,000 --> 0:04:25,000
des trafics d'armes et de drogues, de la corruption politique.

114
0:04:26.229,000 --> 0:04:28,000
Tout ça a vraiment de l'importance,

115
0:04:28.731,000 --> 0:04:29,000
parce que pour moi, assurer la sécurité publique

116
0:04:30.676,000 --> 0:04:32,000
est la plus importante fonction du gouvernement.

117
0:04:33.212,000 --> 0:04:35,000
Si nous ne sommes pas en sécurité, on ne peut pas être éduqué,

118
0:04:35.51,000 --> 0:04:36,000
on n'est pas en bonne santé,

119
0:04:36.858,000 --> 0:04:38,000
on ne peut rien faire de toutes les autres choses que l'on veut dans nos vies.

120
0:04:39.803,000 --> 0:04:4,000
Aujourd'hui, nous vivons dans un pays

121
0:04:41.504,000 --> 0:04:44,000
qui fait face à de sérieux problèmes de justice criminelle.

122
0:04:44.638,000 --> 0:04:47,000
Nous avons 12 millions d'arrestations chaque année.

123
0:04:48.299,000 --> 0:04:5,000
La grande majorité de ces arrestations

124
0:04:50.342,000 --> 0:04:53,000
concernent des petits crimes, comme des délits mineurs,

125
0:04:53.354,000 --> 0:04:54,000
70 à 80 pour cent.

126
0:04:55.088,000 --> 0:04:56,000
Moins de cinq pour cent de toutes les arrestations

127
0:04:57.079,000 --> 0:04:58,000
sont pour des crimes violents.

128
0:04:58.974,000 --> 0:05:,000
Pourtant nous avons dépensé 75 milliards,

129
0:05:01.029,000 --> 0:05:02,000
je dis bien milliards,

130
0:05:02.447,000 --> 0:05:06,000
de dollars par an en dépenses fédérale et locale.

131
0:05:06.574,000 --> 0:05:08,000
Maintenant, aujourd'hui, nous avons 2,3 millions de personnes

132
0:05:09.415,000 --> 0:05:1,000
dans nos prisons.

133
0:05:11.315,000 --> 0:05:13,000
Nous faisons face à des défis inimaginables de sécurité publique

134
0:05:14.111,000 --> 0:05:15,000
parce que nous sommes dans une situation

135
0:05:16.05,000 --> 0:05:18,000
où deux tiers des gens dans nos prisons

136
0:05:18.948,000 --> 0:05:19,000
sont là en attente de procès.

137
0:05:20.702,000 --> 0:05:22,000
Ils n'ont pas été reconnus coupables de crime.

138
0:05:22.837,000 --> 0:05:24,000
Ils attendent simplement leurs tours au tribunal.

139
0:05:24.956,000 --> 0:05:27,000
Et 67 pour cent des gens reviennent.

140
0:05:28.504,000 --> 0:05:31,000
Notre taux de récidive est parmi les plus hauts du monde.

141
0:05:31.532,000 --> 0:05:33,000
Presque sept personnes sur dix qui sont relâchées

142
0:05:33.635,000 --> 0:05:34,000
de prison seront, de nouveau, arrêtés

143
0:05:35.286,000 --> 0:05:38,000
dans un cycle régulier de crime et d'incarcération.

144
0:05:39.241,000 --> 0:05:41,000
Donc lorsque j'ai commencé mon travail à la Fondation Arnold,

145
0:05:41.823,000 --> 0:05:43,000
je suis revenue pour étudier beaucoup de ces questions,

146
0:05:44.559,000 --> 0:05:45,000
je suis revenue pour réfléchir à la façon

147
0:05:46.213,000 --> 0:05:48,000
dont nous avions utiliser les données et les analyses pour transformer

148
0:05:48.596,000 --> 0:05:5,000
la façon dont nous traitions la justice pénale au New Jersey.

149
0:05:51.18,000 --> 0:05:53,000
Lorsque je regarde le système de justice pénale

150
0:05:53.324,000 --> 0:05:54,000
aux Etats-Unis aujourd'hui,

151
0:05:54.98,000 --> 0:05:55,000
j'ai exactement le même sentiment que j'avais

152
0:05:56.619,000 --> 0:05:58,000
au sujet de l'état du New Jersey quand j'ai commencé ici,

153
0:05:59.085,000 --> 0:06:02,000
qui est que nous devons absolument faire mieux

154
0:06:02.313,000 --> 0:06:03,000
et je sais que nous pouvons mieux faire.

155
0:06:04.236,000 --> 0:06:05,000
J'ai donc décidé de nous concentrer

156
0:06:05.941,000 --> 0:06:07,000
sur l'utilisation des données et les analyses

157
0:06:08.158,000 --> 0:06:1,000
pour aider à prendre la décision la plus cruciale

158
0:06:10.519,000 --> 0:06:11,000
en matière de sécurité publique.

159
0:06:12.125,000 --> 0:06:14,000
Il s'agit de déterminer,

160
0:06:14.146,000 --> 0:06:16,000
lorsque quelqu'un est arrêté,

161
0:06:16.681,000 --> 0:06:17,000
si il pose un risque pour la sécurité publique

162
0:06:18.596,000 --> 0:06:19,000
et devrait être détenu,

163
0:06:20.122,000 --> 0:06:22,000
ou s'il ne pose pas de risque pour la sécurité publique

164
0:06:22.478,000 --> 0:06:23,000
et pourrait être relâché.

165
0:06:24.115,000 --> 0:06:25,000
Tout ce qui arrive dans les affaires criminelles

166
0:06:26.034,000 --> 0:06:27,000
ressort de cette unique décision.

167
0:06:27.806,000 --> 0:06:28,000
Elle influence tout.

168
0:06:29.302,000 --> 0:06:3,000
Elle influence la condamnation.

169
0:06:30.652,000 --> 0:06:31,000
Elle conditionne si quelqu'un reçoit un traitement médical.

170
0:06:32.553,000 --> 0:06:34,000
Elle influence les crimes et la violence.

171
0:06:34.876,000 --> 0:06:35,000
Lorsque je parle aux juges à travers les Etats-Unis,

172
0:06:36.813,000 --> 0:06:37,000
ce que je fais tout le temps maintenant,

173
0:06:38.741,000 --> 0:06:39,000
ils disent tous la même chose,

174
0:06:40.578,000 --> 0:06:43,000
qui est : « Nous mettons les gens dangereux en prison,

175
0:06:43.685,000 --> 0:06:46,000
et nous laissons les personnes non dangereuses, non violentes dehors. »

176
0:06:47.21,000 --> 0:06:49,000
Ils le pensent et ils y croient.

177
0:06:49.443,000 --> 0:06:5,000
Mais quand on commence à regarder les données,

178
0:06:51.176,000 --> 0:06:53,000
que les juges n'ont pas, au passage,

179
0:06:53.64,000 --> 0:06:54,000
lorsqu'on commence à regarder les données,

180
0:06:55.252,000 --> 0:06:57,000
on trouve encore trop souvent

181
0:06:57.67,000 --> 0:06:58,000
que ce n'est pas le cas.

182
0:06:59.652,000 --> 0:07:,000
On trouve des délinquants à faibles risques,

183
0:07:01.333,000 --> 0:07:04,000
qui représentent jusqu'à 50 pour cent de notre population carcérale entière,

184
0:07:05.047,000 --> 0:07:07,000
on voit qu'ils sont en prison.

185
0:07:07.446,000 --> 0:07:09,000
Prenez Leslie Chew, qui est un texan

186
0:07:09.932,000 --> 0:07:11,000
qui a volé quatre couvertures lors d'une froide nuit d'hiver.

187
0:07:12.816,000 --> 0:07:14,000
Il a été arrêté et fut gardé en prison

188
0:07:15.411,000 --> 0:07:17,000
avec une caution de 3500 dollars,

189
0:07:17.464,000 --> 0:07:19,000
une somme qu'il ne pouvait pas se permettre de payer.

190
0:07:20.24,000 --> 0:07:22,000
Il est resté en prison pendant huit mois

191
0:07:22.828,000 --> 0:07:24,000
jusqu'à ce que son affaire soit jugée,

192
0:07:24.893,000 --> 0:07:27,000
avec une facture pour les contribuables de plus de 9000 dollars.

193
0:07:28.798,000 --> 0:07:29,000
De l'autre côté du spectre,

194
0:07:30.795,000 --> 0:07:32,000
on fait un travail aussi mauvais.

195
0:07:33.077,000 --> 0:07:34,000
Les gens que nous y trouvons

196
0:07:34.649,000 --> 0:07:36,000
sont les criminels les plus dangereux,

197
0:07:36.668,000 --> 0:07:38,000
les gens que nous estimons avoir la plus haute probabilité

198
0:07:39.165,000 --> 0:07:4,000
de commettre un nouveau crime s'ils sont relâchés,

199
0:07:41.117,000 --> 0:07:43,000
au niveau national, on voit que pour cent de ces personnes

200
0:07:44.067,000 --> 0:07:45,000
sont libérées.

201
0:07:46.041,000 --> 0:07:49,000
La raison à ça est la façon dont nous prenons les décisions.

202
0:07:49.215,000 --> 0:07:5,000
Les juges ont les meilleurs intentions

203
0:07:50.924,000 --> 0:07:51,000
lorsqu'ils prennent ces décisions sur le risque,

204
0:07:52.876,000 --> 0:07:54,000
mais ils le font de manière subjective.

205
0:07:55.36,000 --> 0:07:57,000
Ils sont comme les éclaireurs du baseball il y a 20 ans,

206
0:07:57.506,000 --> 0:07:59,000
qui utilisaient leur instinct et leur expérience

207
0:07:59.637,000 --> 0:08:01,000
pour essayer de déterminer quels étaient les risques de quelqu'un.

208
0:08:02.316,000 --> 0:08:03,000
Ils sont subjectifs,

209
0:08:03.846,000 --> 0:08:06,000
nous savons que ce qui arrive avec des décisions prises subjectivement,

210
0:08:06.906,000 --> 0:08:08,000
c'est que nous avons souvent tort.

211
0:08:09.649,000 --> 0:08:1,000
Ce dont nous avons besoin ici

212
0:08:11.032,000 --> 0:08:13,000
sont des données solides et des analyses.

213
0:08:13.584,000 --> 0:08:14,000
Ce que j'ai décidé de chercher

214
0:08:15.331,000 --> 0:08:17,000
était des données solides et un outil analytique

215
0:08:18.167,000 --> 0:08:2,000
quelque chose qui donnerait aux juges la possibilité de comprendre vraiment

216
0:08:20.931,000 --> 0:08:22,000
d'une façon scientifique et objective

217
0:08:23.19,000 --> 0:08:24,000
quel était le risque qui était posé

218
0:08:24.837,000 --> 0:08:25,000
par la personne en face d'eux.

219
0:08:26.447,000 --> 0:08:27,000
J'ai cherché partout dans le pays,

220
0:08:28.096,000 --> 0:08:29,000
et j'ai trouvé qu'entre 5 et 10 pour cent

221
0:08:30.038,000 --> 0:08:31,000
des juridictions américaines

222
0:08:31.367,000 --> 0:08:33,000
utilisait en fait tous types d'outil d'analyse de risque,

223
0:08:34.345,000 --> 0:08:35,000
et lorsque j'étudiais ces outils,

224
0:08:35.97,000 --> 0:08:36,000
j'ai rapidement compris pourquoi.

225
0:08:37.83,000 --> 0:08:39,000
Ils étaient incroyablement cher à administrer,

226
0:08:40.52,000 --> 0:08:41,000
ils exigeaient beaucoup de temps,

227
0:08:42.048,000 --> 0:08:44,000
ils étaient limités à la juridiction locale

228
0:08:44.155,000 --> 0:08:45,000
dans laquelle ils avaient été créés.

229
0:08:45.585,000 --> 0:08:46,000
Donc, ils ne pouvaient pas s'étendre

230
0:08:47.378,000 --> 0:08:49,000
ou être transférés à d'autres endroits.

231
0:08:49.587,000 --> 0:08:51,000
Donc je suis sortie et j'ai construit une équipe phénoménale

232
0:08:51.824,000 --> 0:08:53,000
d'analystes, de chercheurs

233
0:08:53.868,000 --> 0:08:54,000
et de statisticiens

234
0:08:55.494,000 --> 0:08:57,000
pour construire un outil d'analyse de risque universel,

235
0:08:58.339,000 --> 0:09:,000
pour que chaque juge aux Etats-Unis

236
0:09:00.732,000 --> 0:09:04,000
puisse avoir une mesure du risque objective et scientifique.

237
0:09:05.056,000 --> 0:09:06,000
Dans l'outil que nous avons construit,

238
0:09:06.714,000 --> 0:09:08,000
nous avons collecté 1,5 millions d'affaires

239
0:09:09.582,000 --> 0:09:1,000
de tous les Etats-Unis,

240
0:09:11.28,000 --> 0:09:12,000
des villes, des comtés,

241
0:09:12.924,000 --> 0:09:13,000
de chaque état du pays,

242
0:09:14.435,000 --> 0:09:15,000
des cours fédérales.

243
0:09:16.181,000 --> 0:09:18,000
Avec ces 1,5 millions d'affaires,

244
0:09:18.37,000 --> 0:09:19,000
ce qui représente le plus grand jeu de données

245
0:09:20.31,000 --> 0:09:21,000
aux Etats-Unis aujourd'hui,

246
0:09:22.115,000 --> 0:09:23,000
nous avons été capables de trouver qu'il y avait

247
0:09:23.98,000 --> 0:09:26,000
plus de 900 facteurs de risques que nous pouvions analyser

248
0:09:27.302,000 --> 0:09:29,000
pour essayer de comprendre ce qui comptait vraiment.

249
0:09:30.168,000 --> 0:09:32,000
Nous avons découvert qu'il y avat neuf éléments spécifiques

250
0:09:32.249,000 --> 0:09:34,000
qui comptaient à travers le pays

251
0:09:34.484,000 --> 0:09:36,000
et qui étaient les facteurs de risques les plus prédictifs.

252
0:09:37.461,000 --> 0:09:4,000
Donc nous avons construit un outil d'analyse de risque universel.

253
0:09:41.166,000 --> 0:09:42,000
Ça ressemble à ça.

254
0:09:42.611,000 --> 0:09:44,000
Comme vous le voyez, on saisit quelques informations

255
0:09:45.223,000 --> 0:09:47,000
mais c'est incroyablement simple,

256
0:09:47.236,000 --> 0:09:48,000
c'est facile à utiliser,

257
0:09:48.668,000 --> 0:09:5,000
il se concentre sur des choses comme les anciennes condamnations des accusés

258
0:09:51.637,000 --> 0:09:52,000
s'ils ont été condamnés à des peines de prison ferme,

259
0:09:53.616,000 --> 0:09:55,000
s'ils ont été impliqués dans des violences auparavant,

260
0:09:55.88,000 --> 0:09:57,000
s'ils ont échoué en revenant devant une cour.

261
0:09:58.273,000 --> 0:10:,000
Avec cet outil, on peut prédire trois choses.

262
0:10:00.773,000 --> 0:10:01,000
Premièrement, si quelqu'un va commettre

263
0:10:02.626,000 --> 0:10:03,000
un nouveau crime une fois relâché.

264
0:10:04.191,000 --> 0:10:05,000
Deuxièmement, pour la première fois,

265
0:10:05.855,000 --> 0:10:06,000
et je crois que c'est extrêmement important,

266
0:10:07.716,000 --> 0:10:08,000
on peut prédire si quelqu'un va commettre

267
0:10:09.639,000 --> 0:10:1,000
un acte violent s'il est relâché.

268
0:10:11.473,000 --> 0:10:12,000
Et c'est la chose la plus importante

269
0:10:13.36,000 --> 0:10:14,000
que les juges vous disent quand vous parlez avec eux.

270
0:10:15.167,000 --> 0:10:16,000
Ensuite, on peut prédire si quelqu'un

271
0:10:16.995,000 --> 0:10:17,000
retournera devant un tribunal.

272
0:10:18.985,000 --> 0:10:21,000
Et chacun des juges aux Etats-Unis peut l'utiliser

273
0:10:22.018,000 --> 0:10:25,000
parce qu'il a été créé avec un jeu de données universel.

274
0:10:25.83,000 --> 0:10:27,000
Ce que les jugent voient lorsqu'ils lancent l'outil de calcul des risques

275
0:10:28.439,000 --> 0:10:3,000
c'est ça, un tableau de bord.

276
0:10:30.559,000 --> 0:10:32,000
En haut, on voit le résultat du New Criminal Activity,

277
0:10:33.407,000 --> 0:10:34,000
six est bien sûr le plus haut,

278
0:10:35.336,000 --> 0:10:37,000
et ensuite, au milieu vous voyez, "un risque élevé de violence".

279
0:10:37.739,000 --> 0:10:38,000
Ce que ça indique c'est si cette personne

280
0:10:39.485,000 --> 0:10:41,000
est quelqu'un qui a un risque élevé de violence

281
0:10:41.545,000 --> 0:10:42,000
alors le juge devrait y regarder deux fois.

282
0:10:43.43,000 --> 0:10:44,000
Ensuite, vers le bas,

283
0:10:44.766,000 --> 0:10:45,000
vous voyez le risque d'apparition de l'échec,

284
0:10:46.734,000 --> 0:10:47,000
qui encore une fois est la probabilité

285
0:10:48.126,000 --> 0:10:51,000
que quelqu'un revienne au tribunal.

286
0:10:51.139,000 --> 0:10:53,000
Maintenant, je voudrais vous dire quelque chose de vraiment important.

287
0:10:53.352,000 --> 0:10:55,000
Je ne pense pas que ça devrait éliminer

288
0:10:56.079,000 --> 0:10:58,000
l'instinct et l'expérience des juges

289
0:10:58.323,000 --> 0:10:59,000
de cet processus.

290
0:10:59.927,000 --> 0:11:,000
Je ne crois pas.

291
0:11:00.985,000 --> 0:11:02,000
Je crois en réalité que le problème auquel nous faisons face

292
0:11:02.992,000 --> 0:11:04,000
et la raison pour laquelle nous avons eu ces incroyables erreurs,

293
0:11:05.846,000 --> 0:11:08,000
où nous avons incarcéré des personnes non violentes

294
0:11:08.933,000 --> 0:11:11,000
et avons relâché des personnes dangereuses à haut risque,

295
0:11:12.105,000 --> 0:11:14,000
c'est que nous n'avions pas de mesure objective du risque.

296
0:11:14.828,000 --> 0:11:15,000
Mais ce que je crois, c'est qu'on devrait pouvoir

297
0:11:16.128,000 --> 0:11:18,000
utiliser cet outil de détermination des risques

298
0:11:18.928,000 --> 0:11:21,000
et combiner ça avec l'instinct et l'expérience des juges

299
0:11:21.969,000 --> 0:11:23,000
pour nous mener à une meilleure prise de décision.

300
0:11:24.927,000 --> 0:11:27,000
L'outil a été lancé dans tout le Kentucky le 1er juillet,

301
0:11:28.23,000 --> 0:11:31,000
et nous nous apprêtons à le lancer dans un certain nombre de juridictions américaines.

302
0:11:31.581,000 --> 0:11:34,000
Notre but est tout simplement, que chaque juge des Etats-Unis

303
0:11:34.712,000 --> 0:11:35,000
utilise cet outil d'analyse de risque

304
0:11:36.364,000 --> 0:11:38,000
dans les cinq premières années.

305
0:11:38.455,000 --> 0:11:39,000
Nous travaillons maintenant à des outils d'analyse de risque

306
0:11:39.807,000 --> 0:11:42,000
pour les procureurs et les officiers de police également,

307
0:11:43.091,000 --> 0:11:45,000
pour essayer de prendre un système qui fonctionne aujourd'hui

308
0:11:45.791,000 --> 0:11:47,000
en Amérique comme il fonctionnait il y a 50 ans,

309
0:11:48.587,000 --> 0:11:5,000
fondé sur l'instinct et l'expérience,

310
0:11:50.684,000 --> 0:11:51,000
et d'en faire un qui fonctionne

311
0:11:52.539,000 --> 0:11:54,000
à partir de données et d'analyses.

312
0:11:55.008,000 --> 0:11:56,000
Maintenant, la bonne nouvelle avec tout ça,

313
0:11:56.929,000 --> 0:11:57,000
on a une tonne de travail qui reste à faire,

314
0:11:58.546,000 --> 0:11:59,000
on doit faire beaucoup d'accompagnement du changement,

315
0:12:00.403,000 --> 0:12:01,000
mais la bonne nouvelle à ce sujet

316
0:12:02.149,000 --> 0:12:03,000
c'est que nous savons que ça fonctionne.

317
0:12:04.017,000 --> 0:12:06,000
C'est pour ça que Google est comme Google,

318
0:12:06.17,000 --> 0:12:08,000
c'est pourquoi toutes ces équipes de baseball utilise le moneyball

319
0:12:08.632,000 --> 0:12:09,000
pour gagner des matchs.

320
0:12:10.413,000 --> 0:12:11,000
La bonne nouvelle pour nous également

321
0:12:12.15,000 --> 0:12:13,000
c'est que c'est la façon dont on modifie

322
0:12:14.046,000 --> 0:12:16,000
le système de justice pénale américain.

323
0:12:16.367,000 --> 0:12:18,000
C'est comme ça que nous rendons nos rues plus sûre,

324
0:12:18.724,000 --> 0:12:2,000
nous pouvons réduire le coût de nos prisons,

325
0:12:21.023,000 --> 0:12:23,000
et nous pouvons rendre notre système plus équitable

326
0:12:23.09,000 --> 0:12:24,000
et plus juste.

327
0:12:24.815,000 --> 0:12:26,000
Certains appellent ça de la science des données.

328
0:12:26.977,000 --> 0:12:28,000
J'appelle ça le moneyball de la justice pénale.

329
0:12:29.278,000 --> 0:12:3,000
Merci.

330
0:12:31.082,000 --> 0:12:35,000
(Applaudissements)

