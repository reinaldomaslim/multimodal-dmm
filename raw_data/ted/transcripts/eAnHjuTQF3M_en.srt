1
0:00:15.26,000 --> 0:00:18,000
Ever since I was a little girl

2
0:00:18.26,000 --> 0:00:2,000
seeing "Star Wars" for the first time,

3
0:00:20.26,000 --> 0:00:22,000
I've been fascinated by this idea

4
0:00:22.26,000 --> 0:00:24,000
of personal robots.

5
0:00:24.26,000 --> 0:00:26,000
And as a little girl,

6
0:00:26.26,000 --> 0:00:28,000
I loved the idea of a robot that interacted with us

7
0:00:28.26,000 --> 0:00:31,000
much more like a helpful, trusted sidekick --

8
0:00:31.26,000 --> 0:00:33,000
something that would delight us, enrich our lives

9
0:00:33.26,000 --> 0:00:36,000
and help us save a galaxy or two.

10
0:00:37.26,000 --> 0:00:4,000
I knew robots like that didn't really exist,

11
0:00:40.26,000 --> 0:00:42,000
but I knew I wanted to build them.

12
0:00:42.26,000 --> 0:00:44,000
So 20 years pass --

13
0:00:44.26,000 --> 0:00:46,000
I am now a graduate student at MIT

14
0:00:46.26,000 --> 0:00:48,000
studying artificial intelligence,

15
0:00:48.26,000 --> 0:00:5,000
the year is 1997,

16
0:00:50.26,000 --> 0:00:53,000
and NASA has just landed the first robot on Mars.

17
0:00:53.26,000 --> 0:00:56,000
But robots are still not in our home, ironically.

18
0:00:56.26,000 --> 0:00:58,000
And I remember thinking about

19
0:00:58.26,000 --> 0:01:,000
all the reasons why that was the case.

20
0:01:00.26,000 --> 0:01:02,000
But one really struck me.

21
0:01:02.26,000 --> 0:01:05,000
Robotics had really been about interacting with things,

22
0:01:05.26,000 --> 0:01:07,000
not with people --

23
0:01:07.26,000 --> 0:01:09,000
certainly not in a social way that would be natural for us

24
0:01:09.26,000 --> 0:01:11,000
and would really help people accept robots

25
0:01:11.26,000 --> 0:01:13,000
into our daily lives.

26
0:01:13.26,000 --> 0:01:16,000
For me, that was the white space; that's what robots could not do yet.

27
0:01:16.26,000 --> 0:01:19,000
And so that year, I started to build this robot, Kismet,

28
0:01:19.26,000 --> 0:01:22,000
the world's first social robot.

29
0:01:22.26,000 --> 0:01:24,000
Three years later --

30
0:01:24.26,000 --> 0:01:26,000
a lot of programming,

31
0:01:26.26,000 --> 0:01:28,000
working with other graduate students in the lab --

32
0:01:28.26,000 --> 0:01:3,000
Kismet was ready to start interacting with people.

33
0:01:30.26,000 --> 0:01:32,000
(Video) Scientist: I want to show you something.

34
0:01:32.26,000 --> 0:01:34,000
Kismet: (Nonsense)

35
0:01:34.26,000 --> 0:01:37,000
Scientist: This is a watch that my girlfriend gave me.

36
0:01:37.26,000 --> 0:01:39,000
Kismet: (Nonsense)

37
0:01:39.26,000 --> 0:01:41,000
Scientist: Yeah, look, it's got a little blue light in it too.

38
0:01:41.26,000 --> 0:01:44,000
I almost lost it this week.

39
0:01:44.26,000 --> 0:01:47,000
Cynthia Breazeal: So Kismet interacted with people

40
0:01:47.26,000 --> 0:01:5,000
like kind of a non-verbal child or pre-verbal child,

41
0:01:50.26,000 --> 0:01:53,000
which I assume was fitting because it was really the first of its kind.

42
0:01:53.26,000 --> 0:01:55,000
It didn't speak language, but it didn't matter.

43
0:01:55.26,000 --> 0:01:57,000
This little robot was somehow able

44
0:01:57.26,000 --> 0:02:,000
to tap into something deeply social within us --

45
0:02:00.26,000 --> 0:02:02,000
and with that, the promise of an entirely new way

46
0:02:02.26,000 --> 0:02:04,000
we could interact with robots.

47
0:02:04.26,000 --> 0:02:06,000
So over the past several years

48
0:02:06.26,000 --> 0:02:08,000
I've been continuing to explore this interpersonal dimension of robots,

49
0:02:08.26,000 --> 0:02:1,000
now at the media lab

50
0:02:10.26,000 --> 0:02:12,000
with my own team of incredibly talented students.

51
0:02:12.26,000 --> 0:02:15,000
And one of my favorite robots is Leonardo.

52
0:02:15.26,000 --> 0:02:18,000
We developed Leonardo in collaboration with Stan Winston Studio.

53
0:02:18.26,000 --> 0:02:21,000
And so I want to show you a special moment for me of Leo.

54
0:02:21.26,000 --> 0:02:23,000
This is Matt Berlin interacting with Leo,

55
0:02:23.26,000 --> 0:02:25,000
introducing Leo to a new object.

56
0:02:25.26,000 --> 0:02:28,000
And because it's new, Leo doesn't really know what to make of it.

57
0:02:28.26,000 --> 0:02:3,000
But sort of like us, he can actually learn about it

58
0:02:30.26,000 --> 0:02:33,000
from watching Matt's reaction.

59
0:02:33.26,000 --> 0:02:35,000
(Video) Matt Berlin: Hello, Leo.

60
0:02:38.26,000 --> 0:02:41,000
Leo, this is Cookie Monster.

61
0:02:44.26,000 --> 0:02:47,000
Can you find Cookie Monster?

62
0:02:52.26,000 --> 0:02:55,000
Leo, Cookie Monster is very bad.

63
0:02:56.26,000 --> 0:02:58,000
He's very bad, Leo.

64
0:03:00.26,000 --> 0:03:03,000
Cookie Monster is very, very bad.

65
0:03:07.26,000 --> 0:03:09,000
He's a scary monster.

66
0:03:09.26,000 --> 0:03:11,000
He wants to get your cookies.

67
0:03:12.26,000 --> 0:03:14,000
(Laughter)

68
0:03:14.26,000 --> 0:03:17,000
CB: All right, so Leo and Cookie

69
0:03:17.26,000 --> 0:03:19,000
might have gotten off to a little bit of a rough start,

70
0:03:19.26,000 --> 0:03:22,000
but they get along great now.

71
0:03:22.26,000 --> 0:03:24,000
So what I've learned

72
0:03:24.26,000 --> 0:03:26,000
through building these systems

73
0:03:26.26,000 --> 0:03:28,000
is that robots are actually

74
0:03:28.26,000 --> 0:03:3,000
a really intriguing social technology,

75
0:03:30.26,000 --> 0:03:32,000
where it's actually their ability

76
0:03:32.26,000 --> 0:03:34,000
to push our social buttons

77
0:03:34.26,000 --> 0:03:36,000
and to interact with us like a partner

78
0:03:36.26,000 --> 0:03:39,000
that is a core part of their functionality.

79
0:03:39.26,000 --> 0:03:41,000
And with that shift in thinking, we can now start to imagine

80
0:03:41.26,000 --> 0:03:44,000
new questions, new possibilities for robots

81
0:03:44.26,000 --> 0:03:47,000
that we might not have thought about otherwise.

82
0:03:47.26,000 --> 0:03:49,000
But what do I mean when I say "push our social buttons?"

83
0:03:49.26,000 --> 0:03:51,000
Well, one of the things that we've learned

84
0:03:51.26,000 --> 0:03:53,000
is that, if we design these robots to communicate with us

85
0:03:53.26,000 --> 0:03:55,000
using the same body language,

86
0:03:55.26,000 --> 0:03:57,000
the same sort of non-verbal cues that people use --

87
0:03:57.26,000 --> 0:04:,000
like Nexi, our humanoid robot, is doing here --

88
0:04:00.26,000 --> 0:04:02,000
what we find is that people respond to robots

89
0:04:02.26,000 --> 0:04:04,000
a lot like they respond to people.

90
0:04:04.26,000 --> 0:04:07,000
People use these cues to determine things like how persuasive someone is,

91
0:04:07.26,000 --> 0:04:09,000
how likable, how engaging,

92
0:04:09.26,000 --> 0:04:11,000
how trustworthy.

93
0:04:11.26,000 --> 0:04:13,000
It turns out it's the same for robots.

94
0:04:13.26,000 --> 0:04:15,000
It's turning out now

95
0:04:15.26,000 --> 0:04:18,000
that robots are actually becoming a really interesting new scientific tool

96
0:04:18.26,000 --> 0:04:2,000
to understand human behavior.

97
0:04:20.26,000 --> 0:04:23,000
To answer questions like, how is it that, from a brief encounter,

98
0:04:23.26,000 --> 0:04:26,000
we're able to make an estimate of how trustworthy another person is?

99
0:04:26.26,000 --> 0:04:29,000
Mimicry's believed to play a role, but how?

100
0:04:29.26,000 --> 0:04:32,000
Is it the mimicking of particular gestures that matters?

101
0:04:32.26,000 --> 0:04:34,000
It turns out it's really hard

102
0:04:34.26,000 --> 0:04:36,000
to learn this or understand this from watching people

103
0:04:36.26,000 --> 0:04:39,000
because when we interact we do all of these cues automatically.

104
0:04:39.26,000 --> 0:04:41,000
We can't carefully control them because they're subconscious for us.

105
0:04:41.26,000 --> 0:04:43,000
But with the robot, you can.

106
0:04:43.26,000 --> 0:04:45,000
And so in this video here --

107
0:04:45.26,000 --> 0:04:48,000
this is a video taken from David DeSteno's lab at Northeastern University.

108
0:04:48.26,000 --> 0:04:5,000
He's a psychologist we've been collaborating with.

109
0:04:50.26,000 --> 0:04:53,000
There's actually a scientist carefully controlling Nexi's cues

110
0:04:53.26,000 --> 0:04:56,000
to be able to study this question.

111
0:04:56.26,000 --> 0:04:58,000
And the bottom line is -- the reason why this works is

112
0:04:58.26,000 --> 0:05:,000
because it turns out people just behave like people

113
0:05:00.26,000 --> 0:05:03,000
even when interacting with a robot.

114
0:05:03.26,000 --> 0:05:05,000
So given that key insight,

115
0:05:05.26,000 --> 0:05:07,000
we can now start to imagine

116
0:05:07.26,000 --> 0:05:1,000
new kinds of applications for robots.

117
0:05:10.26,000 --> 0:05:13,000
For instance, if robots do respond to our non-verbal cues,

118
0:05:13.26,000 --> 0:05:17,000
maybe they would be a cool, new communication technology.

119
0:05:17.26,000 --> 0:05:19,000
So imagine this:

120
0:05:19.26,000 --> 0:05:21,000
What about a robot accessory for your cellphone?

121
0:05:21.26,000 --> 0:05:23,000
You call your friend, she puts her handset in a robot,

122
0:05:23.26,000 --> 0:05:25,000
and, bam! You're a MeBot --

123
0:05:25.26,000 --> 0:05:28,000
you can make eye contact, you can talk with your friends,

124
0:05:28.26,000 --> 0:05:3,000
you can move around, you can gesture --

125
0:05:30.26,000 --> 0:05:33,000
maybe the next best thing to really being there, or is it?

126
0:05:33.26,000 --> 0:05:35,000
To explore this question,

127
0:05:35.26,000 --> 0:05:38,000
my student, Siggy Adalgeirsson, did a study

128
0:05:38.26,000 --> 0:05:41,000
where we brought human participants, people, into our lab

129
0:05:41.26,000 --> 0:05:43,000
to do a collaborative task

130
0:05:43.26,000 --> 0:05:45,000
with a remote collaborator.

131
0:05:45.26,000 --> 0:05:47,000
The task involved things

132
0:05:47.26,000 --> 0:05:49,000
like looking at a set of objects on the table,

133
0:05:49.26,000 --> 0:05:52,000
discussing them in terms of their importance and relevance to performing a certain task --

134
0:05:52.26,000 --> 0:05:54,000
this ended up being a survival task --

135
0:05:54.26,000 --> 0:05:56,000
and then rating them in terms

136
0:05:56.26,000 --> 0:05:58,000
of how valuable and important they thought they were.

137
0:05:58.26,000 --> 0:06:01,000
The remote collaborator was an experimenter from our group

138
0:06:01.26,000 --> 0:06:03,000
who used one of three different technologies

139
0:06:03.26,000 --> 0:06:05,000
to interact with the participants.

140
0:06:05.26,000 --> 0:06:07,000
The first was just the screen.

141
0:06:07.26,000 --> 0:06:1,000
This is just like video conferencing today.

142
0:06:10.26,000 --> 0:06:13,000
The next was to add mobility -- so, have the screen on a mobile base.

143
0:06:13.26,000 --> 0:06:16,000
This is like, if you're familiar with any of the telepresence robots today --

144
0:06:16.26,000 --> 0:06:19,000
this is mirroring that situation.

145
0:06:19.26,000 --> 0:06:21,000
And then the fully expressive MeBot.

146
0:06:21.26,000 --> 0:06:23,000
So after the interaction,

147
0:06:23.26,000 --> 0:06:26,000
we asked people to rate their quality of interaction

148
0:06:26.26,000 --> 0:06:28,000
with the technology, with a remote collaborator

149
0:06:28.26,000 --> 0:06:31,000
through this technology, in a number of different ways.

150
0:06:31.26,000 --> 0:06:33,000
We looked at psychological involvement --

151
0:06:33.26,000 --> 0:06:35,000
how much empathy did you feel for the other person?

152
0:06:35.26,000 --> 0:06:37,000
We looked at overall engagement.

153
0:06:37.26,000 --> 0:06:39,000
We looked at their desire to cooperate.

154
0:06:39.26,000 --> 0:06:42,000
And this is what we see when they use just the screen.

155
0:06:42.26,000 --> 0:06:45,000
It turns out, when you add mobility -- the ability to roll around the table --

156
0:06:45.26,000 --> 0:06:47,000
you get a little more of a boost.

157
0:06:47.26,000 --> 0:06:5,000
And you get even more of a boost when you add the full expression.

158
0:06:50.26,000 --> 0:06:52,000
So it seems like this physical, social embodiment

159
0:06:52.26,000 --> 0:06:54,000
actually really makes a difference.

160
0:06:54.26,000 --> 0:06:57,000
Now let's try to put this into a little bit of context.

161
0:06:57.26,000 --> 0:07:,000
Today we know that families are living further and further apart,

162
0:07:00.26,000 --> 0:07:02,000
and that definitely takes a toll on family relationships

163
0:07:02.26,000 --> 0:07:04,000
and family bonds over distance.

164
0:07:04.26,000 --> 0:07:06,000
For me, I have three young boys,

165
0:07:06.26,000 --> 0:07:08,000
and I want them to have a really good relationship

166
0:07:08.26,000 --> 0:07:1,000
with their grandparents.

167
0:07:10.26,000 --> 0:07:12,000
But my parents live thousands of miles away,

168
0:07:12.26,000 --> 0:07:14,000
so they just don't get to see each other that often.

169
0:07:14.26,000 --> 0:07:16,000
We try Skype, we try phone calls,

170
0:07:16.26,000 --> 0:07:18,000
but my boys are little -- they don't really want to talk;

171
0:07:18.26,000 --> 0:07:2,000
they want to play.

172
0:07:20.26,000 --> 0:07:22,000
So I love the idea of thinking about robots

173
0:07:22.26,000 --> 0:07:25,000
as a new kind of distance-play technology.

174
0:07:25.26,000 --> 0:07:28,000
I imagine a time not too far from now --

175
0:07:28.26,000 --> 0:07:3,000
my mom can go to her computer,

176
0:07:30.26,000 --> 0:07:32,000
open up a browser and jack into a little robot.

177
0:07:32.26,000 --> 0:07:35,000
And as grandma-bot,

178
0:07:35.26,000 --> 0:07:37,000
she can now play, really play,

179
0:07:37.26,000 --> 0:07:39,000
with my sons, with her grandsons,

180
0:07:39.26,000 --> 0:07:42,000
in the real world with his real toys.

181
0:07:42.26,000 --> 0:07:44,000
I could imagine grandmothers being able to do social-plays

182
0:07:44.26,000 --> 0:07:46,000
with their granddaughters, with their friends,

183
0:07:46.26,000 --> 0:07:48,000
and to be able to share all kinds of other activities around the house,

184
0:07:48.26,000 --> 0:07:5,000
like sharing a bedtime story.

185
0:07:50.26,000 --> 0:07:52,000
And through this technology,

186
0:07:52.26,000 --> 0:07:54,000
being able to be an active participant

187
0:07:54.26,000 --> 0:07:56,000
in their grandchildren's lives

188
0:07:56.26,000 --> 0:07:58,000
in a way that's not possible today.

189
0:07:58.26,000 --> 0:08:,000
Let's think about some other domains,

190
0:08:00.26,000 --> 0:08:02,000
like maybe health.

191
0:08:02.26,000 --> 0:08:04,000
So in the United States today,

192
0:08:04.26,000 --> 0:08:07,000
over 65 percent of people are either overweight or obese,

193
0:08:07.26,000 --> 0:08:09,000
and now it's a big problem with our children as well.

194
0:08:09.26,000 --> 0:08:11,000
And we know that as you get older in life,

195
0:08:11.26,000 --> 0:08:14,000
if you're obese when you're younger, that can lead to chronic diseases

196
0:08:14.26,000 --> 0:08:16,000
that not only reduce your quality of life,

197
0:08:16.26,000 --> 0:08:19,000
but are a tremendous economic burden on our health care system.

198
0:08:19.26,000 --> 0:08:21,000
But if robots can be engaging,

199
0:08:21.26,000 --> 0:08:23,000
if we like to cooperate with robots,

200
0:08:23.26,000 --> 0:08:25,000
if robots are persuasive,

201
0:08:25.26,000 --> 0:08:27,000
maybe a robot can help you

202
0:08:27.26,000 --> 0:08:29,000
maintain a diet and exercise program,

203
0:08:29.26,000 --> 0:08:32,000
maybe they can help you manage your weight.

204
0:08:32.26,000 --> 0:08:34,000
Sort of like a digital Jiminy --

205
0:08:34.26,000 --> 0:08:36,000
as in the well-known fairy tale --

206
0:08:36.26,000 --> 0:08:38,000
a kind of friendly, supportive presence that's always there

207
0:08:38.26,000 --> 0:08:4,000
to be able to help you make the right decision

208
0:08:40.26,000 --> 0:08:42,000
in the right way at the right time

209
0:08:42.26,000 --> 0:08:44,000
to help you form healthy habits.

210
0:08:44.26,000 --> 0:08:46,000
So we actually explored this idea in our lab.

211
0:08:46.26,000 --> 0:08:48,000
This is a robot, Autom.

212
0:08:48.26,000 --> 0:08:51,000
Cory Kidd developed this robot for his doctoral work.

213
0:08:51.26,000 --> 0:08:54,000
And it was designed to be a robot diet-and-exercise coach.

214
0:08:54.26,000 --> 0:08:56,000
It had a couple of simple non-verbal skills it could do.

215
0:08:56.26,000 --> 0:08:58,000
It could make eye contact with you.

216
0:08:58.26,000 --> 0:09:,000
It could share information looking down at a screen.

217
0:09:00.26,000 --> 0:09:02,000
You'd use a screen interface to enter information,

218
0:09:02.26,000 --> 0:09:04,000
like how many calories you ate that day,

219
0:09:04.26,000 --> 0:09:06,000
how much exercise you got.

220
0:09:06.26,000 --> 0:09:08,000
And then it could help track that for you.

221
0:09:08.26,000 --> 0:09:1,000
And the robot spoke with a synthetic voice

222
0:09:10.26,000 --> 0:09:12,000
to engage you in a coaching dialogue

223
0:09:12.26,000 --> 0:09:14,000
modeled after trainers

224
0:09:14.26,000 --> 0:09:16,000
and patients and so forth.

225
0:09:16.26,000 --> 0:09:18,000
And it would build a working alliance with you

226
0:09:18.26,000 --> 0:09:2,000
through that dialogue.

227
0:09:20.26,000 --> 0:09:22,000
It could help you set goals and track your progress,

228
0:09:22.26,000 --> 0:09:24,000
and it would help motivate you.

229
0:09:24.26,000 --> 0:09:26,000
So an interesting question is,

230
0:09:26.26,000 --> 0:09:29,000
does the social embodiment really matter? Does it matter that it's a robot?

231
0:09:29.26,000 --> 0:09:32,000
Is it really just the quality of advice and information that matters?

232
0:09:32.26,000 --> 0:09:34,000
To explore that question,

233
0:09:34.26,000 --> 0:09:36,000
we did a study in the Boston area

234
0:09:36.26,000 --> 0:09:39,000
where we put one of three interventions in people's homes

235
0:09:39.26,000 --> 0:09:41,000
for a period of several weeks.

236
0:09:41.26,000 --> 0:09:44,000
One case was the robot you saw there, Autom.

237
0:09:44.26,000 --> 0:09:47,000
Another was a computer that ran the same touch-screen interface,

238
0:09:47.26,000 --> 0:09:49,000
ran exactly the same dialogues.

239
0:09:49.26,000 --> 0:09:51,000
The quality of advice was identical.

240
0:09:51.26,000 --> 0:09:53,000
And the third was just a pen and paper log,

241
0:09:53.26,000 --> 0:09:55,000
because that's the standard intervention you typically get

242
0:09:55.26,000 --> 0:09:58,000
when you start a diet-and-exercise program.

243
0:09:58.26,000 --> 0:10:01,000
So one of the things we really wanted to look at

244
0:10:01.26,000 --> 0:10:04,000
was not how much weight people lost,

245
0:10:04.26,000 --> 0:10:07,000
but really how long they interacted with the robot.

246
0:10:07.26,000 --> 0:10:1,000
Because the challenge is not losing weight, it's actually keeping it off.

247
0:10:10.26,000 --> 0:10:13,000
And the longer you could interact with one of these interventions,

248
0:10:13.26,000 --> 0:10:16,000
well that's indicative, potentially, of longer-term success.

249
0:10:16.26,000 --> 0:10:18,000
So the first thing I want to look at is how long,

250
0:10:18.26,000 --> 0:10:2,000
how long did people interact with these systems.

251
0:10:20.26,000 --> 0:10:22,000
It turns out that people interacted with the robot

252
0:10:22.26,000 --> 0:10:24,000
significantly more,

253
0:10:24.26,000 --> 0:10:27,000
even though the quality of the advice was identical to the computer.

254
0:10:28.26,000 --> 0:10:31,000
When it asked people to rate it on terms of the quality of the working alliance,

255
0:10:31.26,000 --> 0:10:33,000
people rated the robot higher

256
0:10:33.26,000 --> 0:10:35,000
and they trusted the robot more.

257
0:10:35.26,000 --> 0:10:37,000
(Laughter)

258
0:10:37.26,000 --> 0:10:39,000
And when you look at emotional engagement,

259
0:10:39.26,000 --> 0:10:41,000
it was completely different.

260
0:10:41.26,000 --> 0:10:43,000
People would name the robots.

261
0:10:43.26,000 --> 0:10:45,000
They would dress the robots.

262
0:10:45.26,000 --> 0:10:47,000
(Laughter)

263
0:10:47.26,000 --> 0:10:5,000
And even when we would come up to pick up the robots at the end of the study,

264
0:10:50.26,000 --> 0:10:52,000
they would come out to the car and say good-bye to the robots.

265
0:10:52.26,000 --> 0:10:54,000
They didn't do this with a computer.

266
0:10:54.26,000 --> 0:10:56,000
The last thing I want to talk about today

267
0:10:56.26,000 --> 0:10:58,000
is the future of children's media.

268
0:10:58.26,000 --> 0:11:01,000
We know that kids spend a lot of time behind screens today,

269
0:11:01.26,000 --> 0:11:04,000
whether it's television or computer games or whatnot.

270
0:11:04.26,000 --> 0:11:07,000
My sons, they love the screen. They love the screen.

271
0:11:07.26,000 --> 0:11:1,000
But I want them to play; as a mom, I want them to play,

272
0:11:10.26,000 --> 0:11:12,000
like, real-world play.

273
0:11:12.26,000 --> 0:11:15,000
And so I have a new project in my group I wanted to present to you today

274
0:11:15.26,000 --> 0:11:17,000
called Playtime Computing

275
0:11:17.26,000 --> 0:11:19,000
that's really trying to think about how we can take

276
0:11:19.26,000 --> 0:11:21,000
what's so engaging about digital media

277
0:11:21.26,000 --> 0:11:23,000
and literally bring it off the screen

278
0:11:23.26,000 --> 0:11:25,000
into the real world of the child,

279
0:11:25.26,000 --> 0:11:28,000
where it can take on many of the properties of real-world play.

280
0:11:29.26,000 --> 0:11:33,000
So here's the first exploration of this idea,

281
0:11:33.26,000 --> 0:11:36,000
where characters can be physical or virtual,

282
0:11:36.26,000 --> 0:11:38,000
and where the digital content

283
0:11:38.26,000 --> 0:11:4,000
can literally come off the screen

284
0:11:40.26,000 --> 0:11:42,000
into the world and back.

285
0:11:42.26,000 --> 0:11:44,000
I like to think of this

286
0:11:44.26,000 --> 0:11:46,000
as the Atari Pong

287
0:11:46.26,000 --> 0:11:48,000
of this blended-reality play.

288
0:11:48.26,000 --> 0:11:5,000
But we can push this idea further.

289
0:11:50.26,000 --> 0:11:52,000
What if --

290
0:11:52.26,000 --> 0:11:55,000
(Game) Nathan: Here it comes. Yay!

291
0:11:55.26,000 --> 0:11:58,000
CB: -- the character itself could come into your world?

292
0:11:58.26,000 --> 0:12:,000
It turns out that kids love it

293
0:12:00.26,000 --> 0:12:03,000
when the character becomes real and enters into their world.

294
0:12:03.26,000 --> 0:12:05,000
And when it's in their world,

295
0:12:05.26,000 --> 0:12:07,000
they can relate to it and play with it in a way

296
0:12:07.26,000 --> 0:12:09,000
that's fundamentally different from how they play with it on the screen.

297
0:12:09.26,000 --> 0:12:11,000
Another important idea is this notion

298
0:12:11.26,000 --> 0:12:14,000
of persistence of character across realities.

299
0:12:14.26,000 --> 0:12:16,000
So changes that children make in the real world

300
0:12:16.26,000 --> 0:12:18,000
need to translate to the virtual world.

301
0:12:18.26,000 --> 0:12:21,000
So here, Nathan has changed the letter A to the number 2.

302
0:12:21.26,000 --> 0:12:23,000
You can imagine maybe these symbols

303
0:12:23.26,000 --> 0:12:26,000
give the characters special powers when it goes into the virtual world.

304
0:12:26.26,000 --> 0:12:29,000
So they are now sending the character back into that world.

305
0:12:29.26,000 --> 0:12:32,000
And now it's got number power.

306
0:12:32.26,000 --> 0:12:34,000
And then finally, what I've been trying to do here

307
0:12:34.26,000 --> 0:12:37,000
is create a really immersive experience for kids,

308
0:12:37.26,000 --> 0:12:4,000
where they really feel like they are part of that story,

309
0:12:40.26,000 --> 0:12:42,000
a part of that experience.

310
0:12:42.26,000 --> 0:12:44,000
And I really want to spark their imaginations

311
0:12:44.26,000 --> 0:12:47,000
the way mine was sparked as a little girl watching "Star Wars."

312
0:12:47.26,000 --> 0:12:49,000
But I want to do more than that.

313
0:12:49.26,000 --> 0:12:52,000
I actually want them to create those experiences.

314
0:12:52.26,000 --> 0:12:54,000
I want them to be able to literally build their imagination

315
0:12:54.26,000 --> 0:12:56,000
into these experiences and make them their own.

316
0:12:56.26,000 --> 0:12:58,000
So we've been exploring a lot of ideas

317
0:12:58.26,000 --> 0:13:,000
in telepresence and mixed reality

318
0:13:00.26,000 --> 0:13:03,000
to literally allow kids to project their ideas into this space

319
0:13:03.26,000 --> 0:13:05,000
where other kids can interact with them

320
0:13:05.26,000 --> 0:13:07,000
and build upon them.

321
0:13:07.26,000 --> 0:13:1,000
I really want to come up with new ways of children's media

322
0:13:10.26,000 --> 0:13:13,000
that foster creativity and learning and innovation.

323
0:13:13.26,000 --> 0:13:16,000
I think that's very, very important.

324
0:13:16.26,000 --> 0:13:18,000
So this is a new project.

325
0:13:18.26,000 --> 0:13:2,000
We've invited a lot of kids into this space,

326
0:13:20.26,000 --> 0:13:23,000
and they think it's pretty cool.

327
0:13:23.26,000 --> 0:13:25,000
But I can tell you, the thing that they love the most

328
0:13:25.26,000 --> 0:13:27,000
is the robot.

329
0:13:27.26,000 --> 0:13:3,000
What they care about is the robot.

330
0:13:30.26,000 --> 0:13:33,000
Robots touch something deeply human within us.

331
0:13:33.26,000 --> 0:13:35,000
And so whether they're helping us

332
0:13:35.26,000 --> 0:13:37,000
to become creative and innovative,

333
0:13:37.26,000 --> 0:13:39,000
or whether they're helping us

334
0:13:39.26,000 --> 0:13:41,000
to feel more deeply connected despite distance,

335
0:13:41.26,000 --> 0:13:43,000
or whether they are our trusted sidekick

336
0:13:43.26,000 --> 0:13:45,000
who's helping us attain our personal goals

337
0:13:45.26,000 --> 0:13:47,000
in becoming our highest and best selves,

338
0:13:47.26,000 --> 0:13:5,000
for me, robots are all about people.

339
0:13:50.26,000 --> 0:13:52,000
Thank you.

340
0:13:52.26,000 --> 0:13:57,000
(Applause)

