1
0:00:,000 --> 0:00:07,000
Traducteur: Lucie Penarrubia Relecteur: julien hamonic

2
0:00:17.26,000 --> 0:00:2,000
Nous vivons à une époque remarquable,

3
0:00:20.26,000 --> 0:00:23,000
l'âge de la génomique.

4
0:00:23.26,000 --> 0:00:26,000
Votre génome est la séquence intégrale de votre ADN.

5
0:00:26.26,000 --> 0:00:29,000
Votre séquence et la mienne sont légèrement différentes.

6
0:00:29.26,000 --> 0:00:31,000
C'est pour cela que nous ne nous ressemblons pas.

7
0:00:31.26,000 --> 0:00:33,000
J'ai les yeux bruns.

8
0:00:33.26,000 --> 0:00:36,000
Les vôtres sont peut-être bleus ou gris.

9
0:00:36.26,000 --> 0:00:38,000
Mais cela ne concerne pas seulement ce qui se voit à l'oeil nu.

10
0:00:38.26,000 --> 0:00:4,000
Les gros titres des journaux nous apprennent

11
0:00:40.26,000 --> 0:00:43,000
que ce sont les gènes qui sont responsables de maladies effrayantes,

12
0:00:43.26,000 --> 0:00:46,000
qui peut-être même modèlent notre personnalité,

13
0:00:46.26,000 --> 0:00:49,000
ou qui causent des désordres mentaux.

14
0:00:49.26,000 --> 0:00:52,000
Nos gènes semblent posséder

15
0:00:52.26,000 --> 0:00:55,000
une emprise phénoménale sur nos destins.

16
0:00:56.26,000 --> 0:00:59,000
Et pourtant, je voudrais penser

17
0:00:59.26,000 --> 0:01:02,000
que je suis plus que mes gènes.

18
0:01:04.26,000 --> 0:01:06,000
Vous en pensez quoi?

19
0:01:06.26,000 --> 0:01:09,000
Vous êtes aussi plus que vos gènes?

20
0:01:09.26,000 --> 0:01:11,000
(Public : Oui.) Oui ?

21
0:01:13.26,000 --> 0:01:15,000
Je pense que certains sont d'accord avec moi.

22
0:01:15.26,000 --> 0:01:17,000
Je pense que nous devrions le décréter.

23
0:01:17.26,000 --> 0:01:19,000
Je pense que nous devrions le dire tous ensemble.

24
0:01:20.26,000 --> 0:01:23,000
Allez : "Je suis plus que mes gènes" -- tous ensemble.

25
0:01:23.26,000 --> 0:01:27,000
Tout le monde : Je suis plus que mes gènes.

26
0:01:27.26,000 --> 0:01:29,000
(Applaudissements)

27
0:01:30.26,000 --> 0:01:32,000
Sebastian Seung : Qu'est-ce que je suis?

28
0:01:32.26,000 --> 0:01:35,000
(Rires)

29
0:01:35.26,000 --> 0:01:38,000
Je suis mon connectome.

30
0:01:40.26,000 --> 0:01:42,000
Bon, comme vous êtes vraiment supers,

31
0:01:42.26,000 --> 0:01:44,000
vous pourriez peut-être me faire plaisir et le dire tous ensemble aussi.

32
0:01:44.26,000 --> 0:01:46,000
(Rires)

33
0:01:46.26,000 --> 0:01:48,000
Voilà. Tous ensemble maintenant.

34
0:01:48.26,000 --> 0:01:51,000
Tout le monde : Je suis mon connectome.

35
0:01:53.26,000 --> 0:01:55,000
SS : C'était super bien.

36
0:01:55.26,000 --> 0:01:57,000
Vous savez quoi, vous êtes vraiment supers, parce que vous n'avez aucune idée de ce qu'est un connectome

37
0:01:57.26,000 --> 0:01:59,000
mais vous jouez quand même le jeu avec moi.

38
0:01:59.26,000 --> 0:02:02,000
Je n'ai plus qu'à rentrer chez moi maintenant.

39
0:02:02.26,000 --> 0:02:05,000
En fait, pour le moment on ne connaît qu'un seul connectome,

40
0:02:05.26,000 --> 0:02:08,000
celui de ce minuscule vers.

41
0:02:08.26,000 --> 0:02:1,000
Son système nerveux très modeste

42
0:02:10.26,000 --> 0:02:12,000
ne contient que 300 neurones.

43
0:02:12.26,000 --> 0:02:14,000
Et dans les années 1970 et 80,

44
0:02:14.26,000 --> 0:02:16,000
une équipe de scientifiques

45
0:02:16.26,000 --> 0:02:18,000
a cartographié les 7000 connexions

46
0:02:18.26,000 --> 0:02:2,000
entre chaque neurone.

47
0:02:21.26,000 --> 0:02:23,000
Dans ce schéma, chaque noeud est un neurone,

48
0:02:23.26,000 --> 0:02:25,000
et chaque ligne une connexion.

49
0:02:25.26,000 --> 0:02:27,000
Voici le connectome

50
0:02:27.26,000 --> 0:02:31,000
du vers C. elegans.

51
0:02:31.26,000 --> 0:02:34,000
Votre connectome est bien plus complexe que cela,

52
0:02:34.26,000 --> 0:02:36,000
car votre cerveau

53
0:02:36.26,000 --> 0:02:38,000
contient 100 milliards de neurones

54
0:02:38.26,000 --> 0:02:41,000
et 10 000 fois autant de connexions.

55
0:02:41.26,000 --> 0:02:43,000
Il y a un schéma comme celui-ci pour votre cerveau

56
0:02:43.26,000 --> 0:02:46,000
mais il n'y a aucune chance qu'il rentre sur cette diapo.

57
0:02:47.26,000 --> 0:02:5,000
Votre connectome contient un million de fois plus de connexions

58
0:02:50.26,000 --> 0:02:53,000
que ce que votre génome a de lettres.

59
0:02:53.26,000 --> 0:02:55,000
Ca fait beaucoup d'informations.

60
0:02:55.26,000 --> 0:02:58,000
Qu'y a-t-il dans cette information?

61
0:02:59.26,000 --> 0:03:02,000
Nous n'en sommes pas sûrs, mais nous avons des théories.

62
0:03:02.26,000 --> 0:03:05,000
Depuis le 19ème siècle, les neuro-scientifiques imaginent

63
0:03:05.26,000 --> 0:03:07,000
que peut-être vos souvenirs --

64
0:03:07.26,000 --> 0:03:09,000
cette information qui fait que vous êtes qui vous êtes --

65
0:03:09.26,000 --> 0:03:11,000
peut-être que vos souvenirs sont stockés

66
0:03:11.26,000 --> 0:03:13,000
dans les connexions entre les neurones de votre cerveau.

67
0:03:15.26,000 --> 0:03:17,000
Et peut-être que d'autres aspects de votre identité --

68
0:03:17.26,000 --> 0:03:2,000
peut-être votre personnalité et votre intelligence --

69
0:03:20.26,000 --> 0:03:22,000
peut-être sont-ils aussi encodés

70
0:03:22.26,000 --> 0:03:25,000
dans les connexions entre les neurones.

71
0:03:26.26,000 --> 0:03:29,000
Maintenant vous comprenez pourquoi j'ai proposé cette hypothèse :

72
0:03:29.26,000 --> 0:03:32,000
je suis mon connectome.

73
0:03:32.26,000 --> 0:03:35,000
Je ne vous ai pas demandé de le scander parce que c'est vrai,

74
0:03:35.26,000 --> 0:03:37,000
je veux juste que vous vous en rappeliez.

75
0:03:37.26,000 --> 0:03:39,000
En fait, nous ne savons pas si cette hypothèse est correcte,

76
0:03:39.26,000 --> 0:03:41,000
parce que nous n'avons pas encore de technologie

77
0:03:41.26,000 --> 0:03:43,000
assez puissante pour la mettre à l'épreuve.

78
0:03:44.26,000 --> 0:03:47,000
Trouver le connectome de ce vers

79
0:03:47.26,000 --> 0:03:5,000
équivaut à plus d'une douzaine d'années de travail acharné.

80
0:03:50.26,000 --> 0:03:53,000
Et pour trouver les connectomes de cerveaux qui s'approchent davantage des nôtres,

81
0:03:53.26,000 --> 0:03:56,000
nous avons besoin de technologies plus sophistiquées, automatisées,

82
0:03:56.26,000 --> 0:03:59,000
qui augmenteront la vitesse du processus qui permet de trouver des connectomes.

83
0:03:59.26,000 --> 0:04:02,000
Et, dans les minutes à venir, je vais vous parler un peu de ces technologies

84
0:04:02.26,000 --> 0:04:04,000
qui sont actuellement en cours de développement

85
0:04:04.26,000 --> 0:04:07,000
dans mon labo et dans les labos de mes collaborateurs.

86
0:04:08.26,000 --> 0:04:11,000
Bon, vous avez probablement déjà vu des images de neurones par le passé.

87
0:04:11.26,000 --> 0:04:13,000
Vous les reconnaissez instantanément

88
0:04:13.26,000 --> 0:04:16,000
à leur forme fantastique.

89
0:04:16.26,000 --> 0:04:19,000
Ils déploient de longues et délicates branches

90
0:04:19.26,000 --> 0:04:22,000
et, pour faire court, ils ressemblent à des arbres.

91
0:04:22.26,000 --> 0:04:25,000
Mais il ne s'agit là que d'un seul neurone.

92
0:04:25.26,000 --> 0:04:27,000
Pour trouver les connectomes,

93
0:04:27.26,000 --> 0:04:3,000
nous devons regarder tous les neurones en même temps.

94
0:04:30.26,000 --> 0:04:32,000
Laissez-moi vous présenter Bobby Kasthuri

95
0:04:32.26,000 --> 0:04:34,000
qui travaille dans le laboratoire de Jeff Lichtman

96
0:04:34.26,000 --> 0:04:36,000
à Harvard.

97
0:04:36.26,000 --> 0:04:38,000
Bobby s'occupe des tranches extrêmement fines

98
0:04:38.26,000 --> 0:04:4,000
du cerveau d'une souris.

99
0:04:40.26,000 --> 0:04:43,000
Nous agrandissons l'image 100 000 fois

100
0:04:44.26,000 --> 0:04:46,000
pour obtenir la résolution

101
0:04:46.26,000 --> 0:04:49,000
qui nous permet de voir toutes les branches du neurone en une seule fois.

102
0:04:50.26,000 --> 0:04:53,000
Sauf qu'il est possible que vous ne puissiez toujours pas les reconnaître

103
0:04:53.26,000 --> 0:04:56,000
et c'est parce qu'il est nécessaire de travailler en trois dimensions.

104
0:04:56.26,000 --> 0:04:58,000
Si on prend plusieurs images de plusieurs tranches du cerveau

105
0:04:58.26,000 --> 0:05:,000
et si on les empile,

106
0:05:00.26,000 --> 0:05:02,000
on obtient une image tri-dimensionnelle.

107
0:05:02.26,000 --> 0:05:04,000
Et pourtant, il est possible que vous ne voyiez toujours pas les branches.

108
0:05:04.26,000 --> 0:05:06,000
Donc on commence par en haut,

109
0:05:06.26,000 --> 0:05:09,000
et on colore en rouge la coupe transversale d'une branche.

110
0:05:09.26,000 --> 0:05:11,000
On fait pareil pour la tranche d'après,

111
0:05:11.26,000 --> 0:05:13,000
et celle d'après.

112
0:05:13.26,000 --> 0:05:15,000
Et on continue de faire ça,

113
0:05:15.26,000 --> 0:05:18,000
tranche après tranche.

114
0:05:18.26,000 --> 0:05:2,000
Si on continue comme ça pour toute la pile,

115
0:05:20.26,000 --> 0:05:23,000
on peut reconstruire la forme en trois dimensions

116
0:05:23.26,000 --> 0:05:26,000
d'un petit fragment de la branche d'un neurone.

117
0:05:26.26,000 --> 0:05:28,000
On peut faire la même chose pour un autre neurone en vert.

118
0:05:28.26,000 --> 0:05:3,000
Vous pouvez voir que le neurone vert touche le neurone rouge

119
0:05:30.26,000 --> 0:05:32,000
à deux endroits,

120
0:05:32.26,000 --> 0:05:34,000
et c'est là ce qu'on appelle les synapses.

121
0:05:34.26,000 --> 0:05:36,000
Agrandissons une synapse.

122
0:05:36.26,000 --> 0:05:39,000
Et fixez attentivement l'intérieur du neurone vert.

123
0:05:39.26,000 --> 0:05:41,000
Vous devriez voir des petits cercles.

124
0:05:41.26,000 --> 0:05:44,000
C'est ce qu'on appelle les vésicules.

125
0:05:44.26,000 --> 0:05:47,000
Elles contiennent une molécule qu'on appelle un neurotransmetteur.

126
0:05:47.26,000 --> 0:05:49,000
Ainsi quand le neurone vert veut communiquer,

127
0:05:49.26,000 --> 0:05:51,000
qu'il veut envoyer un message au neurone rouge,

128
0:05:51.26,000 --> 0:05:54,000
il lâche des neurotransmetteurs.

129
0:05:54.26,000 --> 0:05:56,000
Au niveau de la synapse, les deux neurones

130
0:05:56.26,000 --> 0:05:58,000
sont connectés

131
0:05:58.26,000 --> 0:06:01,000
comme deux amis qui parleraient au téléphone.

132
0:06:02.26,000 --> 0:06:04,000
Vous voyez donc comment trouver une synapse.

133
0:06:04.26,000 --> 0:06:07,000
Comment fait-on pour trouver un connectome entier?

134
0:06:07.26,000 --> 0:06:1,000
Eh bien on prend cette pile d'images en trois dimensions

135
0:06:10.26,000 --> 0:06:13,000
et on la traite comme un livre de coloriage tridimensionnel géant.

136
0:06:13.26,000 --> 0:06:16,000
On colorie chaque neurone avec une couleur différente

137
0:06:16.26,000 --> 0:06:18,000
et puis on regarde à travers toutes ces images,

138
0:06:18.26,000 --> 0:06:2,000
on trouve les synapses

139
0:06:20.26,000 --> 0:06:23,000
et on note les couleurs des deux neurones impliqués dans chaque synapse.

140
0:06:23.26,000 --> 0:06:26,000
Si on peut faire ça pour toutes les images,

141
0:06:26.26,000 --> 0:06:28,000
on doit pouvoir trouver un connectome.

142
0:06:29.26,000 --> 0:06:31,000
Bien, arrivés à ce point,

143
0:06:31.26,000 --> 0:06:33,000
vous avez appris ce qu'il y a d'élémentaire à savoir sur les neurones et les synapses.

144
0:06:33.26,000 --> 0:06:35,000
Je pense donc que nous sommes prêts à aborder

145
0:06:35.26,000 --> 0:06:38,000
l'une des questions les plus importantes de la neuroscience :

146
0:06:39.26,000 --> 0:06:42,000
en quoi les cerveau des hommes et des femmes sont-ils différents?

147
0:06:42.26,000 --> 0:06:44,000
(Rires)

148
0:06:44.26,000 --> 0:06:46,000
Si on en croit ce livre de développement personnel,

149
0:06:46.26,000 --> 0:06:48,000
les cerveaux des hommes sont comme des gaufres;

150
0:06:48.26,000 --> 0:06:51,000
leur vie est comme compartimentée dans des boîtes.

151
0:06:51.26,000 --> 0:06:54,000
Le cerveau des filles ressemble aux spaghettis;

152
0:06:54.26,000 --> 0:06:57,000
tout dans leur vie est connecté à quelque chose d'autre.

153
0:06:57.26,000 --> 0:06:59,000
(Rires)

154
0:06:59.26,000 --> 0:07:01,000
Vous riez

155
0:07:01.26,000 --> 0:07:03,000
mais, vous savez, ce livre a changé ma vie.

156
0:07:03.26,000 --> 0:07:05,000
(Rires)

157
0:07:07.26,000 --> 0:07:1,000
Non mais sérieusement, qu'est-ce qui cloche ici?

158
0:07:10.26,000 --> 0:07:13,000
Vous en savez déjà assez pour me le dire. Pourquoi cette idée est-elle fausse?

159
0:07:20.26,000 --> 0:07:23,000
Peu importe que vous soyez un garçon ou une fille,

160
0:07:23.26,000 --> 0:07:26,000
tous les cerveaux sont comme des spaghettis.

161
0:07:26.26,000 --> 0:07:29,000
Ou alors des capellini vraiment très fins, avec des branches.

162
0:07:30.26,000 --> 0:07:32,000
Exactement de la même façon qu'un brin de spaghetti

163
0:07:32.26,000 --> 0:07:35,000
est en contact avec plein d'autres brins dans votre assiette,

164
0:07:35.26,000 --> 0:07:37,000
un neurone touche plein d'autres neurones

165
0:07:37.26,000 --> 0:07:39,000
grâce à leurs branches, emmêlées les unes aux autres.

166
0:07:39.26,000 --> 0:07:42,000
Un neurone peut être connecté à beaucoup d'autres neurones

167
0:07:42.26,000 --> 0:07:44,000
parce que des synapses peuvent apparaître

168
0:07:44.26,000 --> 0:07:47,000
à ces points de contact.

169
0:07:49.26,000 --> 0:07:52,000
Il se peut que vous n'ayez plus trop conscience à ce stade

170
0:07:52.26,000 --> 0:07:55,000
de la taille de ce cube de tissu cérébral.

171
0:07:55.26,000 --> 0:07:58,000
Je vous propose donc de faire une série de comparaisons pour vous montrer.

172
0:07:58.26,000 --> 0:08:01,000
Je vais vous montrer. Ca, c'est vraiment minuscule. Seulement six microns sur un côté.

173
0:08:03.26,000 --> 0:08:06,000
Là vous voyez comment ça s'empile dans un neurone entier.

174
0:08:06.26,000 --> 0:08:09,000
Et vous pouvez voir que, vraiment, seuls les plus petits fragments des branches

175
0:08:09.26,000 --> 0:08:12,000
sont contenus dans ce cube.

176
0:08:12.26,000 --> 0:08:15,000
Et un neurone, eh bien c'est plus petit qu'un cerveau.

177
0:08:17.26,000 --> 0:08:19,000
Et il ne s'agit là que du cerveau d'une souris.

178
0:08:21.26,000 --> 0:08:24,000
C'est bien plus petit qu'un cerveau humain.

179
0:08:25.26,000 --> 0:08:27,000
Du coup quand j'ai montré ça à mes amis

180
0:08:27.26,000 --> 0:08:29,000
ils m'ont parfois dit

181
0:08:29.26,000 --> 0:08:32,000
"Tu sais, Sebastian, tu devrais simplement abandonner.

182
0:08:32.26,000 --> 0:08:34,000
Il n'y a pas d'espoir en neuroscience."

183
0:08:34.26,000 --> 0:08:36,000
Parce que si vous observez votre cerveau à l'oeil nu,

184
0:08:36.26,000 --> 0:08:38,000
vous ne vous rendez pas vraiment compte à quel point c'est complexe,

185
0:08:38.26,000 --> 0:08:4,000
mais quand vous utilisez un microscope,

186
0:08:40.26,000 --> 0:08:43,000
cette complexité qui se cachait est révélée."

187
0:08:45.26,000 --> 0:08:47,000
Au 17ème siècle,

188
0:08:47.26,000 --> 0:08:49,000
Blaise Pascal, mathématicien et philosophe,

189
0:08:49.26,000 --> 0:08:52,000
a écrit sur sa peur de l'infini,

190
0:08:52.26,000 --> 0:08:54,000
son sentiment de vanité

191
0:08:54.26,000 --> 0:08:57,000
quand il contemple "le silence éternel de ces espaces infinis".

192
0:08:59.26,000 --> 0:09:01,000
En tant que scientifique,

193
0:09:01.26,000 --> 0:09:04,000
je ne suis pas supposé parler de mes sentiments.

194
0:09:04.26,000 --> 0:09:06,000
Trop d'informations, professeur.

195
0:09:06.26,000 --> 0:09:08,000
(Rires)

196
0:09:08.26,000 --> 0:09:1,000
Mais pourquoi pas?

197
0:09:10.26,000 --> 0:09:12,000
(Rires)

198
0:09:12.26,000 --> 0:09:14,000
(Applaudissements)

199
0:09:14.26,000 --> 0:09:16,000
Je ressens une vraie curiosité,

200
0:09:16.26,000 --> 0:09:18,000
et une vraie envie de comprendre

201
0:09:18.26,000 --> 0:09:21,000
mais parfois je ressens aussi du désespoir.

202
0:09:22.26,000 --> 0:09:24,000
Pourquoi ai-je choisi d'étudier

203
0:09:24.26,000 --> 0:09:27,000
cet organe, si formidable dans sa complexité,

204
0:09:27.26,000 --> 0:09:29,000
qu'il pourrait bien être infini?

205
0:09:29.26,000 --> 0:09:31,000
C'est absurde.

206
0:09:31.26,000 --> 0:09:33,000
Comment pourrions-nous même oser penser

207
0:09:33.26,000 --> 0:09:36,000
que nous arriverons un jour à comprendre cela?

208
0:09:38.26,000 --> 0:09:41,000
Et pourtant, je m'obstine à lutter contre des moulins à vent.

209
0:09:41.26,000 --> 0:09:44,000
Et de fait, j'entretiens depuis peu de nouveaux espoirs.

210
0:09:45.26,000 --> 0:09:47,000
Un jour,

211
0:09:47.26,000 --> 0:09:49,000
un équipement de microscopes capturera

212
0:09:49.26,000 --> 0:09:51,000
chaque neurone et chaque synapse

213
0:09:51.26,000 --> 0:09:54,000
et le stockera dans une énorme base de données d'images.

214
0:09:54.26,000 --> 0:09:57,000
Et un jour, des super ordinateurs à intelligence artificielle

215
0:09:57.26,000 --> 0:10:,000
analyseront les images sans l'aide des humains

216
0:10:00.26,000 --> 0:10:03,000
pour les synthétiser en un connectome.

217
0:10:04.26,000 --> 0:10:07,000
Je ne sais pas si cela sera possible, mais j'espère que je vivrai assez longtemps pour voir ce jour.

218
0:10:08.26,000 --> 0:10:1,000
Parce que trouver un connectome humain en eniter

219
0:10:10.26,000 --> 0:10:13,000
est l'un des plus grands défis technologiques de tous les temps.

220
0:10:13.26,000 --> 0:10:16,000
Cela demandera le travail de plusieurs générations pour y arriver.

221
0:10:17.26,000 --> 0:10:2,000
Actuellement, mes collaborateurs et moi-même,

222
0:10:20.26,000 --> 0:10:22,000
visons quelque chose de bien plus modeste --

223
0:10:22.26,000 --> 0:10:24,000
seulement trouver des connectomes partiels

224
0:10:24.26,000 --> 0:10:27,000
de petits morceaux de cerveaux de souris et d'humains.

225
0:10:27.26,000 --> 0:10:3,000
Mais même cela suffirait pour les premières mises à l'épreuve de l'hypothèse

226
0:10:30.26,000 --> 0:10:33,000
qui affirme que je suis mon connectome.

227
0:10:35.26,000 --> 0:10:38,000
Pour le moment, laissez-moi vous convaincre de la plausibilité de cette hypothèse,

228
0:10:38.26,000 --> 0:10:41,000
et qu'elle vaut vraiment la peine qu'on la prenne au sérieux.

229
0:10:42.26,000 --> 0:10:44,000
Pendant que vous grandissez dans votre enfance

230
0:10:44.26,000 --> 0:10:47,000
et que vous murissez à l'âge adulte,

231
0:10:47.26,000 --> 0:10:5,000
votre identité change doucement.

232
0:10:50.26,000 --> 0:10:52,000
De même, chaque connectome

233
0:10:52.26,000 --> 0:10:54,000
change à travers le temps.

234
0:10:55.26,000 --> 0:10:57,000
De quelle sorte de changements s'agit-il?

235
0:10:57.26,000 --> 0:10:59,000
Eh bien, les neurones, comme les arbres,

236
0:10:59.26,000 --> 0:11:01,000
peuvent avoir de nouvelles branches qui poussent

237
0:11:01.26,000 --> 0:11:04,000
et en perdre des anciennes.

238
0:11:04.26,000 --> 0:11:07,000
Des synapses peuvent être créées

239
0:11:07.26,000 --> 0:11:1,000
puis éliminées.

240
0:11:10.26,000 --> 0:11:12,000
Et les synapses peuvent s'agrandirent

241
0:11:12.26,000 --> 0:11:15,000
et rapetisser.

242
0:11:15.26,000 --> 0:11:17,000
Deuxième question :

243
0:11:17.26,000 --> 0:11:2,000
qu'est-ce qui cause ces changements?

244
0:11:20.26,000 --> 0:11:22,000
Eh bien, c'est vrai.

245
0:11:22.26,000 --> 0:11:25,000
D'une certaine manière, ils sont programmés par vos gènes.

246
0:11:25.26,000 --> 0:11:27,000
Mais l'histoire ne s'arrête pas là,

247
0:11:27.26,000 --> 0:11:29,000
parce que ce sont des signaux, des signaux électriques

248
0:11:29.26,000 --> 0:11:31,000
qui voyagent le long des branches de neurones

249
0:11:31.26,000 --> 0:11:33,000
et des signaux chimiques

250
0:11:33.26,000 --> 0:11:35,000
qui sautent d'une branche à une autre.

251
0:11:35.26,000 --> 0:11:38,000
On appelle ces signaux l'activité cérébrale.

252
0:11:38.26,000 --> 0:11:4,000
Il y a beaucoup à parier

253
0:11:40.26,000 --> 0:11:43,000
que l'activité cérébrale

254
0:11:43.26,000 --> 0:11:46,000
encode nos pensées, sentiments et perceptions,

255
0:11:46.26,000 --> 0:11:48,000
nos expériences mentales.

256
0:11:48.26,000 --> 0:11:51,000
Et il y a beaucoup à parier que l'activité cérébrale

257
0:11:51.26,000 --> 0:11:54,000
puisse amener vos connexions à changer.

258
0:11:54.26,000 --> 0:11:57,000
Et si vous on rassemble ces deux faits

259
0:11:57.26,000 --> 0:11:59,000
on comprends que vos expériences

260
0:11:59.26,000 --> 0:12:02,000
peuvent changer votre connectome.

261
0:12:02.26,000 --> 0:12:04,000
C'est pour cela que chaque connectome est unique,

262
0:12:04.26,000 --> 0:12:07,000
même ceux de jumeaux identiques génétiquement.

263
0:12:08.26,000 --> 0:12:11,000
Le connectome est ce lieu où l'acquis rencontre l'inné.

264
0:12:12.26,000 --> 0:12:14,000
Et il peut être vrai

265
0:12:14.26,000 --> 0:12:16,000
que le simple fait de penser

266
0:12:16.26,000 --> 0:12:18,000
change votre connectome --

267
0:12:18.26,000 --> 0:12:21,000
une idée que vous trouverez sans doute stimulante.

268
0:12:24.26,000 --> 0:12:26,000
Qu'y a-t-il dans cette image?

269
0:12:28.26,000 --> 0:12:31,000
D'après vous, un courant d'eau froid et revigorant.

270
0:12:32.26,000 --> 0:12:34,000
Qu'y a-t-il d'autre dans cette image?

271
0:12:37.26,000 --> 0:12:39,000
N'oubliez pas ce sillon dans la terre

272
0:12:39.26,000 --> 0:12:42,000
qu'on appelle le lit de la rivière.

273
0:12:42.26,000 --> 0:12:45,000
Sans lui, l'eau ne saurait pas dans quelle direction s'écouler.

274
0:12:45.26,000 --> 0:12:47,000
Et avec l'idée de courant,

275
0:12:47.26,000 --> 0:12:49,000
j'aimerais proposer une métaphore

276
0:12:49.26,000 --> 0:12:51,000
pour désigner la relation entre l'activité neuronale

277
0:12:51.26,000 --> 0:12:53,000
et la connectivité.

278
0:12:54.26,000 --> 0:12:57,000
L'activité neuronale change constamment.

279
0:12:57.26,000 --> 0:13:,000
C'est comme l'eau d'un courant; il ne reste jamais en place.

280
0:13:00.26,000 --> 0:13:02,000
Les connexions

281
0:13:02.26,000 --> 0:13:04,000
du réseau neuronal du cerveau

282
0:13:04.26,000 --> 0:13:06,000
déterminent les chemins

283
0:13:06.26,000 --> 0:13:08,000
que vont emprunter les flux d'activité cérébrale.

284
0:13:08.26,000 --> 0:13:11,000
Et donc le connectome est comme le lit de la rivière.

285
0:13:13.26,000 --> 0:13:16,000
Mais la métaphore est plus riche que cela.

286
0:13:16.26,000 --> 0:13:19,000
Parce que s'il est vrai que le lit de la rivière

287
0:13:19.26,000 --> 0:13:21,000
guide les flots de l'eau,

288
0:13:21.26,000 --> 0:13:23,000
il faut dire aussi que sur un long terme

289
0:13:23.26,000 --> 0:13:26,000
l'eau à son tour remodèle le lit de la rivière.

290
0:13:26.26,000 --> 0:13:28,000
Et comme je vous le disais justement,

291
0:13:28.26,000 --> 0:13:31,000
l'activité neuronal peut changer le connectome.

292
0:13:33.26,000 --> 0:13:35,000
Et si vous m'autorisez à gravir

293
0:13:35.26,000 --> 0:13:38,000
les hautes cimes de la métaphore,

294
0:13:38.26,000 --> 0:13:41,000
je vous rappellerais que l'activité neuronale

295
0:13:41.26,000 --> 0:13:43,000
est le fondement physique -- du moins c'est ce que pensent les neuroscientifiques --

296
0:13:43.26,000 --> 0:13:46,000
des pensées, des sentiments et des perceptions.

297
0:13:46.26,000 --> 0:13:48,000
Nous pouvons donc même parler

298
0:13:48.26,000 --> 0:13:5,000
d'un flux de conscience (stream of consciousness).

299
0:13:50.26,000 --> 0:13:53,000
L'activité neuronale est son cours d'eau,

300
0:13:53.26,000 --> 0:13:56,000
et le connectome son lit.

301
0:13:57.26,000 --> 0:13:59,000
Quittons donc ces hauts sommets de la métaphore

302
0:13:59.26,000 --> 0:14:01,000
et retournons à la science.

303
0:14:01.26,000 --> 0:14:03,000
Supposez que les technologies qui nous permettent de trouver des connectomes

304
0:14:03.26,000 --> 0:14:05,000
marchent vraiment.

305
0:14:05.26,000 --> 0:14:07,000
Comment nous y prendrons-nous pour mettre à l'épreuve l'hypothèse selon laquelle

306
0:14:07.26,000 --> 0:14:1,000
"Je suis mon connectome"?

307
0:14:10.26,000 --> 0:14:13,000
Eh bien je vous propose un test en direct.

308
0:14:13.26,000 --> 0:14:15,000
Essayons

309
0:14:15.26,000 --> 0:14:18,000
de déchiffrer des souvenirs depuis des connectomes.

310
0:14:18.26,000 --> 0:14:2,000
Examinez le souvenir

311
0:14:20.26,000 --> 0:14:23,000
de longues séquences temporelles de mouvements

312
0:14:23.26,000 --> 0:14:26,000
comme un pianiste jouant une sonate de Beethoven.

313
0:14:26.26,000 --> 0:14:29,000
Selon une théorie qui remonte au 19°siècle,

314
0:14:29.26,000 --> 0:14:31,000
des souvenirs comme cela sont stockés

315
0:14:31.26,000 --> 0:14:34,000
dans nos cerveaux sous formes de connexions synaptiques.

316
0:14:35.26,000 --> 0:14:38,000
Parce que, si les premiers neurones dans la chaîne sont activés,

317
0:14:38.26,000 --> 0:14:41,000
ils envoient des messages par leurs synapses aux seconds neurones, qui sont activés,

318
0:14:41.26,000 --> 0:14:43,000
et cela se poursuit ainsi sur toute la ligne,

319
0:14:43.26,000 --> 0:14:45,000
un peu comme une chaîne de dominos qui s'écroulerait.

320
0:14:45.26,000 --> 0:14:47,000
Et cette séquence d'activation neuronale

321
0:14:47.26,000 --> 0:14:5,000
est envisagée hypothétiquement comme étant la base neuronale

322
0:14:50.26,000 --> 0:14:52,000
de ces séquences de mouvements.

323
0:14:52.26,000 --> 0:14:54,000
Aussi un des moyens d'essayer de tester cette théorie

324
0:14:54.26,000 --> 0:14:56,000
consiste à chercher ce genre de chaînes

325
0:14:56.26,000 --> 0:14:58,000
à l'intérieur des connectomes.

326
0:14:58.26,000 --> 0:15:01,000
Mais ce ne sera pas facile, parce qu'elles ne ressembleront pas à ça.

327
0:15:01.26,000 --> 0:15:03,000
Elles seront toutes emmêlées.

328
0:15:03.26,000 --> 0:15:05,000
On va donc devoir utiliser nos ordinateurs

329
0:15:05.26,000 --> 0:15:08,000
pour essayer de démêler les chaînes.

330
0:15:08.26,000 --> 0:15:1,000
Et si on arrive à faire ça,

331
0:15:10.26,000 --> 0:15:13,000
la séquence de neurones que nous récupèrerons

332
0:15:13.26,000 --> 0:15:16,000
sera une prédiction du modèle de l'activité neuronale

333
0:15:16.26,000 --> 0:15:19,000
qui est rejouée dans le cerveau lors de la recollection des souvenirs.

334
0:15:19.26,000 --> 0:15:21,000
Et si cela s'avérait être une réussite,

335
0:15:21.26,000 --> 0:15:24,000
cela serait le premier exemple d'une lecture de souvenirs à partir d'un connectome.

336
0:15:28.26,000 --> 0:15:3,000
(Rires)

337
0:15:30.26,000 --> 0:15:32,000
Quel bazard.

338
0:15:33.26,000 --> 0:15:35,000
Avez-vous déjà essayé de faire les branchements d'un système

339
0:15:35.26,000 --> 0:15:37,000
aussi complexe que celui-ci?

340
0:15:37.26,000 --> 0:15:39,000
J'espère que non.

341
0:15:39.26,000 --> 0:15:42,000
Mais si jamais c'est le cas, vous savez comme il peut être facile de faire une erreur.

342
0:15:45.26,000 --> 0:15:47,000
Les branchements des neurones sont comme les fils électriques du cerveau.

343
0:15:47.26,000 --> 0:15:51,000
Est-ce que quelqu'un peut deviner ça : quelle est la longueur totale des fils dans notre cerveau?

344
0:15:54.26,000 --> 0:15:56,000
Je vous donne un indice. C'est un nombre très grand.

345
0:15:56.26,000 --> 0:15:58,000
(Rires)

346
0:15:59.26,000 --> 0:16:02,000
Je l'estime à des millions de miles.

347
0:16:02.26,000 --> 0:16:05,000
Tout empaqueté dans notre boîte crânienne.

348
0:16:05.26,000 --> 0:16:07,000
Et si vous arrivez à estimer ce nombre,

349
0:16:07.26,000 --> 0:16:09,000
vous pouvez facilement comprendre

350
0:16:09.26,000 --> 0:16:11,000
qu'il y a une immense probabilité pour qu'il y ait de mauvaises connexions dans le cerveau.

351
0:16:11.26,000 --> 0:16:14,000
Et en effet, la presse populaire adore les gros titres du genre

352
0:16:14.26,000 --> 0:16:16,000
"Le cerveau des anorexiques est connecté différemment"

353
0:16:16.26,000 --> 0:16:18,000
ou "Le cerveau des autistes est connecté différement".

354
0:16:18.26,000 --> 0:16:2,000
Ce sont des affirmations plausibles

355
0:16:20.26,000 --> 0:16:22,000
mais, en vérité,

356
0:16:22.26,000 --> 0:16:24,000
on n'est pas capable de regarder le "câblage" du cerveau assez clairement

357
0:16:24.26,000 --> 0:16:26,000
pour dire si elles sont vraies.

358
0:16:26.26,000 --> 0:16:29,000
Donc les technologies qui visent à observer des connectomes

359
0:16:29.26,000 --> 0:16:31,000
nous permettrons en fin de compte

360
0:16:31.26,000 --> 0:16:33,000
de déchiffrer les erreurs de câblage dans le cerveau,

361
0:16:33.26,000 --> 0:16:36,000
de repérer les désordres mentaux dans les connectomes.

362
0:16:40.26,000 --> 0:16:43,000
Parfois le meilleur moyen de tester une hypothèse

363
0:16:43.26,000 --> 0:16:46,000
est de la considérer dans ce qu'elle implique de plus extrême.

364
0:16:46.26,000 --> 0:16:49,000
Les philosophes connaissent très bien ce jeu.

365
0:16:50.26,000 --> 0:16:53,000
Si vous pensez que je suis mon connectome,

366
0:16:53.26,000 --> 0:16:56,000
je pense que vous devrez aussi accepter l'idée

367
0:16:56.26,000 --> 0:16:58,000
que la mort entraîne la destruction

368
0:16:58.26,000 --> 0:17:01,000
de votre connectome.

369
0:17:02.26,000 --> 0:17:05,000
Je me permets de mentionner cela parce qu'il y a des prophètes aujourd'hui

370
0:17:05.26,000 --> 0:17:08,000
qui affirment que la technologie

371
0:17:08.26,000 --> 0:17:11,000
finira par modifier fondamentalement la condition humaine

372
0:17:11.26,000 --> 0:17:14,000
et peut-être même par transformer l'espèce humaine.

373
0:17:14.26,000 --> 0:17:17,000
Un de leurs rêves les plus tendres

374
0:17:17.26,000 --> 0:17:19,000
est de tromper la mort

375
0:17:19.26,000 --> 0:17:21,000
grâce à cette pratique connue sous le nom de cryonie.

376
0:17:21.26,000 --> 0:17:23,000
Pour 100 000 dollars,

377
0:17:23.26,000 --> 0:17:26,000
vous pouvez vous arranger pour qu'on congèle votre corps après votre mort

378
0:17:26.26,000 --> 0:17:28,000
et pour qu'on le place dans de l'azote liquide

379
0:17:28.26,000 --> 0:17:3,000
dans un de ces aquariums dans un entrepôt en Arizona

380
0:17:30.26,000 --> 0:17:32,000
dans l'attente d'une civilisation future

381
0:17:32.26,000 --> 0:17:35,000
assez avancée pour pouvoir vous ressusciter.

382
0:17:36.26,000 --> 0:17:38,000
Devons-nous tourner en ridicule les chercheurs d'immortalité des temps modernes,

383
0:17:38.26,000 --> 0:17:4,000
et les appeler idiots?

384
0:17:40.26,000 --> 0:17:42,000
Ou bien reviendront-ils un jour ricaner

385
0:17:42.26,000 --> 0:17:44,000
au-dessus de nos tombes?

386
0:17:45.26,000 --> 0:17:47,000
Je ne sais pas.

387
0:17:47.26,000 --> 0:17:5,000
Je préfère mettre à l'épreuve leurs croyances, scientifiquement.

388
0:17:50.26,000 --> 0:17:52,000
Je propose que nous essayions de trouver un connectome

389
0:17:52.26,000 --> 0:17:54,000
d'un cerveau congelé.

390
0:17:54.26,000 --> 0:17:56,000
Nous savons que des dommages sont infligés au cerveau

391
0:17:56.26,000 --> 0:17:58,000
après la mort et pendant le refroidissement du cadavre.

392
0:17:58.26,000 --> 0:18:01,000
La question est : est-ce que ces dommages effacent le connectome?

393
0:18:01.26,000 --> 0:18:04,000
Si c'est le cas, il n'y a aucun moyen pour qu'une civilisation du future

394
0:18:04.26,000 --> 0:18:07,000
soit cabale de récupérer les souvenirs de ces cerveaux congelés.

395
0:18:07.26,000 --> 0:18:09,000
La résurrection pourrait bien fonctionner pour le corps,

396
0:18:09.26,000 --> 0:18:11,000
mais pas pour l'esprit.

397
0:18:11.26,000 --> 0:18:14,000
D'un autre côté, si le connectome est toujours intact,

398
0:18:14.26,000 --> 0:18:17,000
on ne peut pas ridiculiser les affirmations des partisans de la cryonie si facilement.

399
0:18:20.26,000 --> 0:18:22,000
J'ai décrit une quête

400
0:18:22.26,000 --> 0:18:25,000
qui commence dans le monde de l'infiniment petit

401
0:18:25.26,000 --> 0:18:28,000
et finit par nous propulser dans le monde d'un futur très éloigné.

402
0:18:28.26,000 --> 0:18:31,000
Les connectomes marqueront un tournant dans l'histoire de l'humanité.

403
0:18:32.26,000 --> 0:18:34,000
Alors que nous nous émancipions de la condition de nos ancêtres à l'apparence de singes

404
0:18:34.26,000 --> 0:18:36,000
dans la savane africaine,

405
0:18:36.26,000 --> 0:18:39,000
ce qui nous distinguait, c'était nos cerveaux plus larges.

406
0:18:40.26,000 --> 0:18:42,000
Nous avons utilisé nos cerveaux pour concevoir

407
0:18:42.26,000 --> 0:18:45,000
des technologies toujours plus incroyables.

408
0:18:45.26,000 --> 0:18:48,000
A la fin, ces technologies deviendront si puissantes

409
0:18:48.26,000 --> 0:18:51,000
que nous les utiliserons pour mieux nous connaître

410
0:18:51.26,000 --> 0:18:54,000
en déconstruisant et reconstruisant

411
0:18:54.26,000 --> 0:18:57,000
nos propres cerveaux.

412
0:18:57.26,000 --> 0:19:,000
Je suis convaincu que cette aventure, qui nous permet de comprendre qui nous sommes,

413
0:19:00.26,000 --> 0:19:03,000
n'est pas réservée qu'aux scientifiques

414
0:19:03.26,000 --> 0:19:05,000
mais s'offre à chacun de nous.

415
0:19:05.26,000 --> 0:19:08,000
Et je suis reconnaissant d'avoir eu la chance de partager cette aventure avec vous aujourd'hui.

416
0:19:08.26,000 --> 0:19:1,000
Merci.

417
0:19:10.26,000 --> 0:19:18,000
(Applaudissements)

