1
0:00:25,000 --> 0:00:27,000
What I'm going to show you first, as quickly as I can,

2
0:00:27.572,000 --> 0:00:3,000
is some foundational work, some new technology

3
0:00:31.365,000 --> 0:00:33,000
that we brought to Microsoft as part of an acquisition

4
0:00:34,000 --> 0:00:35,000
almost exactly a year ago.

5
0:00:35.845,000 --> 0:00:37,000
This is Seadragon, and it's an environment

6
0:00:38.237,000 --> 0:00:4,000
in which you can either locally or remotely interact

7
0:00:40.737,000 --> 0:00:42,000
with vast amounts of visual data.

8
0:00:43.165,000 --> 0:00:46,000
We're looking at many, many gigabytes of digital photos here

9
0:00:46.593,000 --> 0:00:48,000
and kind of seamlessly and continuously zooming in,

10
0:00:49.532,000 --> 0:00:51,000
panning through it, rearranging it in any way we want.

11
0:00:52.389,000 --> 0:00:55,000
And it doesn't matter how much information we're looking at,

12
0:00:56,000 --> 0:00:58,000
how big these collections are or how big the images are.

13
0:00:59,000 --> 0:01:01,000
Most of them are ordinary digital camera photos,

14
0:01:01.31,000 --> 0:01:04,000
but this one, for example, is a scan from the Library of Congress,

15
0:01:04.478,000 --> 0:01:06,000
and it's in the 300 megapixel range.

16
0:01:07.32,000 --> 0:01:08,000
It doesn't make any difference

17
0:01:09,000 --> 0:01:13,000
because the only thing that ought to limit the performance of a system like this one

18
0:01:13.168,000 --> 0:01:15,000
is the number of pixels on your screen at any given moment.

19
0:01:15.969,000 --> 0:01:16,000
It's also very flexible architecture.

20
0:01:17.963,000 --> 0:01:2,000
This is an entire book, so this is an example of non-image data.

21
0:01:21.714,000 --> 0:01:23,000
This is "Bleak House" by Dickens.

22
0:01:24.525,000 --> 0:01:26,000
Every column is a chapter.

23
0:01:27.333,000 --> 0:01:3,000
To prove to you that it's really text, and not an image,

24
0:01:31,000 --> 0:01:33,000
we can do something like so, to really show

25
0:01:33.072,000 --> 0:01:36,000
that this is a real representation of the text; it's not a picture.

26
0:01:36.288,000 --> 0:01:38,000
Maybe this is an artificial way to read an e-book.

27
0:01:38.976,000 --> 0:01:39,000
I wouldn't recommend it.

28
0:01:40.2,000 --> 0:01:42,000
This is a more realistic case, an issue of The Guardian.

29
0:01:43.072,000 --> 0:01:45,000
Every large image is the beginning of a section.

30
0:01:45.382,000 --> 0:01:47,000
And this really gives you the joy and the good experience

31
0:01:48.31,000 --> 0:01:53,000
of reading the real paper version of a magazine or a newspaper,

32
0:01:53.517,000 --> 0:01:55,000
which is an inherently multi-scale kind of medium.

33
0:01:55.976,000 --> 0:01:56,000
We've done something

34
0:01:57,000 --> 0:01:59,000
with the corner of this particular issue of The Guardian.

35
0:02:,000 --> 0:02:02,000
We've made up a fake ad that's very high resolution --

36
0:02:03,000 --> 0:02:05,000
much higher than in an ordinary ad --

37
0:02:05.222,000 --> 0:02:06,000
and we've embedded extra content.

38
0:02:07,000 --> 0:02:1,000
If you want to see the features of this car, you can see it here.

39
0:02:10.072,000 --> 0:02:14,000
Or other models, or even technical specifications.

40
0:02:14.276,000 --> 0:02:17,000
And this really gets at some of these ideas

41
0:02:17.615,000 --> 0:02:21,000
about really doing away with those limits on screen real estate.

42
0:02:22.3,000 --> 0:02:24,000
We hope that this means no more pop-ups

43
0:02:24.435,000 --> 0:02:26,000
and other rubbish like that -- shouldn't be necessary.

44
0:02:27,000 --> 0:02:29,000
Of course, mapping is one of those obvious applications

45
0:02:29.682,000 --> 0:02:3,000
for a technology like this.

46
0:02:31,000 --> 0:02:33,000
And this one I really won't spend any time on,

47
0:02:33.215,000 --> 0:02:36,000
except to say that we have things to contribute to this field as well.

48
0:02:37.213,000 --> 0:02:38,000
But those are all the roads in the U.S.

49
0:02:39.095,000 --> 0:02:43,000
superimposed on top of a NASA geospatial image.

50
0:02:44,000 --> 0:02:45,000
So let's pull up, now, something else.

51
0:02:46,000 --> 0:02:48,000
This is actually live on the Web now; you can go check it out.

52
0:02:49,000 --> 0:02:52,000
This is a project called Photosynth, which marries two different technologies.

53
0:02:52.728,000 --> 0:02:53,000
One of them is Seadragon

54
0:02:54,000 --> 0:02:56,000
and the other is some very beautiful computer-vision research

55
0:02:56.93,000 --> 0:02:59,000
done by Noah Snavely, a graduate student at the University of Washington,

56
0:03:00.416,000 --> 0:03:01,000
co-advised by Steve Seitz at U.W.

57
0:03:02.269,000 --> 0:03:03,000
and Rick Szeliski at Microsoft Research.

58
0:03:04.271,000 --> 0:03:05,000
A very nice collaboration.

59
0:03:06.412,000 --> 0:03:09,000
And so this is live on the Web. It's powered by Seadragon.

60
0:03:09.544,000 --> 0:03:11,000
You can see that when we do these sorts of views,

61
0:03:12.072,000 --> 0:03:13,000
where we can dive through images

62
0:03:13.819,000 --> 0:03:15,000
and have this kind of multi-resolution experience.

63
0:03:16.177,000 --> 0:03:19,000
But the spatial arrangement of the images here is actually meaningful.

64
0:03:2,000 --> 0:03:23,000
The computer vision algorithms have registered these images together

65
0:03:23.215,000 --> 0:03:26,000
so that they correspond to the real space in which these shots --

66
0:03:27,000 --> 0:03:3,000
all taken near Grassi Lakes in the Canadian Rockies --

67
0:03:30.324,000 --> 0:03:31,000
all these shots were taken.

68
0:03:32.011,000 --> 0:03:33,000
So you see elements here

69
0:03:33.502,000 --> 0:03:39,000
of stabilized slide-show or panoramic imaging,

70
0:03:39.539,000 --> 0:03:41,000
and these things have all been related spatially.

71
0:03:42,000 --> 0:03:45,000
I'm not sure if I have time to show you any other environments.

72
0:03:45.024,000 --> 0:03:46,000
Some are much more spatial.

73
0:03:46.479,000 --> 0:03:49,000
I would like to jump straight to one of Noah's original data-sets --

74
0:03:50.448,000 --> 0:03:53,000
this is from an early prototype that we first got working this summer --

75
0:03:54.024,000 --> 0:03:55,000
to show you what I think

76
0:03:55.942,000 --> 0:03:58,000
is really the punch line behind the Photosynth technology,

77
0:03:59.804,000 --> 0:04:,000
It's not necessarily so apparent

78
0:04:01.389,000 --> 0:04:03,000
from looking at the environments we've put up on the website.

79
0:04:04.308,000 --> 0:04:06,000
We had to worry about the lawyers and so on.

80
0:04:06.509,000 --> 0:04:08,000
This is a reconstruction of Notre Dame Cathedral

81
0:04:08.834,000 --> 0:04:11,000
that was done entirely computationally from images scraped from Flickr.

82
0:04:12.315,000 --> 0:04:14,000
You just type Notre Dame into Flickr,

83
0:04:14.358,000 --> 0:04:17,000
and you get some pictures of guys in T-shirts, and of the campus and so on.

84
0:04:18.236,000 --> 0:04:21,000
And each of these orange cones represents an image

85
0:04:21.406,000 --> 0:04:24,000
that was discovered to belong to this model.

86
0:04:26,000 --> 0:04:27,000
And so these are all Flickr images,

87
0:04:28,000 --> 0:04:3,000
and they've all been related spatially in this way.

88
0:04:31,000 --> 0:04:33,000
We can just navigate in this very simple way.

89
0:04:35,000 --> 0:04:38,000
(Applause)

90
0:04:42.557,000 --> 0:04:43,000
(Applause ends)

91
0:04:43.595,000 --> 0:04:45,000
You know, I never thought that I'd end up working at Microsoft.

92
0:04:46.573,000 --> 0:04:49,000
It's very gratifying to have this kind of reception here.

93
0:04:49.597,000 --> 0:04:52,000
(Laughter)

94
0:04:53,000 --> 0:04:58,000
I guess you can see this is lots of different types of cameras:

95
0:04:58.072,000 --> 0:05:01,000
it's everything from cell-phone cameras to professional SLRs,

96
0:05:01.257,000 --> 0:05:04,000
quite a large number of them, stitched together in this environment.

97
0:05:04.472,000 --> 0:05:06,000
If I can find some of the sort of weird ones --

98
0:05:08,000 --> 0:05:11,000
So many of them are occluded by faces, and so on.

99
0:05:12.595,000 --> 0:05:16,000
Somewhere in here there is actually a series of photographs -- here we go.

100
0:05:16.896,000 --> 0:05:19,000
This is actually a poster of Notre Dame that registered correctly.

101
0:05:20.221,000 --> 0:05:23,000
We can dive in from the poster

102
0:05:23.461,000 --> 0:05:26,000
to a physical view of this environment.

103
0:05:31.421,000 --> 0:05:32,000
What the point here really is

104
0:05:33.311,000 --> 0:05:35,000
is that we can do things with the social environment.

105
0:05:35.926,000 --> 0:05:38,000
This is now taking data from everybody --

106
0:05:38.952,000 --> 0:05:41,000
from the entire collective memory, visually, of what the Earth looks like --

107
0:05:42.847,000 --> 0:05:43,000
and link all of that together.

108
0:05:44.62,000 --> 0:05:46,000
Those photos become linked, and they make something emergent

109
0:05:47.483,000 --> 0:05:48,000
that's greater than the sum of the parts.

110
0:05:49.46,000 --> 0:05:51,000
You have a model that emerges of the entire Earth.

111
0:05:51.84,000 --> 0:05:55,000
Think of this as the long tail to Stephen Lawler's Virtual Earth work.

112
0:05:55.941,000 --> 0:05:58,000
And this is something that grows in complexity as people use it,

113
0:05:59.165,000 --> 0:06:02,000
and whose benefits become greater to the users as they use it.

114
0:06:03,000 --> 0:06:06,000
Their own photos are getting tagged with meta-data that somebody else entered.

115
0:06:06.716,000 --> 0:06:09,000
If somebody bothered to tag all of these saints

116
0:06:10.1,000 --> 0:06:12,000
and say who they all are, then my photo of Notre Dame Cathedral

117
0:06:13.077,000 --> 0:06:15,000
suddenly gets enriched with all of that data,

118
0:06:15.199,000 --> 0:06:17,000
and I can use it as an entry point to dive into that space,

119
0:06:18,000 --> 0:06:2,000
into that meta-verse, using everybody else's photos,

120
0:06:20.705,000 --> 0:06:23,000
and do a kind of a cross-modal

121
0:06:24.03,000 --> 0:06:27,000
and cross-user social experience that way.

122
0:06:27.805,000 --> 0:06:31,000
And of course, a by-product of all of that is immensely rich virtual models

123
0:06:32,000 --> 0:06:33,000
of every interesting part of the Earth,

124
0:06:33.992,000 --> 0:06:37,000
collected not just from overhead flights and from satellite images

125
0:06:38.503,000 --> 0:06:4,000
and so on, but from the collective memory.

126
0:06:40.579,000 --> 0:06:41,000
Thank you so much.

127
0:06:41.697,000 --> 0:06:47,000
(Applause)

128
0:06:51.967,000 --> 0:06:52,000
(Applause ends)

129
0:06:52.992,000 --> 0:06:54,000
Chris Anderson: Do I understand this right?

130
0:06:55.342,000 --> 0:06:57,000
What your software is going to allow,

131
0:06:57.863,000 --> 0:07:,000
is that at some point, really within the next few years,

132
0:07:01.363,000 --> 0:07:05,000
all the pictures that are shared by anyone across the world

133
0:07:05.622,000 --> 0:07:06,000
are going to link together?

134
0:07:07.207,000 --> 0:07:09,000
BAA: Yes. What this is really doing is discovering,

135
0:07:09.618,000 --> 0:07:11,000
creating hyperlinks, if you will, between images.

136
0:07:12,000 --> 0:07:14,000
It's doing that based on the content inside the images.

137
0:07:14.608,000 --> 0:07:17,000
And that gets really exciting when you think about the richness

138
0:07:17.654,000 --> 0:07:19,000
of the semantic information a lot of images have.

139
0:07:19.982,000 --> 0:07:2,000
Like when you do a web search for images,

140
0:07:21.966,000 --> 0:07:22,000
you type in phrases,

141
0:07:23.235,000 --> 0:07:25,000
and the text on the web page is carrying a lot of information

142
0:07:26.159,000 --> 0:07:27,000
about what that picture is of.

143
0:07:27.685,000 --> 0:07:29,000
What if that picture links to all of your pictures?

144
0:07:30.1,000 --> 0:07:32,000
The amount of semantic interconnection and richness

145
0:07:32.537,000 --> 0:07:33,000
that comes out of that is really huge.

146
0:07:34.415,000 --> 0:07:35,000
It's a classic network effect.

147
0:07:35.888,000 --> 0:07:37,000
CA: Truly incredible. Congratulations.

