1
0:00:12.849,000 --> 0:00:15,000
Chris Anderson: I have been long so fascinated and amazed

2
0:00:16.017,000 --> 0:00:17,000
by so many aspects of Netflix.

3
0:00:17.88,000 --> 0:00:19,000
You're full of surprises, if I may say so.

4
0:00:20.595,000 --> 0:00:23,000
One of those surprises happened, I think about six years ago.

5
0:00:24.65,000 --> 0:00:27,000
So, the company back then was doing really well,

6
0:00:28.61,000 --> 0:00:3,000
but you were basically a streaming service

7
0:00:30.693,000 --> 0:00:33,000
for other people's films and TV content.

8
0:00:34.522,000 --> 0:00:36,000
You'd persuaded Wall Street that you were right

9
0:00:36.832,000 --> 0:00:4,000
to make the kind of radical shift away from just sending people DVDs,

10
0:00:40.913,000 --> 0:00:41,000
so you were doing it by streaming.

11
0:00:42.575,000 --> 0:00:43,000
And you were growing like a weed --

12
0:00:44.272,000 --> 0:00:47,000
you had more than six million subscribers and healthy growth rates,

13
0:00:47.496,000 --> 0:00:49,000
and yet, you chose that moment

14
0:00:49.76,000 --> 0:00:54,000
to kind of make a giant -- really, a bet-the-company decision.

15
0:00:55.141,000 --> 0:00:58,000
What was that decision, and what motivated it?

16
0:00:58.466,000 --> 0:01:,000
Reed Hastings: Well, cable networks from all time

17
0:01:01.403,000 --> 0:01:03,000
have started on other people's content

18
0:01:03.546,000 --> 0:01:05,000
and then grown into doing their own originals.

19
0:01:06.379,000 --> 0:01:09,000
So we knew of the general idea for quite a while.

20
0:01:10.545,000 --> 0:01:14,000
And we had actually tried to get into original content back in 2005,

21
0:01:14.855,000 --> 0:01:17,000
when we were on DVD only and buying films at Sundance --

22
0:01:18.482,000 --> 0:01:2,000
Maggie Gyllenhaal, "Sherrybaby," we published on DVD --

23
0:01:21.342,000 --> 0:01:22,000
we were a mini studio.

24
0:01:22.831,000 --> 0:01:24,000
And it didn't work out, because we were subscale.

25
0:01:25.514,000 --> 0:01:28,000
And then, as you said, in 2011,

26
0:01:28.711,000 --> 0:01:32,000
Ted Sarandos, my partner at Netflix who runs content,

27
0:01:32.998,000 --> 0:01:34,000
got very excited about "House of Cards."

28
0:01:35.038,000 --> 0:01:37,000
And at that time, it was 100 million dollars,

29
0:01:37.982,000 --> 0:01:4,000
it was a fantastic investment,

30
0:01:41.839,000 --> 0:01:43,000
and it was in competition with HBO.

31
0:01:44.244,000 --> 0:01:47,000
And that was really the breakthrough, that he picked right upfront.

32
0:01:47.458,000 --> 0:01:5,000
CA: But that was a significant percentage of the revenue of the company

33
0:01:50.911,000 --> 0:01:51,000
at that time.

34
0:01:52.958,000 --> 0:01:56,000
But how could you get confident that that was actually worth doing?

35
0:01:56.99,000 --> 0:01:57,000
If you got that wrong,

36
0:01:58.181,000 --> 0:02:,000
it might have been really devastating for the company.

37
0:02:00.966,000 --> 0:02:03,000
RH: Yeah, we weren't confident. I mean, that's the whole tension of it.

38
0:02:04.704,000 --> 0:02:06,000
We were like, "Holy ...!" -- I can't say that.

39
0:02:08.775,000 --> 0:02:09,000
Yeah, it was scary.

40
0:02:10.891,000 --> 0:02:12,000
(Laughter)

41
0:02:13.098,000 --> 0:02:16,000
CA: And with that, it wasn't just producing new content.

42
0:02:17.098,000 --> 0:02:19,000
You also, pretty much with that, if I understand right,

43
0:02:19.735,000 --> 0:02:21,000
introduced this idea of binge-viewing.

44
0:02:21.783,000 --> 0:02:24,000
It wasn't, "We're going to do these episodes and build excitement" --

45
0:02:25.066,000 --> 0:02:26,000
boom! -- all at one time.

46
0:02:27.45,000 --> 0:02:29,000
And that consumer mode hadn't really been tested.

47
0:02:29.77,000 --> 0:02:3,000
Why did you risk that?

48
0:02:31.6,000 --> 0:02:33,000
RH: Well, you know, we had grown up shipping DVDs.

49
0:02:34.008,000 --> 0:02:36,000
And then there were series, box sets, on DVD.

50
0:02:36.522,000 --> 0:02:41,000
And all of us had that experience watching some of the great HBO content

51
0:02:41.559,000 --> 0:02:44,000
you know, with the DVD -- next episode, next episode.

52
0:02:44.878,000 --> 0:02:46,000
And so that was the trigger to make us think,

53
0:02:47.168,000 --> 0:02:5,000
wow, you know, with episodic content, especially serialized,

54
0:02:51.101,000 --> 0:02:54,000
it's so powerful to have all the episodes at once.

55
0:02:54.313,000 --> 0:02:56,000
And it's something that linear TV can't do.

56
0:02:57.1,000 --> 0:02:59,000
And so both of those made it really positive.

57
0:03:01.179,000 --> 0:03:04,000
CA: And so, did it work out on the math pretty much straight away,

58
0:03:04.958,000 --> 0:03:07,000
that an hour spent watching "House of Cards," say,

59
0:03:08.692,000 --> 0:03:09,000
was more profitable to you

60
0:03:10.689,000 --> 0:03:13,000
than an hour spent watching someone else's licensed content?

61
0:03:14.879,000 --> 0:03:18,000
RH: You know, because we're subscription, we don't have to track it at that level.

62
0:03:19.235,000 --> 0:03:21,000
And so it's really about making the brand stronger,

63
0:03:21.895,000 --> 0:03:22,000
so that more people want to join.

64
0:03:23.767,000 --> 0:03:24,000
And "House of Cards" absolutely did that,

65
0:03:25.753,000 --> 0:03:27,000
because then many people would talk about it

66
0:03:28.061,000 --> 0:03:3,000
and associate that brand with us,

67
0:03:30.728,000 --> 0:03:33,000
whereas "Mad Men" we carried -- great show, AMC show --

68
0:03:34.212,000 --> 0:03:36,000
but they didn't associate it with Netflix,

69
0:03:36.252,000 --> 0:03:37,000
even if they watched it on Netflix.

70
0:03:38.061,000 --> 0:03:41,000
CA: And so you added all these other remarkable series,

71
0:03:42.593,000 --> 0:03:46,000
"Narcos," "Jessica Jones," "Orange is the New Black," "The Crown,"

72
0:03:47.196,000 --> 0:03:5,000
"Black Mirror" -- personal favorite --

73
0:03:50.268,000 --> 0:03:51,000
"Stranger Things" and so on.

74
0:03:51.657,000 --> 0:03:53,000
And so, this coming year,

75
0:03:54.008,000 --> 0:03:57,000
the level of investment you're planning to make in new content

76
0:03:57.498,000 --> 0:03:58,000
is not 100 million.

77
0:03:59.027,000 --> 0:04:,000
It's what?

78
0:04:00.307,000 --> 0:04:02,000
RH: It's about eight billion dollars around the world.

79
0:04:03.966,000 --> 0:04:05,000
And it's not enough.

80
0:04:06.855,000 --> 0:04:09,000
There are so many great shows on other networks.

81
0:04:10.192,000 --> 0:04:11,000
And so we have a long way to go.

82
0:04:12.149,000 --> 0:04:14,000
CA: But eight billion --

83
0:04:14.76,000 --> 0:04:18,000
that's pretty much higher than any other content commissioner at this point?

84
0:04:19.649,000 --> 0:04:2,000
RH: No, Disney is in that realm,

85
0:04:21.427,000 --> 0:04:24,000
and if they're able to acquire Fox, they're even bigger.

86
0:04:26.299,000 --> 0:04:29,000
And then, really, that's spread globally,

87
0:04:29.442,000 --> 0:04:31,000
so it's not as much as it sounds.

88
0:04:32.56,000 --> 0:04:34,000
(Laughter)

89
0:04:34.879,000 --> 0:04:37,000
CA: But clearly, from the Barry Dillers and others in the media business,

90
0:04:38.324,000 --> 0:04:39,000
it feels like from nowhere,

91
0:04:40.131,000 --> 0:04:43,000
this company has come and has really revolutionized the business.

92
0:04:43.254,000 --> 0:04:45,000
It's like, as if Blockbuster one day said,

93
0:04:45.593,000 --> 0:04:47,000
"We're going to make Blockbuster videos,"

94
0:04:47.696,000 --> 0:04:5,000
and then, six years later, was as big as Disney.

95
0:04:51.275,000 --> 0:04:55,000
I mean, that story would never have happened, and yet it did.

96
0:04:55.855,000 --> 0:04:58,000
RH: That's the bitch about the internet -- it moves fast, you know?

97
0:05:00.037,000 --> 0:05:02,000
Everything around us moves really quick.

98
0:05:02.474,000 --> 0:05:06,000
CA: I mean, there must be something unusual about Netflix's culture

99
0:05:07.231,000 --> 0:05:12,000
that allowed you to take such bold -- I won't say "reckless" --

100
0:05:12.532,000 --> 0:05:13,000
bold, well thought-through decisions.

101
0:05:14.474,000 --> 0:05:15,000
RH: Yeah, absolutely.

102
0:05:15.673,000 --> 0:05:17,000
We did have one advantage, which is we were born on DVD,

103
0:05:18.411,000 --> 0:05:2,000
and we knew that that was going to be temporary.

104
0:05:20.68,000 --> 0:05:22,000
No one thought we'd be mailing discs for 100 years.

105
0:05:23.109,000 --> 0:05:26,000
So then you have a lot of paranoia about what's coming next,

106
0:05:26.768,000 --> 0:05:28,000
and that's part of the founding ethos,

107
0:05:29.585,000 --> 0:05:31,000
is really worrying about what's coming next.

108
0:05:32.561,000 --> 0:05:33,000
So that's an advantage.

109
0:05:33.736,000 --> 0:05:34,000
And then in terms of the culture,

110
0:05:35.357,000 --> 0:05:37,000
it's very big on freedom and responsibility.

111
0:05:37.476,000 --> 0:05:4,000
I pride myself on making as few decisions as possible in a quarter.

112
0:05:41.717,000 --> 0:05:43,000
And we're getting better and better at that.

113
0:05:43.933,000 --> 0:05:45,000
There are some times I can go a whole quarter

114
0:05:46.073,000 --> 0:05:47,000
without making any decisions.

115
0:05:47.851,000 --> 0:05:48,000
(Laughter)

116
0:05:49.131,000 --> 0:05:51,000
(Applause)

117
0:05:51.973,000 --> 0:05:54,000
CA: But there are some really surprising things about your people.

118
0:05:55.617,000 --> 0:05:57,000
For example, I looked at one survey.

119
0:05:58.315,000 --> 0:06:02,000
It looks like Netflix employees, compared to your peers',

120
0:06:02.957,000 --> 0:06:04,000
are basically the highest paid for equivalent jobs.

121
0:06:05.626,000 --> 0:06:07,000
And the least likely to want to leave.

122
0:06:08.863,000 --> 0:06:13,000
And if you Google the Netflix culture deck,

123
0:06:14.117,000 --> 0:06:18,000
you see this list of quite surprising admonitions to your employees.

124
0:06:18.625,000 --> 0:06:19,000
Talk about a few of them.

125
0:06:20.665,000 --> 0:06:24,000
RH: Well, you know, my first company -- we were very process obsessed.

126
0:06:24.845,000 --> 0:06:25,000
This was in the 1990s.

127
0:06:26.51,000 --> 0:06:27,000
And every time someone made a mistake,

128
0:06:28.44,000 --> 0:06:29,000
we tried to put a process in place

129
0:06:30.108,000 --> 0:06:32,000
to make sure that mistake didn't happen again --

130
0:06:32.466,000 --> 0:06:35,000
so, very semiconductor-yield orientation.

131
0:06:36.173,000 --> 0:06:39,000
And the problem is, we were trying to dummy-proof the system.

132
0:06:39.26,000 --> 0:06:41,000
And then, eventually, only dummies wanted to work there.

133
0:06:43.404,000 --> 0:06:47,000
Then, of course, the market shifted -- in that case, it was C++ to Java.

134
0:06:47.442,000 --> 0:06:48,000
But you know, there's always some shift.

135
0:06:49.394,000 --> 0:06:5,000
And the company was unable to adapt,

136
0:06:51.395,000 --> 0:06:53,000
and it got acquired by our largest competitor.

137
0:06:54.561,000 --> 0:06:59,000
And so with Netflix, I was super focused on how to run with no process

138
0:07:00.093,000 --> 0:07:01,000
but not have chaos.

139
0:07:01.862,000 --> 0:07:03,000
And so then we've developed all these mechanisms,

140
0:07:04.3,000 --> 0:07:07,000
super high-talented people, alignment,

141
0:07:07.49,000 --> 0:07:09,000
talking openly, sharing information --

142
0:07:09.855,000 --> 0:07:11,000
internally, people are stunned at how much information --

143
0:07:12.649,000 --> 0:07:14,000
all the core strategies, etc.

144
0:07:14.752,000 --> 0:07:17,000
We're like the "anti-Apple" -- you know how they compartmentalize?

145
0:07:17.934,000 --> 0:07:2,000
We do the opposite, which is: everybody gets all the information.

146
0:07:21.704,000 --> 0:07:24,000
So what we're trying to do is build a sense of responsibility in people

147
0:07:25.322,000 --> 0:07:26,000
and the ability to do things.

148
0:07:26.998,000 --> 0:07:29,000
I find out about big decisions now that are made all the time,

149
0:07:30.276,000 --> 0:07:32,000
I've never even heard about it, which is great.

150
0:07:32.692,000 --> 0:07:33,000
And mostly, they go well.

151
0:07:35.166,000 --> 0:07:37,000
CA: So you just wake up and read them on the internet.

152
0:07:37.736,000 --> 0:07:38,000
RH: Sometimes.

153
0:07:38.912,000 --> 0:07:39,000
CA: "Oh, we just entered China!"

154
0:07:40.577,000 --> 0:07:41,000
RH: Yeah, well that would be a big one.

155
0:07:43.354,000 --> 0:07:48,000
CA: But you allow employees to set their own vacation time, and ...

156
0:07:48.777,000 --> 0:07:49,000
There's just --

157
0:07:50.504,000 --> 0:07:52,000
RH: Sure, that's a big symbolic one, vacation,

158
0:07:53.512,000 --> 0:07:56,000
because most people, in practice, do that, anyway.

159
0:07:56.934,000 --> 0:07:59,000
But yeah, there's a whole lot of that freedom.

160
0:08:01.736,000 --> 0:08:05,000
CA: And courage, you ask for as a fundamental value.

161
0:08:07.04,000 --> 0:08:09,000
RH: Yeah, we want people to speak the truth.

162
0:08:09.31,000 --> 0:08:12,000
And we say, "To disagree silently is disloyal."

163
0:08:13.896,000 --> 0:08:17,000
It's not OK to let some decision go through without saying your piece,

164
0:08:18.793,000 --> 0:08:19,000
and typically, writing it down.

165
0:08:20.531,000 --> 0:08:23,000
And so we're very focused on trying to get to good decisions

166
0:08:23.762,000 --> 0:08:26,000
through the debate that always happens.

167
0:08:27.052,000 --> 0:08:3,000
And we try not to make it intense, like yelling at each other --

168
0:08:30.277,000 --> 0:08:31,000
nothing like that.

169
0:08:31.472,000 --> 0:08:33,000
You know, it's really curiosity drawing people out.

170
0:08:35.252,000 --> 0:08:37,000
CA: You've got this other secret weapon at Netflix, it seems,

171
0:08:38.213,000 --> 0:08:4,000
which is this vast trove of data,

172
0:08:40.66,000 --> 0:08:42,000
a word we've heard a certain amount about this week.

173
0:08:43.561,000 --> 0:08:47,000
You've often taken really surprising stances

174
0:08:47.59,000 --> 0:08:49,000
towards building smart algorithms at Netflix.

175
0:08:50.284,000 --> 0:08:53,000
Back in the day, you opened up your algorithm to the world

176
0:08:54.248,000 --> 0:08:57,000
and said, "Hey, can anyone do better than this recommendation we've got?

177
0:08:57.692,000 --> 0:08:58,000
If so, we'll pay you a million dollars."

178
0:08:59.63,000 --> 0:09:,000
You paid someone a million dollars,

179
0:09:01.341,000 --> 0:09:03,000
because it was like 10 percent better than yours.

180
0:09:03.669,000 --> 0:09:04,000
RH: That's right.

181
0:09:04.844,000 --> 0:09:06,000
CA: Was that a good decision? Would you do that again?

182
0:09:07.401,000 --> 0:09:1,000
RH: Yeah, it was super exciting at the time; this was about 2007.

183
0:09:10.545,000 --> 0:09:11,000
But you know, we haven't done it again.

184
0:09:12.561,000 --> 0:09:14,000
So clearly, it's a very specialized tool.

185
0:09:15.728,000 --> 0:09:18,000
And so think of that as a lucky break of good timing,

186
0:09:19.053,000 --> 0:09:2,000
rather than a general framework.

187
0:09:21.903,000 --> 0:09:25,000
So what we've done is invest a lot on the algorithms,

188
0:09:26.411,000 --> 0:09:28,000
so that we feature the right content to the right people

189
0:09:29.269,000 --> 0:09:31,000
and try to make it fun and easy to explore.

190
0:09:32.33,000 --> 0:09:35,000
CA: And you made this, what seems like a really interesting shift,

191
0:09:35.691,000 --> 0:09:36,000
a few years ago.

192
0:09:36.87,000 --> 0:09:4,000
You used to ask people, "Here are 10 movies. What do you think?

193
0:09:41.824,000 --> 0:09:43,000
Which ones of these are your best movies?"

194
0:09:44.823,000 --> 0:09:48,000
And then tried to match those movies with recommendations for what was coming.

195
0:09:49.68,000 --> 0:09:51,000
And then you changed away from that.

196
0:09:51.831,000 --> 0:09:52,000
Talk about that.

197
0:09:53.006,000 --> 0:09:54,000
RH: Sure.

198
0:09:54.18,000 --> 0:09:56,000
Everyone would rate "Schindler's List" five stars,

199
0:09:56.652,000 --> 0:10:,000
and then they'd rate Adam Sandler, "The Do-Over" three stars.

200
0:10:01.204,000 --> 0:10:03,000
But, in fact, when you looked at what they watched,

201
0:10:03.623,000 --> 0:10:05,000
it was almost always Adam Sandler.

202
0:10:06.157,000 --> 0:10:1,000
And so what happens is, when we rate and we're metacognitive about quality,

203
0:10:11.007,000 --> 0:10:13,000
that's sort of our aspirational self.

204
0:10:14.133,000 --> 0:10:16,000
And it works out much better to please people

205
0:10:16.506,000 --> 0:10:18,000
to look at the actual choices that they make,

206
0:10:18.982,000 --> 0:10:22,000
their revealed preferences by how much they enjoy simple pleasures.

207
0:10:24.493,000 --> 0:10:26,000
CA: OK, I want to talk for a couple of minutes about this,

208
0:10:27.291,000 --> 0:10:29,000
because this strikes me as a huge deal, not just for Netflix,

209
0:10:30.208,000 --> 0:10:31,000
for the internet as a whole.

210
0:10:31.609,000 --> 0:10:33,000
The difference between aspirational values

211
0:10:34.347,000 --> 0:10:36,000
and revealed values.

212
0:10:36.632,000 --> 0:10:39,000
You, brilliantly, didn't pay too much attention to what people said,

213
0:10:40.161,000 --> 0:10:43,000
you watched what they did, and then found the stuff that,

214
0:10:43.609,000 --> 0:10:47,000
"Oh my God, I never knew I would like a show about making horrible recipes,

215
0:10:48.226,000 --> 0:10:49,000
called 'Nailed It!'"

216
0:10:49.657,000 --> 0:10:5,000
RH: Called "Nailed It!" Right.

217
0:10:51.162,000 --> 0:10:53,000
CA: It's hilarious. I would never have even thought of that.

218
0:10:54.085,000 --> 0:10:55,000
But aren't there risks with this,

219
0:10:55.728,000 --> 0:11:,000
if this go-only-with-revealed-values approach is taken too far?

220
0:11:01.434,000 --> 0:11:04,000
RH: Well, we get a lot of joy from making people happy,

221
0:11:04.482,000 --> 0:11:07,000
Sometimes you just want to relax and watch a show like "Nailed It!"

222
0:11:08.736,000 --> 0:11:1,000
And it's fun, and it's not stressful.

223
0:11:11.28,000 --> 0:11:14,000
Other times, people want to watch very intensive film.

224
0:11:14.466,000 --> 0:11:16,000
"Mudbound" was Oscar-nominated,

225
0:11:17.369,000 --> 0:11:19,000
it's a great, very intensive film.

226
0:11:19.522,000 --> 0:11:23,000
And you know, we've had over 20 million hours of viewing on "Mudbound,"

227
0:11:24.289,000 --> 0:11:27,000
which is dramatically bigger than it would have been in the theaters

228
0:11:27.569,000 --> 0:11:28,000
or any other distribution.

229
0:11:28.839,000 --> 0:11:32,000
And so, we have some candy, too, but we have lots of broccoli.

230
0:11:33.236,000 --> 0:11:37,000
And you know, if you have the good mix, you get to a healthy diet.

231
0:11:37.882,000 --> 0:11:38,000
CA: But -- yes, indeed.

232
0:11:39.53,000 --> 0:11:44,000
But isn't it the case that algorithms tend to point you away from the broccoli

233
0:11:44.643,000 --> 0:11:45,000
and towards the candy,

234
0:11:45.818,000 --> 0:11:46,000
if you're not careful?

235
0:11:46.993,000 --> 0:11:48,000
We just had a talk about how, on YouTube, somehow algorithms

236
0:11:49.871,000 --> 0:11:52,000
tend to, just by actually being smarter,

237
0:11:53.403,000 --> 0:11:57,000
tend to drive people towards more radical or specific content.

238
0:11:57.665,000 --> 0:12:,000
It'd be easy to imagine that Netflix algorithms,

239
0:12:00.839,000 --> 0:12:03,000
just going on revealed values, would gradually --

240
0:12:04.807,000 --> 0:12:05,000
RH: Right, get too base --

241
0:12:06.427,000 --> 0:12:09,000
CA: We'd all be watching violent pornography or something.

242
0:12:09.776,000 --> 0:12:1,000
Or some people would, you know.

243
0:12:11.393,000 --> 0:12:12,000
But, how --

244
0:12:12.569,000 --> 0:12:14,000
(Laughter)

245
0:12:14.903,000 --> 0:12:15,000
Not me!

246
0:12:16.728,000 --> 0:12:19,000
I'm the child of a missionary, I don't even think about these things.

247
0:12:20.006,000 --> 0:12:21,000
But --

248
0:12:21.188,000 --> 0:12:22,000
(Laughter)

249
0:12:22.45,000 --> 0:12:23,000
But I mean, it's possible, right?

250
0:12:25.037,000 --> 0:12:28,000
RH: In practice, you're right that you can't just rely on algorithms.

251
0:12:28.38,000 --> 0:12:3,000
It's a mix of judgment and what we carry,

252
0:12:30.53,000 --> 0:12:31,000
and we're a curated service

253
0:12:31.911,000 --> 0:12:33,000
versus a platform like Facebook and YouTube,

254
0:12:34.228,000 --> 0:12:37,000
so we have an easier set of issues,

255
0:12:37.441,000 --> 0:12:41,000
which is: What are these great films and series that we acquire?

256
0:12:42.379,000 --> 0:12:44,000
But then within that, the algorithm is a tool.

257
0:12:45.958,000 --> 0:12:49,000
CA: But how -- John Doerr just talked about measuring what matters.

258
0:12:51.148,000 --> 0:12:53,000
As a business, what matters, I presume,

259
0:12:53.754,000 --> 0:12:55,000
is fundamentally just growing subscribers.

260
0:12:56.399,000 --> 0:13:,000
I mean, that's your unique advantage.

261
0:13:00.522,000 --> 0:13:06,000
Are subscribers grown only by the more time they spend watching Netflix,

262
0:13:07.522,000 --> 0:13:08,000
that is what will make them re-subscribe?

263
0:13:09.506,000 --> 0:13:13,000
Or is it even more about having shows

264
0:13:14.259,000 --> 0:13:15,000
that might not have been so much time

265
0:13:16.261,000 --> 0:13:18,000
as watching the whole season of "Nailed It!" or whatever?

266
0:13:18.973,000 --> 0:13:2,000
But just get into them more; they just think,

267
0:13:21.168,000 --> 0:13:23,000
"That was nourishing, that was extraordinary,

268
0:13:23.815,000 --> 0:13:25,000
I'm so glad I watched that with my family."

269
0:13:26.053,000 --> 0:13:28,000
Isn't there a version of the business model

270
0:13:28.911,000 --> 0:13:3,000
that would be less content but more awesome content,

271
0:13:31.498,000 --> 0:13:33,000
possibly even more uplifting content?

272
0:13:34.625,000 --> 0:13:36,000
RH: And people choose that uplifting content.

273
0:13:36.761,000 --> 0:13:39,000
I think you're right, which is, when people talk about Netflix,

274
0:13:39.807,000 --> 0:13:41,000
they talk about the shows that move them:

275
0:13:41.839,000 --> 0:13:43,000
"13 Reasons Why" or "The Crown."

276
0:13:44.672,000 --> 0:13:47,000
And that is way disproportionate and positive impact,

277
0:13:48.18,000 --> 0:13:5,000
even for the subscriber growth that you talked about

278
0:13:50.688,000 --> 0:13:52,000
is those couple big, memorable shows.

279
0:13:53.029,000 --> 0:13:55,000
But what we want to do is offer a variety.

280
0:13:55.116,000 --> 0:13:58,000
You don't want to watch the same thing every night, as much as you like it;

281
0:13:58.669,000 --> 0:13:59,000
you want to try different things.

282
0:14:00.347,000 --> 0:14:02,000
And what we haven't seen is this, say,

283
0:14:02.505,000 --> 0:14:05,000
race to the bottom of your violent pornography kind of examples.

284
0:14:06.474,000 --> 0:14:08,000
Instead, we've seen great viewing across a whole range --

285
0:14:09.467,000 --> 0:14:12,000
"Black Mirror" -- we're filming season five now.

286
0:14:13.649,000 --> 0:14:16,000
And that was a struggling show when it was only in the BBC.

287
0:14:17.427,000 --> 0:14:19,000
And with the distribution of on-demand,

288
0:14:19.854,000 --> 0:14:22,000
you can make these much bigger shows.

289
0:14:23.442,000 --> 0:14:25,000
CA: You're telling me humans can get addicted

290
0:14:25.609,000 --> 0:14:27,000
by their angels as well as their demons.

291
0:14:28.481,000 --> 0:14:31,000
RH: Yeah, and again, we try not to think about it in addiction terms,

292
0:14:32.077,000 --> 0:14:33,000
we think about it as, you know:

293
0:14:33.672,000 --> 0:14:37,000
What are you going to do with your time and when you want to relax?

294
0:14:37.72,000 --> 0:14:4,000
You can watch linear TV, you can do video games, you can do YouTube,

295
0:14:41.625,000 --> 0:14:42,000
or you can watch Netflix.

296
0:14:43.006,000 --> 0:14:47,000
And if we're as great as we can be, and we have a variety of moods,

297
0:14:47.188,000 --> 0:14:49,000
then more often, people will choose us.

298
0:14:49.434,000 --> 0:14:52,000
CA: But you have people in the organization

299
0:14:52.996,000 --> 0:14:57,000
who are looking regularly at the actual impacts

300
0:14:58.361,000 --> 0:15:,000
of these brilliant algorithms that you've created.

301
0:15:00.776,000 --> 0:15:01,000
Just for reality check, just,

302
0:15:02.311,000 --> 0:15:04,000
"Are we sure that this is the direction we want to go?"

303
0:15:05.951,000 --> 0:15:06,000
RH: You know, I think we learn.

304
0:15:07.532,000 --> 0:15:1,000
And you have to be humble and sort of say, "Look, there's no perfect tool."

305
0:15:11.356,000 --> 0:15:14,000
The algorithm’s one part, the way we commission the content,

306
0:15:15.165,000 --> 0:15:17,000
our relationships with societies.

307
0:15:17.934,000 --> 0:15:19,000
So there's a lot of ways that we have to look at it.

308
0:15:20.441,000 --> 0:15:23,000
So if you get too stuck in "Let's just increase viewing"

309
0:15:23.989,000 --> 0:15:24,000
or "Just increase subscribers,"

310
0:15:25.503,000 --> 0:15:29,000
you're unlikely to be able to grow and be the great company you want to be.

311
0:15:30.014,000 --> 0:15:32,000
So think of it as this multiple measures of success.

312
0:15:33.196,000 --> 0:15:36,000
CA: So, speaking of algorithms that have raised questions:

313
0:15:36.331,000 --> 0:15:37,000
You were on the board of Facebook,

314
0:15:38.26,000 --> 0:15:42,000
and I think Mark Zuckerberg -- you've done some mentoring for him.

315
0:15:42.95,000 --> 0:15:47,000
What should we know about Mark Zuckerberg that people don't know?

316
0:15:49.268,000 --> 0:15:51,000
RH: Well, many of you know him or have seen him.

317
0:15:51.639,000 --> 0:15:53,000
I mean, he's a fantastic human being.

318
0:15:54.077,000 --> 0:15:55,000
Really first-class.

319
0:15:56.323,000 --> 0:16:01,000
And social -- these platforms, whether that's YouTube or Facebook,

320
0:16:01.688,000 --> 0:16:03,000
are clearly trying to grow up quickly.

321
0:16:04.641,000 --> 0:16:06,000
And we see that with all new technologies.

322
0:16:06.815,000 --> 0:16:08,000
I mean, yesterday we were talking about printed DNA,

323
0:16:09.792,000 --> 0:16:12,000
and it's like: could be fantastic or could be horrific.

324
0:16:14.315,000 --> 0:16:16,000
And you know, all new technologies --

325
0:16:16.355,000 --> 0:16:19,000
when television was first popular in the 1960s in the US,

326
0:16:19.506,000 --> 0:16:21,000
it was called a "vast wasteland,"

327
0:16:21.625,000 --> 0:16:24,000
and that television was going to rot the minds of everybody.

328
0:16:24.911,000 --> 0:16:26,000
It turns out everybody's minds were fine.

329
0:16:27.284,000 --> 0:16:29,000
And there were some adjustments,

330
0:16:29.387,000 --> 0:16:31,000
but think of it as -- or, I think of it as --

331
0:16:31.913,000 --> 0:16:33,000
all new technologies have pros and cons.

332
0:16:34.67,000 --> 0:16:36,000
And in social, we're just figuring that out.

333
0:16:37.146,000 --> 0:16:39,000
CA: How much of a priority is it for the board of Facebook

334
0:16:40.069,000 --> 0:16:42,000
to really address some of the issues?

335
0:16:42.363,000 --> 0:16:43,000
Or is the belief that, actually,

336
0:16:43.962,000 --> 0:16:46,000
the company has been completely unfairly criticized?

337
0:16:47.236,000 --> 0:16:48,000
RH: Oh, it's not completely unfairly.

338
0:16:49.054,000 --> 0:16:52,000
And Mark's leading the charge on fixing Facebook.

339
0:16:52.474,000 --> 0:16:54,000
And he's very passionate about that.

340
0:16:56.839,000 --> 0:16:58,000
CA: Reed, I want to look at another passion of yours.

341
0:16:59.474,000 --> 0:17:03,000
I mean, you've done incredibly well with Netflix, you're a billionaire,

342
0:17:04.156,000 --> 0:17:09,000
and you spend a lot of time and indeed, money, on education.

343
0:17:09.291,000 --> 0:17:1,000
RH: Yep.

344
0:17:10.466,000 --> 0:17:12,000
CA: Why is this a passion, and what are you doing about it?

345
0:17:13.331,000 --> 0:17:16,000
RH: Sure. Right out of college, I was a high school math teacher.

346
0:17:16.641,000 --> 0:17:19,000
So when I later went into business and became a philanthropist,

347
0:17:20.585,000 --> 0:17:22,000
I think I gravitated towards education

348
0:17:23.871,000 --> 0:17:25,000
and trying to make a difference there.

349
0:17:26.101,000 --> 0:17:28,000
And the main thing I noticed is, you know,

350
0:17:28.413,000 --> 0:17:3,000
educators want to work with other great educators

351
0:17:31.22,000 --> 0:17:34,000
and to create many unique environments for kids.

352
0:17:34.458,000 --> 0:17:36,000
And we need a lot more variety in the system

353
0:17:37.222,000 --> 0:17:38,000
than we have,

354
0:17:38.397,000 --> 0:17:41,000
and a lot more educator-centric organizations.

355
0:17:41.658,000 --> 0:17:43,000
And so the tricky thing is, right now in the US,

356
0:17:44.252,000 --> 0:17:47,000
most schools are run by a local school board.

357
0:17:48.141,000 --> 0:17:51,000
And it has to meet all needs in the community,

358
0:17:51.188,000 --> 0:17:53,000
and, in fact, what we need is a lot more variety.

359
0:17:53.887,000 --> 0:17:55,000
So in the US there's a form of public school

360
0:17:56.861,000 --> 0:17:58,000
called charter public schools, that are run by nonprofits.

361
0:17:59.884,000 --> 0:18:,000
And that's the big emphasis for me,

362
0:18:01.728,000 --> 0:18:03,000
is if you can have schools run by nonprofits,

363
0:18:04.391,000 --> 0:18:07,000
they are more mission-focused, they support the educators well.

364
0:18:08.292,000 --> 0:18:1,000
I'm on the board of KIPP charter schools,

365
0:18:10.539,000 --> 0:18:11,000
which is one of the larger networks.

366
0:18:12.522,000 --> 0:18:17,000
And, you know, it's 30,000 kids a year getting very stimulating education.

367
0:18:17.649,000 --> 0:18:2,000
CA: Paint me a picture of what a school should look like.

368
0:18:22.029,000 --> 0:18:23,000
RH: It depends on the kid.

369
0:18:23.295,000 --> 0:18:26,000
Think about it as: with multiple kids, there's all different needs

370
0:18:26.424,000 --> 0:18:27,000
that need to be met,

371
0:18:27.599,000 --> 0:18:28,000
so there's not any one model.

372
0:18:29.011,000 --> 0:18:3,000
And you want to be able to choose,

373
0:18:30.67,000 --> 0:18:32,000
depending on your kid and what you think they need.

374
0:18:33.091,000 --> 0:18:36,000
But they should be very educator-centric and curious and stimulating

375
0:18:36.823,000 --> 0:18:37,000
and all of those things.

376
0:18:38.149,000 --> 0:18:4,000
And this whole idea of 30 kids in fifth grade,

377
0:18:40.889,000 --> 0:18:42,000
all learning the same thing at the same time,

378
0:18:43.355,000 --> 0:18:45,000
you know, is clearly an industrial throwback.

379
0:18:46.489,000 --> 0:18:49,000
But changing that, given the current government structure,

380
0:18:50.173,000 --> 0:18:51,000
is super hard.

381
0:18:51.363,000 --> 0:18:56,000
But what these innovative, nonprofit schools are doing is pushing the bounds,

382
0:18:56.624,000 --> 0:18:58,000
letting kids try new things.

383
0:18:59.553,000 --> 0:19:02,000
And so think of it as the governance reform,

384
0:19:03.133,000 --> 0:19:04,000
that is, the nonprofit,

385
0:19:04.49,000 --> 0:19:06,000
to allow the educational changes.

386
0:19:07.718,000 --> 0:19:11,000
CA: And sometimes the criticism is put that charter schools,

387
0:19:12.419,000 --> 0:19:13,000
intentionally or unintentionally,

388
0:19:14.032,000 --> 0:19:16,000
suck resources away from the public school system.

389
0:19:16.625,000 --> 0:19:18,000
Should we be concerned about that?

390
0:19:18.705,000 --> 0:19:19,000
RH: Well, they are public schools.

391
0:19:20.451,000 --> 0:19:22,000
I mean, there's these multiple types of public schools.

392
0:19:23.76,000 --> 0:19:25,000
And if you look at charters as a whole,

393
0:19:26.189,000 --> 0:19:27,000
they serve low-income kids.

394
0:19:28.442,000 --> 0:19:3,000
Because if high-income kids get in trouble,

395
0:19:30.641,000 --> 0:19:32,000
the parents will send them to a private school

396
0:19:32.832,000 --> 0:19:33,000
or they move neighborhoods.

397
0:19:34.259,000 --> 0:19:36,000
And low-income families generally don't have those choices.

398
0:19:37.517,000 --> 0:19:41,000
Like KIPP -- it's 80 percent low-income kids, free and reduced lunch.

399
0:19:42.141,000 --> 0:19:44,000
And the college admissions for KIPP is fantastic.

400
0:19:45.53,000 --> 0:19:47,000
CA: Reed, you signed the Giving Pledge a few years ago,

401
0:19:48.376,000 --> 0:19:5,000
you're committed to giving away more than half of your fortune

402
0:19:51.356,000 --> 0:19:52,000
during your lifetime.

403
0:19:52.76,000 --> 0:19:55,000
Can I cheekily ask how much you've invested in education

404
0:19:55.862,000 --> 0:19:56,000
in the last few years?

405
0:19:57.116,000 --> 0:20:,000
RH: It's a couple hundred million, I don't know exactly how many hundreds,

406
0:20:00.701,000 --> 0:20:02,000
but we're continuing to invest and --

407
0:20:02.921,000 --> 0:20:03,000
(Applause)

408
0:20:04.096,000 --> 0:20:05,000
thank you all --

409
0:20:05.27,000 --> 0:20:06,000
(Applause)

410
0:20:06.704,000 --> 0:20:1,000
You know, honestly, for a little while I tried to do politics full-time,

411
0:20:11.554,000 --> 0:20:12,000
working for John Doerr.

412
0:20:13.462,000 --> 0:20:16,000
And while I loved working for John, I just didn't thrive on politics.

413
0:20:17.446,000 --> 0:20:19,000
I love business, I love competing.

414
0:20:19.839,000 --> 0:20:21,000
I love going up against Disney and HBO.

415
0:20:22.663,000 --> 0:20:23,000
(Laughter)

416
0:20:23.736,000 --> 0:20:24,000
That's what gets me going.

417
0:20:25.02,000 --> 0:20:28,000
And now I do that to really increase Netflix's value,

418
0:20:28.729,000 --> 0:20:3,000
which allows me to write more checks to schools.

419
0:20:32.364,000 --> 0:20:34,000
And so for now, it's the perfect life.

420
0:20:35.651,000 --> 0:20:38,000
CA: Reed, you're a remarkable person, you've changed all of our lives

421
0:20:38.968,000 --> 0:20:39,000
and the lives of many kids.

422
0:20:40.54,000 --> 0:20:42,000
Thank you so much for coming to TED.

423
0:20:42.968,000 --> 0:20:46,000
(Applause)

