1
0:00:12.881,000 --> 0:00:16,000
What happens when technology knows more about us than we do?

2
0:00:17.992,000 --> 0:00:2,000
A computer now can detect our slightest facial microexpressions

3
0:00:21.688,000 --> 0:00:24,000
and be able to tell the difference between a real smile and a fake one.

4
0:00:25.323,000 --> 0:00:26,000
That's only the beginning.

5
0:00:27.466,000 --> 0:00:29,000
Technology has become incredibly intelligent

6
0:00:30.355,000 --> 0:00:33,000
and already knows a lot about our internal states.

7
0:00:34.085,000 --> 0:00:36,000
And whether we like it or not,

8
0:00:36.395,000 --> 0:00:39,000
we already are sharing parts of our inner lives

9
0:00:39.918,000 --> 0:00:4,000
that's out of our control.

10
0:00:43.413,000 --> 0:00:44,000
That seems like a problem,

11
0:00:44.858,000 --> 0:00:47,000
because a lot of us like to keep what's going on inside

12
0:00:48.128,000 --> 0:00:49,000
from what people actually see.

13
0:00:50.323,000 --> 0:00:54,000
We want to have agency over what we share and what we don't.

14
0:00:55.473,000 --> 0:00:57,000
We all like to have a poker face.

15
0:00:59.584,000 --> 0:01:02,000
But I'm here to tell you that I think that's a thing of the past.

16
0:01:03.347,000 --> 0:01:07,000
And while that might sound scary, it's not necessarily a bad thing.

17
0:01:09.03,000 --> 0:01:11,000
I've spent a lot of time studying the circuits in the brain

18
0:01:11.824,000 --> 0:01:14,000
that create the unique perceptual realities that we each have.

19
0:01:16.11,000 --> 0:01:17,000
And now I bring that together

20
0:01:17.539,000 --> 0:01:19,000
with the capabilities of current technology

21
0:01:19.625,000 --> 0:01:21,000
to create new technology that does make us better,

22
0:01:22.186,000 --> 0:01:23,000
feel more, connect more.

23
0:01:24.482,000 --> 0:01:25,000
And I believe to do that,

24
0:01:26.292,000 --> 0:01:28,000
we have to be OK losing some of our agency.

25
0:01:30.149,000 --> 0:01:32,000
With some animals, it's really amazing,

26
0:01:32.696,000 --> 0:01:35,000
and we get to see into their internal experiences.

27
0:01:36.649,000 --> 0:01:39,000
We get this upfront look at the mechanistic interaction

28
0:01:40.395,000 --> 0:01:42,000
between how they respond to the world around them

29
0:01:43.236,000 --> 0:01:45,000
and the state of their biological systems.

30
0:01:45.268,000 --> 0:01:48,000
This is where evolutionary pressures like eating, mating

31
0:01:49.101,000 --> 0:01:5,000
and making sure we don't get eaten

32
0:01:50.887,000 --> 0:01:54,000
drive deterministic behavioral responses to information in the world.

33
0:01:55.806,000 --> 0:01:57,000
And we get to see into this window,

34
0:01:58.624,000 --> 0:02:01,000
into their internal states and their biological experiences.

35
0:02:02.284,000 --> 0:02:03,000
It's really pretty cool.

36
0:02:03.95,000 --> 0:02:07,000
Now, stay with me for a moment -- I'm a violinist, not a singer.

37
0:02:08.077,000 --> 0:02:11,000
But the spider's already given me a critical review.

38
0:02:16.907,000 --> 0:02:18,000
(Video) (Singing in a low pitch)

39
0:02:19.868,000 --> 0:02:21,000
(Singing in a middle pitch)

40
0:02:23.8,000 --> 0:02:25,000
(Singing in a high pitch)

41
0:02:27.069,000 --> 0:02:28,000
(Singing in a low pitch)

42
0:02:29.236,000 --> 0:02:3,000
(Singing in a middle pitch)

43
0:02:31.403,000 --> 0:02:32,000
(Singing in a high pitch)

44
0:02:33.204,000 --> 0:02:34,000
(Laughter)

45
0:02:36.387,000 --> 0:02:39,000
Poppy Crum: It turns out, some spiders tune their webs like violins

46
0:02:39.609,000 --> 0:02:41,000
to resonate with certain sounds.

47
0:02:41.791,000 --> 0:02:43,000
And likely, the harmonics of my voice as it went higher

48
0:02:44.586,000 --> 0:02:45,000
coupled with how loud I was singing

49
0:02:46.34,000 --> 0:02:5,000
recreated either the predatory call of an echolocating bat or a bird,

50
0:02:50.831,000 --> 0:02:51,000
and the spider did what it should.

51
0:02:53.3,000 --> 0:02:55,000
It predictively told me to bug off.

52
0:02:56.824,000 --> 0:02:57,000
I love this.

53
0:02:58.546,000 --> 0:03:01,000
The spider's responding to its external world

54
0:03:01.879,000 --> 0:03:05,000
in a way that we get to see and know what's happening to its internal world.

55
0:03:07.069,000 --> 0:03:09,000
Biology is controlling the spider's response;

56
0:03:09.299,000 --> 0:03:11,000
it's wearing its internal state on its sleeve.

57
0:03:13.768,000 --> 0:03:14,000
But us, humans --

58
0:03:16.184,000 --> 0:03:17,000
we're different.

59
0:03:17.899,000 --> 0:03:22,000
We like to think we have cognitive control over what people see, know and understand

60
0:03:23.658,000 --> 0:03:24,000
about our internal states --

61
0:03:25.091,000 --> 0:03:29,000
our emotions, our insecurities, our bluffs, our trials and tribulations --

62
0:03:29.418,000 --> 0:03:3,000
and how we respond.

63
0:03:31.927,000 --> 0:03:33,000
We get to have our poker face.

64
0:03:35.799,000 --> 0:03:36,000
Or maybe we don't.

65
0:03:37.728,000 --> 0:03:38,000
Try this with me.

66
0:03:38.934,000 --> 0:03:4,000
Your eye responds to how hard your brain is working.

67
0:03:42.363,000 --> 0:03:45,000
The response you're about to see is driven entirely by mental effort

68
0:03:45.617,000 --> 0:03:47,000
and has nothing to do with changes in lighting.

69
0:03:48.276,000 --> 0:03:49,000
We know this from neuroscience.

70
0:03:49.95,000 --> 0:03:53,000
I promise, your eyes are doing the same thing as the subject in our lab,

71
0:03:54.534,000 --> 0:03:55,000
whether you want them to or not.

72
0:03:56.292,000 --> 0:03:58,000
At first, you'll hear some voices.

73
0:03:58.489,000 --> 0:04:01,000
Try and understand them and keep watching the eye in front of you.

74
0:04:01.791,000 --> 0:04:02,000
It's going to be hard at first,

75
0:04:03.313,000 --> 0:04:05,000
one should drop out, and it should get really easy.

76
0:04:05.728,000 --> 0:04:08,000
You're going to see the change in effort in the diameter of the pupil.

77
0:04:10.14,000 --> 0:04:12,000
(Video) (Two overlapping voices talking)

78
0:04:12.731,000 --> 0:04:14,000
(Single voice) Intelligent technology depends on personal data.

79
0:04:15.718,000 --> 0:04:17,000
(Two overlapping voices talking)

80
0:04:18.188,000 --> 0:04:2,000
(Single voice) Intelligent technology depends on personal data.

81
0:04:21.68,000 --> 0:04:22,000
PC: Your pupil doesn't lie.

82
0:04:23.03,000 --> 0:04:25,000
Your eye gives away your poker face.

83
0:04:25.99,000 --> 0:04:26,000
When your brain's having to work harder,

84
0:04:27.927,000 --> 0:04:29,000
your autonomic nervous system drives your pupil to dilate.

85
0:04:30.736,000 --> 0:04:31,000
When it's not, it contracts.

86
0:04:32.68,000 --> 0:04:33,000
When I take away one of the voices,

87
0:04:34.395,000 --> 0:04:36,000
the cognitive effort to understand the talkers

88
0:04:36.681,000 --> 0:04:37,000
gets a lot easier.

89
0:04:37.863,000 --> 0:04:4,000
I could have put the two voices in different spatial locations,

90
0:04:40.887,000 --> 0:04:41,000
I could have made one louder.

91
0:04:42.577,000 --> 0:04:43,000
You would have seen the same thing.

92
0:04:45.006,000 --> 0:04:49,000
We might think we have more agency over the reveal of our internal state

93
0:04:49.816,000 --> 0:04:5,000
than that spider,

94
0:04:51.419,000 --> 0:04:52,000
but maybe we don't.

95
0:04:53.021,000 --> 0:04:55,000
Today's technology is starting to make it really easy

96
0:04:56.014,000 --> 0:04:58,000
to see the signals and tells that give us away.

97
0:04:59.109,000 --> 0:05:02,000
The amalgamation of sensors paired with machine learning

98
0:05:02.427,000 --> 0:05:04,000
on us, around us and in our environments,

99
0:05:04.864,000 --> 0:05:08,000
is a lot more than cameras and microphones tracking our external actions.

100
0:05:12.529,000 --> 0:05:14,000
Our bodies radiate our stories

101
0:05:15.371,000 --> 0:05:17,000
from changes in the temperature of our physiology.

102
0:05:18.546,000 --> 0:05:2,000
We can look at these as infrared thermal images

103
0:05:20.831,000 --> 0:05:21,000
showing up behind me,

104
0:05:22.015,000 --> 0:05:24,000
where reds are hotter and blues are cooler.

105
0:05:24.458,000 --> 0:05:27,000
The dynamic signature of our thermal response

106
0:05:27.665,000 --> 0:05:3,000
gives away our changes in stress,

107
0:05:30.72,000 --> 0:05:32,000
how hard our brain is working,

108
0:05:32.752,000 --> 0:05:33,000
whether we're paying attention

109
0:05:34.712,000 --> 0:05:36,000
and engaged in the conversation we might be having

110
0:05:37.363,000 --> 0:05:41,000
and even whether we're experiencing a picture of fire as if it were real.

111
0:05:41.482,000 --> 0:05:43,000
We can actually see people give off heat on their cheeks

112
0:05:44.149,000 --> 0:05:46,000
in response to an image of flame.

113
0:05:48.013,000 --> 0:05:5,000
But aside from giving away our poker bluffs,

114
0:05:50.966,000 --> 0:05:54,000
what if dimensions of data from someone's thermal response

115
0:05:55.736,000 --> 0:05:57,000
gave away a glow of interpersonal interest?

116
0:05:58.966,000 --> 0:06:01,000
Tracking the honesty of feelings in someone's thermal image

117
0:06:02.522,000 --> 0:06:05,000
might be a new part of how we fall in love and see attraction.

118
0:06:06.172,000 --> 0:06:09,000
Our technology can listen, develop insights and make predictions

119
0:06:09.889,000 --> 0:06:11,000
about our mental and physical health

120
0:06:12.008,000 --> 0:06:16,000
just by analyzing the timing dynamics of our speech and language

121
0:06:16.032,000 --> 0:06:17,000
picked up by microphones.

122
0:06:18.038,000 --> 0:06:21,000
Groups have shown that changes in the statistics of our language

123
0:06:21.942,000 --> 0:06:22,000
paired with machine learning

124
0:06:23.386,000 --> 0:06:26,000
can predict the likelihood someone will develop psychosis.

125
0:06:27.442,000 --> 0:06:28,000
I'm going to take it a step further

126
0:06:29.217,000 --> 0:06:31,000
and look at linguistic changes and changes in our voice

127
0:06:31.828,000 --> 0:06:33,000
that show up with a lot of different conditions.

128
0:06:34.091,000 --> 0:06:38,000
Dementia, diabetes can alter the spectral coloration of our voice.

129
0:06:39.205,000 --> 0:06:42,000
Changes in our language associated with Alzheimer's

130
0:06:42.348,000 --> 0:06:46,000
can sometimes show up more than 10 years before clinical diagnosis.

131
0:06:47.236,000 --> 0:06:5,000
What we say and how we say it tells a much richer story

132
0:06:51.22,000 --> 0:06:52,000
than we used to think.

133
0:06:53.022,000 --> 0:06:57,000
And devices we already have in our homes could, if we let them,

134
0:06:57.093,000 --> 0:06:59,000
give us invaluable insight back.

135
0:06:59.998,000 --> 0:07:01,000
The chemical composition of our breath

136
0:07:03.959,000 --> 0:07:04,000
gives away our feelings.

137
0:07:06.363,000 --> 0:07:1,000
There's a dynamic mixture of acetone, isoprene and carbon dioxide

138
0:07:10.865,000 --> 0:07:13,000
that changes when our heart speeds up, when our muscles tense,

139
0:07:14.809,000 --> 0:07:16,000
and all without any obvious change in our behaviors.

140
0:07:18.268,000 --> 0:07:2,000
Alright, I want you to watch this clip with me.

141
0:07:21.03,000 --> 0:07:24,000
Some things might be going on on the side screens,

142
0:07:24.173,000 --> 0:07:27,000
but try and focus on the image in the front

143
0:07:27.974,000 --> 0:07:28,000
and the man at the window.

144
0:07:31.633,000 --> 0:07:33,000
(Eerie music)

145
0:07:39.767,000 --> 0:07:4,000
(Woman screams)

146
0:07:50.692,000 --> 0:07:52,000
PC: Sorry about that. I needed to get a reaction.

147
0:07:53.111,000 --> 0:07:54,000
(Laughter)

148
0:07:55.412,000 --> 0:07:59,000
I'm actually tracking the carbon dioxide you exhale in the room right now.

149
0:08:01.903,000 --> 0:08:04,000
We've installed tubes throughout the theater,

150
0:08:05.22,000 --> 0:08:07,000
lower to the ground, because CO2 is heavier than air.

151
0:08:07.839,000 --> 0:08:09,000
But they're connected to a device in the back

152
0:08:10.53,000 --> 0:08:13,000
that lets us measure, in real time, with high precision,

153
0:08:13.841,000 --> 0:08:15,000
the continuous differential concentration of CO2.

154
0:08:17.246,000 --> 0:08:22,000
The clouds on the sides are actually the real-time data visualization

155
0:08:22.778,000 --> 0:08:23,000
of the density of our CO2.

156
0:08:25.374,000 --> 0:08:28,000
You might still see a patch of red on the screen,

157
0:08:29.097,000 --> 0:08:32,000
because we're showing increases with larger colored clouds,

158
0:08:32.826,000 --> 0:08:34,000
larger colored areas of red.

159
0:08:35.046,000 --> 0:08:37,000
And that's the point where a lot of us jumped.

160
0:08:38.173,000 --> 0:08:42,000
It's our collective suspense driving a change in carbon dioxide.

161
0:08:43.649,000 --> 0:08:45,000
Alright, now, watch this with me one more time.

162
0:08:46.395,000 --> 0:08:48,000
(Cheerful music)

163
0:08:54.553,000 --> 0:08:56,000
(Woman laughs)

164
0:09:05.344,000 --> 0:09:06,000
PC: You knew it was coming.

165
0:09:06.717,000 --> 0:09:09,000
But it's a lot different when we changed the creator's intent.

166
0:09:10.776,000 --> 0:09:12,000
Changing the music and the sound effects

167
0:09:13.569,000 --> 0:09:16,000
completely alter the emotional impact of that scene.

168
0:09:17.196,000 --> 0:09:19,000
And we can see it in our breath.

169
0:09:20.196,000 --> 0:09:22,000
Suspense, fear, joy

170
0:09:22.482,000 --> 0:09:26,000
all show up as reproducible, visually identifiable moments.

171
0:09:27.473,000 --> 0:09:31,000
We broadcast a chemical signature of our emotions.

172
0:09:35.249,000 --> 0:09:37,000
It is the end of the poker face.

173
0:09:38.582,000 --> 0:09:41,000
Our spaces, our technology will know what we're feeling.

174
0:09:42.736,000 --> 0:09:44,000
We will know more about each other than we ever have.

175
0:09:45.911,000 --> 0:09:49,000
We get a chance to reach in and connect to the experience and sentiments

176
0:09:50.242,000 --> 0:09:51,000
that are fundamental to us as humans

177
0:09:52.008,000 --> 0:09:54,000
in our senses, emotionally and socially.

178
0:09:55.482,000 --> 0:09:57,000
I believe it is the era of the empath.

179
0:09:58.046,000 --> 0:10:03,000
And we are enabling the capabilities that true technological partners can bring

180
0:10:03.292,000 --> 0:10:06,000
to how we connect with each other and with our technology.

181
0:10:06.363,000 --> 0:10:09,000
If we recognize the power of becoming technological empaths,

182
0:10:09.776,000 --> 0:10:1,000
we get this opportunity

183
0:10:11.736,000 --> 0:10:15,000
where technology can help us bridge the emotional and cognitive divide.

184
0:10:16.68,000 --> 0:10:18,000
And in that way, we get to change how we tell our stories.

185
0:10:19.427,000 --> 0:10:22,000
We can enable a better future for technologies like augmented reality

186
0:10:23.031,000 --> 0:10:27,000
to extend our own agency and connect us at a much deeper level.

187
0:10:27.625,000 --> 0:10:29,000
Imagine a high school counselor being able to realize

188
0:10:30.196,000 --> 0:10:33,000
that an outwardly cheery student really was having a deeply hard time,

189
0:10:34.046,000 --> 0:10:37,000
where reaching out can make a crucial, positive difference.

190
0:10:37.766,000 --> 0:10:4,000
Or authorities, being able to know the difference

191
0:10:41.02,000 --> 0:10:43,000
between someone having a mental health crisis

192
0:10:43.369,000 --> 0:10:44,000
and a different type of aggression,

193
0:10:45.219,000 --> 0:10:46,000
and responding accordingly.

194
0:10:47.609,000 --> 0:10:5,000
Or an artist, knowing the direct impact of their work.

195
0:10:52.173,000 --> 0:10:54,000
Leo Tolstoy defined his perspective of art

196
0:10:54.84,000 --> 0:10:55,000
by whether what the creator intended

197
0:10:56.649,000 --> 0:10:58,000
was experienced by the person on the other end.

198
0:10:59.259,000 --> 0:11:01,000
Today's artists can know what we're feeling.

199
0:11:02.204,000 --> 0:11:05,000
But regardless of whether it's art or human connection,

200
0:11:06.608,000 --> 0:11:08,000
today's technologies will know and can know

201
0:11:09.434,000 --> 0:11:11,000
what we're experiencing on the other side,

202
0:11:11.506,000 --> 0:11:13,000
and this means we can be closer and more authentic.

203
0:11:14.498,000 --> 0:11:18,000
But I realize a lot of us have a really hard time

204
0:11:18.815,000 --> 0:11:2,000
with the idea of sharing our data,

205
0:11:21.673,000 --> 0:11:24,000
and especially the idea that people know things about us

206
0:11:24.808,000 --> 0:11:26,000
that we didn't actively choose to share.

207
0:11:28.728,000 --> 0:11:3,000
Anytime we talk to someone,

208
0:11:31.946,000 --> 0:11:32,000
look at someone

209
0:11:33.525,000 --> 0:11:34,000
or choose not to look,

210
0:11:35.017,000 --> 0:11:37,000
data is exchanged, given away,

211
0:11:38.533,000 --> 0:11:4,000
that people use to learn,

212
0:11:40.762,000 --> 0:11:43,000
make decisions about their lives and about ours.

213
0:11:45.469,000 --> 0:11:48,000
I'm not looking to create a world where our inner lives are ripped open

214
0:11:49.461,000 --> 0:11:51,000
and our personal data and our privacy given away

215
0:11:51.833,000 --> 0:11:53,000
to people and entities where we don't want to see it go.

216
0:11:55.117,000 --> 0:11:57,000
But I am looking to create a world

217
0:11:57.903,000 --> 0:12:,000
where we can care about each other more effectively,

218
0:12:01.335,000 --> 0:12:04,000
we can know more about when someone is feeling something

219
0:12:04.419,000 --> 0:12:05,000
that we ought to pay attention to.

220
0:12:06.8,000 --> 0:12:09,000
And we can have richer experiences from our technology.

221
0:12:10.887,000 --> 0:12:12,000
Any technology can be used for good or bad.

222
0:12:13.268,000 --> 0:12:15,000
Transparency to engagement and effective regulation

223
0:12:15.704,000 --> 0:12:18,000
are absolutely critical to building the trust for any of this.

224
0:12:20.106,000 --> 0:12:24,000
But the benefits that "empathetic technology" can bring to our lives

225
0:12:24.964,000 --> 0:12:27,000
are worth solving the problems that make us uncomfortable.

226
0:12:29.315,000 --> 0:12:33,000
And if we don't, there are too many opportunities and feelings

227
0:12:33.364,000 --> 0:12:34,000
we're going to be missing out on.

228
0:12:35.083,000 --> 0:12:36,000
Thank you.

229
0:12:36.282,000 --> 0:12:38,000
(Applause)

