1
0:00:,000 --> 0:00:07,000
Traductor: Larisa Esteche Revisor: Lissette Bolvarán Aguilar

2
0:00:15.931,000 --> 0:00:17,000
¡Hola! Bien, este hombre de acá

3
0:00:18.716,000 --> 0:00:2,000
cree que puede predecir el futuro.

4
0:00:20.978,000 --> 0:00:21,000
Su nombre es Nostradamus, aunque en este caso el periódico

5
0:00:22.957,000 --> 0:00:25,000
lo hace parecer un poco a Sean Connery. (Risas)

6
0:00:26.627,000 --> 0:00:28,000
Y al igual que la mayoría de ustedes, me imagino, no creo

7
0:00:29.53,000 --> 0:00:3,000
que la gente pueda predecir el futuro.

8
0:00:30.638,000 --> 0:00:32,000
No creo en la clarividencia y de vez en cuando

9
0:00:33.342,000 --> 0:00:36,000
se oye que alguien ha sido capaz de predecir algo que sucedió en el futuro,

10
0:00:36.524,000 --> 0:00:39,000
probablemente fue un golpe de suerte

11
0:00:39.583,000 --> 0:00:41,000
y sólo escuchamos sobre casualidades y fenómenos.

12
0:00:42.198,000 --> 0:00:46,000
No oímos sobre todas las veces que la gente se equivoca.

13
0:00:46.277,000 --> 0:00:48,000
Ahora esperamos que eso suceda con historias comunes

14
0:00:48.437,000 --> 0:00:51,000
acerca de la clarividencia, pero el problema es

15
0:00:51.576,000 --> 0:00:54,000
que tenemos exactamente el mismo problema en el mundo académico,

16
0:00:54.92,000 --> 0:00:58,000
en medicina y en este entorno, cuesta vidas.

17
0:00:59.421,000 --> 0:01:02,000
Así que primero, pensar sólo en la clarividencia, como resultado,

18
0:01:02.786,000 --> 0:01:04,000
el año pasado un investigador llamado Daryl Bem dirigió

19
0:01:05.315,000 --> 0:01:06,000
un trabajo de investigación donde encontró evidencia

20
0:01:07.151,000 --> 0:01:1,000
de poderes de clarividencia en estudiantes de pregrado,

21
0:01:10.809,000 --> 0:01:12,000
esto fue publicado en una revista académica

22
0:01:13.383,000 --> 0:01:15,000
y la mayoría de las personas que la leyeron solo dijeron: "Bueno, está bien,

23
0:01:15.664,000 --> 0:01:17,000
pero creo que eso es un golpe de suerte, sólo un fenómeno, porque sé

24
0:01:17.845,000 --> 0:01:19,000
que si yo hiciera un estudio en el que no encontrara evidencia

25
0:01:20.679,000 --> 0:01:22,000
acerca de que los estudiantes universitarios tenían poderes de clarividencia,

26
0:01:23.191,000 --> 0:01:26,000
probablemente no se publicaría en una revista científica.

27
0:01:26.743,000 --> 0:01:28,000
De hecho, sabemos que eso es cierto, porque

28
0:01:29.598,000 --> 0:01:31,000
varios grupos de científicos investigadores intentaron

29
0:01:32.127,000 --> 0:01:35,000
repetir los hallazgos de este estudio acerca de la clarividencia

30
0:01:35.647,000 --> 0:01:37,000
y cuando lo presentaron a la misma revista,

31
0:01:38.282,000 --> 0:01:41,000
les dijeron, "No, no estamos interesados en publicar duplicados.

32
0:01:41.434,000 --> 0:01:45,000
No estamos interesados en su información negativa ".

33
0:01:45.959,000 --> 0:01:47,000
Esta es la evidencia de cómo, en la literatura académica,

34
0:01:48.713,000 --> 0:01:52,000
veremos una muestra sesgada de la verdadera imagen

35
0:01:53.583,000 --> 0:01:56,000
de todos los estudios científicos que se han realizado.

36
0:01:57.05,000 --> 0:02:01,000
Pero no sólo sucede en el campo de la psicología.

37
0:02:01.479,000 --> 0:02:05,000
También sucede, por ejemplo, en la investigación sobre el cáncer.

38
0:02:05.846,000 --> 0:02:09,000
En marzo de 2012, algunos investigadores

39
0:02:09.923,000 --> 0:02:11,000
informaron en la revista Nature cómo habían intentado

40
0:02:12.819,000 --> 0:02:15,000
repetir 53 diferentes estudios de ciencia básica buscando

41
0:02:16.665,000 --> 0:02:19,000
posibles objetivos de tratamiento del cáncer,

42
0:02:20.22,000 --> 0:02:22,000
de esos 53 estudios, sólo pudieron

43
0:02:22.858,000 --> 0:02:25,000
repetir seis con éxito.

44
0:02:25.934,000 --> 0:02:29,000
Cuarenta y siete de los 53 eran irrepetibles.

45
0:02:30.267,000 --> 0:02:33,000
En su debate dicen que esto es muy probable

46
0:02:34.18,000 --> 0:02:36,000
porque los fenómenos sí son publicados.

47
0:02:36.819,000 --> 0:02:38,000
La gente va a hacer miles de estudios diferentes

48
0:02:38.915,000 --> 0:02:4,000
y cuando sean de utilidad, serán publicados,

49
0:02:41.035,000 --> 0:02:42,000
aquellos que no lo sean, no serán publicados.

50
0:02:42.714,000 --> 0:02:45,000
Su primera recomendación para solucionar este problema,

51
0:02:46.655,000 --> 0:02:49,000
porque realmente es un problema, ya que nos envía a callejones sin salida,

52
0:02:49.944,000 --> 0:02:5,000
es que sea más fácil

53
0:02:51.65,000 --> 0:02:54,000
publicar los resultados negativos de la ciencia

54
0:02:55.043,000 --> 0:02:57,000
y cambiar los incentivos para que los científicos estén

55
0:02:57.95,000 --> 0:03:01,000
motivados a publicar más sobre sus resultados negativos en público.

56
0:03:02.302,000 --> 0:03:05,000
Pero esto no sólo sucede en el mundo

57
0:03:06.154,000 --> 0:03:09,000
de la investigación del cáncer de la ciencia básica preclínica.

58
0:03:10.005,000 --> 0:03:13,000
También sucede en la realidad de carne y hueso

59
0:03:13.662,000 --> 0:03:16,000
de la medicina académica. En 1980,

60
0:03:17.253,000 --> 0:03:2,000
algunos investigadores realizaron un estudio sobre un medicamento llamado lorcainide,

61
0:03:20.261,000 --> 0:03:22,000
un fármaco antiarrítmico

62
0:03:22.592,000 --> 0:03:24,000
que suprime los ritmos cardíacos anormales.

63
0:03:24.858,000 --> 0:03:26,000
La idea era que, después de que las personas sufren un ataque al corazón,

64
0:03:27.086,000 --> 0:03:28,000
son muy propensas a tener ritmos cardíacos anormales,

65
0:03:28.623,000 --> 0:03:3,000
así que si les damos un medicamento que suprima estos ritmos cardíacos anormales

66
0:03:31,000 --> 0:03:34,000
las posibilidades de que sobrevivan aumentarán.

67
0:03:34.713,000 --> 0:03:37,000
Al inicio de su desarrollo, hicieron una pequeña prueba

68
0:03:37.721,000 --> 0:03:38,000
con cien pacientes.

69
0:03:39.365,000 --> 0:03:42,000
Cincuenta pacientes tomaron lorcainide, de esos pacientes murieron 10.

70
0:03:43.017,000 --> 0:03:46,000
Otros 50 pacientes recibieron un placebo o una píldora de azúcar

71
0:03:46.06,000 --> 0:03:48,000
con ningún ingrediente activo y sólo uno de ellos murió.

72
0:03:49.018,000 --> 0:03:51,000
Así que rápidamente consideraron esta droga como un fracaso,

73
0:03:51.667,000 --> 0:03:53,000
su desarrollo comercial se detuvo y debido a esto,

74
0:03:54.536,000 --> 0:03:58,000
este ensayo nunca fue publicado.

75
0:03:58.884,000 --> 0:04:03,000
Lamentablemente, en el transcurso de los siguientes cinco o diez años,

76
0:04:04.281,000 --> 0:04:07,000
otras compañías tuvieron la misma idea de que los medicamentos

77
0:04:08.106,000 --> 0:04:1,000
podrían evitar arritmias en personas que han sufrido ataques cardíacos.

78
0:04:10.698,000 --> 0:04:11,000
Estos medicamentos fueron llevados al mercado. Se recetaron

79
0:04:12.418,000 --> 0:04:15,000
ampliamente debido a que los ataques al corazón son muy comúnes

80
0:04:15.83,000 --> 0:04:18,000
y nos tómo tanto tiempo para supiéramos que estos fármacos

81
0:04:19.673,000 --> 0:04:21,000
también causaron un aumento en la tasa de muerte

82
0:04:22.584,000 --> 0:04:24,000
que antes de detectar esa señal de seguridad,

83
0:04:25.331,000 --> 0:04:31,000
más de 100.000 personas murieron innecesariamente en América

84
0:04:31.382,000 --> 0:04:34,000
por la receta de los fármacos antiarrítmicos.

85
0:04:34.833,000 --> 0:04:37,000
En 1993,

86
0:04:38.431,000 --> 0:04:41,000
los investigadores que hicieron ese apresurado estudio en 1980,

87
0:04:41.991,000 --> 0:04:44,000
publicaron un mea culpa, una disculpa a la comunidad científica,

88
0:04:45.832,000 --> 0:04:48,000
en la que dijeron: "Cuando realizamos nuestro estudio en 1980,

89
0:04:48.957,000 --> 0:04:49,000
pensamos que el incremento en la tasa de mortalidad

90
0:04:50.893,000 --> 0:04:53,000
que se produjo en el grupo de lorcainide fue producto del azar".

91
0:04:54.251,000 --> 0:04:56,000
El desarrollo de lorcainide se abandonó por razones comerciales

92
0:04:56.283,000 --> 0:04:57,000
y este estudio nunca fue publicado;

93
0:04:57.921,000 --> 0:04:59,000
ahora es un buen ejemplo del sesgo en la publicación.

94
0:05:00.307,000 --> 0:05:01,000
Ese es el término técnico para el fenómeno donde

95
0:05:02.198,000 --> 0:05:06,000
datos poco halagadores se pierden, no se publican,

96
0:05:06.436,000 --> 0:05:09,000
desaparecen en acción y dicen que los resultados descritos aquí

97
0:05:09.807,000 --> 0:05:13,000
"podrían haber brindado una alerta temprana de futuros problemas".

98
0:05:14.615,000 --> 0:05:17,000
Estas son historias de ciencia básica.

99
0:05:17.828,000 --> 0:05:21,000
Historias de hace 20 o 30 años.

100
0:05:22.615,000 --> 0:05:25,000
El entorno de una publicación académica es muy diferente ahora.

101
0:05:25.762,000 --> 0:05:28,000
Existen revistas como "Trials", la revista de libre acceso,

102
0:05:29.757,000 --> 0:05:31,000
que publicarán cualquier estudio realizado en seres humanos

103
0:05:32.412,000 --> 0:05:35,000
independientemente de si tiene un resultado positivo o negativo.

104
0:05:35.715,000 --> 0:05:38,000
Pero este problema de resultados negativos que se pierden en acción

105
0:05:39.684,000 --> 0:05:42,000
todavía es muy frecuente. De hecho es tan frecuente

106
0:05:43.243,000 --> 0:05:48,000
que corta el núcleo de la medicina basada en evidencia.

107
0:05:49.094,000 --> 0:05:52,000
Esto es un medicamento llamado reboxetine, es una droga

108
0:05:52.109,000 --> 0:05:54,000
que yo mismo he recetado. Es un antidepresivo.

109
0:05:54.644,000 --> 0:05:56,000
Yo soy un médico muy nerd, por lo que he leído todos los estudios

110
0:05:57.18,000 --> 0:06:,000
sobre este fármaco. Leí un estudio

111
0:06:00.232,000 --> 0:06:02,000
que demostraba que reboxetine era mejor que el placebo

112
0:06:03.179,000 --> 0:06:04,000
y leí los otros tres estudios que fueron publicados

113
0:06:05.043,000 --> 0:06:08,000
que demostraban que reboxetine era tan bueno como cualquier otro antidepresivo

114
0:06:08.614,000 --> 0:06:1,000
y debido a que este paciente no había tenido buenos resultados con otros antidepresivos,

115
0:06:10.801,000 --> 0:06:12,000
pensé, bueno, reboxetine es igual de bueno. Habría que probar.

116
0:06:13.267,000 --> 0:06:16,000
Pero resultó que estaba confundido. En realidad,

117
0:06:16.659,000 --> 0:06:18,000
se realizaron siete ensayos que comparaban reboxetine

118
0:06:19.108,000 --> 0:06:21,000
con una píldora placebo. Uno de ellos

119
0:06:21.82,000 --> 0:06:23,000
fue positivo y fue publicado, pero seis de ellos

120
0:06:24.132,000 --> 0:06:28,000
fueron negativos y quedaron sin publicar.

121
0:06:28.18,000 --> 0:06:29,000
Tres ensayos fueron publicados comparando reboxetine

122
0:06:29.919,000 --> 0:06:31,000
con otros antidepresivos, en los que reboxetine

123
0:06:32.145,000 --> 0:06:33,000
era igual de bueno, y fueron publicados,

124
0:06:33.938,000 --> 0:06:37,000
pero se reunió información de el triple de pacientes

125
0:06:38.327,000 --> 0:06:39,000
que mostraron que reboxetine era peor

126
0:06:40.198,000 --> 0:06:44,000
que los otros tratamientos y esos ensayos no se publicaron.

127
0:06:44.899,000 --> 0:06:47,000
Me sentí engañado.

128
0:06:48.658,000 --> 0:06:5,000
Ahora bien, usted podría decir que es un ejemplo extremadamente inusual

129
0:06:50.788,000 --> 0:06:52,000
y no quiero ser culpable de la misma clase de

130
0:06:52.796,000 --> 0:06:54,000
referencias manipuladas y selectivas

131
0:06:55.777,000 --> 0:06:56,000
de las que estoy acusando a otras personas.

132
0:06:57.568,000 --> 0:06:58,000
Pero resulta que este fenómeno de sesgo en publicación

133
0:06:59.452,000 --> 0:07:01,000
ha sido muy bien estudiado.

134
0:07:01.579,000 --> 0:07:03,000
Así que aquí está un ejemplo sobre cómo abordarlo.

135
0:07:03.797,000 --> 0:07:05,000
El modelo clásico es: tienes un montón de estudios

136
0:07:06.237,000 --> 0:07:08,000
que sabes que efectivamente se realizaron y se completaron

137
0:07:08.422,000 --> 0:07:1,000
y luego buscas si fueron publicados en algún

138
0:07:10.743,000 --> 0:07:12,000
lugar en la literatura académica. Esto abarcó todos los ensayos

139
0:07:13.606,000 --> 0:07:15,000
que se realizaron acerca de los antidepresivos

140
0:07:15.76,000 --> 0:07:18,000
y que se aprobaron en un período de 15 años por la FDA.

141
0:07:19.402,000 --> 0:07:22,000
Tomaron todas los ensayos que se presentaron a la FDA para su aprobación.

142
0:07:23.158,000 --> 0:07:26,000
Sin embargo, estos no son todos los ensayos realizados acerca de estos medicamentos,

143
0:07:26.358,000 --> 0:07:28,000
porque nunca podemos saber si los tenemos,

144
0:07:28.456,000 --> 0:07:31,000
pero son los que se realizaron para conseguir autorización comercial.

145
0:07:31.95,000 --> 0:07:33,000
Luego fueron a ver si estos ensayos habían sido publicados

146
0:07:34.299,000 --> 0:07:36,000
en la literatura académica revisada y esto es lo que encontraron.

147
0:07:36.871,000 --> 0:07:39,000
Era prácticamente una división de 50-50. La mitad de estos ensayos

148
0:07:40.04,000 --> 0:07:43,000
fueron positivos, la mitad de ellos fueron negativos, en realidad.

149
0:07:43.637,000 --> 0:07:47,000
Pero cuando fueron a buscar estos ensayos en la literatura académica revisada,

150
0:07:48.378,000 --> 0:07:5,000
lo que encontraron fue una imagen muy diferente.

151
0:07:50.612,000 --> 0:07:54,000
Sólo tres de los ensayos negativos fueron publicados,

152
0:07:54.984,000 --> 0:07:58,000
pero todos, excepto uno de los ensayos positivos fueron publicados.

153
0:07:59.626,000 --> 0:08:02,000
Si hojeamos hacia atrás y adelante entre esos dos,

154
0:08:03.387,000 --> 0:08:05,000
podemos ver la diferencia asombrosa que hubo

155
0:08:05.981,000 --> 0:08:08,000
entre la realidad y lo que los médicos, pacientes,

156
0:08:09.431,000 --> 0:08:11,000
miembros de servicios de salud y académicos

157
0:08:12.053,000 --> 0:08:15,000
pudimos ver en la literatura revisada.

158
0:08:15.334,000 --> 0:08:19,000
Fuimos engañados y esto es un error sistemático

159
0:08:19.788,000 --> 0:08:22,000
en el núcleo de la medicina.

160
0:08:23.118,000 --> 0:08:25,000
De hecho, se han realizado tantos estudios sobre

161
0:08:25.781,000 --> 0:08:28,000
el sesgo de publicación, más de un centenar, que han sido

162
0:08:29.165,000 --> 0:08:32,000
reunídos en una crítica sistemática publicada en 2010,

163
0:08:32.359,000 --> 0:08:34,000
que examinó cada estudio sobre el sesgo de publicación

164
0:08:35.125,000 --> 0:08:36,000
que pudieron encontrar.

165
0:08:36.424,000 --> 0:08:38,000
El sesgo de publicación afecta a cada campo de la medicina.

166
0:08:39.276,000 --> 0:08:43,000
En promedio, cerca de la mitad de todos los ensayos desaparecen en acción

167
0:08:43.589,000 --> 0:08:46,000
y sabemos que es probable que los resultados positivos se publiquen el doble

168
0:08:46.647,000 --> 0:08:49,000
que los resultados negativos.

169
0:08:49.701,000 --> 0:08:53,000
Esto es un cáncer en el núcleo de la medicina basada en evidencia.

170
0:08:53.762,000 --> 0:08:56,000
Si tiro una moneda 100 veces pero luego

171
0:08:57.633,000 --> 0:09:,000
retengo los resultados de la mitad de esas arrojadas,

172
0:09:00.892,000 --> 0:09:03,000
puedo hacerlo parecer como si tuviera una moneda que siempre cae cara.

173
0:09:04.292,000 --> 0:09:05,000
Pero eso no significa que tenga una moneda de dos caras.

174
0:09:06.113,000 --> 0:09:07,000
Eso significaría que yo era un oportunista

175
0:09:07.825,000 --> 0:09:1,000
y tu un idiota por dejarme salir con la mía. (Risas)

176
0:09:10.939,000 --> 0:09:13,000
Pero esto es exactamente lo que toleramos a ciegas

177
0:09:14.576,000 --> 0:09:17,000
en el conjunto de la medicina basada en evidencia.

178
0:09:18.365,000 --> 0:09:22,000
Para mí, esto es una falta grave en la investigación.

179
0:09:22.797,000 --> 0:09:24,000
Si he realizado un estudio y retuve

180
0:09:25.54,000 --> 0:09:28,000
la mitad de los puntos de ese estudio,

181
0:09:28.54,000 --> 0:09:32,000
me podrías acusar con motivos, esencialmente, de fraude de investigación.

182
0:09:33.247,000 --> 0:09:35,000
Sin embargo, por alguna razón, si alguien realiza

183
0:09:36.03,000 --> 0:09:4,000
10 estudios pero sólo publica los cinco que dan el resultado que quieren,

184
0:09:40.588,000 --> 0:09:42,000
no consideramos que eso sea una falta grave de la investigación.

185
0:09:43.376,000 --> 0:09:45,000
Cuando esa responsabilidad se difunde entre

186
0:09:45.943,000 --> 0:09:48,000
toda una red de investigadores, académicos,

187
0:09:49.104,000 --> 0:09:52,000
patrocinadores de la industria, editores de revistas, por alguna razón

188
0:09:52.632,000 --> 0:09:53,000
nos parece más aceptable,

189
0:09:54.085,000 --> 0:09:57,000
pero el efecto en los pacientes es crítico.

190
0:09:57.76,000 --> 0:10:02,000
Esto está ocurriendo ahora mismo, hoy.

191
0:10:02.778,000 --> 0:10:04,000
Este es un medicamento llamado Tamiflu. Tamiflu es un fármaco

192
0:10:05.489,000 --> 0:10:07,000
en el que los gobiernos del mundo han gastado miles de millones

193
0:10:08.085,000 --> 0:10:1,000
de dólares en almacenamiento

194
0:10:10.657,000 --> 0:10:13,000
y hemos almacenado Tamiflu en pánico,

195
0:10:13.805,000 --> 0:10:16,000
con la creencia de que reducirá la tasa de complicaciones de la gripe.

196
0:10:17.754,000 --> 0:10:19,000
Complicaciones es un eufemismo médico para la neumonía

197
0:10:20.438,000 --> 0:10:24,000
y la muerte. (Risas)

198
0:10:25.252,000 --> 0:10:28,000
Cuando los revisores sistemáticos de Cochrane

199
0:10:28.46,000 --> 0:10:3,000
trataban de reunir todos los datos de todos los

200
0:10:30.985,000 --> 0:10:33,000
ensayos que se han realizado sobre si Tamiflu realmente hacía esto o no,

201
0:10:34.633,000 --> 0:10:36,000
descubrieron que varios de esos ensayos no fueron publicados.

202
0:10:37.584,000 --> 0:10:38,000
Los resultados no estaban disponibles para ellos.

203
0:10:39.426,000 --> 0:10:42,000
Cuando empezaron a obtener los artículos de esos ensayos por diversos medios

204
0:10:43.39,000 --> 0:10:44,000
a través de peticiones de la Ley por la Libertad de la Información y

205
0:10:45.072,000 --> 0:10:49,000
hostigando a diversas organizaciones, lo que encontraron fue inconsistente.

206
0:10:49.881,000 --> 0:10:51,000
Cuando intentaron conseguir los informes del estudio clínico,

207
0:10:52.347,000 --> 0:10:55,000
los documentos de 10.000 páginas que tienen

208
0:10:55.393,000 --> 0:10:58,000
la mejor representación posible de la información,

209
0:10:58.993,000 --> 0:11:,000
les dijeron que no se les permitía tenerlos.

210
0:11:01.881,000 --> 0:11:03,000
Y si quieres leer la correspondencia completa,

211
0:11:04.564,000 --> 0:11:07,000
las excusas y las explicaciones brindadas por la compañía farmacéutica,

212
0:11:07.854,000 --> 0:11:09,000
se puede ver en la edición de esta semana

213
0:11:10.571,000 --> 0:11:14,000
de PLOS Medicine.

214
0:11:14.938,000 --> 0:11:17,000
Lo más sorprendente de todo esto, para mí,

215
0:11:18.797,000 --> 0:11:21,000
es que esto no sólo es un problema, no sólo reconocemos

216
0:11:22.096,000 --> 0:11:26,000
que esto es un problema, pero tuvimos que sufrir correcciones falsas.

217
0:11:26.291,000 --> 0:11:29,000
Hicimos creer a la gente que este problema fue resuelto.

218
0:11:29.349,000 --> 0:11:31,000
En primer lugar, tuvimos registros de ensayos y todos dijeron:

219
0:11:31.537,000 --> 0:11:34,000
Oh, está bien. Pondremos a todos a registrar sus ensayos, anunciarán el protocolo,

220
0:11:35.14,000 --> 0:11:37,000
dirán lo que van a hacer antes de hacerlo,

221
0:11:37.164,000 --> 0:11:39,000
y después podremos comprobar y ver si todos los ensayos

222
0:11:39.285,000 --> 0:11:41,000
que se han realizado y completado fueron publicados.

223
0:11:41.753,000 --> 0:11:43,000
Pero la gente no se preocupaba en usar esos registros.

224
0:11:43.949,000 --> 0:11:45,000
Entonces llegó el Comité Internacional de editores de revistas médicas,

225
0:11:46.568,000 --> 0:11:47,000
y dijeron: Bien, vamos a esperar.

226
0:11:48.111,000 --> 0:11:5,000
No publicaremos las revistas, no publicaremos ningún ensayo,

227
0:11:50.744,000 --> 0:11:52,000
a menos que hayan sido registrados antes de comenzar.

228
0:11:53.426,000 --> 0:11:56,000
Pero no esperaron. En 2008, se realizó un estudio

229
0:11:56.957,000 --> 0:11:59,000
que mostró que la mitad de todos los ensayos publicados por revistas

230
0:11:59.972,000 --> 0:12:01,000
editados por miembros del ICMJE

231
0:12:02.639,000 --> 0:12:06,000
no estaban debidamente registrados y un cuarto de ellos no estaban registrados en absoluto.

232
0:12:07.452,000 --> 0:12:09,000
Finalmente, se aprobó la Ley de Enmienda de la FDA

233
0:12:10.253,000 --> 0:12:12,000
hace un par de años, la cual decía que quien realice

234
0:12:12.602,000 --> 0:12:15,000
un ensayo debe publicar los resultados de esa prueba dentro de un año.

235
0:12:16.045,000 --> 0:12:2,000
En el BMJ, en la primera edición de enero de 2012

236
0:12:20.141,000 --> 0:12:22,000
se puede ver un estudio que busca ver si la gente mantiene

237
0:12:22.845,000 --> 0:12:25,000
esa regla y resulta que sólo uno de cada cinco

238
0:12:26.564,000 --> 0:12:28,000
lo ha hecho.

239
0:12:29.428,000 --> 0:12:32,000
Esto es un desastre.

240
0:12:32.711,000 --> 0:12:35,000
No podemos conocer los verdaderos efectos de los medicamentos

241
0:12:36.275,000 --> 0:12:39,000
que recetamos si no tenemos acceso

242
0:12:39.491,000 --> 0:12:42,000
a toda la información.

243
0:12:42.671,000 --> 0:12:45,000
Y esto no es un problema difícil de solucionar.

244
0:12:46.63,000 --> 0:12:51,000
Tenemos que forzar a la gente a publicar todos los ensayos

245
0:12:51.758,000 --> 0:12:53,000
realizados en seres humanos, incluídos los ensayos anteriores,

246
0:12:54.729,000 --> 0:12:57,000
porque la ley de enmienda de la FDA sólo pide que se publiquen los ensayos realizados después del 2008,

247
0:12:58.674,000 --> 0:13:,000
no se en qué mundo vivimos en el que solo

248
0:13:01.287,000 --> 0:13:05,000
practicamos la medicina en base a ensayos completados en los últimos dos años.

249
0:13:05.743,000 --> 0:13:07,000
Tenemos que publicar todos los estudios en seres humanos,

250
0:13:07.848,000 --> 0:13:1,000
incluyendo los ensayos anteriores, para todos los medicamentos en uso

251
0:13:10.922,000 --> 0:13:12,000
y necesita decirle a todos los que conoces

252
0:13:13.838,000 --> 0:13:16,000
que esto es un problema y que no se ha resuelto.

253
0:13:17.28,000 --> 0:13:19,000
Muchas gracias. (Aplausos)

254
0:13:20.231,000 --> 0:13:23,000
(Aplausos)

