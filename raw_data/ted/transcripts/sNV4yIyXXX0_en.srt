1
0:00:,000 --> 0:00:07,000
Translator: Joseph Geni Reviewer: Morton Bast

2
0:00:15.895,000 --> 0:00:17,000
I've been a journalist now since I was about 17,

3
0:00:18.516,000 --> 0:00:21,000
and it's an interesting industry to be in at the moment,

4
0:00:22.076,000 --> 0:00:24,000
because as you all know, there's a huge amount of upheaval

5
0:00:24.412,000 --> 0:00:26,000
going on in media, and most of you probably know this

6
0:00:26.892,000 --> 0:00:29,000
from the business angle, which is that the business model

7
0:00:30.115,000 --> 0:00:32,000
is pretty screwed, and as my grandfather would say,

8
0:00:33.058,000 --> 0:00:35,000
the profits have all been gobbled up by Google.

9
0:00:35.772,000 --> 0:00:37,000
So it's a really interesting time to be a journalist,

10
0:00:38.116,000 --> 0:00:41,000
but the upheaval that I'm interested in is not on the output side.

11
0:00:41.2,000 --> 0:00:44,000
It's on the input side. It's concern with

12
0:00:44.295,000 --> 0:00:46,000
how we get information and how we gather the news.

13
0:00:46.793,000 --> 0:00:49,000
And that's changed, because we've had a huge shift

14
0:00:49.864,000 --> 0:00:51,000
in the balance of power from

15
0:00:52.102,000 --> 0:00:54,000
the news organizations to the audience.

16
0:00:54.119,000 --> 0:00:56,000
And the audience for such a long time was in a position

17
0:00:56.334,000 --> 0:00:58,000
where they didn't have any way of affecting news

18
0:00:59.024,000 --> 0:01:01,000
or making any change. They couldn't really connect.

19
0:01:01.291,000 --> 0:01:02,000
And that's changed irrevocably.

20
0:01:02.767,000 --> 0:01:04,000
My first connection with the news media was

21
0:01:05.656,000 --> 0:01:08,000
in 1984, the BBC had a one-day strike.

22
0:01:09.467,000 --> 0:01:12,000
I wasn't happy. I was angry. I couldn't see my cartoons.

23
0:01:12.755,000 --> 0:01:14,000
So I wrote a letter.

24
0:01:15.302,000 --> 0:01:17,000
And it's a very effective way of ending your hate mail:

25
0:01:18.151,000 --> 0:01:21,000
"Love Markham, Aged 4." Still works.

26
0:01:21.238,000 --> 0:01:24,000
I'm not sure if I had any impact on the one-day strike,

27
0:01:24.249,000 --> 0:01:26,000
but what I do know is that it took them three weeks to get back to me.

28
0:01:26.931,000 --> 0:01:28,000
And that was the round journey. It took that long for anyone

29
0:01:29.091,000 --> 0:01:31,000
to have any impact and get some feedback.

30
0:01:31.284,000 --> 0:01:33,000
And that's changed now because, as journalists,

31
0:01:33.766,000 --> 0:01:36,000
we interact in real time. We're not in a position

32
0:01:36.932,000 --> 0:01:38,000
where the audience is reacting to news.

33
0:01:39.266,000 --> 0:01:42,000
We're reacting to the audience, and we're actually relying on them.

34
0:01:43.023,000 --> 0:01:45,000
They're helping us find the news. They're helping us

35
0:01:45.409,000 --> 0:01:49,000
figure out what is the best angle to take and what is the stuff that they want to hear.

36
0:01:50.179,000 --> 0:01:53,000
So it's a real-time thing. It's much quicker. It's happening

37
0:01:54.083,000 --> 0:01:59,000
on a constant basis, and the journalist is always playing catch up.

38
0:02:,000 --> 0:02:02,000
To give an example of how we rely on the audience,

39
0:02:02.633,000 --> 0:02:06,000
on the 5th of September in Costa Rica, an earthquake hit.

40
0:02:07.17,000 --> 0:02:09,000
It was a 7.6 magnitude. It was fairly big.

41
0:02:09.496,000 --> 0:02:11,000
And 60 seconds is the amount of time it took

42
0:02:12.376,000 --> 0:02:14,000
for it to travel 250 kilometers to Managua.

43
0:02:14.941,000 --> 0:02:18,000
So the ground shook in Managua 60 seconds after it hit the epicenter.

44
0:02:19.086,000 --> 0:02:21,000
Thirty seconds later, the first message went onto Twitter,

45
0:02:21.742,000 --> 0:02:23,000
and this was someone saying "temblor," which means earthquake.

46
0:02:24.603,000 --> 0:02:26,000
So 60 seconds was how long it took

47
0:02:26.94,000 --> 0:02:27,000
for the physical earthquake to travel.

48
0:02:28.846,000 --> 0:02:3,000
Thirty seconds later news of that earthquake had traveled

49
0:02:31.406,000 --> 0:02:33,000
all around the world, instantly. Everyone in the world,

50
0:02:34.38,000 --> 0:02:37,000
hypothetically, had the potential to know that an earthquake

51
0:02:37.577,000 --> 0:02:39,000
was happening in Managua.

52
0:02:39.991,000 --> 0:02:41,000
And that happened because this one person had

53
0:02:42.342,000 --> 0:02:45,000
a documentary instinct, which was to post a status update,

54
0:02:46.291,000 --> 0:02:48,000
which is what we all do now, so if something happens,

55
0:02:48.823,000 --> 0:02:5,000
we put our status update, or we post a photo,

56
0:02:50.905,000 --> 0:02:53,000
we post a video, and it all goes up into the cloud in a constant stream.

57
0:02:54.683,000 --> 0:02:56,000
And what that means is just constant,

58
0:02:57.444,000 --> 0:02:59,000
huge volumes of data going up.

59
0:02:59.85,000 --> 0:03:01,000
It's actually staggering. When you look at the numbers,

60
0:03:02.131,000 --> 0:03:04,000
every minute there are 72 more hours

61
0:03:05.122,000 --> 0:03:06,000
of video on YouTube.

62
0:03:06.504,000 --> 0:03:09,000
So that's, every second, more than an hour of video gets uploaded.

63
0:03:09.786,000 --> 0:03:13,000
And in photos, Instagram, 58 photos are uploaded to Instagram a second.

64
0:03:14.042,000 --> 0:03:17,000
More than three and a half thousand photos go up onto Facebook.

65
0:03:17.798,000 --> 0:03:2,000
So by the time I'm finished talking here, there'll be 864

66
0:03:21.506,000 --> 0:03:24,000
more hours of video on Youtube than there were when I started,

67
0:03:25.124,000 --> 0:03:28,000
and two and a half million more photos on Facebook and Instagram than when I started.

68
0:03:28.987,000 --> 0:03:31,000
So it's an interesting position to be in as a journalist,

69
0:03:32.919,000 --> 0:03:34,000
because we should have access to everything.

70
0:03:35.335,000 --> 0:03:37,000
Any event that happens anywhere in the world, I should be able to know about it

71
0:03:38.233,000 --> 0:03:41,000
pretty much instantaneously, as it happens, for free.

72
0:03:42.164,000 --> 0:03:45,000
And that goes for every single person in this room.

73
0:03:45.329,000 --> 0:03:47,000
The only problem is, when you have that much information,

74
0:03:47.939,000 --> 0:03:49,000
you have to find the good stuff, and that can be

75
0:03:50.226,000 --> 0:03:51,000
incredibly difficult when you're dealing with those volumes.

76
0:03:52.214,000 --> 0:03:54,000
And nowhere was this brought home more than during

77
0:03:54.533,000 --> 0:03:56,000
Hurricane Sandy. So what you had in Hurricane Sandy was

78
0:03:57.437,000 --> 0:04:,000
a superstorm, the likes of which we hadn't seen for a long time,

79
0:04:00.464,000 --> 0:04:03,000
hitting the iPhone capital of the universe -- (Laughter) --

80
0:04:03.607,000 --> 0:04:07,000
and you got volumes of media like we'd never seen before.

81
0:04:07.822,000 --> 0:04:09,000
And that meant that journalists had to deal with fakes,

82
0:04:10.566,000 --> 0:04:12,000
so we had to deal with old photos that were being reposted.

83
0:04:13.482,000 --> 0:04:15,000
We had to deal with composite images

84
0:04:15.73,000 --> 0:04:18,000
that were merging photos from previous storms.

85
0:04:18.913,000 --> 0:04:23,000
We had to deal with images from films like "The Day After Tomorrow." (Laughter)

86
0:04:24.147,000 --> 0:04:26,000
And we had to deal with images that were so realistic

87
0:04:26.981,000 --> 0:04:28,000
it was nearly difficult to tell if they were real at all.

88
0:04:29.351,000 --> 0:04:33,000
(Laughter)

89
0:04:33.664,000 --> 0:04:36,000
But joking aside, there were images like this one from Instagram

90
0:04:37.388,000 --> 0:04:39,000
which was subjected to a grilling by journalists.

91
0:04:39.664,000 --> 0:04:41,000
They weren't really sure. It was filtered in Instagram.

92
0:04:41.897,000 --> 0:04:43,000
The lighting was questioned. Everything was questioned about it.

93
0:04:44.42,000 --> 0:04:46,000
And it turned out to be true. It was from Avenue C

94
0:04:46.713,000 --> 0:04:48,000
in downtown Manhattan, which was flooded.

95
0:04:48.873,000 --> 0:04:5,000
And the reason that they could tell that it was real

96
0:04:50.973,000 --> 0:04:52,000
was because they could get to the source, and in this case,

97
0:04:53.062,000 --> 0:04:55,000
these guys were New York food bloggers.

98
0:04:55.169,000 --> 0:04:57,000
They were well respected. They were known.

99
0:04:57.199,000 --> 0:05:,000
So this one wasn't a debunk, it was actually something that they could prove.

100
0:05:00.291,000 --> 0:05:02,000
And that was the job of the journalist. It was filtering all this stuff.

101
0:05:03.209,000 --> 0:05:05,000
And you were, instead of going and finding the information

102
0:05:05.92,000 --> 0:05:07,000
and bringing it back to the reader, you were holding back

103
0:05:08.487,000 --> 0:05:1,000
the stuff that was potentially damaging.

104
0:05:10.547,000 --> 0:05:12,000
And finding the source becomes more and more important --

105
0:05:13.505,000 --> 0:05:16,000
finding the good source -- and Twitter is where most journalists now go.

106
0:05:17.239,000 --> 0:05:2,000
It's like the de facto real-time newswire,

107
0:05:20.392,000 --> 0:05:22,000
if you know how to use it, because there is so much on Twitter.

108
0:05:23.359,000 --> 0:05:25,000
And a good example of how useful it can be

109
0:05:25.744,000 --> 0:05:28,000
but also how difficult was the Egyptian revolution in 2011.

110
0:05:29.277,000 --> 0:05:31,000
As a non-Arabic speaker, as someone who was looking

111
0:05:31.923,000 --> 0:05:33,000
from the outside, from Dublin,

112
0:05:34.224,000 --> 0:05:35,000
Twitter lists, and lists of good sources,

113
0:05:36.016,000 --> 0:05:39,000
people we could establish were credible, were really important.

114
0:05:39.638,000 --> 0:05:41,000
And how do you build a list like that from scratch?

115
0:05:42.147,000 --> 0:05:44,000
Well, it can be quite difficult, but you have to know what to look for.

116
0:05:44.577,000 --> 0:05:46,000
This visualization was done by an Italian academic.

117
0:05:47.435,000 --> 0:05:5,000
He's called André Pannison, and he basically

118
0:05:50.829,000 --> 0:05:52,000
took the Twitter conversation in Tahrir Square

119
0:05:53.004,000 --> 0:05:56,000
on the day that Hosni Mubarak would eventually resign,

120
0:05:56.458,000 --> 0:05:58,000
and the dots you can see are retweets, so when someone

121
0:05:59.09,000 --> 0:06:01,000
retweets a message, a connection is made between two dots,

122
0:06:01.869,000 --> 0:06:03,000
and the more times that message is retweeted by other people,

123
0:06:04.479,000 --> 0:06:07,000
the more you get to see these nodes, these connections being made.

124
0:06:07.685,000 --> 0:06:08,000
And it's an amazing way of visualizing the conversation,

125
0:06:09.607,000 --> 0:06:11,000
but what you get is hints at who is more interesting

126
0:06:12.318,000 --> 0:06:14,000
and who is worth investigating.

127
0:06:14.999,000 --> 0:06:16,000
And as the conversation grew and grew, it became

128
0:06:17.878,000 --> 0:06:19,000
more and more lively, and eventually you were left

129
0:06:20.162,000 --> 0:06:24,000
with this huge, big, rhythmic pointer of this conversation.

130
0:06:24.943,000 --> 0:06:25,000
You could find the nodes, though, and then you went,

131
0:06:26.752,000 --> 0:06:28,000
and you go, "Right, I've got to investigate these people.

132
0:06:29.046,000 --> 0:06:3,000
These are the ones that are obviously making sense.

133
0:06:30.76,000 --> 0:06:32,000
Let's see who they are."

134
0:06:33.069,000 --> 0:06:35,000
Now in the deluge of information, this is where

135
0:06:35.759,000 --> 0:06:38,000
the real-time web gets really interesting for a journalist like myself,

136
0:06:38.966,000 --> 0:06:39,000
because we have more tools than ever

137
0:06:40.94,000 --> 0:06:42,000
to do that kind of investigation.

138
0:06:43.697,000 --> 0:06:46,000
And when you start digging into the sources, you can go

139
0:06:46.706,000 --> 0:06:48,000
further and further than you ever could before.

140
0:06:49.005,000 --> 0:06:52,000
Sometimes you come across a piece of content that

141
0:06:52.357,000 --> 0:06:55,000
is so compelling, you want to use it, you're dying to use it,

142
0:06:55.817,000 --> 0:06:57,000
but you're not 100 percent sure if you can because

143
0:06:58.492,000 --> 0:06:59,000
you don't know if the source is credible.

144
0:06:59.699,000 --> 0:07:01,000
You don't know if it's a scrape. You don't know if it's a re-upload.

145
0:07:01.881,000 --> 0:07:02,000
And you have to do that investigative work.

146
0:07:03.59,000 --> 0:07:05,000
And this video, which I'm going to let run through,

147
0:07:05.934,000 --> 0:07:07,000
was one we discovered a couple of weeks ago.

148
0:07:08.923,000 --> 0:07:1,000
Video: Getting real windy in just a second.

149
0:07:11.122,000 --> 0:07:15,000
(Rain and wind sounds)

150
0:07:16.01,000 --> 0:07:19,000
(Explosion) Oh, shit!

151
0:07:19.177,000 --> 0:07:21,000
Markham Nolan: Okay, so now if you're a news producer, this is something

152
0:07:22.114,000 --> 0:07:24,000
you'd love to run with, because obviously, this is gold.

153
0:07:24.666,000 --> 0:07:26,000
You know? This is a fantastic reaction from someone,

154
0:07:26.929,000 --> 0:07:28,000
very genuine video that they've shot in their back garden.

155
0:07:29.499,000 --> 0:07:32,000
But how do you find if this person, if it's true, if it's faked,

156
0:07:32.993,000 --> 0:07:34,000
or if it's something that's old and that's been reposted?

157
0:07:35.651,000 --> 0:07:37,000
So we set about going to work on this video, and

158
0:07:37.877,000 --> 0:07:39,000
the only thing that we had to go on was the username on the YouTube account.

159
0:07:40.737,000 --> 0:07:42,000
There was only one video posted to that account,

160
0:07:43.088,000 --> 0:07:44,000
and the username was Rita Krill.

161
0:07:44.576,000 --> 0:07:47,000
And we didn't know if Rita existed or if it was a fake name.

162
0:07:47.868,000 --> 0:07:49,000
But we started looking, and we used free Internet tools to do so.

163
0:07:50.781,000 --> 0:07:53,000
The first one was called Spokeo, which allowed us to look for Rita Krills.

164
0:07:54.089,000 --> 0:07:56,000
So we looked all over the U.S. We found them in New York,

165
0:07:56.471,000 --> 0:07:58,000
we found them in Pennsylvania, Nevada and Florida.

166
0:07:59.233,000 --> 0:08:01,000
So we went and we looked for a second free Internet tool

167
0:08:01.882,000 --> 0:08:03,000
called Wolfram Alpha, and we checked the weather reports

168
0:08:04.349,000 --> 0:08:06,000
for the day in which this video had been uploaded,

169
0:08:06.846,000 --> 0:08:07,000
and when we went through all those various cities,

170
0:08:08.729,000 --> 0:08:11,000
we found that in Florida, there were thunderstorms and rain on the day.

171
0:08:12.225,000 --> 0:08:14,000
So we went to the white pages, and we found,

172
0:08:14.87,000 --> 0:08:16,000
we looked through the Rita Krills in the phonebook,

173
0:08:17.794,000 --> 0:08:18,000
and we looked through a couple of different addresses,

174
0:08:19.366,000 --> 0:08:22,000
and that took us to Google Maps, where we found a house.

175
0:08:22.682,000 --> 0:08:23,000
And we found a house with a swimming pool that looked

176
0:08:24.597,000 --> 0:08:26,000
remarkably like Rita's. So we went back to the video,

177
0:08:27.515,000 --> 0:08:29,000
and we had to look for clues that we could cross-reference.

178
0:08:30.486,000 --> 0:08:33,000
So if you look in the video, there's the big umbrella,

179
0:08:33.701,000 --> 0:08:34,000
there's a white lilo in the pool,

180
0:08:35.546,000 --> 0:08:37,000
there are some unusually rounded edges in the swimming pool,

181
0:08:37.986,000 --> 0:08:39,000
and there's two trees in the background.

182
0:08:40.04,000 --> 0:08:42,000
And we went back to Google Maps, and we looked a little bit closer,

183
0:08:42.467,000 --> 0:08:44,000
and sure enough, there's the white lilo,

184
0:08:45.138,000 --> 0:08:47,000
there are the two trees,

185
0:08:48.132,000 --> 0:08:49,000
there's the umbrella. It's actually folded in this photo.

186
0:08:50.118,000 --> 0:08:53,000
Little bit of trickery. And there are the rounded edges on the swimming pool.

187
0:08:53.896,000 --> 0:08:56,000
So we were able to call Rita, clear the video,

188
0:08:57.046,000 --> 0:08:59,000
make sure that it had been shot, and then our clients

189
0:08:59.132,000 --> 0:09:02,000
were delighted because they were able to run it without being worried.

190
0:09:02.326,000 --> 0:09:03,000
Sometimes the search for truth, though,

191
0:09:04.101,000 --> 0:09:08,000
is a little bit less flippant, and it has much greater consequences.

192
0:09:08.51,000 --> 0:09:1,000
Syria has been really interesting for us, because obviously

193
0:09:11.493,000 --> 0:09:13,000
a lot of the time you're trying to debunk stuff that can be

194
0:09:14.174,000 --> 0:09:17,000
potentially war crime evidence, so this is where YouTube

195
0:09:17.973,000 --> 0:09:19,000
actually becomes the most important repository

196
0:09:20.33,000 --> 0:09:24,000
of information about what's going on in the world.

197
0:09:24.48,000 --> 0:09:26,000
So this video, I'm not going to show you the whole thing,

198
0:09:27.234,000 --> 0:09:29,000
because it's quite gruesome, but you'll hear some of the sounds.

199
0:09:29.955,000 --> 0:09:31,000
This is from Hama.

200
0:09:32.283,000 --> 0:09:34,000
Video: (Shouting)

201
0:09:35.253,000 --> 0:09:38,000
And what this video shows, when you watch the whole thing through,

202
0:09:39.157,000 --> 0:09:41,000
is bloody bodies being taken out of a pickup truck

203
0:09:41.918,000 --> 0:09:43,000
and thrown off a bridge.

204
0:09:44.523,000 --> 0:09:46,000
The allegations were that these guys were Muslim Brotherhood

205
0:09:47.304,000 --> 0:09:49,000
and they were throwing Syrian Army officers' bodies

206
0:09:50.179,000 --> 0:09:52,000
off the bridge, and they were cursing and using blasphemous language,

207
0:09:53.113,000 --> 0:09:55,000
and there were lots of counterclaims about who they were,

208
0:09:55.495,000 --> 0:09:57,000
and whether or not they were what the video said it was.

209
0:09:57.737,000 --> 0:10:,000
So we talked to some sources in Hama who we had been

210
0:10:01.003,000 --> 0:10:03,000
back and forth with on Twitter, and we asked them about this,

211
0:10:03.336,000 --> 0:10:06,000
and the bridge was interesting to us because it was something we could identify.

212
0:10:07.15,000 --> 0:10:09,000
Three different sources said three different things about the bridge.

213
0:10:10.064,000 --> 0:10:12,000
They said, one, the bridge doesn't exist.

214
0:10:12.326,000 --> 0:10:15,000
Another one said the bridge does exist, but it's not in Hama. It's somewhere else.

215
0:10:15.85,000 --> 0:10:17,000
And the third one said, "I think the bridge does exist,

216
0:10:18.412,000 --> 0:10:21,000
but the dam upstream of the bridge was closed,

217
0:10:21.776,000 --> 0:10:24,000
so the river should actually have been dry, so this doesn't make sense."

218
0:10:25.173,000 --> 0:10:27,000
So that was the only one that gave us a clue.

219
0:10:27.785,000 --> 0:10:28,000
We looked through the video for other clues.

220
0:10:29.01,000 --> 0:10:32,000
We saw the distinctive railings, which we could use.

221
0:10:32.099,000 --> 0:10:35,000
We looked at the curbs. The curbs were throwing shadows south,

222
0:10:35.843,000 --> 0:10:37,000
so we could tell the bridge was running east-west across the river.

223
0:10:38.16,000 --> 0:10:39,000
It had black-and-white curbs.

224
0:10:40.116,000 --> 0:10:41,000
As we looked at the river itself, you could see there's

225
0:10:42.102,000 --> 0:10:44,000
a concrete stone on the west side. There's a cloud of blood.

226
0:10:45.056,000 --> 0:10:46,000
That's blood in the river. So the river is flowing

227
0:10:46.79,000 --> 0:10:47,000
south to north. That's what that tells me.

228
0:10:48.487,000 --> 0:10:5,000
And also, as you look away from the bridge,

229
0:10:50.836,000 --> 0:10:51,000
there's a divot on the left-hand side of the bank,

230
0:10:52.485,000 --> 0:10:54,000
and the river narrows.

231
0:10:54.915,000 --> 0:10:56,000
So onto Google Maps we go, and we start

232
0:10:57.494,000 --> 0:10:59,000
looking through literally every single bridge.

233
0:10:59.552,000 --> 0:11:02,000
We go to the dam that we talked about, we start just

234
0:11:03.032,000 --> 0:11:06,000
literally going through every time that road crosses the river,

235
0:11:06.642,000 --> 0:11:07,000
crossing off the bridges that don't match.

236
0:11:08.38,000 --> 0:11:09,000
We're looking for one that crosses east-west.

237
0:11:10.143,000 --> 0:11:11,000
And we get to Hama. We get all the way from the dam

238
0:11:12.095,000 --> 0:11:14,000
to Hama and there's no bridge.

239
0:11:14.098,000 --> 0:11:16,000
So we go a bit further. We switch to the satellite view,

240
0:11:16.582,000 --> 0:11:18,000
and we find another bridge, and everything starts to line up.

241
0:11:19.502,000 --> 0:11:22,000
The bridge looks like it's crossing the river east to west.

242
0:11:22.54,000 --> 0:11:25,000
So this could be our bridge. And we zoom right in.

243
0:11:25.701,000 --> 0:11:27,000
We start to see that it's got a median, so it's a two-lane bridge.

244
0:11:28.603,000 --> 0:11:31,000
And it's got the black-and-white curbs that we saw in the video,

245
0:11:32.249,000 --> 0:11:34,000
and as we click through it, you can see someone's

246
0:11:34.561,000 --> 0:11:36,000
uploaded photos to go with the map, which is very handy,

247
0:11:37.515,000 --> 0:11:39,000
so we click into the photos. And the photos start showing us

248
0:11:40.202,000 --> 0:11:42,000
more detail that we can cross-reference with the video.

249
0:11:42.824,000 --> 0:11:45,000
The first thing that we see is we see black-and-white curbing,

250
0:11:46.547,000 --> 0:11:48,000
which is handy because we've seen that before.

251
0:11:48.652,000 --> 0:11:51,000
We see the distinctive railing that we saw the guys

252
0:11:52.151,000 --> 0:11:54,000
throwing the bodies over.

253
0:11:54.502,000 --> 0:11:56,000
And we keep going through it until we're certain that this is our bridge.

254
0:11:57.157,000 --> 0:11:58,000
So what does that tell me? I've got to go back now

255
0:11:58.681,000 --> 0:12:,000
to my three sources and look at what they told me:

256
0:12:00.994,000 --> 0:12:01,000
the one who said the bridge didn't exist,

257
0:12:02.719,000 --> 0:12:03,000
the one who said the bridge wasn't in Hama,

258
0:12:04.578,000 --> 0:12:07,000
and the one guy who said, "Yes, the bridge does exist, but I'm not sure about the water levels."

259
0:12:08.531,000 --> 0:12:11,000
Number three is looking like the most truthful all of a sudden,

260
0:12:11.862,000 --> 0:12:13,000
and we've been able to find that out using some free Internet tools

261
0:12:14.843,000 --> 0:12:16,000
sitting in a cubicle in an office in Dublin

262
0:12:17.363,000 --> 0:12:18,000
in the space of 20 minutes.

263
0:12:18.85,000 --> 0:12:2,000
And that's part of the joy of this. Although the web

264
0:12:21.289,000 --> 0:12:24,000
is running like a torrent, there's so much information there

265
0:12:24.554,000 --> 0:12:27,000
that it's incredibly hard to sift and getting harder every day,

266
0:12:27.741,000 --> 0:12:3,000
if you use them intelligently, you can find out incredible information.

267
0:12:31.068,000 --> 0:12:33,000
Given a couple of clues, I could probably find out

268
0:12:33.463,000 --> 0:12:36,000
a lot of things about most of you in the audience that you might not like me finding out.

269
0:12:36.997,000 --> 0:12:39,000
But what it tells me is that, at a time when

270
0:12:40.002,000 --> 0:12:44,000
there's more -- there's a greater abundance of information than there ever has been,

271
0:12:44.031,000 --> 0:12:46,000
it's harder to filter, we have greater tools.

272
0:12:46.664,000 --> 0:12:47,000
We have free Internet tools that allow us,

273
0:12:48.527,000 --> 0:12:5,000
help us do this kind of investigation.

274
0:12:50.753,000 --> 0:12:51,000
We have algorithms that are smarter than ever before,

275
0:12:52.576,000 --> 0:12:54,000
and computers that are quicker than ever before.

276
0:12:54.997,000 --> 0:12:57,000
But here's the thing. Algorithms are rules. They're binary.

277
0:12:58.424,000 --> 0:12:59,000
They're yes or no, they're black or white.

278
0:13:00.209,000 --> 0:13:03,000
Truth is never binary. Truth is a value.

279
0:13:03.763,000 --> 0:13:07,000
Truth is emotional, it's fluid, and above all, it's human.

280
0:13:08.427,000 --> 0:13:1,000
No matter how quick we get with computers, no matter

281
0:13:10.534,000 --> 0:13:12,000
how much information we have, you'll never be able

282
0:13:12.918,000 --> 0:13:14,000
to remove the human from the truth-seeking exercise,

283
0:13:15.914,000 --> 0:13:18,000
because in the end, it is a uniquely human trait.

284
0:13:19.572,000 --> 0:13:23,000
Thanks very much. (Applause)

