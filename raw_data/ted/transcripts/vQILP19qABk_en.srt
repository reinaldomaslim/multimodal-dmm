1
0:00:12.82,000 --> 0:00:16,000
Roy Price is a man that most of you have probably never heard about,

2
0:00:17.12,000 --> 0:00:19,000
even though he may have been responsible

3
0:00:19.64,000 --> 0:00:25,000
for 22 somewhat mediocre minutes of your life on April 19, 2013.

4
0:00:26.56,000 --> 0:00:29,000
He may have also been responsible for 22 very entertaining minutes,

5
0:00:29.76,000 --> 0:00:31,000
but not very many of you.

6
0:00:32.04,000 --> 0:00:33,000
And all of that goes back to a decision

7
0:00:33.96,000 --> 0:00:35,000
that Roy had to make about three years ago.

8
0:00:35.984,000 --> 0:00:39,000
So you see, Roy Price is a senior executive with Amazon Studios.

9
0:00:40.84,000 --> 0:00:43,000
That's the TV production company of Amazon.

10
0:00:43.88,000 --> 0:00:46,000
He's 47 years old, slim, spiky hair,

11
0:00:47.16,000 --> 0:00:51,000
describes himself on Twitter as "movies, TV, technology, tacos."

12
0:00:52,000 --> 0:00:57,000
And Roy Price has a very responsible job, because it's his responsibility

13
0:00:57.2,000 --> 0:01:01,000
to pick the shows, the original content that Amazon is going to make.

14
0:01:01.28,000 --> 0:01:03,000
And of course that's a highly competitive space.

15
0:01:03.64,000 --> 0:01:05,000
I mean, there are so many TV shows already out there,

16
0:01:06.4,000 --> 0:01:08,000
that Roy can't just choose any show.

17
0:01:08.6,000 --> 0:01:12,000
He has to find shows that are really, really great.

18
0:01:12.72,000 --> 0:01:14,000
So in other words, he has to find shows

19
0:01:15.56,000 --> 0:01:17,000
that are on the very right end of this curve here.

20
0:01:17.96,000 --> 0:01:19,000
So this curve here is the rating distribution

21
0:01:20.64,000 --> 0:01:24,000
of about 2,500 TV shows on the website IMDB,

22
0:01:25.04,000 --> 0:01:27,000
and the rating goes from one to 10,

23
0:01:27.96,000 --> 0:01:29,000
and the height here shows you how many shows get that rating.

24
0:01:30.96,000 --> 0:01:34,000
So if your show gets a rating of nine points or higher, that's a winner.

25
0:01:35.68,000 --> 0:01:36,000
Then you have a top two percent show.

26
0:01:37.52,000 --> 0:01:4,000
That's shows like "Breaking Bad," "Game of Thrones," "The Wire,"

27
0:01:41.44,000 --> 0:01:43,000
so all of these shows that are addictive,

28
0:01:43.76,000 --> 0:01:46,000
whereafter you've watched a season, your brain is basically like,

29
0:01:46.84,000 --> 0:01:48,000
"Where can I get more of these episodes?"

30
0:01:49.04,000 --> 0:01:5,000
That kind of show.

31
0:01:50.92,000 --> 0:01:52,000
On the left side, just for clarity, here on that end,

32
0:01:53.44,000 --> 0:01:56,000
you have a show called "Toddlers and Tiaras" --

33
0:01:56.64,000 --> 0:01:58,000
(Laughter)

34
0:01:59.32,000 --> 0:02:,000
-- which should tell you enough

35
0:02:00.88,000 --> 0:02:02,000
about what's going on on that end of the curve.

36
0:02:03.095,000 --> 0:02:07,000
Now, Roy Price is not worried about getting on the left end of the curve,

37
0:02:07.28,000 --> 0:02:09,000
because I think you would have to have some serious brainpower

38
0:02:10.24,000 --> 0:02:11,000
to undercut "Toddlers and Tiaras."

39
0:02:11.96,000 --> 0:02:14,000
So what he's worried about is this middle bulge here,

40
0:02:15.92,000 --> 0:02:16,000
the bulge of average TV,

41
0:02:17.76,000 --> 0:02:19,000
you know, those shows that aren't really good or really bad,

42
0:02:20.639,000 --> 0:02:21,000
they don't really get you excited.

43
0:02:22.32,000 --> 0:02:26,000
So he needs to make sure that he's really on the right end of this.

44
0:02:27.2,000 --> 0:02:28,000
So the pressure is on,

45
0:02:28.8,000 --> 0:02:3,000
and of course it's also the first time

46
0:02:31,000 --> 0:02:33,000
that Amazon is even doing something like this,

47
0:02:33.2,000 --> 0:02:36,000
so Roy Price does not want to take any chances.

48
0:02:36.56,000 --> 0:02:38,000
He wants to engineer success.

49
0:02:39.04,000 --> 0:02:4,000
He needs a guaranteed success,

50
0:02:40.84,000 --> 0:02:42,000
and so what he does is, he holds a competition.

51
0:02:43.44,000 --> 0:02:46,000
So he takes a bunch of ideas for TV shows,

52
0:02:46.6,000 --> 0:02:48,000
and from those ideas, through an evaluation,

53
0:02:48.92,000 --> 0:02:52,000
they select eight candidates for TV shows,

54
0:02:53.04,000 --> 0:02:56,000
and then he just makes the first episode of each one of these shows

55
0:02:56.28,000 --> 0:02:59,000
and puts them online for free for everyone to watch.

56
0:02:59.44,000 --> 0:03:01,000
And so when Amazon is giving out free stuff,

57
0:03:01.72,000 --> 0:03:02,000
you're going to take it, right?

58
0:03:03.28,000 --> 0:03:08,000
So millions of viewers are watching those episodes.

59
0:03:08.44,000 --> 0:03:11,000
What they don't realize is that, while they're watching their shows,

60
0:03:11.68,000 --> 0:03:13,000
actually, they are being watched.

61
0:03:14,000 --> 0:03:16,000
They are being watched by Roy Price and his team,

62
0:03:16.36,000 --> 0:03:17,000
who record everything.

63
0:03:17.76,000 --> 0:03:2,000
They record when somebody presses play, when somebody presses pause,

64
0:03:21.16,000 --> 0:03:23,000
what parts they skip, what parts they watch again.

65
0:03:23.72,000 --> 0:03:25,000
So they collect millions of data points,

66
0:03:26,000 --> 0:03:28,000
because they want to have those data points

67
0:03:28.12,000 --> 0:03:3,000
to then decide which show they should make.

68
0:03:30.84,000 --> 0:03:32,000
And sure enough, so they collect all the data,

69
0:03:33.04,000 --> 0:03:35,000
they do all the data crunching, and an answer emerges,

70
0:03:35.64,000 --> 0:03:36,000
and the answer is,

71
0:03:36.88,000 --> 0:03:41,000
"Amazon should do a sitcom about four Republican US Senators."

72
0:03:42.44,000 --> 0:03:43,000
They did that show.

73
0:03:43.68,000 --> 0:03:45,000
So does anyone know the name of the show?

74
0:03:46.72,000 --> 0:03:47,000
(Audience: "Alpha House.")

75
0:03:48.04,000 --> 0:03:49,000
Yes, "Alpha House,"

76
0:03:49.52,000 --> 0:03:53,000
but it seems like not too many of you here remember that show, actually,

77
0:03:53.64,000 --> 0:03:54,000
because it didn't turn out that great.

78
0:03:55.52,000 --> 0:03:56,000
It's actually just an average show,

79
0:03:57.4,000 --> 0:04:01,000
actually -- literally, in fact, because the average of this curve here is at 7.4,

80
0:04:02,000 --> 0:04:04,000
and "Alpha House" lands at 7.5,

81
0:04:04.44,000 --> 0:04:06,000
so a slightly above average show,

82
0:04:06.48,000 --> 0:04:08,000
but certainly not what Roy Price and his team were aiming for.

83
0:04:10.32,000 --> 0:04:12,000
Meanwhile, however, at about the same time,

84
0:04:13.2,000 --> 0:04:14,000
at another company,

85
0:04:14.8,000 --> 0:04:18,000
another executive did manage to land a top show using data analysis,

86
0:04:19.04,000 --> 0:04:2,000
and his name is Ted,

87
0:04:20.64,000 --> 0:04:23,000
Ted Sarandos, who is the Chief Content Officer of Netflix,

88
0:04:24.08,000 --> 0:04:26,000
and just like Roy, he's on a constant mission

89
0:04:26.24,000 --> 0:04:27,000
to find that great TV show,

90
0:04:27.76,000 --> 0:04:29,000
and he uses data as well to do that,

91
0:04:29.8,000 --> 0:04:31,000
except he does it a little bit differently.

92
0:04:31.839,000 --> 0:04:34,000
So instead of holding a competition, what he did -- and his team of course --

93
0:04:35.6,000 --> 0:04:38,000
was they looked at all the data they already had about Netflix viewers,

94
0:04:39.16,000 --> 0:04:41,000
you know, the ratings they give their shows,

95
0:04:41.28,000 --> 0:04:43,000
the viewing histories, what shows people like, and so on.

96
0:04:44,000 --> 0:04:45,000
And then they use that data to discover

97
0:04:45.92,000 --> 0:04:47,000
all of these little bits and pieces about the audience:

98
0:04:48.56,000 --> 0:04:49,000
what kinds of shows they like,

99
0:04:50.04,000 --> 0:04:52,000
what kind of producers, what kind of actors.

100
0:04:52.16,000 --> 0:04:54,000
And once they had all of these pieces together,

101
0:04:54.76,000 --> 0:04:55,000
they took a leap of faith,

102
0:04:56.44,000 --> 0:04:58,000
and they decided to license

103
0:04:58.56,000 --> 0:05:,000
not a sitcom about four Senators

104
0:05:01.04,000 --> 0:05:03,000
but a drama series about a single Senator.

105
0:05:04.76,000 --> 0:05:05,000
You guys know the show?

106
0:05:06.44,000 --> 0:05:07,000
(Laughter)

107
0:05:07.76,000 --> 0:05:1,000
Yes, "House of Cards," and Netflix of course, nailed it with that show,

108
0:05:11.52,000 --> 0:05:13,000
at least for the first two seasons.

109
0:05:13.68,000 --> 0:05:16,000
(Laughter) (Applause)

110
0:05:17.68,000 --> 0:05:2,000
"House of Cards" gets a 9.1 rating on this curve,

111
0:05:20.88,000 --> 0:05:23,000
so it's exactly where they wanted it to be.

112
0:05:24.08,000 --> 0:05:26,000
Now, the question of course is, what happened here?

113
0:05:26.52,000 --> 0:05:28,000
So you have two very competitive, data-savvy companies.

114
0:05:29.2,000 --> 0:05:31,000
They connect all of these millions of data points,

115
0:05:32.08,000 --> 0:05:34,000
and then it works beautifully for one of them,

116
0:05:34.48,000 --> 0:05:35,000
and it doesn't work for the other one.

117
0:05:36.36,000 --> 0:05:37,000
So why?

118
0:05:37.6,000 --> 0:05:4,000
Because logic kind of tells you that this should be working all the time.

119
0:05:41.08,000 --> 0:05:43,000
I mean, if you're collecting millions of data points

120
0:05:43.56,000 --> 0:05:44,000
on a decision you're going to make,

121
0:05:45.32,000 --> 0:05:47,000
then you should be able to make a pretty good decision.

122
0:05:47.96,000 --> 0:05:49,000
You have 200 years of statistics to rely on.

123
0:05:50.2,000 --> 0:05:53,000
You're amplifying it with very powerful computers.

124
0:05:53.24,000 --> 0:05:56,000
The least you could expect is good TV, right?

125
0:05:57.88,000 --> 0:05:59,000
And if data analysis does not work that way,

126
0:06:01.52,000 --> 0:06:03,000
then it actually gets a little scary,

127
0:06:03.6,000 --> 0:06:06,000
because we live in a time where we're turning to data more and more

128
0:06:07.44,000 --> 0:06:11,000
to make very serious decisions that go far beyond TV.

129
0:06:12.76,000 --> 0:06:15,000
Does anyone here know the company Multi-Health Systems?

130
0:06:17.08,000 --> 0:06:18,000
No one. OK, that's good actually.

131
0:06:18.76,000 --> 0:06:21,000
OK, so Multi-Health Systems is a software company,

132
0:06:22,000 --> 0:06:24,000
and I hope that nobody here in this room

133
0:06:24.84,000 --> 0:06:27,000
ever comes into contact with that software,

134
0:06:28.04,000 --> 0:06:3,000
because if you do, it means you're in prison.

135
0:06:30.16,000 --> 0:06:31,000
(Laughter)

136
0:06:31.36,000 --> 0:06:34,000
If someone here in the US is in prison, and they apply for parole,

137
0:06:34.92,000 --> 0:06:38,000
then it's very likely that data analysis software from that company

138
0:06:39.24,000 --> 0:06:42,000
will be used in determining whether to grant that parole.

139
0:06:42.88,000 --> 0:06:44,000
So it's the same principle as Amazon and Netflix,

140
0:06:45.48,000 --> 0:06:49,000
but now instead of deciding whether a TV show is going to be good or bad,

141
0:06:50.12,000 --> 0:06:52,000
you're deciding whether a person is going to be good or bad.

142
0:06:53.04,000 --> 0:06:58,000
And mediocre TV, 22 minutes, that can be pretty bad,

143
0:06:58.56,000 --> 0:07:,000
but more years in prison, I guess, even worse.

144
0:07:02.36,000 --> 0:07:06,000
And unfortunately, there is actually some evidence that this data analysis,

145
0:07:06.52,000 --> 0:07:1,000
despite having lots of data, does not always produce optimum results.

146
0:07:10.76,000 --> 0:07:12,000
And that's not because a company like Multi-Health Systems

147
0:07:13.506,000 --> 0:07:14,000
doesn't know what to do with data.

148
0:07:15.158,000 --> 0:07:17,000
Even the most data-savvy companies get it wrong.

149
0:07:17.48,000 --> 0:07:19,000
Yes, even Google gets it wrong sometimes.

150
0:07:20.68,000 --> 0:07:24,000
In 2009, Google announced that they were able, with data analysis,

151
0:07:25.2,000 --> 0:07:29,000
to predict outbreaks of influenza, the nasty kind of flu,

152
0:07:29.36,000 --> 0:07:32,000
by doing data analysis on their Google searches.

153
0:07:33.16,000 --> 0:07:36,000
And it worked beautifully, and it made a big splash in the news,

154
0:07:37.04,000 --> 0:07:39,000
including the pinnacle of scientific success:

155
0:07:39.2,000 --> 0:07:41,000
a publication in the journal "Nature."

156
0:07:41.68,000 --> 0:07:44,000
It worked beautifully for year after year after year,

157
0:07:45.32,000 --> 0:07:46,000
until one year it failed.

158
0:07:47,000 --> 0:07:49,000
And nobody could even tell exactly why.

159
0:07:49.28,000 --> 0:07:5,000
It just didn't work that year,

160
0:07:51,000 --> 0:07:52,000
and of course that again made big news,

161
0:07:52.96,000 --> 0:07:53,000
including now a retraction

162
0:07:54.6,000 --> 0:07:56,000
of a publication from the journal "Nature."

163
0:07:58.48,000 --> 0:08:01,000
So even the most data-savvy companies, Amazon and Google,

164
0:08:01.84,000 --> 0:08:03,000
they sometimes get it wrong.

165
0:08:04,000 --> 0:08:06,000
And despite all those failures,

166
0:08:06.96,000 --> 0:08:09,000
data is moving rapidly into real-life decision-making --

167
0:08:10.84,000 --> 0:08:11,000
into the workplace,

168
0:08:12.68,000 --> 0:08:13,000
law enforcement,

169
0:08:14.52,000 --> 0:08:15,000
medicine.

170
0:08:16.4,000 --> 0:08:19,000
So we should better make sure that data is helping.

171
0:08:19.76,000 --> 0:08:22,000
Now, personally I've seen a lot of this struggle with data myself,

172
0:08:22.92,000 --> 0:08:23,000
because I work in computational genetics,

173
0:08:24.92,000 --> 0:08:26,000
which is also a field where lots of very smart people

174
0:08:27.44,000 --> 0:08:3,000
are using unimaginable amounts of data to make pretty serious decisions

175
0:08:31.12,000 --> 0:08:34,000
like deciding on a cancer therapy or developing a drug.

176
0:08:35.52,000 --> 0:08:37,000
And over the years, I've noticed a sort of pattern

177
0:08:37.92,000 --> 0:08:39,000
or kind of rule, if you will, about the difference

178
0:08:40.4,000 --> 0:08:42,000
between successful decision-making with data

179
0:08:43.12,000 --> 0:08:44,000
and unsuccessful decision-making,

180
0:08:44.76,000 --> 0:08:47,000
and I find this a pattern worth sharing, and it goes something like this.

181
0:08:50.52,000 --> 0:08:52,000
So whenever you're solving a complex problem,

182
0:08:52.679,000 --> 0:08:53,000
you're doing essentially two things.

183
0:08:54.44,000 --> 0:08:57,000
The first one is, you take that problem apart into its bits and pieces

184
0:08:57.76,000 --> 0:08:59,000
so that you can deeply analyze those bits and pieces,

185
0:09:00.28,000 --> 0:09:02,000
and then of course you do the second part.

186
0:09:02.32,000 --> 0:09:04,000
You put all of these bits and pieces back together again

187
0:09:05,000 --> 0:09:06,000
to come to your conclusion.

188
0:09:06.36,000 --> 0:09:08,000
And sometimes you have to do it over again,

189
0:09:08.72,000 --> 0:09:09,000
but it's always those two things:

190
0:09:10.4,000 --> 0:09:12,000
taking apart and putting back together again.

191
0:09:14.28,000 --> 0:09:15,000
And now the crucial thing is

192
0:09:15.92,000 --> 0:09:17,000
that data and data analysis

193
0:09:18.84,000 --> 0:09:2,000
is only good for the first part.

194
0:09:21.36,000 --> 0:09:23,000
Data and data analysis, no matter how powerful,

195
0:09:23.6,000 --> 0:09:27,000
can only help you taking a problem apart and understanding its pieces.

196
0:09:28.08,000 --> 0:09:31,000
It's not suited to put those pieces back together again

197
0:09:31.6,000 --> 0:09:32,000
and then to come to a conclusion.

198
0:09:33.52,000 --> 0:09:35,000
There's another tool that can do that, and we all have it,

199
0:09:36.28,000 --> 0:09:37,000
and that tool is the brain.

200
0:09:37.6,000 --> 0:09:38,000
If there's one thing a brain is good at,

201
0:09:39.56,000 --> 0:09:41,000
it's taking bits and pieces back together again,

202
0:09:41.84,000 --> 0:09:43,000
even when you have incomplete information,

203
0:09:43.88,000 --> 0:09:44,000
and coming to a good conclusion,

204
0:09:45.48,000 --> 0:09:47,000
especially if it's the brain of an expert.

205
0:09:48.44,000 --> 0:09:5,000
And that's why I believe that Netflix was so successful,

206
0:09:51.12,000 --> 0:09:54,000
because they used data and brains where they belong in the process.

207
0:09:54.72,000 --> 0:09:57,000
They use data to first understand lots of pieces about their audience

208
0:09:58.28,000 --> 0:10:01,000
that they otherwise wouldn't have been able to understand at that depth,

209
0:10:01.72,000 --> 0:10:03,000
but then the decision to take all these bits and pieces

210
0:10:04.36,000 --> 0:10:07,000
and put them back together again and make a show like "House of Cards,"

211
0:10:07.72,000 --> 0:10:08,000
that was nowhere in the data.

212
0:10:09.16,000 --> 0:10:12,000
Ted Sarandos and his team made that decision to license that show,

213
0:10:13.16,000 --> 0:10:15,000
which also meant, by the way, that they were taking

214
0:10:15.565,000 --> 0:10:17,000
a pretty big personal risk with that decision.

215
0:10:18.44,000 --> 0:10:21,000
And Amazon, on the other hand, they did it the wrong way around.

216
0:10:21.48,000 --> 0:10:23,000
They used data all the way to drive their decision-making,

217
0:10:24.24,000 --> 0:10:26,000
first when they held their competition of TV ideas,

218
0:10:26.68,000 --> 0:10:29,000
then when they selected "Alpha House" to make as a show.

219
0:10:30.4,000 --> 0:10:32,000
Which of course was a very safe decision for them,

220
0:10:32.92,000 --> 0:10:34,000
because they could always point at the data, saying,

221
0:10:35.4,000 --> 0:10:36,000
"This is what the data tells us."

222
0:10:37.12,000 --> 0:10:41,000
But it didn't lead to the exceptional results that they were hoping for.

223
0:10:42.12,000 --> 0:10:46,000
So data is of course a massively useful tool to make better decisions,

224
0:10:47.12,000 --> 0:10:49,000
but I believe that things go wrong

225
0:10:49.52,000 --> 0:10:51,000
when data is starting to drive those decisions.

226
0:10:52.12,000 --> 0:10:55,000
No matter how powerful, data is just a tool,

227
0:10:55.92,000 --> 0:10:58,000
and to keep that in mind, I find this device here quite useful.

228
0:10:59.28,000 --> 0:11:,000
Many of you will ...

229
0:11:00.52,000 --> 0:11:01,000
(Laughter)

230
0:11:01.76,000 --> 0:11:02,000
Before there was data,

231
0:11:03,000 --> 0:11:05,000
this was the decision-making device to use.

232
0:11:05.88,000 --> 0:11:06,000
(Laughter)

233
0:11:07.16,000 --> 0:11:08,000
Many of you will know this.

234
0:11:08.52,000 --> 0:11:09,000
This toy here is called the Magic 8 Ball,

235
0:11:10.497,000 --> 0:11:11,000
and it's really amazing,

236
0:11:11.72,000 --> 0:11:13,000
because if you have a decision to make, a yes or no question,

237
0:11:14.64,000 --> 0:11:17,000
all you have to do is you shake the ball, and then you get an answer --

238
0:11:18.4,000 --> 0:11:2,000
"Most Likely" -- right here in this window in real time.

239
0:11:21.24,000 --> 0:11:23,000
I'll have it out later for tech demos.

240
0:11:23.36,000 --> 0:11:24,000
(Laughter)

241
0:11:24.6,000 --> 0:11:27,000
Now, the thing is, of course -- so I've made some decisions in my life

242
0:11:28.2,000 --> 0:11:3,000
where, in hindsight, I should have just listened to the ball.

243
0:11:31.12,000 --> 0:11:34,000
But, you know, of course, if you have the data available,

244
0:11:34.48,000 --> 0:11:37,000
you want to replace this with something much more sophisticated,

245
0:11:37.56,000 --> 0:11:4,000
like data analysis to come to a better decision.

246
0:11:41.2,000 --> 0:11:43,000
But that does not change the basic setup.

247
0:11:43.84,000 --> 0:11:46,000
So the ball may get smarter and smarter and smarter,

248
0:11:47.04,000 --> 0:11:49,000
but I believe it's still on us to make the decisions

249
0:11:49.88,000 --> 0:11:52,000
if we want to achieve something extraordinary,

250
0:11:52.92,000 --> 0:11:53,000
on the right end of the curve.

251
0:11:54.88,000 --> 0:11:58,000
And I find that a very encouraging message, in fact,

252
0:11:59.4,000 --> 0:12:02,000
that even in the face of huge amounts of data,

253
0:12:03.4,000 --> 0:12:07,000
it still pays off to make decisions,

254
0:12:07.52,000 --> 0:12:09,000
to be an expert in what you're doing

255
0:12:10.2,000 --> 0:12:12,000
and take risks.

256
0:12:12.32,000 --> 0:12:14,000
Because in the end, it's not data,

257
0:12:15.12,000 --> 0:12:18,000
it's risks that will land you on the right end of the curve.

258
0:12:19.84,000 --> 0:12:2,000
Thank you.

259
0:12:21.08,000 --> 0:12:24,000
(Applause)

