1
0:00:,000 --> 0:00:07,000
Traductor: Marlén Scholand Cámara

2
0:00:13.52,000 --> 0:00:16,000
Me invitaron a un lugar exclusivo

3
0:00:17.44,000 --> 0:00:19,000
para dar una charla sobre el futuro digital

4
0:00:19.92,000 --> 0:00:22,000
por eso asumí que seríamos un par de cientos de ejecutivos de tecnología.

5
0:00:23.52,000 --> 0:00:25,000
Y estaba allí en la sala verde, esperando para continuar

6
0:00:26.24,000 --> 0:00:3,000
y, en lugar de llevarme al escenario, trajeron a cinco hombres a la sala verde

7
0:00:30.47,000 --> 0:00:33,000
quienes se sentaron alrededor de esta mesa pequeña conmigo.

8
0:00:33.52,000 --> 0:00:35,000
Eran multimillonarios tecnológicos.

9
0:00:35.64,000 --> 0:00:39,000
Y empezaron a salpicarme con estas preguntas realmente binarias,

10
0:00:40.2,000 --> 0:00:42,000
como: ¿Bitcoin o Etherium?

11
0:00:43.12,000 --> 0:00:45,000
¿Realidad virtual o realidad aumentada?

12
0:00:45.8,000 --> 0:00:47,000
No sé si estaban apostando o qué.

13
0:00:48.32,000 --> 0:00:5,000
Y a medida que se sintieron más cómodos conmigo,

14
0:00:51.16,000 --> 0:00:54,000
abordaron su verdadera cuestión de preocupación.

15
0:00:54.4,000 --> 0:00:56,000
¿Alaska o Nueva Zelanda?

16
0:00:57.41,000 --> 0:00:58,000
Está bien.

17
0:00:58.66,000 --> 0:01:01,000
Estos multimillonarios tecnológicos pedían consejo a un teórico de medios

18
0:01:02.296,000 --> 0:01:04,000
sobre donde poner sus bunkers del fin del mundo.

19
0:01:04.63,000 --> 0:01:07,000
Pasamos el resto de la hora con una única pregunta:

20
0:01:07.76,000 --> 0:01:1,000
"¿Cómo mantengo el control de mi personal de seguridad

21
0:01:11.4,000 --> 0:01:12,000
después del evento?"

22
0:01:13.92,000 --> 0:01:15,000
Por "el evento" se refieren a la guerra termonuclear.

23
0:01:16.68,000 --> 0:01:2,000
o catástrofe climática o malestar social que acaba con el mundo como lo conocemos,

24
0:01:21.36,000 --> 0:01:24,000
y lo más importante, hace que su dinero sea obsoleto.

25
0:01:26.2,000 --> 0:01:28,000
Y no pude evitar pensar:

26
0:01:28.44,000 --> 0:01:32,000
estos son los hombres más ricos y poderosos del mundo,

27
0:01:33.2,000 --> 0:01:37,000
sin embargo, se ven totalmente impotentes para influir en el futuro.

28
0:01:37.88,000 --> 0:01:41,000
Lo mejor que pueden hacer es aferrarse a la inevitable catástrofe

29
0:01:42.36,000 --> 0:01:45,000
y luego usar su tecnología y dinero para alejarnos del resto de nosotros.

30
0:01:47.52,000 --> 0:01:49,000
Y estos son los ganadores de la economía digital.

31
0:01:50.08,000 --> 0:01:53,000
(Risas)

32
0:01:53.52,000 --> 0:01:55,000
El renacimiento digital

33
0:01:56.32,000 --> 0:02:,000
tenía que ver con el potencial desenfrenado

34
0:02:00.6,000 --> 0:02:02,000
de la imaginación humana colectiva.

35
0:02:03.04,000 --> 0:02:08,000
Abarcó todo, desde las matemáticas del caos y la física cuántica

36
0:02:08.2,000 --> 0:02:12,000
a los juegos de rol de fantasía y la hipótesis de Gaia.

37
0:02:12.4,000 --> 0:02:18,000
Creíamos que los humanos conectados podían crear cualquier futuro imaginable.

38
0:02:20.84,000 --> 0:02:22,000
Y luego vino el boom del punto com.

39
0:02:24.6,000 --> 0:02:27,000
Y el futuro digital se convirtió en futuros de acciones.

40
0:02:28.24,000 --> 0:02:31,000
Y usamos toda esa energía de la era digital.

41
0:02:31.28,000 --> 0:02:35,000
para bombear esteroides en la bolsa de valores NASDAQ ya agonizante.

42
0:02:35.56,000 --> 0:02:38,000
Las revistas de tecnología nos dijeron que se avecinaba un tsunami.

43
0:02:39.2,000 --> 0:02:43,000
Y solo los inversores que contrataron a los mejores planificadores de escenarios

44
0:02:43.68,000 --> 0:02:45,000
y futuristas serían capaces de sobrevivir a la ola.

45
0:02:47.16,000 --> 0:02:52,000
Y así, el futuro cambió a partir de esto que creamos juntos en el presente

46
0:02:53.08,000 --> 0:02:54,000
por algo por lo que apostamos

47
0:02:54.6,000 --> 0:02:57,000
por algún tipo de una competencia de suma cero de ganadores de todo.

48
0:03:00.12,000 --> 0:03:03,000
Y cuando las cosas se vuelven tan competitivas sobre el futuro,

49
0:03:03.28,000 --> 0:03:06,000
los humanos ya no somos valorados por nuestra creatividad.

50
0:03:06.6,000 --> 0:03:09,000
No, ahora solo estamos valorados por nuestros datos.

51
0:03:09.76,000 --> 0:03:11,000
Porque pueden usar los datos para hacer predicciones.

52
0:03:12.366,000 --> 0:03:14,000
Creatividad, en todo caso, que crea ruido.

53
0:03:14.76,000 --> 0:03:16,000
Eso hace que sea más difícil de predecir.

54
0:03:17,000 --> 0:03:19,000
Así que terminamos con un paisaje digital.

55
0:03:19.44,000 --> 0:03:22,000
Esa creatividad realmente reprimida, inovación reprimida,

56
0:03:22.72,000 --> 0:03:24,000
reprimió lo que nos hace más humanos.

57
0:03:26.35,000 --> 0:03:27,000
Terminamos en las redes sociales.

58
0:03:28.24,000 --> 0:03:31,000
¿Las redes sociales conectan a gente de manera nueva e interesante?

59
0:03:31.526,000 --> 0:03:33,000
No, las redes sociales usan en realidad nuestros datos

60
0:03:34.29,000 --> 0:03:36,000
para predecir nuestro comportamiento futuro

61
0:03:36.51,000 --> 0:03:39,000
para cuando sea necesario, influir en nuestro comportamiento futuro.

62
0:03:40.126,000 --> 0:03:43,000
Para que actuemos más de acuerdo con nuestros perfiles estadísticos.

63
0:03:44.84,000 --> 0:03:46,000
La economía digital: ¿Le gusta la gente?

64
0:03:47.08,000 --> 0:03:5,000
No, si se tiene un plan de negocios, ¿qué se supone que hay que hacer?

65
0:03:50.606,000 --> 0:03:51,000
Desháganse de todas las personas.

66
0:03:52.236,000 --> 0:03:55,000
Los humanos quieren atención médica, quieren dinero, quieren significado.

67
0:03:56.36,000 --> 0:03:57,000
No se puede escalar con la gente.

68
0:03:59.36,000 --> 0:03:59,000
(Risas)

69
0:04:00.356,000 --> 0:04:02,000
Incluso nuestras aplicaciones digitales

70
0:04:02.492,000 --> 0:04:04,000
no nos ayudan a formar ninguna relación o solidaridad.

71
0:04:05.32,000 --> 0:04:07,000
Quiero decir, ¿dónde está el botón de la aplicación de viaje

72
0:04:08.246,000 --> 0:04:11,000
para que los conductores hablen entre sí sobre sus condiciones de trabajo

73
0:04:11.876,000 --> 0:04:12,000
o sindicalizarse?

74
0:04:13.13,000 --> 0:04:15,000
Incluso nuestras herramientas de videoconferencia,

75
0:04:15.64,000 --> 0:04:17,000
no nos permiten establecer una relación real.

76
0:04:18.04,000 --> 0:04:21,000
Por buena que sea la resolución del video,

77
0:04:21.4,000 --> 0:04:24,000
todavía no puedes ver si el iris de alguien se está abriendo para recibirte.

78
0:04:25.12,000 --> 0:04:27,000
Todo lo que hemos hecho para establecer una buena relación

79
0:04:27.906,000 --> 0:04:3,000
que hemos desarrollado a lo largo de cientos de miles de años de evolución,

80
0:04:31.565,000 --> 0:04:31,000
no funcionan.

81
0:04:32.46,000 --> 0:04:35,000
No puedes ver si la respiración de alguien se está sincronizando con la tuya.

82
0:04:36.306,000 --> 0:04:39,000
Y las neuronas espejo nunca se disparan, la oxitocina nunca pasa por tu cuerpo,

83
0:04:40.156,000 --> 0:04:43,000
nunca tienes esa experiencia de vinculación con el otro ser humano.

84
0:04:43.4,000 --> 0:04:44,000
Y en cambio, te quedan como

85
0:04:44.71,000 --> 0:04:47,000
"Bueno, estaban de acuerdo conmigo, pero ¿realmente lo estaban,

86
0:04:47.736,000 --> 0:04:48,000
realmente me llegaron?"

87
0:04:48.966,000 --> 0:04:51,000
Y no culpamos a la tecnología por esa falta de fidelidad.

88
0:04:52.24,000 --> 0:04:53,000
Culparemos a la otra persona.

89
0:04:55.32,000 --> 0:04:59,000
Incluso las tecnologías y las iniciativas digitales que tenemos

90
0:04:59.4,000 --> 0:05:01,000
para promover a los humanos,

91
0:05:01.6,000 --> 0:05:03,000
son intensamente antihumanos en el centro.

92
0:05:05.6,000 --> 0:05:07,000
Piensen en el blockchain.

93
0:05:08.05,000 --> 0:05:12,000
¿El blockchain está aquí para ayudarnos a tener una gran economía humanizada? No.

94
0:05:12.16,000 --> 0:05:14,000
El blockchain no genera confianza entre los usuarios,

95
0:05:14.88,000 --> 0:05:17,000
el blockchain simplemente sustituye la confianza en un nuevo,

96
0:05:18.44,000 --> 0:05:2,000
de manera aún menos transparente.

97
0:05:21.6,000 --> 0:05:22,000
O el movimiento del código,

98
0:05:23.1,000 --> 0:05:25,000
quiero decir, la educación es genial, amamos la educación

99
0:05:25.916,000 --> 0:05:26,000
y es una idea maravillosa

100
0:05:27.216,000 --> 0:05:3,000
el querer que los niños obtengan empleos en el futuro digital,

101
0:05:30.516,000 --> 0:05:32,000
Así que les enseñaremos el código ahora.

102
0:05:32.64,000 --> 0:05:35,000
¿Pero desde cuándo se trata la educación de conseguir trabajo?

103
0:05:35.77,000 --> 0:05:37,000
La educación no se trataba de conseguir trabajo.

104
0:05:38.166,000 --> 0:05:41,000
La educación era una compensación por un trabajo bien hecho.

105
0:05:41.68,000 --> 0:05:42,000
La idea de la educación pública

106
0:05:43.21,000 --> 0:05:46,000
era para los mineros del carbón que todo el día trabajaban en las minas de carbón.

107
0:05:47.196,000 --> 0:05:49,000
Luego volverían a casa y deberían tener la dignidad

108
0:05:49.636,000 --> 0:05:51,000
para poder leer una novela y entenderla.

109
0:05:51.656,000 --> 0:05:53,000
O la inteligencia para poder participar en la democracia.

110
0:05:55.2,000 --> 0:05:58,000
Cuando la hacemos extensión del trabajo, ¿qué hacemos realmente?

111
0:05:58.44,000 --> 0:06:,000
Solo estamos dejando que las corporaciones

112
0:06:01,000 --> 0:06:04,000
externalicen el coste de formación de sus trabajadores.

113
0:06:05.52,000 --> 0:06:08,000
Y lo peor de todo es realmente el movimiento tecnológico humano.

114
0:06:09.39,000 --> 0:06:12,000
Quiero decir, me encantan estos chicos, los antiguos que tomaban

115
0:06:12.48,000 --> 0:06:14,000
Los algoritmos de las máquinas tragamonedas de Las Vegas y

116
0:06:15.44,000 --> 0:06:18,000
los ponían en nuestro feed de redes sociales para que nos volviéramos adictos.

117
0:06:19.136,000 --> 0:06:2,000
Ahora han visto el error

118
0:06:20.486,000 --> 0:06:22,000
quieren hacer que la tecnología sea más humana.

119
0:06:22.83,000 --> 0:06:24,000
Pero cuando escucho la expresión "tecnología humana",

120
0:06:25.396,000 --> 0:06:27,000
pienso en gallinas sin jaula o algo así.

121
0:06:28.16,000 --> 0:06:3,000
Vamos a ser tan humanos posible para ellos,

122
0:06:30.44,000 --> 0:06:31,000
hasta que los llevemos al matadero.

123
0:06:33.2,000 --> 0:06:36,000
Así que ahora dejarán que estas tecnologías sean lo más humanas posible,

124
0:06:36.64,000 --> 0:06:39,000
siempre que extraigan suficientes datos y suficiente dinero de nosotros

125
0:06:40.156,000 --> 0:06:41,000
para complacer a sus accionistas.

126
0:06:42.26,000 --> 0:06:45,000
Mientras tanto, los accionistas, por su parte, solo están pensando,

127
0:06:45.72,000 --> 0:06:47,000
"Necesito ganar suficiente dinero ahora, para poder aislarme

128
0:06:48.72,000 --> 0:06:51,000
del mundo que estoy creando ganando dinero de esta manera".

129
0:06:51.8,000 --> 0:06:53,000
(Risas)

130
0:06:54.2,000 --> 0:06:58,000
No importa cuántas gafas VR se pongan en la cara

131
0:06:58.28,000 --> 0:07:,000
y cualquier mundo de fantasía en el que entren,

132
0:07:00.56,000 --> 0:07:03,000
no pueden externalizar la esclavitud y la contaminación causada

133
0:07:04.12,000 --> 0:07:06,000
a través de la fabricación del mismo dispositivo.

134
0:07:07.12,000 --> 0:07:1,000
Me recuerda a los tontos de Thomas Jefferson.

135
0:07:10.32,000 --> 0:07:12,000
Nos gusta pensar que él hizo el tonto

136
0:07:12.68,000 --> 0:07:15,000
con el fin de ahorrar a sus esclavos todo el trabajo de llevar la comida

137
0:07:16.36,000 --> 0:07:18,000
hasta el comedor para que la gente comiera.

138
0:07:19.16,000 --> 0:07:21,000
Eso no era para lo que era, no era para los esclavos,

139
0:07:21.776,000 --> 0:07:23,000
fue para Thomas Jefferson y sus invitados a la cena,

140
0:07:24.296,000 --> 0:07:26,000
para no tener que ver al esclavo trayendo la comida.

141
0:07:27.16,000 --> 0:07:28,000
La comida acaba de llegar mágicamente,

142
0:07:29.026,000 --> 0:07:31,000
como si saliera de un replicador de "Start Trek".

143
0:07:32.72,000 --> 0:07:34,000
Es parte de un espíritu que dice:

144
0:07:34.84,000 --> 0:07:38,000
Los humanos son el problema y la tecnología es la solución.

145
0:07:40.68,000 --> 0:07:42,000
Ya no podemos pensar de esa manera.

146
0:07:42.76,000 --> 0:07:47,000
Hay que dejar de usar la tecnología para optimizar a los humanos para el mercado

147
0:07:48.08,000 --> 0:07:53,000
y empezar a optimizar la tecnología para el futuro humano.

148
0:07:54.4,000 --> 0:07:57,000
Pero ese es un argumento muy difícil de plantear en estos días,

149
0:07:57.76,000 --> 0:08:01,000
porque los humanos no son seres populares.

150
0:08:01.84,000 --> 0:08:04,000
Hablé de esto frente a una ambientalista el otro día,

151
0:08:04.92,000 --> 0:08:06,000
y ella dijo: "¿Por qué defiendes a los humanos?

152
0:08:07.386,000 --> 0:08:1,000
Los humanos destruyeron el planeta. Merecen extinguirse".

153
0:08:10.516,000 --> 0:08:12,000
(Risas)

154
0:08:12.86,000 --> 0:08:14,000
Incluso nuestros medios populares odian a los humanos.

155
0:08:15.64,000 --> 0:08:15,000
Vean la televisión,

156
0:08:16.63,000 --> 0:08:18,000
todos los programas de ciencia ficción son sobre

157
0:08:19.01,000 --> 0:08:21,000
cómo los robots son mejores y más amables que las personas.

158
0:08:21.92,000 --> 0:08:24,000
Incluso los shows de zombies, ¿de qué se trata cada show de zombies?

159
0:08:25.206,000 --> 0:08:27,000
Alguna persona, mirando el horizonte a un zombie,

160
0:08:27.636,000 --> 0:08:29,000
se acercan a la persona y ves la cara de la persona,

161
0:08:30.4,000 --> 0:08:31,000
y Uds. saben lo que están pensando:

162
0:08:32.16,000 --> 0:08:34,000
"¿Cuál es realmente la diferencia entre ese zombie y yo?

163
0:08:34.92,000 --> 0:08:35,000
Él camina, yo camino.

164
0:08:36.48,000 --> 0:08:38,000
Él come, yo como.

165
0:08:38.52,000 --> 0:08:4,000
Él mata, yo mato".

166
0:08:42.36,000 --> 0:08:43,000
Pero es un zombie.

167
0:08:43.75,000 --> 0:08:44,000
Al menos eres consciente de ello.

168
0:08:45.516,000 --> 0:08:48,000
Si realmente tenemos problemas para distinguirnos de los zombies,

169
0:08:49.08,000 --> 0:08:51,000
tenemos un problema bastante grande.

170
0:08:51.28,000 --> 0:08:52,000
(Risas)

171
0:08:52.52,000 --> 0:08:54,000
Y ni siquiera me refiero a los transhumanistas.

172
0:08:55.48,000 --> 0:08:58,000
Estuve en un panel con un transhumanista, y él hablaba sobre la singularidad.

173
0:08:59.32,000 --> 0:09:,000
"Pronto llegará el día,

174
0:09:00.55,000 --> 0:09:03,000
cuando las computadoras sean más inteligentes que las personas".

175
0:09:03.74,000 --> 0:09:05,000
Y la única opción para las personas en ese punto

176
0:09:06.166,000 --> 0:09:08,000
es pasar el testigo evolutivo a nuestro sucesor

177
0:09:08.72,000 --> 0:09:09,000
y desaparecer en el fondo.

178
0:09:10.36,000 --> 0:09:13,000
En el mejor de los casos, suban su conciencia a un chip de silicona

179
0:09:13.84,000 --> 0:09:14,000
y acepten su extinción".

180
0:09:16.64,000 --> 0:09:17,000
(Risas)

181
0:09:18.12,000 --> 0:09:21,000
Y dije, "No, los humanos son especiales.

182
0:09:21.52,000 --> 0:09:24,000
Podemos abrazar la ambigüedad, entendemos la paradoja,

183
0:09:25.08,000 --> 0:09:27,000
somos conscientes, raros, peculiares.

184
0:09:27.72,000 --> 0:09:3,000
Debería haber un lugar para los humanos en el futuro digital".

185
0:09:31.08,000 --> 0:09:32,000
Y él dijo: "Oh, Rushkoff,

186
0:09:32.64,000 --> 0:09:34,000
solo lo dices porque eres un humano".

187
0:09:34.96,000 --> 0:09:35,000
(Risas)

188
0:09:36.76,000 --> 0:09:37,000
Como si fuera arrogancia.

189
0:09:39.28,000 --> 0:09:41,000
Bien, estoy en el "Equipo humano".

190
0:09:43.2,000 --> 0:09:46,000
Esa fue la idea original de la era digital.

191
0:09:47.08,000 --> 0:09:49,000
Que ser humano es un deporte de equipo.

192
0:09:49.32,000 --> 0:09:51,000
La evolución es un acto de colaboración.

193
0:09:52.08,000 --> 0:09:53,000
Incluso los árboles en el bosque,

194
0:09:53.686,000 --> 0:09:55,000
no todos compiten entre sí.

195
0:09:55.76,000 --> 0:09:58,000
Están conectados con la vasta red de raíces y setas

196
0:09:59,000 --> 0:10:03,000
que les permite comunicarse entre sí y pasar nutrientes de un lado a otro.

197
0:10:03.29,000 --> 0:10:05,000
Si los humanos somos la especie más evolucionada,

198
0:10:05.72,000 --> 0:10:09,000
es porque tenemos formas más evolucionadas de colaboración y comunicación.

199
0:10:09.88,000 --> 0:10:1,000
Tenemos lenguaje

200
0:10:11.4,000 --> 0:10:12,000
Tenemos tecnología.

201
0:10:14.12,000 --> 0:10:18,000
Es gracioso, solía ser el tipo que hablaba del futuro digital

202
0:10:18.72,000 --> 0:10:2,000
a personas que aún no habían experimentado nada digital.

203
0:10:22.2,000 --> 0:10:23,000
Y ahora siento que soy el último

204
0:10:24.04,000 --> 0:10:26,000
que recuerda cómo era la vida antes de la tecnología digital.

205
0:10:28.68,000 --> 0:10:32,000
No se trata de rechazar lo digital o de rechazar lo tecnológico.

206
0:10:32.92,000 --> 0:10:36,000
Es una cuestión de recuperar los valores que están en peligro de perderse

207
0:10:37.04,000 --> 0:10:4,000
e incorporarlos en la infraestructura digital para el futuro.

208
0:10:41.88,000 --> 0:10:43,000
Y eso no es ciencia espacial.

209
0:10:44.2,000 --> 0:10:46,000
Es tan simple como hacer una red social

210
0:10:46.32,000 --> 0:10:49,000
que en lugar de enseñarnos a ver a las personas como adversarios,

211
0:10:49.88,000 --> 0:10:52,000
nos enseñe a ver a nuestros adversarios como personas.

212
0:10:54.24,000 --> 0:10:58,000
Significa crear una economía que no favorezca un monopolio de plataforma

213
0:10:58.56,000 --> 0:11:01,000
que quiere extraer todo el valor de personas y lugares,

214
0:11:01.92,000 --> 0:11:04,000
sino uno que promueva la circulación de valor a través de una comunidad

215
0:11:05.88,000 --> 0:11:07,000
y nos permita establecer cooperativas de plataforma

216
0:11:08.32,000 --> 0:11:11,000
que distribuyan la propiedad lo más ampliamente posible.

217
0:11:12.16,000 --> 0:11:13,000
Significa construir plataformas.

218
0:11:13.84,000 --> 0:11:17,000
Eso no reprime nuestra creatividad y novedad en nombre de la predicción.

219
0:11:18.52,000 --> 0:11:2,000
Pero en realidad promueve la creatividad y la novedad

220
0:11:21.12,000 --> 0:11:23,000
para poder llegar a algunas de las soluciones

221
0:11:23.48,000 --> 0:11:25,000
y salir realmente del lío en el que estamos,

222
0:11:27.44,000 --> 0:11:3,000
en lugar de tratar de ganar suficiente dinero para aislarnos

223
0:11:30.52,000 --> 0:11:31,000
del mundo que estamos creando,

224
0:11:32.04,000 --> 0:11:35,000
¿Por qué no gastamos ese tiempo y energía haciendo del mundo un lugar?

225
0:11:35.426,000 --> 0:11:37,000
De lo que no sentimos la necesidad de escapar.

226
0:11:38,000 --> 0:11:41,000
No hay escape, solo una cosa está sucediendo aquí.

227
0:11:42.68,000 --> 0:11:44,000
Por favor, no se vayan.

228
0:11:45.64,000 --> 0:11:46,000
Únanse a nosotros.

229
0:11:47.52,000 --> 0:11:48,000
Puede que no seamos perfectos,

230
0:11:49.12,000 --> 0:11:51,000
pero pase lo que pase, al menos no estarán solos.

231
0:11:52.64,000 --> 0:11:53,000
Únanse al "Equipo humano".

232
0:11:55.16,000 --> 0:11:57,000
Encuentren a los otros.

233
0:11:57.28,000 --> 0:11:59,000
Juntos, hagamos el futuro que siempre quisimos.

234
0:12:00.9,000 --> 0:12:03,000
Y a esos multimillonarios técnicos que querían saber

235
0:12:04.196,000 --> 0:12:07,000
cómo mantener el control de su fuerza de seguridad tras el apocalipsis,

236
0:12:07.546,000 --> 0:12:08,000
¿saben qué les dije?

237
0:12:09.28,000 --> 0:12:13,000
"Comiencen a tratar a las personas con amor y respeto ahora mismo.

238
0:12:13.52,000 --> 0:12:15,000
Y tal vez no tengan apocalipsis del que preocuparte".

239
0:12:16.84,000 --> 0:12:17,000
Gracias.

240
0:12:18.08,000 --> 0:12:22,000
(Aplausos)

