1
0:00:26,000 --> 0:00:29,000
So I'm going to speak about a problem that I have

2
0:00:29,000 --> 0:00:32,000
and that's that I'm a philosopher.

3
0:00:32,000 --> 0:00:34,000
(Laughter)

4
0:00:34,000 --> 0:00:37,000
When I go to a party and people ask me what do I do

5
0:00:37,000 --> 0:00:42,000
and I say, "I'm a professor," their eyes glaze over.

6
0:00:42,000 --> 0:00:44,000
When I go to an academic cocktail party

7
0:00:44,000 --> 0:00:48,000
and there are all the professors around, they ask me what field I'm in

8
0:00:48,000 --> 0:00:51,000
and I say, "philosophy" -- their eyes glaze over.

9
0:00:51,000 --> 0:00:53,000
(Laughter)

10
0:00:53,000 --> 0:00:56,000
When I go to a philosopher's party

11
0:00:56,000 --> 0:00:59,000
(Laughter)

12
0:00:59,000 --> 0:01:03,000
and they ask me what I work on and I say, "consciousness,"

13
0:01:03,000 --> 0:01:08,000
their eyes don't glaze over -- their lips curl into a snarl.

14
0:01:08,000 --> 0:01:09,000
(Laughter)

15
0:01:09,000 --> 0:01:15,000
And I get hoots of derision and cackles and growls

16
0:01:15,000 --> 0:01:2,000
because they think, "That's impossible! You can't explain consciousness."

17
0:01:2,000 --> 0:01:22,000
The very chutzpah of somebody thinking

18
0:01:22,000 --> 0:01:26,000
that you could explain consciousness is just out of the question.

19
0:01:26,000 --> 0:01:3,000
My late, lamented friend Bob Nozick, a fine philosopher,

20
0:01:3,000 --> 0:01:34,000
in one of his books, "Philosophical Explanations,"

21
0:01:34,000 --> 0:01:39,000
is commenting on the ethos of philosophy --

22
0:01:39,000 --> 0:01:41,000
the way philosophers go about their business.

23
0:01:41,000 --> 0:01:45,000
And he says, you know, "Philosophers love rational argument."

24
0:01:45,000 --> 0:01:47,000
And he says, "It seems as if the ideal argument

25
0:01:47,000 --> 0:01:53,000
for most philosophers is you give your audience the premises

26
0:01:53,000 --> 0:01:58,000
and then you give them the inferences and the conclusion,

27
0:01:58,000 --> 0:02:02,000
and if they don't accept the conclusion, they die.

28
0:02:02,000 --> 0:02:05,000
Their heads explode." The idea is to have an argument

29
0:02:05,000 --> 0:02:09,000
that is so powerful that it knocks out your opponents.

30
0:02:09,000 --> 0:02:12,000
But in fact that doesn't change people's minds at all.

31
0:02:12,000 --> 0:02:13,000
It's very hard to change people's minds

32
0:02:13,000 --> 0:02:15,000
about something like consciousness,

33
0:02:15,000 --> 0:02:2,000
and I finally figured out the reason for that.

34
0:02:2,000 --> 0:02:24,000
The reason for that is that everybody's an expert on consciousness.

35
0:02:24,000 --> 0:02:28,000
We heard the other day that everybody's got a strong opinion about video games.

36
0:02:28,000 --> 0:02:31,000
They all have an idea for a video game, even if they're not experts.

37
0:02:31,000 --> 0:02:34,000
But they don't consider themselves experts on video games;

38
0:02:34,000 --> 0:02:35,000
they've just got strong opinions.

39
0:02:35,000 --> 0:02:4,000
I'm sure that people here who work on, say, climate change

40
0:02:4,000 --> 0:02:45,000
and global warming, or on the future of the Internet,

41
0:02:45,000 --> 0:02:47,000
encounter people who have very strong opinions

42
0:02:47,000 --> 0:02:5,000
about what's going to happen next.

43
0:02:5,000 --> 0:02:54,000
But they probably don't think of these opinions as expertise.

44
0:02:54,000 --> 0:02:56,000
They're just strongly held opinions.

45
0:02:56,000 --> 0:03:,000
But with regard to consciousness, people seem to think,

46
0:03:,000 --> 0:03:03,000
each of us seems to think, "I am an expert.

47
0:03:03,000 --> 0:03:06,000
Simply by being conscious, I know all about this."

48
0:03:06,000 --> 0:03:08,000
And so, you tell them your theory and they say,

49
0:03:08,000 --> 0:03:09,000
"No, no, that's not the way consciousness is!

50
0:03:09,000 --> 0:03:11,000
No, you've got it all wrong."

51
0:03:11,000 --> 0:03:15,000
And they say this with an amazing confidence.

52
0:03:15,000 --> 0:03:17,000
And so what I'm going to try to do today

53
0:03:17,000 --> 0:03:2,000
is to shake your confidence. Because I know the feeling --

54
0:03:2,000 --> 0:03:22,000
I can feel it myself.

55
0:03:22,000 --> 0:03:28,000
I want to shake your confidence that you know your own innermost minds --

56
0:03:28,000 --> 0:03:33,000
that you are, yourselves, authoritative about your own consciousness.

57
0:03:33,000 --> 0:03:36,000
That's the order of the day here.

58
0:03:36,000 --> 0:03:39,000
Now, this nice picture shows a thought-balloon, a thought-bubble.

59
0:03:39,000 --> 0:03:41,000
I think everybody understands what that means.

60
0:03:41,000 --> 0:03:44,000
That's supposed to exhibit the stream of consciousness.

61
0:03:44,000 --> 0:03:46,000
This is my favorite picture of consciousness that's ever been done.

62
0:03:46,000 --> 0:03:49,000
It's a Saul Steinberg of course -- it was a New Yorker cover.

63
0:03:49,000 --> 0:03:54,000
And this fellow here is looking at the painting by Braque.

64
0:03:54,000 --> 0:03:58,000
That reminds him of the word baroque, barrack, bark, poodle,

65
0:03:58,000 --> 0:04:,000
Suzanne R. -- he's off to the races.

66
0:04:,000 --> 0:04:04,000
There's a wonderful stream of consciousness here

67
0:04:04,000 --> 0:04:08,000
and if you follow it along, you learn a lot about this man.

68
0:04:08,000 --> 0:04:1,000
What I particularly like about this picture, too,

69
0:04:1,000 --> 0:04:12,000
is that Steinberg has rendered the guy

70
0:04:12,000 --> 0:04:15,000
in this sort of pointillist style.

71
0:04:15,000 --> 0:04:18,000
Which reminds us, as Rod Brooks was saying yesterday:

72
0:04:18,000 --> 0:04:22,000
what we are, what each of us is -- what you are, what I am --

73
0:04:22,000 --> 0:04:28,000
is approximately 100 trillion little cellular robots.

74
0:04:28,000 --> 0:04:3,000
That's what we're made of.

75
0:04:3,000 --> 0:04:34,000
No other ingredients at all. We're just made of cells, about 100 trillion of them.

76
0:04:34,000 --> 0:04:36,000
Not a single one of those cells is conscious;

77
0:04:36,000 --> 0:04:41,000
not a single one of those cells knows who you are, or cares.

78
0:04:41,000 --> 0:04:43,000
Somehow, we have to explain

79
0:04:43,000 --> 0:04:47,000
how when you put together teams, armies, battalions

80
0:04:47,000 --> 0:04:51,000
of hundreds of millions of little robotic unconscious cells --

81
0:04:51,000 --> 0:04:55,000
not so different really from a bacterium, each one of them --

82
0:04:55,000 --> 0:04:59,000
the result is this. I mean, just look at it.

83
0:04:59,000 --> 0:05:03,000
The content -- there's color, there's ideas, there's memories,

84
0:05:03,000 --> 0:05:07,000
there's history. And somehow all that content of consciousness

85
0:05:07,000 --> 0:05:12,000
is accomplished by the busy activity of those hoards of neurons.

86
0:05:12,000 --> 0:05:16,000
How is that possible? Many people just think it isn't possible at all.

87
0:05:16,000 --> 0:05:18,000
They think, "No, there can't be any

88
0:05:18,000 --> 0:05:22,000
sort of naturalistic explanation of consciousness."

89
0:05:22,000 --> 0:05:25,000
This is a lovely book by a friend of mine named Lee Siegel,

90
0:05:25,000 --> 0:05:28,000
who's a professor of religion, actually, at the University of Hawaii,

91
0:05:28,000 --> 0:05:3,000
and he's an expert magician, and an expert

92
0:05:3,000 --> 0:05:34,000
on the street magic of India, which is what this book is about,

93
0:05:34,000 --> 0:05:36,000
"Net of Magic."

94
0:05:36,000 --> 0:05:39,000
And there's a passage in it which I would love to share with you.

95
0:05:39,000 --> 0:05:45,000
It speaks so eloquently to the problem.

96
0:05:45,000 --> 0:05:5,000
"'I'm writing a book on magic,' I explain, and I'm asked, 'Real magic?'

97
0:05:5,000 --> 0:05:52,000
By 'real magic,' people mean miracles,

98
0:05:52,000 --> 0:05:54,000
thaumaturgical acts, and supernatural powers.

99
0:05:54,000 --> 0:05:58,000
'No,' I answer. 'Conjuring tricks, not real magic.'

100
0:05:58,000 --> 0:06:02,000
'Real magic,' in other words, refers to the magic that is not real;

101
0:06:02,000 --> 0:06:07,000
while the magic that is real, that can actually be done, is not real magic."

102
0:06:07,000 --> 0:06:11,000
(Laughter)

103
0:06:11,000 --> 0:06:15,000
Now, that's the way a lot of people feel about consciousness.

104
0:06:15,000 --> 0:06:16,000
(Laughter)

105
0:06:16,000 --> 0:06:18,000
Real consciousness is not a bag of tricks.

106
0:06:18,000 --> 0:06:2,000
If you're going to explain this as a bag of tricks,

107
0:06:2,000 --> 0:06:23,000
then it's not real consciousness, whatever it is.

108
0:06:23,000 --> 0:06:29,000
And, as Marvin said, and as other people have said,

109
0:06:29,000 --> 0:06:32,000
"Consciousness is a bag of tricks."

110
0:06:32,000 --> 0:06:37,000
This means that a lot of people are just left completely dissatisfied

111
0:06:37,000 --> 0:06:4,000
and incredulous when I attempt to explain consciousness.

112
0:06:4,000 --> 0:06:43,000
So this is the problem. So I have to

113
0:06:43,000 --> 0:06:46,000
do a little bit of the sort of work

114
0:06:46,000 --> 0:06:5,000
that a lot of you won't like,

115
0:06:5,000 --> 0:06:52,000
for the same reason that you don't like to see

116
0:06:52,000 --> 0:06:54,000
a magic trick explained to you.

117
0:06:54,000 --> 0:06:58,000
How many of you here, if somebody -- some smart aleck --

118
0:06:58,000 --> 0:07:01,000
starts telling you how a particular magic trick is done,

119
0:07:01,000 --> 0:07:04,000
you sort of want to block your ears and say, "No, no, I don't want to know!

120
0:07:04,000 --> 0:07:07,000
Don't take the thrill of it away. I'd rather be mystified.

121
0:07:07,000 --> 0:07:1,000
Don't tell me the answer."

122
0:07:1,000 --> 0:07:13,000
A lot of people feel that way about consciousness, I've discovered.

123
0:07:13,000 --> 0:07:19,000
And I'm sorry if I impose some clarity, some understanding on you.

124
0:07:19,000 --> 0:07:24,000
You'd better leave now if you don't want to know some of these tricks.

125
0:07:24,000 --> 0:07:28,000
But I'm not going to explain it all to you.

126
0:07:28,000 --> 0:07:31,000
I'm going to do what philosophers do.

127
0:07:31,000 --> 0:07:37,000
Here's how a philosopher explains the sawing-the-lady-in-half trick.

128
0:07:37,000 --> 0:07:39,000
You know the sawing-the-lady-in-half trick?

129
0:07:39,000 --> 0:07:43,000
The philosopher says, "I'm going to explain to you how that's done.

130
0:07:43,000 --> 0:07:48,000
You see, the magician doesn't really saw the lady in half."

131
0:07:48,000 --> 0:07:5,000
(Laughter)

132
0:07:5,000 --> 0:07:54,000
"He merely makes you think that he does."

133
0:07:54,000 --> 0:07:55,000
And you say, "Yes, and how does he do that?"

134
0:07:55,000 --> 0:07:57,000
He says, "Oh, that's not my department, I'm sorry."

135
0:07:57,000 --> 0:08:02,000
(Laughter)

136
0:08:02,000 --> 0:08:05,000
So now I'm going to illustrate how philosophers explain consciousness.

137
0:08:05,000 --> 0:08:08,000
But I'm going to try to also show you

138
0:08:08,000 --> 0:08:11,000
that consciousness isn't quite as marvelous --

139
0:08:11,000 --> 0:08:13,000
your own consciousness isn't quite as wonderful --

140
0:08:13,000 --> 0:08:15,000
as you may have thought it is.

141
0:08:15,000 --> 0:08:19,000
This is something, by the way, that Lee Siegel talks about in his book.

142
0:08:19,000 --> 0:08:23,000
He marvels at how he'll do a magic show, and afterwards

143
0:08:23,000 --> 0:08:27,000
people will swear they saw him do X, Y, and Z. He never did those things.

144
0:08:27,000 --> 0:08:29,000
He didn't even try to do those things.

145
0:08:29,000 --> 0:08:33,000
People's memories inflate what they think they saw.

146
0:08:33,000 --> 0:08:36,000
And the same is true of consciousness.

147
0:08:36,000 --> 0:08:43,000
Now, let's see if this will work. All right. Let's just watch this.

148
0:08:43,000 --> 0:08:44,000
Watch it carefully.

149
0:08:56,000 --> 0:08:59,000
I'm working with a young computer-animator documentarian

150
0:08:59,000 --> 0:09:04,000
named Nick Deamer, and this is a little demo that he's done for me,

151
0:09:04,000 --> 0:09:07,000
part of a larger project some of you may be interested in.

152
0:09:07,000 --> 0:09:1,000
We're looking for a backer.

153
0:09:1,000 --> 0:09:14,000
It's a feature-length documentary on consciousness.

154
0:09:14,000 --> 0:09:16,000
OK, now, you all saw what changed, right?

155
0:09:2,000 --> 0:09:25,000
How many of you noticed that every one of those squares changed color?

156
0:09:25,000 --> 0:09:29,000
Every one. I'll just show you by running it again.

157
0:09:34,000 --> 0:09:39,000
Even when you know that they're all going to change color,

158
0:09:39,000 --> 0:09:43,000
it's very hard to notice. You have to really concentrate

159
0:09:43,000 --> 0:09:46,000
to pick up any of the changes at all.

160
0:09:46,000 --> 0:09:51,000
Now, this is an example -- one of many --

161
0:09:51,000 --> 0:09:53,000
of a phenomenon that's now being studied quite a bit.

162
0:09:53,000 --> 0:09:57,000
It's one that I predicted in the last page or two of my

163
0:09:57,000 --> 0:09:59,000
1991 book, "Consciousness Explained,"

164
0:09:59,000 --> 0:10:02,000
where I said if you did experiments of this sort,

165
0:10:02,000 --> 0:10:05,000
you'd find that people were unable to pick up really large changes.

166
0:10:05,000 --> 0:10:07,000
If there's time at the end,

167
0:10:07,000 --> 0:10:1,000
I'll show you the much more dramatic case.

168
0:10:1,000 --> 0:10:15,000
Now, how can it be that there are all those changes going on,

169
0:10:15,000 --> 0:10:18,000
and that we're not aware of them?

170
0:10:18,000 --> 0:10:23,000
Well, earlier today, Jeff Hawkins mentioned the way your eye saccades,

171
0:10:23,000 --> 0:10:26,000
the way your eye moves around three or four times a second.

172
0:10:26,000 --> 0:10:29,000
He didn't mention the speed. Your eye is constantly in motion,

173
0:10:29,000 --> 0:10:32,000
moving around, looking at eyes, noses, elbows,

174
0:10:32,000 --> 0:10:34,000
looking at interesting things in the world.

175
0:10:34,000 --> 0:10:36,000
And where your eye isn't looking,

176
0:10:36,000 --> 0:10:39,000
you're remarkably impoverished in your vision.

177
0:10:39,000 --> 0:10:42,000
That's because the foveal part of your eye,

178
0:10:42,000 --> 0:10:44,000
which is the high-resolution part,

179
0:10:44,000 --> 0:10:47,000
is only about the size of your thumbnail held at arms length.

180
0:10:47,000 --> 0:10:49,000
That's the detail part.

181
0:10:49,000 --> 0:10:52,000
It doesn't seem that way, does it?

182
0:10:52,000 --> 0:10:54,000
It doesn't seem that way, but that's the way it is.

183
0:10:54,000 --> 0:10:58,000
You're getting in a lot less information than you think.

184
0:10:58,000 --> 0:11:04,000
Here's a completely different effect. This is a painting by Bellotto.

185
0:11:04,000 --> 0:11:06,000
It's in the museum in North Carolina.

186
0:11:06,000 --> 0:11:09,000
Bellotto was a student of Canaletto's.

187
0:11:09,000 --> 0:11:1,000
And I love paintings like that --

188
0:11:1,000 --> 0:11:14,000
the painting is actually about as big as it is right here.

189
0:11:14,000 --> 0:11:17,000
And I love Canalettos, because Canaletto has this fantastic detail,

190
0:11:17,000 --> 0:11:2,000
and you can get right up

191
0:11:2,000 --> 0:11:23,000
and see all the details on the painting.

192
0:11:23,000 --> 0:11:28,000
And I started across the hall in North Carolina,

193
0:11:28,000 --> 0:11:3,000
because I thought it was probably a Canaletto,

194
0:11:3,000 --> 0:11:32,000
and would have all that in detail.

195
0:11:32,000 --> 0:11:35,000
And I noticed that on the bridge there, there's a lot of people --

196
0:11:35,000 --> 0:11:38,000
you can just barely see them walking across the bridge.

197
0:11:38,000 --> 0:11:39,000
And I thought as I got closer

198
0:11:39,000 --> 0:11:42,000
I would be able to see all the detail of most people,

199
0:11:42,000 --> 0:11:44,000
see their clothes, and so forth.

200
0:11:44,000 --> 0:11:48,000
And as I got closer and closer, I actually screamed.

201
0:11:48,000 --> 0:11:5,000
I yelled out because when I got closer,

202
0:11:5,000 --> 0:11:54,000
I found the detail wasn't there at all.

203
0:11:54,000 --> 0:11:58,000
There were just little artfully placed blobs of paint.

204
0:11:58,000 --> 0:12:01,000
And as I walked towards the picture,

205
0:12:01,000 --> 0:12:04,000
I was expecting detail that wasn't there.

206
0:12:04,000 --> 0:12:09,000
The artist had very cleverly suggested people and clothes

207
0:12:09,000 --> 0:12:12,000
and wagons and all sorts of things,

208
0:12:12,000 --> 0:12:15,000
and my brain had taken the suggestion.

209
0:12:15,000 --> 0:12:21,000
You're familiar with a more recent technology, which is -- There,

210
0:12:21,000 --> 0:12:23,000
you can get a better view of the blobs.

211
0:12:23,000 --> 0:12:25,000
See, when you get close

212
0:12:25,000 --> 0:12:3,000
they're really just blobs of paint.

213
0:12:3,000 --> 0:12:36,000
You will have seen something like this -- this is the reverse effect.

214
0:12:44,000 --> 0:12:47,000
I'll just give that to you one more time.

215
0:12:47,000 --> 0:12:54,000
Now, what does your brain do when it takes the suggestion?

216
0:12:54,000 --> 0:12:59,000
When an artful blob of paint or two, by an artist,

217
0:12:59,000 --> 0:13:05,000
suggests a person -- say, one of

218
0:13:05,000 --> 0:13:07,000
Marvin Minsky's little society of mind --

219
0:13:07,000 --> 0:13:12,000
do they send little painters out to fill in all the details in your brain somewhere?

220
0:13:12,000 --> 0:13:17,000
I don't think so. Not a chance. But then, how on Earth is it done?

221
0:13:17,000 --> 0:13:22,000
Well, remember the philosopher's explanation of the lady?

222
0:13:22,000 --> 0:13:25,000
It's the same thing.

223
0:13:25,000 --> 0:13:28,000
The brain just makes you think that it's got the detail there.

224
0:13:28,000 --> 0:13:31,000
You think the detail's there, but it isn't there.

225
0:13:31,000 --> 0:13:34,000
The brain isn't actually putting the detail in your head at all.

226
0:13:34,000 --> 0:13:37,000
It's just making you expect the detail.

227
0:13:37,000 --> 0:13:4,000
Let's just do this experiment very quickly.

228
0:13:4,000 --> 0:13:45,000
Is the shape on the left the same as the shape on the right, rotated?

229
0:13:45,000 --> 0:13:47,000
Yes.

230
0:13:47,000 --> 0:13:49,000
How many of you did it by rotating the one on the left

231
0:13:49,000 --> 0:13:52,000
in your mind's eye, to see if it matched up with the one on the right?

232
0:13:52,000 --> 0:13:56,000
How many of you rotated the one on the right? OK.

233
0:13:56,000 --> 0:13:58,000
How do you know that's what you did?

234
0:13:58,000 --> 0:14:01,000
(Laughter)

235
0:14:01,000 --> 0:14:03,000
There's in fact been a very interesting debate

236
0:14:03,000 --> 0:14:06,000
raging for over 20 years in cognitive science --

237
0:14:06,000 --> 0:14:08,000
various experiments started by Roger Shepherd,

238
0:14:08,000 --> 0:14:13,000
who measured the angular velocity of rotation of mental images.

239
0:14:13,000 --> 0:14:15,000
Yes, it's possible to do that.

240
0:14:15,000 --> 0:14:22,000
But the details of the process are still in significant controversy.

241
0:14:22,000 --> 0:14:25,000
And if you read that literature, one of the things

242
0:14:25,000 --> 0:14:28,000
that you really have to come to terms with is

243
0:14:28,000 --> 0:14:3,000
even when you're the subject in the experiment, you don't know.

244
0:14:3,000 --> 0:14:32,000
You don't know how you do it.

245
0:14:32,000 --> 0:14:35,000
You just know that you have certain beliefs.

246
0:14:35,000 --> 0:14:38,000
And they come in a certain order, at a certain time.

247
0:14:38,000 --> 0:14:4,000
And what explains the fact that that's what you think?

248
0:14:4,000 --> 0:14:44,000
Well, that's where you have to go backstage and ask the magician.

249
0:14:44,000 --> 0:14:48,000
This is a figure that I love: Bradley, Petrie, and Dumais.

250
0:14:48,000 --> 0:14:5,000
You may think that I've cheated,

251
0:14:5,000 --> 0:14:55,000
that I've put a little whiter-than-white boundary there.

252
0:14:55,000 --> 0:14:57,000
How many of you see that sort of boundary,

253
0:14:57,000 --> 0:15:,000
with the Necker cube floating in front of the circles?

254
0:15:,000 --> 0:15:02,000
Can you see it?

255
0:15:02,000 --> 0:15:07,000
Well, you know, in effect, the boundary's really there, in a certain sense.

256
0:15:07,000 --> 0:15:1,000
Your brain is actually computing that boundary,

257
0:15:1,000 --> 0:15:15,000
the boundary that goes right there.

258
0:15:15,000 --> 0:15:17,000
But now, notice there are two ways of seeing the cube, right?

259
0:15:17,000 --> 0:15:19,000
It's a Necker cube.

260
0:15:19,000 --> 0:15:23,000
Everybody can see the two ways of seeing the cube? OK.

261
0:15:23,000 --> 0:15:27,000
Can you see the four ways of seeing the cube?

262
0:15:27,000 --> 0:15:29,000
Because there's another way of seeing it.

263
0:15:29,000 --> 0:15:32,000
If you're seeing it as a cube floating in front of some circles,

264
0:15:32,000 --> 0:15:35,000
some black circles, there's another way of seeing it.

265
0:15:35,000 --> 0:15:37,000
As a cube, on a black background,

266
0:15:37,000 --> 0:15:39,000
as seen through a piece of Swiss cheese.

267
0:15:39,000 --> 0:15:42,000
(Laughter)

268
0:15:42,000 --> 0:15:48,000
Can you get it? How many of you can't get it? That'll help.

269
0:15:48,000 --> 0:15:5,000
(Laughter)

270
0:15:5,000 --> 0:15:55,000
Now you can get it. These are two very different phenomena.

271
0:15:55,000 --> 0:16:01,000
When you see the cube one way, behind the screen,

272
0:16:01,000 --> 0:16:03,000
those boundaries go away.

273
0:16:03,000 --> 0:16:08,000
But there's still a sort of filling in, as we can tell if we look at this.

274
0:16:08,000 --> 0:16:12,000
We don't have any trouble seeing the cube, but where does the color change?

275
0:16:12,000 --> 0:16:15,000
Does your brain have to send little painters in there?

276
0:16:15,000 --> 0:16:17,000
The purple-painters and the green-painters

277
0:16:17,000 --> 0:16:2,000
fight over who's going to paint that bit behind the curtain? No.

278
0:16:2,000 --> 0:16:24,000
Your brain just lets it go. The brain doesn't need to fill that in.

279
0:16:29,000 --> 0:16:32,000
When I first started talking about

280
0:16:32,000 --> 0:16:36,000
the Bradley, Petrie, Dumais example that you just saw --

281
0:16:36,000 --> 0:16:4,000
I'll go back to it, this one --

282
0:16:4,000 --> 0:16:47,000
I said that there was no filling-in behind there.

283
0:16:47,000 --> 0:16:5,000
And I supposed that that was just a flat truth, always true.

284
0:16:5,000 --> 0:16:55,000
But Rob Van Lier has recently shown that it isn't.

285
0:16:55,000 --> 0:17:,000
Now, if you think you see some pale yellow --

286
0:17:,000 --> 0:17:02,000
I'll run this a few more times.

287
0:17:02,000 --> 0:17:06,000
Look in the gray areas,

288
0:17:06,000 --> 0:17:11,000
and see if you seem to see something sort of shadowy moving in there --

289
0:17:11,000 --> 0:17:18,000
yeah, it's amazing. There's nothing there. It's no trick.

290
0:17:18,000 --> 0:17:24,000
["Failure to Detect Changes in Scenes" slide]

291
0:17:24,000 --> 0:17:26,000
This is Ron Rensink's work, which was in some degree

292
0:17:26,000 --> 0:17:3,000
inspired by that suggestion right at the end of the book.

293
0:17:3,000 --> 0:17:32,000
Let me just pause this for a second if I can.

294
0:17:32,000 --> 0:17:34,000
This is change-blindness.

295
0:17:34,000 --> 0:17:36,000
What you're going to see is two pictures,

296
0:17:36,000 --> 0:17:38,000
one of which is slightly different from the other.

297
0:17:38,000 --> 0:17:41,000
You see here the red roof and the gray roof,

298
0:17:41,000 --> 0:17:43,000
and in between them there will be a mask,

299
0:17:43,000 --> 0:17:47,000
which is just a blank screen, for about a quarter of a second.

300
0:17:47,000 --> 0:17:49,000
So you'll see the first picture, then a mask,

301
0:17:49,000 --> 0:17:51,000
then the second picture, then a mask.

302
0:17:51,000 --> 0:17:55,000
And this will just continue, and your job as the subject

303
0:17:55,000 --> 0:17:58,000
is to press the button when you see the change.

304
0:17:58,000 --> 0:18:06,000
So, show the original picture for 240 milliseconds. Blank.

305
0:18:06,000 --> 0:18:12,000
Show the next picture for 240 milliseconds. Blank.

306
0:18:12,000 --> 0:18:16,000
And keep going, until the subject presses the button, saying,

307
0:18:16,000 --> 0:18:18,000
"I see the change."

308
0:18:18,000 --> 0:18:21,000
So now we're going to be subjects in the experiment.

309
0:18:21,000 --> 0:18:3,000
We're going to start easy. Some examples.

310
0:18:3,000 --> 0:18:32,000
No trouble there.

311
0:18:32,000 --> 0:18:35,000
Can everybody see? All right.

312
0:18:35,000 --> 0:18:39,000
Indeed, Rensink's subjects took only a little bit more

313
0:18:39,000 --> 0:18:41,000
than a second to press the button.

314
0:18:46,000 --> 0:18:47,000
Can you see that one?

315
0:18:55,000 --> 0:18:57,000
2.9 seconds.

316
0:19:04,000 --> 0:19:07,000
How many don't see it still?

317
0:19:07,000 --> 0:19:09,000
What's on the roof of that barn?

318
0:19:09,000 --> 0:19:12,000
(Laughter)

319
0:19:2,000 --> 0:19:22,000
It's easy.

320
0:19:46,000 --> 0:19:48,000
Is it a bridge or a dock?

321
0:19:52,000 --> 0:19:56,000
There are a few more really dramatic ones, and then I'll close.

322
0:19:56,000 --> 0:20:,000
I want you to see a few that are particularly striking.

323
0:20:,000 --> 0:20:07,000
This one because it's so large and yet it's pretty hard to see.

324
0:20:07,000 --> 0:20:1,000
Can you see it?

325
0:20:1,000 --> 0:20:12,000
Audience: Yes.

326
0:20:12,000 --> 0:20:15,000
Dan Dennett: See the shadows going back and forth? Pretty big.

327
0:20:23,000 --> 0:20:27,000
So 15.5 seconds is the median time

328
0:20:27,000 --> 0:20:29,000
for subjects in his experiment there.

329
0:20:29,000 --> 0:20:32,000
I love this one. I'll end with this one,

330
0:20:32,000 --> 0:20:35,000
just because it's such an obvious and important thing.

331
0:20:37,000 --> 0:20:43,000
How many still don't see it? How many still don't see it?

332
0:20:43,000 --> 0:20:46,000
How many engines on the wing of that Boeing?

333
0:20:46,000 --> 0:20:47,000
(Laughter)

334
0:20:47,000 --> 0:20:53,000
Right in the middle of the picture!

335
0:20:53,000 --> 0:20:54,000
Thanks very much for your attention.

336
0:20:54,000 --> 0:20:59,000
What I wanted to show you is that scientists,

337
0:20:59,000 --> 0:21:03,000
using their from-the-outside, third-person methods,

338
0:21:03,000 --> 0:21:05,000
can tell you things about your own consciousness

339
0:21:05,000 --> 0:21:07,000
that you would never dream of,

340
0:21:07,000 --> 0:21:09,000
and that, in fact, you're not the authority

341
0:21:09,000 --> 0:21:11,000
on your own consciousness that you think you are.

342
0:21:11,000 --> 0:21:13,000
And we're really making a lot of progress

343
0:21:13,000 --> 0:21:16,000
on coming up with a theory of mind.

344
0:21:16,000 --> 0:21:22,000
Jeff Hawkins, this morning, was describing his attempt

345
0:21:22,000 --> 0:21:26,000
to get theory, and a good, big theory, into the neuroscience.

346
0:21:26,000 --> 0:21:31,000
And he's right. This is a problem.

347
0:21:31,000 --> 0:21:33,000
Harvard Medical School once -- I was at a talk --

348
0:21:33,000 --> 0:21:37,000
director of the lab said, "In our lab, we have a saying.

349
0:21:37,000 --> 0:21:4,000
If you work on one neuron, that's neuroscience.

350
0:21:4,000 --> 0:21:43,000
If you work on two neurons, that's psychology."

351
0:21:43,000 --> 0:21:47,000
(Laughter)

352
0:21:47,000 --> 0:21:5,000
We have to have more theory, and it can come as much from the top down.

353
0:21:5,000 --> 0:21:52,000
Thank you very much.

354
0:21:52,000 --> 0:21:56,000
(Applause)

