1
0:00:,000 --> 0:00:07,000
Traductor: Ana María Pérez Revisor: Veronica Martinez Starnes

2
0:00:15.652,000 --> 0:00:17,000
Hoy se habla de persuasión moral.

3
0:00:18.303,000 --> 0:00:19,000
¿Qué es moral o inmoral

4
0:00:19.852,000 --> 0:00:21,000
al tratar de cambiar el comportamiento de las personas

5
0:00:22.268,000 --> 0:00:24,000
por medio de la tecnología y el diseño?

6
0:00:24.619,000 --> 0:00:25,000
No sé qué esperan ustedes,

7
0:00:26.471,000 --> 0:00:28,000
pero cuando estaba pensando en eso,

8
0:00:28.519,000 --> 0:00:29,000
enseguida me di cuenta

9
0:00:29.752,000 --> 0:00:32,000
de que no soy capaz de darles respuestas.

10
0:00:33.086,000 --> 0:00:35,000
No sé decirles qué es moral o inmoral

11
0:00:35.402,000 --> 0:00:37,000
porque vivimos en una sociedad pluralista.

12
0:00:38.318,000 --> 0:00:4,000
Mis valores pueden ser radicalmente diferentes

13
0:00:40.951,000 --> 0:00:41,000
de los suyos.

14
0:00:42.835,000 --> 0:00:45,000
Esto significa que lo que yo considero moral o inmoral,

15
0:00:46.254,000 --> 0:00:49,000
no necesariamente corresponde a lo que ustedes consideran moral o inmoral.

16
0:00:49.985,000 --> 0:00:51,000
Pero también me di cuenta de que hay algo que les puedo dar.

17
0:00:52.851,000 --> 0:00:55,000
Y es lo que este hombre detrás de mí le dio al mundo:

18
0:00:55.91,000 --> 0:00:55,000
Sócrates.

19
0:00:56.821,000 --> 0:00:57,000
Las preguntas.

20
0:00:58.268,000 --> 0:01:,000
Lo que puedo hacer y lo que me gustaría hacer con ustedes

21
0:01:00.893,000 --> 0:01:02,000
es darles, al igual que la pregunta inicial,

22
0:01:02.913,000 --> 0:01:03,000
una serie de preguntas

23
0:01:04.228,000 --> 0:01:06,000
para que descubran por su propia cuenta,

24
0:01:06.261,000 --> 0:01:07,000
capa por capa,

25
0:01:07.695,000 --> 0:01:09,000
como pelando una cebolla,

26
0:01:09.912,000 --> 0:01:11,000
hasta llegar al centro de lo que creen

27
0:01:12.128,000 --> 0:01:15,000
que es la persuasión moral o inmoral.

28
0:01:15.46,000 --> 0:01:17,000
Y me gustaría hacerlo con un par de ejemplos

29
0:01:18.328,000 --> 0:01:2,000
de tecnologías donde se han usado elementos de juego

30
0:01:21.311,000 --> 0:01:24,000
para lograr que la gente haga cosas.

31
0:01:24.628,000 --> 0:01:27,000
Es muy sencillo; una pregunta muy obvia

32
0:01:28.094,000 --> 0:01:29,000
que quisiera hacerles:

33
0:01:29.627,000 --> 0:01:31,000
¿Cuáles son sus intenciones si están diseñando algo?

34
0:01:32.445,000 --> 0:01:35,000
Y, por supuesto, las intenciones no son lo único,

35
0:01:35.678,000 --> 0:01:38,000
así que aquí hay otro ejemplo de una de estas aplicaciones.

36
0:01:39.061,000 --> 0:01:41,000
Actualmente hay un par de estos ecopaneles de mando,

37
0:01:41.96,000 --> 0:01:42,000
tableros integrados en los autos

38
0:01:43.861,000 --> 0:01:45,000
que tratan de motivarnos a conducir ahorrando combustible.

39
0:01:46.594,000 --> 0:01:47,000
Este es el Nissan MyLeaf

40
0:01:48.211,000 --> 0:01:5,000
que permite comparar su comportamiento al volante

41
0:01:50.508,000 --> 0:01:51,000
con el de otras personas,

42
0:01:52.227,000 --> 0:01:53,000
así que pueden competir para ver quién conduce

43
0:01:54.18,000 --> 0:01:55,000
de forma más eficiente.

44
0:01:55.578,000 --> 0:01:57,000
Y resulta que esas cosas son muy efectivas,

45
0:01:57.844,000 --> 0:01:59,000
tanto que animan a la gente

46
0:02:00.461,000 --> 0:02:02,000
a adoptar conductas de riesgo al volante,

47
0:02:02.543,000 --> 0:02:03,000
como no detenerse en un semáforo en rojo.

48
0:02:04.285,000 --> 0:02:06,000
Porque de ese modo hay que parar y reiniciar el motor

49
0:02:06.506,000 --> 0:02:09,000
y eso hace consumir más combustible, ¿no es cierto?

50
0:02:10.426,000 --> 0:02:14,000
A pesar de ser una aplicación muy bien intencionada,

51
0:02:14.771,000 --> 0:02:16,000
obviamente tenía efectos secundarios.

52
0:02:17.351,000 --> 0:02:19,000
Aquí hay otro ejemplo de uno de estos efectos secundarios.

53
0:02:19.5,000 --> 0:02:2,000
“Commendable” (loable):

54
0:02:20.901,000 --> 0:02:23,000
un sitio web que permite a los padres dar medallas a sus hijos

55
0:02:24.55,000 --> 0:02:26,000
cuando hacen algo que quieren que hagan,

56
0:02:26.75,000 --> 0:02:27,000
como amarrarse los zapatos.

57
0:02:28.085,000 --> 0:02:3,000
Y eso aparentemente suena muy bien,

58
0:02:30.439,000 --> 0:02:31,000
muy inofensivo, bien intencionado.

59
0:02:32.4,000 --> 0:02:35,000
Pero resulta que si miramos la investigación sobre la mentalidad de la gente,

60
0:02:36.284,000 --> 0:02:38,000
esta preocupación por los resultados,

61
0:02:38.319,000 --> 0:02:39,000
por el reconocimiento público,

62
0:02:40.116,000 --> 0:02:43,000
por este tipo de símbolos públicos de reconocimiento

63
0:02:43.501,000 --> 0:02:45,000
no es necesariamente de gran ayuda

64
0:02:46.019,000 --> 0:02:48,000
para nuestro bienestar psicológico a largo plazo.

65
0:02:48.216,000 --> 0:02:5,000
Es mejor preocuparse por aprender algo.

66
0:02:51.05,000 --> 0:02:52,000
Es mejor preocuparse por uno mismo

67
0:02:52.883,000 --> 0:02:54,000
que en cómo nos vemos frente a los demás.

68
0:02:55.869,000 --> 0:02:58,000
Ese tipo de herramienta motivacional

69
0:02:59.05,000 --> 0:03:,000
usada por sí sola

70
0:03:00.834,000 --> 0:03:02,000
tiene un efecto secundario a largo plazo.

71
0:03:03.018,000 --> 0:03:04,000
Cada vez que usamos una tecnología

72
0:03:04.735,000 --> 0:03:07,000
que se sirve del reconocimiento público o la posición social,

73
0:03:08.05,000 --> 0:03:1,000
en realidad la estamos apoyando positivamente

74
0:03:10.45,000 --> 0:03:13,000
como una cosa normal de la cual hay que preocuparse,

75
0:03:13.884,000 --> 0:03:15,000
cuando probablemente tiene un efecto negativo

76
0:03:16.569,000 --> 0:03:2,000
en nuestro bienestar psicológico cultural a largo plazo.

77
0:03:20.651,000 --> 0:03:22,000
Esta es una segunda pregunta obvia:

78
0:03:23.119,000 --> 0:03:25,000
¿Cuáles son los efectos de lo que están haciendo?

79
0:03:25.751,000 --> 0:03:27,000
Los efectos que se obtienen con el dispositivo,

80
0:03:27.856,000 --> 0:03:28,000
como menos combustible,

81
0:03:29.273,000 --> 0:03:31,000
así como los efectos de la herramienta usada

82
0:03:32.056,000 --> 0:03:34,000
para empujar a la gente a hacer algo...

83
0:03:34.088,000 --> 0:03:35,000
reconocimiento público.

84
0:03:35.671,000 --> 0:03:37,000
¿Eso es todo?: ¿intención, efecto?

85
0:03:38.621,000 --> 0:03:39,000
Bueno, existen tecnologías

86
0:03:40.141,000 --> 0:03:41,000
que obviamente combinan ambos.

87
0:03:41.875,000 --> 0:03:43,000
Los efectos a corto y largo plazo

88
0:03:44.24,000 --> 0:03:47,000
y una intención positiva como Freedom de Fred Stutzman,

89
0:03:47.292,000 --> 0:03:48,000
una aplicación que tiene como finalidad

90
0:03:48.851,000 --> 0:03:51,000
–ya que vivimos bombardeados de llamadas

91
0:03:52.122,000 --> 0:03:53,000
y solicitudes de otros–

92
0:03:53.323,000 --> 0:03:55,000
desconectar la conexión a Internet

93
0:03:55.939,000 --> 0:03:58,000
de su computadora por un tiempo predeterminado

94
0:03:59.323,000 --> 0:04:01,000
para poder trabajar en paz.

95
0:04:01.523,000 --> 0:04:02,000
Y creo que muchos estaremos de acuerdo

96
0:04:02.856,000 --> 0:04:03,000
en que es algo bien planeado

97
0:04:04.305,000 --> 0:04:06,000
y que tiene consecuencias positivas.

98
0:04:06.422,000 --> 0:04:08,000
En palabras de Michel Foucault:

99
0:04:08.539,000 --> 0:04:1,000
“Es una tecnología del yo”.

100
0:04:10.756,000 --> 0:04:12,000
Es una tecnología que permite al individuo

101
0:04:13.107,000 --> 0:04:15,000
determinar su propia vida,

102
0:04:15.455,000 --> 0:04:16,000
darle forma.

103
0:04:17.339,000 --> 0:04:18,000
Pero el problema es,

104
0:04:18.455,000 --> 0:04:19,000
como señala Foucault,

105
0:04:20.256,000 --> 0:04:21,000
que toda la tecnología del yo

106
0:04:22.055,000 --> 0:04:25,000
tiene una tecnología de dominación como contrapartida.

107
0:04:25.222,000 --> 0:04:29,000
Como puede verse hoy en día en las democracias liberales modernas,

108
0:04:29.556,000 --> 0:04:31,000
la sociedad y el Estado,

109
0:04:31.675,000 --> 0:04:35,000
no solo nos permite determinar y dar forma a nuestro yo,

110
0:04:36.054,000 --> 0:04:37,000
también es exigente con nosotros.

111
0:04:37.872,000 --> 0:04:39,000
Exige que mejoremos,

112
0:04:40.206,000 --> 0:04:41,000
que aprendamos a controlarnos,

113
0:04:41.756,000 --> 0:04:43,000
que nos manejemos constantemente

114
0:04:44.205,000 --> 0:04:45,000
porque es la única forma

115
0:04:46.006,000 --> 0:04:48,000
en que una sociedad liberal funciona.

116
0:04:48.721,000 --> 0:04:52,000
Estas tecnologías quieren que nos quedemos en el juego

117
0:04:53.014,000 --> 0:04:55,000
que la sociedad ha creado para nosotros.

118
0:04:55.656,000 --> 0:04:57,000
Quieren que nos adaptemos mejor,

119
0:04:58.121,000 --> 0:05:,000
que mejoremos para adaptarnos.

120
0:05:00.98,000 --> 0:05:03,000
Ahora, no estoy diciendo que sea necesariamente algo malo.

121
0:05:04.51,000 --> 0:05:06,000
Simplemente creo que este ejemplo

122
0:05:07.143,000 --> 0:05:09,000
nos conduce a una comprensión general,

123
0:05:09.459,000 --> 0:05:12,000
es decir, no importa qué tecnología o diseño miremos,

124
0:05:13.178,000 --> 0:05:18,000
incluso algo que consideremos bien diseñado y positivo en sus efectos

125
0:05:18.244,000 --> 0:05:19,000
–como Freedom de Stutzman–

126
0:05:19.477,000 --> 0:05:21,000
lleva consigo ciertos valores.

127
0:05:22.177,000 --> 0:05:23,000
Y podemos cuestionar estos valores.

128
0:05:23.86,000 --> 0:05:24,000
Podemos preguntarnos: ¿es bueno

129
0:05:25.791,000 --> 0:05:28,000
que todos mejoremos continuamente

130
0:05:29.674,000 --> 0:05:3,000
para adaptarnos mejor a esa sociedad?

131
0:05:31.576,000 --> 0:05:32,000
O para darles otro ejemplo,

132
0:05:33.075,000 --> 0:05:34,000
¿qué pasa con la tecnología persuasiva

133
0:05:34.959,000 --> 0:05:37,000
que convence a las mujeres musulmanas para usar el velo?

134
0:05:38.659,000 --> 0:05:4,000
¿Es una tecnología buena o mala

135
0:05:40.943,000 --> 0:05:42,000
en sus intenciones o en sus efectos?

136
0:05:43.459,000 --> 0:05:44,000
Bueno, eso depende básicamente

137
0:05:44.859,000 --> 0:05:46,000
del tipo de valores que cada uno tiene

138
0:05:47.543,000 --> 0:05:49,000
para hacer este tipo de juicios.

139
0:05:49.659,000 --> 0:05:51,000
Entonces, una tercera pregunta es:

140
0:05:51.693,000 --> 0:05:52,000
¿Qué valores usan para juzgar?

141
0:05:53.245,000 --> 0:05:54,000
Y hablando de valores,

142
0:05:55.094,000 --> 0:05:58,000
he notado que en los debates en Internet sobre la persuasión moral,

143
0:05:58.38,000 --> 0:05:59,000
y cuando hablo con la gente,

144
0:06:00.178,000 --> 0:06:02,000
a menudo noto un prejuicio extraño.

145
0:06:02.967,000 --> 0:06:05,000
Y por ese prejuicio es que nos preguntamos:

146
0:06:06.227,000 --> 0:06:09,000
¿esto o aquello “todavía” es ético?,

147
0:06:09.344,000 --> 0:06:11,000
¿“todavía” es aceptable?

148
0:06:11.678,000 --> 0:06:12,000
Preguntamos cosas como:

149
0:06:12.946,000 --> 0:06:14,000
¿Este formulario de donación para Oxfam

150
0:06:15.212,000 --> 0:06:18,000
–donde la donación mensual regular está predeterminada

151
0:06:18.228,000 --> 0:06:2,000
y la gente, tal vez sin pretenderlo,

152
0:06:20.312,000 --> 0:06:22,000
se ve alentada o empujada

153
0:06:23.127,000 --> 0:06:25,000
a hacer donaciones regulares en lugar de donaciones ocasionales–

154
0:06:25.524,000 --> 0:06:26,000
todavía es aceptable?

155
0:06:26.89,000 --> 0:06:27,000
¿Todavía es ético?

156
0:06:28.276,000 --> 0:06:29,000
Estamos pescando en aguas poco profundas.

157
0:06:29.96,000 --> 0:06:3,000
De hecho, la pregunta,

158
0:06:31.837,000 --> 0:06:31,000
“¿todavía es ético?”

159
0:06:32.747,000 --> 0:06:34,000
es solo una forma de ver la ética.

160
0:06:35.077,000 --> 0:06:37,000
Porque si se fijan en los comienzos de la ética

161
0:06:37.668,000 --> 0:06:39,000
en la cultura occidental,

162
0:06:39.893,000 --> 0:06:41,000
notarán una idea muy diferente

163
0:06:42.058,000 --> 0:06:43,000
de lo que podría ser la ética.

164
0:06:43.594,000 --> 0:06:47,000
Para Aristóteles, la ética no se ocupaba de la cuestión

165
0:06:47.692,000 --> 0:06:49,000
de si algo aún era bueno o malo.

166
0:06:50.177,000 --> 0:06:53,000
Se refería a la cuestión de cómo vivir bien la vida.

167
0:06:53.627,000 --> 0:06:55,000
Y lo puso en la palabra “areté”,

168
0:06:55.789,000 --> 0:06:57,000
que del latín, traducimos como “virtud”.

169
0:06:58.71,000 --> 0:06:59,000
Pero en realidad significa “excelencia”.

170
0:07:00.335,000 --> 0:07:03,000
Significa vivir de acuerdo a nuestro propio potencial

171
0:07:04.334,000 --> 0:07:06,000
como seres humanos.

172
0:07:06.562,000 --> 0:07:07,000
Y es una idea que creo

173
0:07:07.746,000 --> 0:07:1,000
que Paul Richard Buchanan expresó perfectamente en un ensayo reciente

174
0:07:11.252,000 --> 0:07:13,000
donde dijo: “Los productos son vivas discusiones

175
0:07:13.703,000 --> 0:07:15,000
sobre cómo deberíamos vivir nuestras vidas”.

176
0:07:15.801,000 --> 0:07:17,000
Nuestros diseños no son morales o inmorales

177
0:07:18.687,000 --> 0:07:22,000
en función de si usan medios morales o inmorales para persuadirnos.

178
0:07:23.301,000 --> 0:07:24,000
Tienen un componente moral

179
0:07:24.868,000 --> 0:07:28,000
solo en el tipo de visión y aspiración de la buena vida

180
0:07:28.957,000 --> 0:07:3,000
que nos presentan.

181
0:07:31.653,000 --> 0:07:34,000
Y si se fijan en el ambiente diseñado a nuestro alrededor

182
0:07:34.968,000 --> 0:07:35,000
desde esa perspectiva,

183
0:07:36.164,000 --> 0:07:38,000
preguntándose: “¿Cuál es la visión de la buena vida

184
0:07:38.385,000 --> 0:07:41,000
que nuestros productos y diseños nos presentan?”,

185
0:07:41.403,000 --> 0:07:43,000
a menudo nos estremecemos

186
0:07:43.703,000 --> 0:07:45,000
a causa de lo poco que esperamos de los demás,

187
0:07:46.055,000 --> 0:07:48,000
de lo poco que, al parecer esperamos

188
0:07:48.773,000 --> 0:07:51,000
de nuestra vida y cómo es la buena vida.

189
0:07:52.356,000 --> 0:07:55,000
Esta es la cuarta pregunta que quisiera dejarles:

190
0:07:56.157,000 --> 0:07:57,000
¿Qué visión de la buena vida

191
0:07:57.64,000 --> 0:08:,000
transmiten sus diseños?

192
0:08:01.305,000 --> 0:08:02,000
Y hablando de diseño,

193
0:08:02.407,000 --> 0:08:05,000
noten que ya he ampliado la discusión.

194
0:08:06.139,000 --> 0:08:1,000
Porque ya no hablamos solo de tecnología persuasiva,

195
0:08:10.874,000 --> 0:08:14,000
sino de cualquier diseño que ponemos en el mundo.

196
0:08:15.074,000 --> 0:08:16,000
No sé si conocen

197
0:08:16.456,000 --> 0:08:17,000
al gran investigador de la comunicación Paul Watzlawick,

198
0:08:18.124,000 --> 0:08:19,000
que en los años 60 argumentó

199
0:08:19.972,000 --> 0:08:2,000
que es imposible no comunicarse.

200
0:08:21.307,000 --> 0:08:23,000
Incluso si optamos por permanecer en silencio,

201
0:08:23.84,000 --> 0:08:27,000
elegimos guardar silencio. Estamos comunicando algo al optar por el silencio.

202
0:08:28.237,000 --> 0:08:3,000
Y de la misma forma que no podemos no comunicar,

203
0:08:30.841,000 --> 0:08:31,000
no podemos dejar de persuadir.

204
0:08:32.358,000 --> 0:08:34,000
Cualquier cosa que hagamos o dejemos de hacer,

205
0:08:34.657,000 --> 0:08:36,000
cualquier cosa que pongamos en el mundo

206
0:08:37.523,000 --> 0:08:38,000
como un diseño

207
0:08:38.79,000 --> 0:08:4,000
tiene un componente persuasivo

208
0:08:41.074,000 --> 0:08:43,000
que trata de influenciar a las personas.

209
0:08:43.19,000 --> 0:08:45,000
Pone una cierta visión de la buena vida

210
0:08:45.374,000 --> 0:08:46,000
frente a nosotros.

211
0:08:46.711,000 --> 0:08:47,000
Y eso es lo que dice Peter-Paul Verbeek,

212
0:08:48.697,000 --> 0:08:5,000
el filósofo holandés de la tecnología.

213
0:08:50.843,000 --> 0:08:54,000
Ya sea voluntario o no, nosotros, como diseñadores,

214
0:08:55.409,000 --> 0:08:56,000
materializamos la moralidad.

215
0:08:57.173,000 --> 0:09:,000
Hacemos que ciertas cosas sean más difíciles o más fáciles de hacer.

216
0:09:00.224,000 --> 0:09:01,000
Organizamos la existencia de las personas.

217
0:09:02.174,000 --> 0:09:04,000
Ponemos delante de la gente una cierta visión

218
0:09:04.924,000 --> 0:09:07,000
de lo que es bueno o malo, o normal o habitual

219
0:09:08.292,000 --> 0:09:1,000
con todo lo que ponemos en el mundo.

220
0:09:10.841,000 --> 0:09:13,000
Incluso algo tan inocuo como un juego de sillas escolares

221
0:09:14.357,000 --> 0:09:15,000
es una tecnología persuasiva.

222
0:09:15.791,000 --> 0:09:17,000
Porque presenta y materializa

223
0:09:18.607,000 --> 0:09:19,000
una cierta visión de la buena vida...

224
0:09:20.541,000 --> 0:09:23,000
buena vida en la que enseñar, aprender y escuchar

225
0:09:24.023,000 --> 0:09:26,000
significa que hay alguien que enseña y otros que escuchan,

226
0:09:26.958,000 --> 0:09:29,000
en la que se aprende estando sentados,

227
0:09:30.71,000 --> 0:09:32,000
en la que se aprende por sí mismo,

228
0:09:32.94,000 --> 0:09:34,000
en la que no está previsto cambiar estas reglas

229
0:09:35.19,000 --> 0:09:38,000
porque las sillas están fijadas al suelo.

230
0:09:38.44,000 --> 0:09:41,000
E incluso algo tan inocuo como una silla de diseño único

231
0:09:41.823,000 --> 0:09:42,000
–como esta de Arne Jacobsen–

232
0:09:43.124,000 --> 0:09:44,000
es una tecnología persuasiva.

233
0:09:44.825,000 --> 0:09:47,000
Porque, reitero, comunica una idea de la buena vida.

234
0:09:48.24,000 --> 0:09:49,000
Una buena vida...

235
0:09:49.739,000 --> 0:09:51,000
una vida que ustedes como diseñadores autorizan

236
0:09:51.94,000 --> 0:09:53,000
diciendo: “En la buena vida,

237
0:09:54.027,000 --> 0:09:58,000
los bienes que se producen son sostenibles o insostenibles como esta silla.

238
0:09:58.041,000 --> 0:10:,000
A los trabajadores se les trata bien o mal

239
0:10:00.663,000 --> 0:10:02,000
como a los que construyeron esa silla”.

240
0:10:03.307,000 --> 0:10:05,000
La buena vida donde el diseño es importante

241
0:10:05.64,000 --> 0:10:07,000
porque obviamente alguien se tomó el tiempo y gastó dinero

242
0:10:08.374,000 --> 0:10:09,000
en ese tipo de silla tan bien diseñada,

243
0:10:10.238,000 --> 0:10:11,000
donde la tradición es importante

244
0:10:11.657,000 --> 0:10:12,000
porque es un clásico tradicional

245
0:10:13.458,000 --> 0:10:14,000
y a alguien le importa

246
0:10:14.97,000 --> 0:10:15,000
y donde existe algo como el consumo ostentoso,

247
0:10:16.922,000 --> 0:10:17,000
donde está bien y es normal

248
0:10:18.49,000 --> 0:10:21,000
gastar una enorme cantidad de dinero en una silla

249
0:10:21.509,000 --> 0:10:24,000
solo para mostrar a los demás cuál es su condición social.

250
0:10:24.924,000 --> 0:10:27,000
Así que estas son las capas, los tipos de preguntas

251
0:10:28.091,000 --> 0:10:29,000
que quería transmitirles hoy.

252
0:10:29.844,000 --> 0:10:31,000
Las preguntas: ¿Qué intenciones

253
0:10:31.992,000 --> 0:10:33,000
tienen cuando diseñan algo?

254
0:10:34.458,000 --> 0:10:37,000
¿Qué efectos, intencionales y no intencionales, obtienen?

255
0:10:37.958,000 --> 0:10:38,000
¿Cuáles son los valores que usan

256
0:10:39.523,000 --> 0:10:4,000
para juzgarlos?

257
0:10:40.875,000 --> 0:10:41,000
¿Cuáles son las virtudes y aspiraciones

258
0:10:42.342,000 --> 0:10:44,000
que en realidad están expresando con eso?

259
0:10:45.061,000 --> 0:10:47,000
Y ¿cómo se aplica,

260
0:10:47.156,000 --> 0:10:48,000
no solo en la tecnología persuasiva,

261
0:10:49.148,000 --> 0:10:51,000
sino a todo lo que diseñan?

262
0:10:51.482,000 --> 0:10:52,000
¿Nos detenemos ahí?

263
0:10:53.384,000 --> 0:10:54,000
No lo creo.

264
0:10:55.017,000 --> 0:10:59,000
Creo que todas esas cosas derivan, en última instancia,

265
0:10:59.482,000 --> 0:11:,000
de la base de todo esto

266
0:11:01.2,000 --> 0:11:04,000
que no es más que la vida misma.

267
0:11:04.315,000 --> 0:11:06,000
¿Por qué cuando la pregunta sobre lo que es la buena vida

268
0:11:07.215,000 --> 0:11:09,000
impregna todo lo que diseñamos,

269
0:11:09.566,000 --> 0:11:11,000
deberíamos parar de diseñar y dejar de preguntarnos,

270
0:11:12.149,000 --> 0:11:14,000
cómo se aplica a nuestra propia vida?

271
0:11:14.882,000 --> 0:11:16,000
“¿Por qué esta lámpara o esta casa puede ser un objeto de arte

272
0:11:17.617,000 --> 0:11:18,000
pero mi vida no?”,

273
0:11:18.848,000 --> 0:11:19,000
como dice Michel Foucault.

274
0:11:20.464,000 --> 0:11:23,000
Quiero darles un ejemplo práctico de Buster Benson.

275
0:11:24.015,000 --> 0:11:26,000
Este es Buster ensamblando un aparato de musculación

276
0:11:26.53,000 --> 0:11:28,000
en la oficina de su nueva empresa Habit Labs,

277
0:11:28.983,000 --> 0:11:3,000
donde están tratando de hacer otras aplicaciones

278
0:11:31,000 --> 0:11:32,000
como “Health Month” para la gente.

279
0:11:32.982,000 --> 0:11:34,000
¿Por qué crea una cosa así?

280
0:11:35.562,000 --> 0:11:37,000
Bueno, aquí hay un conjunto de axiomas

281
0:11:37.567,000 --> 0:11:4,000
que Habit Labs, la empresa de Buster, presentó

282
0:11:40.77,000 --> 0:11:43,000
sobre cómo querían trabajar juntos en equipo

283
0:11:43.891,000 --> 0:11:44,000
cuando estaban construyendo estas aplicaciones

284
0:11:45.715,000 --> 0:11:47,000
–un conjunto de principios morales establecidos por ellos mismos

285
0:11:47.767,000 --> 0:11:48,000
para trabajar juntos–

286
0:11:49.515,000 --> 0:11:5,000
y uno de ellos era:

287
0:11:50.913,000 --> 0:11:53,000
“Nos preocupamos por nuestra propia salud y dirigimos nuestros ejercicios físicos”.

288
0:11:53.995,000 --> 0:11:56,000
Porque en última instancia, ¿cómo pueden preguntarse

289
0:11:57.745,000 --> 0:11:58,000
y encontrar una respuesta

290
0:11:59.212,000 --> 0:12:01,000
sobre la visión de la buena vida

291
0:12:01.512,000 --> 0:12:04,000
que quieren transmitir y crear con sus diseños

292
0:12:04.613,000 --> 0:12:05,000
sin preguntarse

293
0:12:06.295,000 --> 0:12:07,000
qué visión de la buena vida

294
0:12:07.779,000 --> 0:12:09,000
les gustaría vivir?

295
0:12:10.679,000 --> 0:12:14,000
Y con eso, les doy las gracias.

296
0:12:14.929,000 --> 0:12:16,000
(Aplausos)

