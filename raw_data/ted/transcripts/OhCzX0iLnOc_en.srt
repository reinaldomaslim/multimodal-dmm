1
0:00:12.879,000 --> 0:00:19,000
so artificial intelligence it's known

2
0:00:17.18,000 --> 0:00:22,000
for disrupting all kinds of industries

3
0:00:20.169,000 --> 0:00:26,000
what about ice cream

4
0:00:23.05,000 --> 0:00:28,000
what kind of mind-blowing new flavors

5
0:00:26.57,000 --> 0:00:3,000
could we generate with the power of an

6
0:00:28.489,000 --> 0:00:33,000
advanced artificial intelligence so I

7
0:00:31.16,000 --> 0:00:35,000
teamed up with a group of coders from

8
0:00:33.68,000 --> 0:00:37,000
Kealing middle school to find out the

9
0:00:35.96,000 --> 0:00:4,000
answer to this question and they

10
0:00:38.27,000 --> 0:00:44,000
collected over 1,600 existing ice cream

11
0:00:41.51,000 --> 0:00:46,000
flavors and together we fed them to a

12
0:00:44.87,000 --> 0:00:48,000
algorithm to see what it would generate

13
0:00:47.3,000 --> 0:01:03,000
and here are some of the flavors that

14
0:00:49.67,000 --> 0:01:05,000
the AI came up with these flavors are

15
0:01:03.38,000 --> 0:01:07,000
not delicious as we might have hoped

16
0:01:05.689,000 --> 0:01:09,000
they would be so the question is what

17
0:01:08.09,000 --> 0:01:14,000
happened what went wrong is the AI

18
0:01:10.64,000 --> 0:01:18,000
trying to kill us or is it trying to do

19
0:01:14.24,000 --> 0:01:2,000
what we asked and there was a problem so

20
0:01:18.74,000 --> 0:01:21,000
in movies when something goes wrong with

21
0:01:20.42,000 --> 0:01:24,000
AI it's usually because the AI has

22
0:01:22.67,000 --> 0:01:26,000
decided that doesn't want to obey the

23
0:01:24.889,000 --> 0:01:28,000
humans anymore and it's got his own

24
0:01:26.78,000 --> 0:01:31,000
goals thank you very much so in real

25
0:01:29.869,000 --> 0:01:34,000
life though the AI that we actually have

26
0:01:32.149,000 --> 0:01:36,000
is not nearly smart enough for that it

27
0:01:34.909,000 --> 0:01:39,000
has the approximate computing power of

28
0:01:37.069,000 --> 0:01:43,000
an earthworm or maybe at most a single

29
0:01:40.639,000 --> 0:01:45,000
honeybee and actually probably maybe

30
0:01:43.67,000 --> 0:01:47,000
less like we're constantly learning new

31
0:01:46.34,000 --> 0:01:5,000
things about brains that make it clear

32
0:01:48.049,000 --> 0:01:51,000
how much our AIS don't measure up to

33
0:01:50.389,000 --> 0:01:54,000
real brains

34
0:01:51.2,000 --> 0:01:57,000
so today's AI can do some a task like

35
0:01:54.77,000 --> 0:01:58,000
identify a pedestrian in a picture but

36
0:01:57.56,000 --> 0:02:,000
it doesn't have a concept of what the

37
0:01:59.209,000 --> 0:02:04,000
pedestrian is beyond it's a lot

38
0:02:01.52,000 --> 0:02:06,000
collection of lines and textures and

39
0:02:04.399,000 --> 0:02:1,000
things it doesn't know what a human

40
0:02:07.069,000 --> 0:02:13,000
actually is so we'll today's AI do what

41
0:02:10.61,000 --> 0:02:15,000
we asked it to do it will if it can but

42
0:02:13.88,000 --> 0:02:17,000
it might not do what we actually want so

43
0:02:16.34,000 --> 0:02:2,000
let's say that you are trying to get an

44
0:02:18.409,000 --> 0:02:21,000
AI to take this collection of robot

45
0:02:20.689,000 --> 0:02:22,000
parts

46
0:02:21.41,000 --> 0:02:24,000
and assemble them into some kind of

47
0:02:23.3,000 --> 0:02:26,000
robot they'd get from point A to point B

48
0:02:25.13,000 --> 0:02:28,000
now if you were going to try and solve

49
0:02:27.05,000 --> 0:02:3,000
this problem by writing a

50
0:02:28.25,000 --> 0:02:33,000
traditional-style computer program you

51
0:02:30.86,000 --> 0:02:34,000
would give the program step by step

52
0:02:33.41,000 --> 0:02:36,000
instructions on how to take these parts

53
0:02:35.3,000 --> 0:02:39,000
how to assemble and for a robot with

54
0:02:37.07,000 --> 0:02:42,000
legs and then how to use those legs to

55
0:02:39.5,000 --> 0:02:43,000
walk to point B but when you're using AI

56
0:02:42.38,000 --> 0:02:46,000
to solve the problem it goes differently

57
0:02:44.36,000 --> 0:02:48,000
you don't tell it how to solve the

58
0:02:47.03,000 --> 0:02:51,000
problem you just give it the goal and it

59
0:02:49.1,000 --> 0:02:54,000
has to figure out for itself via trial

60
0:02:51.62,000 --> 0:02:56,000
and error how to reach that goal and it

61
0:02:54.68,000 --> 0:02:58,000
turns out the way the AI tends to solve

62
0:02:56.9,000 --> 0:03:01,000
this particular problem is by doing this

63
0:02:59.3,000 --> 0:03:05,000
it assembles itself into a tower and

64
0:03:02.18,000 --> 0:03:07,000
then falls over and lands at point B and

65
0:03:05.5,000 --> 0:03:09,000
technically this solves the problem

66
0:03:07.97,000 --> 0:03:11,000
technically it got to point B the danger

67
0:03:10.16,000 --> 0:03:15,000
if AI is not that it's going to rebel

68
0:03:12.68,000 --> 0:03:18,000
against us if that is going to do

69
0:03:15.47,000 --> 0:03:21,000
exactly what we ask it to do so then the

70
0:03:19.28,000 --> 0:03:22,000
trick of working with AI becomes how do

71
0:03:21.68,000 --> 0:03:26,000
we set up the problem so that it

72
0:03:23.06,000 --> 0:03:29,000
actually does what we want so this

73
0:03:27.14,000 --> 0:03:31,000
little robot here is being controlled by

74
0:03:29.27,000 --> 0:03:33,000
an AI the AI came up with the design for

75
0:03:31.91,000 --> 0:03:34,000
the robot legs and then figured out how

76
0:03:33.68,000 --> 0:03:37,000
to use them to get past all these

77
0:03:35.57,000 --> 0:03:4,000
obstacles but when David Hass set up

78
0:03:38.36,000 --> 0:03:43,000
this experiment he had to set it up with

79
0:03:41.03,000 --> 0:03:46,000
very very strict limits on how big the

80
0:03:43.43,000 --> 0:03:48,000
AI was allowed to make the legs because

81
0:03:46.22,000 --> 0:03:48,000
otherwise

82
0:03:58.88,000 --> 0:04:04,000
and technically it got to the end of

83
0:04:02.43,000 --> 0:04:07,000
that obstacle course so you can see how

84
0:04:05.069,000 --> 0:04:1,000
hard it is to get AI to do something as

85
0:04:07.44,000 --> 0:04:13,000
simple as just walk so seeing the AI do

86
0:04:11.01,000 --> 0:04:15,000
this you may say okay no fair you can't

87
0:04:13.53,000 --> 0:04:17,000
just be a tall tower and fall over you

88
0:04:15.75,000 --> 0:04:19,000
have to actually like use legs to walk

89
0:04:18.299,000 --> 0:04:23,000
and it turns out that doesn't always

90
0:04:20.31,000 --> 0:04:25,000
work either so this a eyes job was to

91
0:04:23.669,000 --> 0:04:28,000
move fast they didn't tell it that it

92
0:04:26.22,000 --> 0:04:32,000
had to run facing forward or that it

93
0:04:29.25,000 --> 0:04:35,000
couldn't use his arms so this is what

94
0:04:33,000 --> 0:04:38,000
you get when you train AI to move fast

95
0:04:35.64,000 --> 0:04:4,000
is you get things like somersaulting and

96
0:04:38.79,000 --> 0:04:43,000
Silly Walks it's really common

97
0:04:40.97,000 --> 0:04:47,000
so is twitching along the floor in a

98
0:04:44.22,000 --> 0:04:49,000
heap so in my opinion you know what

99
0:04:48.6,000 --> 0:04:52,000
should have been a whole lot weirder is

100
0:04:49.89,000 --> 0:04:53,000
the Terminator robots hacking the matrix

101
0:04:53.25,000 --> 0:04:56,000
is another thing that AI will do if you

102
0:04:54.87,000 --> 0:04:58,000
give it a chance so if you train an AI

103
0:04:56.91,000 --> 0:05:01,000
in a simulation it will learn how to do

104
0:04:59.55,000 --> 0:05:03,000
things like hack into the simulations

105
0:05:01.919,000 --> 0:05:06,000
math errors and harvest them for energy

106
0:05:03.979,000 --> 0:05:08,000
or it'll figure out how to move faster

107
0:05:07.05,000 --> 0:05:12,000
by glitching repeatedly into the floor

108
0:05:09.62,000 --> 0:05:14,000
when you're working with AI is less like

109
0:05:12.75,000 --> 0:05:15,000
working with another human and a lot

110
0:05:14.76,000 --> 0:05:18,000
more like working with some kind of

111
0:05:16.26,000 --> 0:05:21,000
weird force of nature and it's really

112
0:05:19.35,000 --> 0:05:23,000
easy to accidentally give AI the wrong

113
0:05:21.6,000 --> 0:05:25,000
problem to solve and often we don't

114
0:05:23.94,000 --> 0:05:27,000
realize that until something has

115
0:05:26.19,000 --> 0:05:31,000
actually gone wrong so here's an

116
0:05:28.77,000 --> 0:05:33,000
experiment I did where I wanted the AI

117
0:05:31.2,000 --> 0:05:37,000
to copy paint colors to invent new paint

118
0:05:34.47,000 --> 0:05:39,000
colors given the list like the ones here

119
0:05:37.38,000 --> 0:05:42,000
on the left and here's what the AI

120
0:05:39.8,000 --> 0:05:42,000
actually came up with

121
0:05:50.29,000 --> 0:05:56,000
so technically it did what I asked it to

122
0:05:54.44,000 --> 0:05:58,000
so I thought I was asking it for like

123
0:05:56.69,000 --> 0:06:,000
nice paint color names what what I was

124
0:05:58.85,000 --> 0:06:02,000
actually asking it to do was just

125
0:06:01.04,000 --> 0:06:05,000
imitate the kinds of letter combinations

126
0:06:03.44,000 --> 0:06:07,000
that it had seen in the original and I

127
0:06:05.87,000 --> 0:06:09,000
didn't tell anything about what words

128
0:06:08,000 --> 0:06:13,000
mean or that there are maybe some words

129
0:06:10.79,000 --> 0:06:16,000
that it should avoid using in these

130
0:06:13.07,000 --> 0:06:19,000
paint colors so it's entire world is the

131
0:06:16.91,000 --> 0:06:2,000
data that I gave it like with the ice

132
0:06:19.4,000 --> 0:06:25,000
cream flavors it doesn't know about

133
0:06:20.99,000 --> 0:06:28,000
anything else so it is through the data

134
0:06:25.91,000 --> 0:06:31,000
that we often accidentally tell AI to do

135
0:06:29.21,000 --> 0:06:34,000
the wrong thing so this is a fish called

136
0:06:32.63,000 --> 0:06:36,000
a tench and there was a group of

137
0:06:34.67,000 --> 0:06:39,000
researchers who trained at AI to

138
0:06:36.92,000 --> 0:06:4,000
identify this tension pictures but then

139
0:06:39.77,000 --> 0:06:42,000
when they asked it what part of the

140
0:06:41.21,000 --> 0:06:44,000
picture that I was actually using to

141
0:06:42.83,000 --> 0:06:47,000
identify the fish here's what it

142
0:06:44.72,000 --> 0:06:5,000
highlighted yes those are human fingers

143
0:06:48.71,000 --> 0:06:52,000
why would it be looking for human

144
0:06:50.72,000 --> 0:06:55,000
fingers if is trying to identify a fish

145
0:06:53.29,000 --> 0:06:58,000
well it turns out that the ten choose a

146
0:06:56.06,000 --> 0:07:,000
trophy fish and so in a lot of the

147
0:06:58.76,000 --> 0:07:01,000
pictures that the AI had seen of this

148
0:07:00.83,000 --> 0:07:05,000
fish during training the fish looked

149
0:07:02.75,000 --> 0:07:1,000
like this and it didn't know that the

150
0:07:06.62,000 --> 0:07:13,000
fingers aren't part of the fish so you

151
0:07:11.24,000 --> 0:07:17,000
see why it is so hard to design an AI

152
0:07:14.57,000 --> 0:07:19,000
that actually can understand what it's

153
0:07:17.33,000 --> 0:07:22,000
looking at and this is why designing the

154
0:07:20.09,000 --> 0:07:24,000
image recognition in self-driving cars

155
0:07:22.37,000 --> 0:07:26,000
is so hard and why so many self-driving

156
0:07:24.56,000 --> 0:07:27,000
car failures are because the AI got

157
0:07:27.14,000 --> 0:07:3,000
confused

158
0:07:27.86,000 --> 0:07:33,000
I want to talk about an example from

159
0:07:30.7,000 --> 0:07:35,000
2016 there was a fatal accident when

160
0:07:34.22,000 --> 0:07:38,000
somebody was using Tesla's autopilot ai

161
0:07:36.5,000 --> 0:07:41,000
but instead of using it on the highway

162
0:07:38.75,000 --> 0:07:43,000
like was design for they used it on city

163
0:07:41.57,000 --> 0:07:45,000
streets and what happened was a truck

164
0:07:44.39,000 --> 0:07:48,000
drove out in front of the car and the

165
0:07:46.46,000 --> 0:07:5,000
car failed to break now the AI

166
0:07:48.98,000 --> 0:07:53,000
definitely was trained to recognize

167
0:07:50.87,000 --> 0:07:55,000
trucks and pictures but what it looks

168
0:07:54.23,000 --> 0:07:57,000
like happened is the a I was trained to

169
0:07:56.51,000 --> 0:07:59,000
recognize trucks on highway driving

170
0:07:58.16,000 --> 0:08:02,000
where you would expect to see trucks

171
0:08:00.11,000 --> 0:08:03,000
from behind trucks on the side is not

172
0:08:02.39,000 --> 0:08:06,000
supposed to happen on

173
0:08:03.66,000 --> 0:08:07,000
highway and so when the AI saw this

174
0:08:07.35,000 --> 0:08:1,000
truck

175
0:08:08.01,000 --> 0:08:12,000
it looks like the AI recognized it as a

176
0:08:10.77,000 --> 0:08:14,000
most likely to be a road sign and

177
0:08:12.9,000 --> 0:08:17,000
therefore safe to drive underneath

178
0:08:15.35,000 --> 0:08:2,000
here's an AI messed up from a different

179
0:08:17.97,000 --> 0:08:21,000
field Amazon recently had to give up on

180
0:08:20.67,000 --> 0:08:23,000
a resume sorting algorithm they were

181
0:08:22.41,000 --> 0:08:25,000
working on when they discovered that the

182
0:08:24.15,000 --> 0:08:27,000
algorithm had learned to discriminate

183
0:08:25.95,000 --> 0:08:29,000
against women what happened is they had

184
0:08:28.02,000 --> 0:08:32,000
trained it on example resumes of people

185
0:08:30.24,000 --> 0:08:34,000
who they had hired in the past and from

186
0:08:32.82,000 --> 0:08:36,000
these examples the AI learned to avoid

187
0:08:34.979,000 --> 0:08:38,000
the resumes of people who had gone to

188
0:08:36.87,000 --> 0:08:4,000
women's colleges or who had the word

189
0:08:39.63,000 --> 0:08:43,000
women somewhere in their resume as in

190
0:08:41.52,000 --> 0:08:46,000
women's soccer team or Society of Women

191
0:08:44.19,000 --> 0:08:49,000
Engineers the AI didn't know that it

192
0:08:47.37,000 --> 0:08:51,000
wasn't supposed to copy this particular

193
0:08:49.32,000 --> 0:08:54,000
thing that it had seen the humans do and

194
0:08:51.68,000 --> 0:08:56,000
technically it did what they asked it to

195
0:08:54.45,000 --> 0:08:59,000
do they just accidentally asked it to do

196
0:08:56.76,000 --> 0:09:02,000
the wrong thing and this happens all the

197
0:08:59.73,000 --> 0:09:04,000
time with ai ai ai can be really

198
0:09:03.57,000 --> 0:09:07,000
destructive and not know it

199
0:09:05.22,000 --> 0:09:11,000
so the AIS that recommend new content in

200
0:09:08.39,000 --> 0:09:13,000
Facebook in YouTube they're optimized to

201
0:09:11.88,000 --> 0:09:15,000
increase the number of clicks and views

202
0:09:13.41,000 --> 0:09:18,000
and unfortunately one way that they have

203
0:09:16.38,000 --> 0:09:2,000
found of doing this is to recommend

204
0:09:18.69,000 --> 0:09:24,000
content of conspiracy theories or

205
0:09:21.3,000 --> 0:09:26,000
bigotry the AI is themselves don't have

206
0:09:24.9,000 --> 0:09:28,000
any concept of what this content

207
0:09:26.79,000 --> 0:09:3,000
actually is and they don't have any

208
0:09:28.92,000 --> 0:09:33,000
concept of what the consequences might

209
0:09:30.96,000 --> 0:09:36,000
be of recommending this content so when

210
0:09:34.71,000 --> 0:09:41,000
we're working with AI it's up to us to

211
0:09:37.68,000 --> 0:09:43,000
avoid problems and avoiding things going

212
0:09:42.42,000 --> 0:09:47,000
wrong that may come down to the age-old

213
0:09:44.64,000 --> 0:09:49,000
problem of communication where we as

214
0:09:48.24,000 --> 0:09:52,000
humans have to learn how to communicate

215
0:09:49.83,000 --> 0:09:54,000
with AI we have to learn what AI is

216
0:09:53.01,000 --> 0:09:57,000
capable of doing and what it's not and

217
0:09:55.26,000 --> 0:09:59,000
to understand that with its tiny little

218
0:09:57.15,000 --> 0:10:03,000
worm brain AI doesn't really understand

219
0:10:00.12,000 --> 0:10:04,000
what we're trying to ask it to do so in

220
0:10:03.39,000 --> 0:10:08,000
other words we have to be prepared to

221
0:10:05.1,000 --> 0:10:1,000
work with an AI that's not the super

222
0:10:08.49,000 --> 0:10:12,000
competent all-knowing AI of science

223
0:10:10.86,000 --> 0:10:14,000
fiction we have to be prepared to work

224
0:10:12.99,000 --> 0:10:15,000
with an AI that's the one that we

225
0:10:15.39,000 --> 0:10:2,000
actually have in the present day

226
0:10:16.98,000 --> 0:10:21,000
and present-day AI is plenty weird

227
0:10:20.88,000 --> 0:10:26,000
enough thank you

228
0:10:22.91,000 --> 0:10:3,000
[Applause]

229
0:10:27.79,000 --> 0:10:3,000
[Music]

