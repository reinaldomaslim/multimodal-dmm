1
0:00:,000 --> 0:00:07,000
Traductor: --Galena-- PTS Revisor: Lidia Cámara de la Fuente

2
0:00:12.76,000 --> 0:00:13,000
Estamos en 1996 en Uvira,

3
0:00:14.51,000 --> 0:00:16,000
en la Provincia Oriental de la R.D. del Congo.

4
0:00:16.68,000 --> 0:00:17,000
Este es Bukeni.

5
0:00:18.04,000 --> 0:00:2,000
Comandantes de la milicia entraron en su pueblo,

6
0:00:20.76,000 --> 0:00:21,000
tocaron en la puerta de sus vecinos

7
0:00:22.56,000 --> 0:00:25,000
y se llevaron a sus hijos a campos de entrenamiento militar.

8
0:00:26.32,000 --> 0:00:3,000
Bukeni pidió prestada la cámara de vídeo de un fotógrafo de bodas local,

9
0:00:30.6,000 --> 0:00:31,000
se hizo pasar por reportero

10
0:00:32.4,000 --> 0:00:35,000
y entró en los campos para negociar la liberación de los niños.

11
0:00:36.56,000 --> 0:00:39,000
Grabó cómo entrenaban a los niños para ser soldados.

12
0:00:40.568,000 --> 0:00:42,000
[Soldados, ¡no os preocupen!]

13
0:00:43.202,000 --> 0:00:44,000
[¡Uds. llevarán uniformes!]

14
0:00:45.22,000 --> 0:00:46,000
[¡Uds. tendrán autos gratis!]

15
0:00:46.84,000 --> 0:00:46,000
[¡Comida gratis!]

16
0:00:47.68,000 --> 0:00:5,000
Muchos de estos niños tienen menos de 15 años,

17
0:00:51.24,000 --> 0:00:52,000
y esto es un crimen de guerra.

18
0:00:53.27,000 --> 0:00:54,000
[¡Gratis!]

19
0:00:55.28,000 --> 0:00:58,000
Pero no hace falta ir al Congo para ver cómo se vulneran los derechos humanos.

20
0:00:59.76,000 --> 0:01:02,000
En EE. UU, donde el envejecimiento de la población se está acelerando,

21
0:01:03.56,000 --> 0:01:07,000
los expertos estiman que una de cada 10 personas mayores de 60 años

22
0:01:07.96,000 --> 0:01:09,000
será víctima de malos tratos.

23
0:01:10.64,000 --> 0:01:12,000
Es una epidemia oculta,

24
0:01:13,000 --> 0:01:15,000
y de hecho la mayor parte de esos malos tratos

25
0:01:15.8,000 --> 0:01:17,000
proviene de cuidadores o de familiares.

26
0:01:19.2,000 --> 0:01:2,000
Esta es Vicky,

27
0:01:20.56,000 --> 0:01:24,000
Vicky puso una verja de hierro en la puerta de su dormitorio

28
0:01:25.04,000 --> 0:01:28,000
y se convirtió en una prisionera en su propia casa,

29
0:01:28.16,000 --> 0:01:32,000
por temor a su sobrino, que se adueñó de su casa para vender droga.

30
0:01:33.76,000 --> 0:01:34,000
Esta es Mary.

31
0:01:35.08,000 --> 0:01:38,000
Mary tuvo en sus manos una cámara de vídeo

32
0:01:38.1,000 --> 0:01:4,000
por primera vez en su vida a los 65 años,

33
0:01:40.316,000 --> 0:01:44,000
y pidió a Vicky y a otras 99 personas mayores,

34
0:01:44.64,000 --> 0:01:47,000
víctimas de malos tratos, que contaran sus historias ante la cámara.

35
0:01:50.16,000 --> 0:01:51,000
Yo soy holandesa,

36
0:01:52.04,000 --> 0:01:54,000
y en Holanda estamos obsesionados con la verdad.

37
0:01:55.04,000 --> 0:01:57,000
Cuando eres un niño, eso es genial,

38
0:01:57.52,000 --> 0:01:59,000
porque siempre te acabas saliendo con la tuya,

39
0:02:00.16,000 --> 0:02:03,000
en plan "Sí, mamá, fui yo quien se fumó los puros".

40
0:02:03.48,000 --> 0:02:04,000
(Risas)

41
0:02:05.92,000 --> 0:02:08,000
Pero creo que es por esto que he dedicado mi vida a promover

42
0:02:09.92,000 --> 0:02:13,000
los vídeos de los ciudadanos que expongan la violación de los derechos humanos,

43
0:02:14.2,000 --> 0:02:18,000
porque creo en el poder del vídeo para mostrar verdades irrefutables.

44
0:02:19.4,000 --> 0:02:2,000
Y mi organización, "WITNESS",

45
0:02:21.12,000 --> 0:02:23,000
ayudó a usar los vídeos del Congo

46
0:02:23.88,000 --> 0:02:29,000
para ayudar a condenar y enviar a prisión al infame caudillo militar Thomas Lubanga.

47
0:02:31.44,000 --> 0:02:33,000
Y los vídeos que Mary grabó,

48
0:02:33.9,000 --> 0:02:36,000
nosotros enseñamos a Mary y a otros defensores de causas justas,

49
0:02:36.93,000 --> 0:02:38,000
a que se aseguraran de que las historias de maltrato a mayores

50
0:02:39.826,000 --> 0:02:4,000
lleguen a los legisladores,

51
0:02:41.4,000 --> 0:02:44,000
y estas historias ayudaron a convencer a los legisladores

52
0:02:45.28,000 --> 0:02:48,000
a aprobar leyes fundamentales que protegen a los mayores en EE. UU.

53
0:02:50.28,000 --> 0:02:51,000
Así que pienso,

54
0:02:52.24,000 --> 0:02:56,000
miles de millones de personas tienen esta herramienta tan potente en sus manos.

55
0:02:56.92,000 --> 0:02:57,000
Es una cámara.

56
0:02:58.44,000 --> 0:03:02,000
¿Por qué no somos un grupo de testigos locales más influyente,

57
0:03:03.28,000 --> 0:03:05,000
como Mary y Bukeni?

58
0:03:05.36,000 --> 0:03:07,000
¿Por qué este mayor número de vídeos

59
0:03:08.24,000 --> 0:03:11,000
no se traduce en más derechos y más justicia?

60
0:03:13,000 --> 0:03:17,000
Y creo que es porque ser testigo es duro.

61
0:03:17.56,000 --> 0:03:19,000
Dirán que su historia es mentira,

62
0:03:20.04,000 --> 0:03:22,000
su vídeo se perderá en un mar de imágenes,

63
0:03:22.92,000 --> 0:03:25,000
no creerán su historia e irán a por Ud.

64
0:03:27.92,000 --> 0:03:29,000
Y, ¿cómo ayudamos a los testigos?

65
0:03:31.56,000 --> 0:03:32,000
En Oaxaca, México,

66
0:03:33.28,000 --> 0:03:35,000
el Movimiento Magisterial organizó una manifestación

67
0:03:35.88,000 --> 0:03:38,000
después de que el presidente impusiera unas reformas muy poco democráticas.

68
0:03:40.16,000 --> 0:03:43,000
La Policía Federal acudió en autobuses y disparó a los manifestantes.

69
0:03:44.64,000 --> 0:03:47,000
Al menos siete personas murieron y muchos otros resultaron heridos.

70
0:03:48.28,000 --> 0:03:51,000
Las imágenes del tiroteo circularon

71
0:03:51.68,000 --> 0:03:53,000
y el Gobierno Mexicano hizo lo que siempre hace.

72
0:03:54.12,000 --> 0:03:55,000
Dio su versión de los hechos,

73
0:03:55.56,000 --> 0:03:58,000
acusando a los medios independientes

74
0:03:58.96,000 --> 0:04:,000
de crear noticias falsas.

75
0:04:01.04,000 --> 0:04:02,000
Dijeron: "Nosotros no estuvimos allí,

76
0:04:02.84,000 --> 0:04:04,000
no fuimos nosotros los que dispararon,

77
0:04:05.6,000 --> 0:04:06,000
eso nunca ocurrió".

78
0:04:08.76,000 --> 0:04:11,000
Pero nosotros acabábamos de enseñar a activistas en México

79
0:04:12,000 --> 0:04:15,000
a usar metadatos, de forma estratégica, con sus imágenes

80
0:04:15.8,000 --> 0:04:18,000
Los metadatos son la información que las cámaras almacenan

81
0:04:19.56,000 --> 0:04:22,000
mostrando la fecha, la localización,

82
0:04:22.6,000 --> 0:04:23,000
la temperatura, el tiempo...

83
0:04:24.36,000 --> 0:04:27,000
Pueden incluso mostrar la forma única de usar la cámara

84
0:04:27.8,000 --> 0:04:28,000
cuando graban algo.

85
0:04:29.56,000 --> 0:04:31,000
Así que las imágenes empezaron a circular,

86
0:04:31.68,000 --> 0:04:34,000
y esta vez con información

87
0:04:34.8,000 --> 0:04:36,000
totalmente confirmatoria.

88
0:04:37.96,000 --> 0:04:39,000
Y el Gobierno Federal tuvo que retractarse.

89
0:04:41.52,000 --> 0:04:44,000
La justicia aún está lejos

90
0:04:45.12,000 --> 0:04:46,000
para la gente de Oaxaca,

91
0:04:46.56,000 --> 0:04:49,000
pero sus historias, sus verdades, ya no se pueden seguir negando.

92
0:04:51.24,000 --> 0:04:52,000
Así que empezamos a pensar:

93
0:04:53.04,000 --> 0:04:54,000
¿Y si hubiera un "modo validación"?

94
0:04:54.76,000 --> 0:04:56,000
¿Y si todo el mundo tuviera una cámara

95
0:04:56.92,000 --> 0:04:59,000
y todas las plataformas tuvieran esa capacidad de validar información?

96
0:05:00.44,000 --> 0:05:01,000
Así que desarrollamos

97
0:05:01.72,000 --> 0:05:05,000
junto a unos desarrolladores de Android llamados "The Guardian Project",

98
0:05:06.2,000 --> 0:05:09,000
una tecnología llamada "Proof Mode",

99
0:05:09.52,000 --> 0:05:12,000
que empareja esos metadatos con las imágenes,

100
0:05:12.72,000 --> 0:05:14,000
y valida el vídeo de cada uno.

101
0:05:16.52,000 --> 0:05:2,000
Imaginen el aluvión de imágenes que vienen

102
0:05:20.56,000 --> 0:05:22,000
de las cámaras de móvil de todo el mundo.

103
0:05:23.64,000 --> 0:05:27,000
Imaginen que esa información fuera un poco más fiable,

104
0:05:28.52,000 --> 0:05:3,000
el potencial que tendría para los periodistas,

105
0:05:30.88,000 --> 0:05:31,000
para los investigadores y abogados

106
0:05:32.72,000 --> 0:05:33,000
pro derechos humanos.

107
0:05:35.44,000 --> 0:05:38,000
Así que empezamos a usar "Proof Mode" con nuestros compañeros en Brasil,

108
0:05:39.04,000 --> 0:05:42,000
un grupo de medios de comunicación que se llama "Coletivo Papo Reto".

109
0:05:44.28,000 --> 0:05:46,000
Brasil es un lugar duro con respecto a los derechos humanos.

110
0:05:47.68,000 --> 0:05:5,000
La Policía de Brasil cada año mata a miles de personas.

111
0:05:52.4,000 --> 0:05:54,000
La única vez que se investiga,

112
0:05:55.92,000 --> 0:05:56,000
¿adivinan cuándo es?

113
0:05:57.44,000 --> 0:05:58,000
Cuando hay un vídeo.

114
0:06:00.24,000 --> 0:06:03,000
Edouardo de 17 años fue asesinado a plena luz del día

115
0:06:04.64,000 --> 0:06:05,000
por la Policía de Río,

116
0:06:06.24,000 --> 0:06:08,000
y miren lo que pasó después de que lo asesinaran.

117
0:06:10.32,000 --> 0:06:12,000
Pusieron una pistola en la mano del chico,

118
0:06:12.88,000 --> 0:06:13,000
y la dispararon dos veces

119
0:06:15.84,000 --> 0:06:16,000
(Disparos)

120
0:06:17.6,000 --> 0:06:21,000
para hacer creer que le dispararon en defensa propia.

121
0:06:22.44,000 --> 0:06:25,000
La mujer que grabó esto fue una testigo muy valiente,

122
0:06:25.92,000 --> 0:06:28,000
y tuvo que esconderse tras publicar su vídeo

123
0:06:29.32,000 --> 0:06:3,000
porque temía por su vida.

124
0:06:31.24,000 --> 0:06:34,000
Pero la gente graba y no va a parar de grabar.

125
0:06:34.72,000 --> 0:06:37,000
Ahora estamos trabajando con grupos de medios de comunicación

126
0:06:37.76,000 --> 0:06:39,000
para que los habitantes reciban

127
0:06:40.28,000 --> 0:06:42,000
orientación y consejos vía WhatsApp

128
0:06:43.04,000 --> 0:06:44,000
sobre cómo grabar de forma segura,

129
0:06:44.8,000 --> 0:06:46,000
cómo subir un vídeo sin peligro,

130
0:06:47.76,000 --> 0:06:5,000
o cómo grabar una escena de forma que sea válida como prueba.

131
0:06:52.36,000 --> 0:06:54,000
Y aquí tenemos un caso inspirador,

132
0:06:54.496,000 --> 0:06:56,000
de un grupo llamado "Mídia NINJA" de Brasil.

133
0:06:58.43,000 --> 0:07:01,000
El hombre de la izquierda es un policía militar armado,

134
0:07:03.53,000 --> 0:07:04,000
que se acerca a un manifestante.

135
0:07:05.52,000 --> 0:07:08,000
Cuando protestas en Brasil, puedes acabar arrestado, o algo peor.

136
0:07:08.76,000 --> 0:07:1,000
El policía dice al manifestante:

137
0:07:11.36,000 --> 0:07:13,000
"Atención, te voy a cachear ahora mismo".

138
0:07:15.08,000 --> 0:07:18,000
El manifestante es un activista que retransmite en directo.

139
0:07:18.84,000 --> 0:07:19,000
Él lleva una pequeña cámara

140
0:07:20.32,000 --> 0:07:23,000
Y le dice al policía militar: "Te estoy viendo,

141
0:07:24.28,000 --> 0:07:27,000
y hay 5 mil personas que te están viendo conmigo".

142
0:07:28.4,000 --> 0:07:3,000
Las tornas han cambiado.

143
0:07:30.88,000 --> 0:07:33,000
Los testigos en la sombra, el público, importan.

144
0:07:35.24,000 --> 0:07:36,000
Así que empezamos a pensar

145
0:07:36.92,000 --> 0:07:38,000
¿Y si pudiéramos aprovechar ese poder,

146
0:07:39.52,000 --> 0:07:41,000
el poder de los testigos en la sombra?

147
0:07:41.72,000 --> 0:07:43,000
¿Y si pudiéramos usar su pericia, su posición de ventaja,

148
0:07:44.48,000 --> 0:07:46,000
su solidaridad, sus habilidades

149
0:07:46.64,000 --> 0:07:49,000
cuando una comunidad en el frente les necesita?

150
0:07:50.96,000 --> 0:07:55,000
Y empezamos a desarrollar un proyecto llamado "Mobilize Us".

151
0:07:56.32,000 --> 0:07:59,000
Porque entiendo que muchos de nosotros

152
0:07:59.56,000 --> 0:08:,000
queremos ayudar

153
0:08:01.24,000 --> 0:08:03,000
y ofrecer nuestras habilidades y nuestra experiencia,

154
0:08:03.88,000 --> 0:08:05,000
pero normalmente no estamos ahí cuando se agrede

155
0:08:06.76,000 --> 0:08:08,000
a una comunidad en el frente, o a un individuo.

156
0:08:10.76,000 --> 0:08:13,000
Y podría ser tan fácil con esta aplicación que hemos creado

157
0:08:14.44,000 --> 0:08:17,000
que muestra al autor de los hechos al otro lado del móvil.

158
0:08:17.52,000 --> 0:08:19,000
¿Cuánta gente le está viendo?

159
0:08:20.88,000 --> 0:08:24,000
Ahora, imaginen que pudieran añadir planificación informática de tareas

160
0:08:25.24,000 --> 0:08:26,000
a todo esto.

161
0:08:26.68,000 --> 0:08:3,000
Imaginen que son una comunidad ante una redada contra los inmigrantes,

162
0:08:31.52,000 --> 0:08:34,000
y que en ese mismo momento, lo retransmitís en directo.

163
0:08:35.28,000 --> 0:08:37,000
Estarían creando cientos de testigos.

164
0:08:38.4,000 --> 0:08:39,000
¿Cómo podría esto cambiar la situación?

165
0:08:41.32,000 --> 0:08:44,000
Así que empezamos con este programa piloto con nuestros compañeros en Brasil.

166
0:08:45.039,000 --> 0:08:47,000
Esta mujer se llama Camilla,

167
0:08:47.2,000 --> 0:08:5,000
es la líder de una favela llamada "Favela Skol"

168
0:08:51.919,000 --> 0:08:55,000
que fue capaz de atraer testigos,

169
0:08:56.08,000 --> 0:08:58,000
mediante una retransmisión en directo

170
0:08:58.16,000 --> 0:08:59,000
para ayudar con la traducción,

171
0:08:59.92,000 --> 0:09:,000
y con la distribución,

172
0:09:01.56,000 --> 0:09:03,000
para ayudar a compartir su historia

173
0:09:04.36,000 --> 0:09:06,000
después de que su comunidad fuera desahuciada

174
0:09:07.08,000 --> 0:09:1,000
para hacer sitio para un evento olímpico muy lustroso el verano pasado.

175
0:09:12.92,000 --> 0:09:14,000
Así que estamos hablando de testigos por una buena causa.

176
0:09:15.92,000 --> 0:09:18,000
¿Pero qué pasa si es el autor el que está grabando?

177
0:09:19.12,000 --> 0:09:22,000
¿Qué pasa si un transeúnte graba y no hace nada?

178
0:09:23.68,000 --> 0:09:25,000
Esta es la historia de Chrissy.

179
0:09:25.92,000 --> 0:09:27,000
Chrissy es una mujer transgénero

180
0:09:28.28,000 --> 0:09:3,000
que entró en un McDonald´s en Maryland

181
0:09:30.92,000 --> 0:09:31,000
para usar el baño de señoras.

182
0:09:32.96,000 --> 0:09:37,000
Dos adolescentes le pegaron brutalmente por usar el baño de señoras,

183
0:09:38.4,000 --> 0:09:41,000
y un empleado del MacDonald´s lo grabó con su teléfono móvil.

184
0:09:42.76,000 --> 0:09:43,000
Y subió el vídeo,

185
0:09:44.92,000 --> 0:09:45,000
que ha recibido

186
0:09:46.64,000 --> 0:09:49,000
miles de comentarios racistas y homofóbicos.

187
0:09:52.92,000 --> 0:09:54,000
Así que empezamos un proyecto llamado "Capturing Hate".

188
0:09:56.84,000 --> 0:09:59,000
Tomamos una muestra muy pequeña de vídeos de testigos

189
0:10:00.8,000 --> 0:10:05,000
que mostraban violencia contra transexuales y personas transgénero.

190
0:10:06.2,000 --> 0:10:1,000
Buscamos dos palabras: "pelea de travelos" y "pelea de bolleras".

191
0:10:11.24,000 --> 0:10:16,000
Y esos 329 videos alcanzaron la friolera

192
0:10:16.32,000 --> 0:10:18,000
de casi 90 millones de visualizaciones,

193
0:10:18.64,000 --> 0:10:21,000
y se siguen viendo ahora, mientras estamos en este teatro.

194
0:10:22.2,000 --> 0:10:25,000
Y esos vídeos reciben cientos de miles de comentarios,

195
0:10:25.44,000 --> 0:10:27,000
promoviendo más violencia y más odio.

196
0:10:30.24,000 --> 0:10:32,000
Así que desarrollamos una metodología

197
0:10:32.68,000 --> 0:10:36,000
que tomaba todas esas pruebas visuales no cuantificadas

198
0:10:37,000 --> 0:10:41,000
y las convirtió en datos, convirtiendo los vídeos en datos,

199
0:10:41.44,000 --> 0:10:42,000
y con esta herramienta,

200
0:10:42.72,000 --> 0:10:46,000
las asociaciones LGBT pueden usar esa información

201
0:10:47.16,000 --> 0:10:48,000
para luchar por sus derechos.

202
0:10:49.4,000 --> 0:10:52,000
Y tomamos esos datos y los llevamos a Silicon Valley,

203
0:10:52.64,000 --> 0:10:53,000
y les dijimos:

204
0:10:54.16,000 --> 0:10:55,000
"¿Cómo es posible

205
0:10:56.6,000 --> 0:10:59,000
que estos vídeos estén aún ahí

206
0:11:00.6,000 --> 0:11:01,000
en un clima de odio

207
0:11:02.52,000 --> 0:11:03,000
creando más odio,

208
0:11:04.4,000 --> 0:11:06,000
llamando a más violencia,

209
0:11:06.44,000 --> 0:11:08,000
cuando existen leyes que dicen:

210
0:11:08.88,000 --> 0:11:11,000
"Este tipo de contenido no está permitido"?

211
0:11:12.12,000 --> 0:11:14,000
Les pedimos que cambiaran su política.

212
0:11:16.48,000 --> 0:11:18,000
Así que tengo fe;

213
0:11:19.16,000 --> 0:11:23,000
fe en que podemos hacer que más vídeos signifiquen más derechos y más justicia.

214
0:11:24.36,000 --> 0:11:29,000
Diez mil millones de visualizaciones en Snapchat

215
0:11:30.76,000 --> 0:11:31,000
cada día.

216
0:11:32.32,000 --> 0:11:35,000
¿Y si pudiéramos convertir a esta generación de Snapchat

217
0:11:35.64,000 --> 0:11:38,000
en testigos efectivos y cívicos?

218
0:11:38.88,000 --> 0:11:41,000
¿Y si se pudieran convertir en los Bukenis de esta nueva generación?

219
0:11:44.92,000 --> 0:11:48,000
En la India las mujeres ya han empezado a usar filtros de Snapchat

220
0:11:48.96,000 --> 0:11:51,000
para proteger su identidad cuando hablan de violencia doméstica.

221
0:11:52.86,000 --> 0:11:54,000
[Me torturaban en casa y no me dejaban salir.

222
0:11:55.84,000 --> 0:11:58,000
La verdad, la auténtica verdad, que no es apropiada para una TED Talk,

223
0:11:59.44,000 --> 0:12:01,000
es que es duro luchar por los derechos humanos.

224
0:12:02.28,000 --> 0:12:05,000
No hay una solución fácil para la violación de los derechos humanos.

225
0:12:05.496,000 --> 0:12:07,000
Y no existe la tecnología

226
0:12:08.16,000 --> 0:12:09,000
que pueda detener a los autores.

227
0:12:11.4,000 --> 0:12:12,000
Pero por los supervivientes,

228
0:12:13.92,000 --> 0:12:14,000
por las víctimas,

229
0:12:15.56,000 --> 0:12:16,000
por las comunidades marginadas,

230
0:12:18.16,000 --> 0:12:22,000
sus historias, su verdad, importan.

231
0:12:22.64,000 --> 0:12:24,000
Y aquí es donde comienza la justicia.

232
0:12:25.48,000 --> 0:12:26,000
Gracias.

233
0:12:26.72,000 --> 0:12:28,000
(Aplausos)

